<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="description" content="Tutorials and short posts about programming, C++, Java, Assembly, Operating Systems Development, Compilers, ...">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Blog blog("Baptiste Wicht"); (old posts, page 32) | Blog blog("Baptiste Wicht");</title>
<link href="assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="alternate" type="application/rss+xml" title="RSS" hreflang="en" href="rss.xml">
<link rel="canonical" href="https://baptiste-wicht.com/index-32.html">
<link rel="prev" href="index-33.html" type="text/html">
<link rel="next" href="index-31.html" type="text/html">
<!--[if lt IE 9]><script src="assets/js/html5.js"></script><![endif]-->
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Menubar -->

<nav class="navbar navbar-inverse navbar-static-top"><div class="container">
<!-- This keeps the margins nice -->
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="https://baptiste-wicht.com/">

                <span id="blog-title">Blog blog("Baptiste Wicht");</span>
            </a>
        </div>
<!-- /.navbar-header -->
        <div class="collapse navbar-collapse" id="bs-navbar" aria-expanded="false">
            <ul class="nav navbar-nav">
<li>
<a href="stories/about.html">About</a>
                </li>
<li>
<a href="stories/publications.html">Publications</a>
                </li>
<li>
<a href="stories/projects.html">Projects</a>
                </li>
<li>
<a href="categories/index.html">Tags</a>
                </li>
<li>
<a href="archive.html">Archives</a>

                
            </li>
</ul>
<ul class="nav navbar-nav navbar-right"></ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        <div class="row">
            
            

    


    
<div class="postindex">
    <article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/2017/10/expression-templates-library-etl-1-2-complete-gpu-support.html" class="u-url">Expression Templates Library (ETL) 1.2 - Complete GPU support</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Baptiste Wicht
            </span></p>
            <p class="dateline">
            <a href="posts/2017/10/expression-templates-library-etl-1-2-complete-gpu-support.html" rel="bookmark">
            <time class="published dt-published" datetime="2017-10-02T10:49:02+02:00" itemprop="datePublished" title="2017-10-02 10:49">2017-10-02 10:49</time></a>
            </p>
                <p class="commentline">
    
    <a href="posts/2017/10/expression-templates-library-etl-1-2-complete-gpu-support.html#disqus_thread" data-disqus-identifier="cache/posts/2017/10/expression-templates-library-etl-1-2-complete-gpu-support.html">Comments</a>


        </p>
</div>
    </header><div class="p-summary entry-summary">
    <img alt="ETL Logo" class="align-center" src="images/logo.png"><p>I'm happy to announce the version 1.2 of my Expression Templates Library (ETL):
ETL 1.2, two months after <a class="reference external" href="https://baptiste-wicht.com/posts/2017/08/expression-templates-library-etl-11.html">I released the version 1.1</a>.
This version features much better GPU Support, a few new features and a lot of
changes in the internal code.</p>
<section id="gpu-support"><h2>GPU Support</h2>
<p>Before, only algorithms such as 4D convolution or matrix-matrix multiplication
were computed in the GPU and lots of operations were causing copies between CPU
and GPU version. Now, the support for basic operations has also been completed
and therefore, expressions like this:</p>
<div class="code"><pre class="code cpp"><a id="rest_code_0650e856844e49efac69281c6548ee93-1" name="rest_code_0650e856844e49efac69281c6548ee93-1" href="posts/2017/10/expression-templates-library-etl-1-2-complete-gpu-support.html#rest_code_0650e856844e49efac69281c6548ee93-1"></a><span class="n">C</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sigmoid</span><span class="p">(</span><span class="mf">2.0</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">A</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">B</span><span class="p">))</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">sum</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
</pre></div>
<p>Can be computed entirely on GPU.</p>
<p>Each matrix and vector containers have a secondary GPU memory space.  During the
execution, the status of both memory spaces is being managed and when necessary,
copies are made between two spaces. In the best case, there should only be
initial copies to the GPU and then everything should be done on the GPU. I've
also considered using Unified Memory in place of this system, but this is
a problem for fast matrix and I'd rather not have two different systems.</p>
<p>If you have an expression such as <code>c = a + b * 2</code>, it can be entirely computed
on GPU, however, it will be computed in two GPU operations such as:</p>
<div class="code"><pre class="code cpp"><a id="rest_code_614eb7f0527945c6854d1ca9222452ca-1" name="rest_code_614eb7f0527945c6854d1ca9222452ca-1" href="posts/2017/10/expression-templates-library-etl-1-2-complete-gpu-support.html#rest_code_614eb7f0527945c6854d1ca9222452ca-1"></a><span class="n">t1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">b</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">2</span>
<a id="rest_code_614eb7f0527945c6854d1ca9222452ca-2" name="rest_code_614eb7f0527945c6854d1ca9222452ca-2" href="posts/2017/10/expression-templates-library-etl-1-2-complete-gpu-support.html#rest_code_614eb7f0527945c6854d1ca9222452ca-2"></a><span class="n">c</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">t1</span>
</pre></div>
<p>This is not perfect in terms of performance but this will be done without any
copies between CPU and GPU memory. I plan to improve this system with a bit more
complex operations to avoid too many GPU operations, but there will always be
more operations than in CPU where this can easily be done in one go.</p>
<p>There are a few expressions that are not computable on the GPU, such as random
generations. A few transformations are also not fully compatible with GPU.
Moreover, if you access an element with operators <code>[]</code> or <code>()</code>, this
will invalidate the GPU memory and force an update to the CPU memory.</p>
<p>GPU operations are not implemented directly in ETL, there are coming from
various libraries. ETL is using NVIDIA CUDNN, CUFFT and CUDNN for most
algorithms. Moreover, for other operations, I've implemented a libraries with
simple GPU operations: ETL-GPU-BLAS (EGBLAS). You can have a look at
<a class="reference external" href="https://github.com/wichtounet/etl-gpu-blas">egblas</a> if you are interested.</p>
<p>My Deep Learning Library (DLL) project is based on ETL and its performances are
mostly dependent on ETL's performances. Now that ETL fully supports GPU, the
GPU performance of DLL is much improved. You may remember a few weeks ago
I posted <a class="reference external" href="https://baptiste-wicht.com/posts/2017/08/dll-blazing-fast-neural-network-library.html">very high CPU performance of DLL</a>.
Now, I've run again the tests to see the GPU performance with DLL. Here is the
performance for training a small CNN on the MNIST data set:</p>
<img alt="Performances for training a Convolutional Neural Network on MNIST" class="align-center" src="images/etl_12_dll_gpu_mnist.png"><p>As you can see, the performances on GPU are now excellent. DLL's performances
are on par with Tensorflow and Keras!</p>
<p>The next results are for training a much larger CNN on ImageNet, with the time
necessary to train a single batch:</p>
<img alt="Performances for training a Convolutional Neural Network on Imagenet" class="align-center" src="images/etl_12_dll_gpu_imagenet.png"><p>Again, using the new version of ETL inside DLL has led to excellent performance.
The framework is again on par with TensorFlow and Keras and faster than all the
other frameworks. The large difference between DLL and Tensorflow and Keras is
due to the inefficiency of reading the dataset in the two frameworks, so the
performance of the three framework themselves are about the same.</p>
</section><section id="other-changes"><h2>Other Changes</h2>
<p>The library also has a few other new features. Logarithms of base 2 and base 10
are now supported in complement to the base e that was already available before.
Categorical Cross Entropy (CCE) computation is also available now, the CCE loss
and error can be computed for one or many samples. Convolutions have also been
improved in that you can use mixed types in both the image and the kernel and
different storage order as well. Nevertheless, the most optimized version
remains the version with the same storage order and the same data type.</p>
<p>I've also made a major change in the way implementations are selected for each
operation. The tests and the benchmark are using a system to force the selection
of an algorithm. This system is now disabled by default. This makes the
compilation much faster by default. Since it's not necessary in most cases, this
will help regular use cases of the library by compiling much faster.</p>
<p>Overall, the support for complex numbers has been improved in ETL. There are
more routines that are supported and <code>etl::complex</code> is better supported
throughout the code. I'll still work on this in the future to make it totally
complete.</p>
<p>The internal code also has a few new changes. First, all traits have been
rewritten to use variable templates instead of struct traits. This makes the
code much nicer in my opinion. Moreover, I've started experimenting with C++17
<code>if constexpr</code>. Most of the if conditions that can be transformed to if
constexpr have been annotated with comments that I can quickly enable or disable
so that I can test the impact of C++17, especially on compilation time.</p>
<p>Finally, a few bugs have been fixed. ETL is now working better with parallel
BLAS library. There should not be issues with double parallelization in ETL and
BLAS. There was a slight bug in the Column-Major matrix-matrix multiplication
kernel. Binary operations with different types in the left and right hand sides
was also problematic with vectorization. The last bug was about GPU status in
case ETL containers were moved.</p>
</section><section id="what-s-next"><h2>What's next ?</h2>
<p>I don't yet know exactly on which features I'm going to focus for the next
version of ETL. I plan to focus a bit more in the near future on Deep Learning
Library (DLL) for which I should release the version 1.0 soon. I also plan to
start support for Recurrent Neural Networks on it, so that will take me quite
some time.</p>
<p>Nevertheless, I'm still planning to consider the switch to C++17, since it is
<a class="reference external" href="https://baptiste-wicht.com/posts/2017/09/how-i-made-deep-learning-library-38-faster-to-compile-optimization-and-cpp17-if-constexpr.html">a bit faster to compile ETL with if constexpr</a>. The next version of ETL will also probably have GPU-support for
integers, at least in the cases that depend on the etl-gpu-blas library, which
is the standard operators. I also plan to improve the support for complex
numbers, especially in terms of performance and tests. Hopefully, I will have also time (and motivation)
to start working on  the sparse capabilities of ETL. It really needs much more
unit tests and the performance should be improved as well.</p>
</section><section id="download-etl"><h2>Download ETL</h2>
<p>You can download ETL <a class="reference external" href="https://github.com/wichtounet/etl">on Github</a>. If you
only interested in the 1.2 version, you can look at the
<a class="reference external" href="https://github.com/wichtounet/etl/releases">Releases pages</a> or clone the tag
1.2. There are several branches:</p>
<ul class="simple">
<li><p><em>master</em> Is the eternal development branch, may not always be stable</p></li>
<li><p><em>stable</em> Is a branch always pointing to the last tag, no development here</p></li>
</ul>
<p>For the future release, there always will tags pointing to the corresponding
commits. You can also have access to previous releases on Github or via the
release tags.</p>
<p>The documentation is still a bit sparse. There are a few examples and the Wiki,
but there still is work to be done. If you have questions on how to use or
configure the library, please don't hesitate.</p>
<p>Don't hesitate to comment this post if you have any comment on this library or
any question. You can also open an Issue on Github if you have a problem using
this library or propose a Pull Request if you have any contribution you'd like
to make to the library.</p>
<p>Hope this may be useful to some of you :)</p>
</section>
</div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/2017/09/cpp11-performance-tip-update-when-to-use-std-pow.html" class="u-url">C++11 Performance tip: Update on when to use std::pow ?</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Baptiste Wicht
            </span></p>
            <p class="dateline">
            <a href="posts/2017/09/cpp11-performance-tip-update-when-to-use-std-pow.html" rel="bookmark">
            <time class="published dt-published" datetime="2017-09-22T11:21:07+02:00" itemprop="datePublished" title="2017-09-22 11:21">2017-09-22 11:21</time></a>
            </p>
                <p class="commentline">
    
    <a href="posts/2017/09/cpp11-performance-tip-update-when-to-use-std-pow.html#disqus_thread" data-disqus-identifier="cache/posts/2017/09/cpp11-performance-tip-update-when-to-use-std-pow.html">Comments</a>


        </p>
</div>
    </header><div class="p-summary entry-summary">
    <p>A few days ago, I published a post comparing the
<a class="reference external" href="https://baptiste-wicht.com/posts/2017/09/cpp11-performance-tip-when-to-use-std-pow.html">performance of std::pow against direct multiplications</a>. When not compiling with -ffast-math, direct multiplication was significantly faster than <code>std::pow</code>, around two orders of magnitude faster when comparing <code>x * x * x</code> and <code>code:std::pow(x, 3)</code>.
One comment that I've got was to test for which <code>n</code> is
<code>code:std::pow(x, n)</code> becoming faster than multiplying in a loop. Since
std::pow is using a special algorithm to perform the computation rather than be
simply loop-based multiplications, there may be a point after which it's more interesting to use the
algorithm rather than a loop. So I decided to do the tests. You can also find
the result in the original article, which I've updated.</p>
<p>First, our pow function:</p>
<div class="code"><pre class="code c++"><a id="rest_code_45ba3bca64344b3b8d8eb7f75d6c4f35-1" name="rest_code_45ba3bca64344b3b8d8eb7f75d6c4f35-1" href="posts/2017/09/cpp11-performance-tip-update-when-to-use-std-pow.html#rest_code_45ba3bca64344b3b8d8eb7f75d6c4f35-1"></a><span class="kt">double</span><span class="w"> </span><span class="nf">my_pow</span><span class="p">(</span><span class="kt">double</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="kt">size_t</span><span class="w"> </span><span class="n">n</span><span class="p">){</span>
<a id="rest_code_45ba3bca64344b3b8d8eb7f75d6c4f35-2" name="rest_code_45ba3bca64344b3b8d8eb7f75d6c4f35-2" href="posts/2017/09/cpp11-performance-tip-update-when-to-use-std-pow.html#rest_code_45ba3bca64344b3b8d8eb7f75d6c4f35-2"></a><span class="w">    </span><span class="kt">double</span><span class="w"> </span><span class="n">r</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1.0</span><span class="p">;</span>
<a id="rest_code_45ba3bca64344b3b8d8eb7f75d6c4f35-3" name="rest_code_45ba3bca64344b3b8d8eb7f75d6c4f35-3" href="posts/2017/09/cpp11-performance-tip-update-when-to-use-std-pow.html#rest_code_45ba3bca64344b3b8d8eb7f75d6c4f35-3"></a>
<a id="rest_code_45ba3bca64344b3b8d8eb7f75d6c4f35-4" name="rest_code_45ba3bca64344b3b8d8eb7f75d6c4f35-4" href="posts/2017/09/cpp11-performance-tip-update-when-to-use-std-pow.html#rest_code_45ba3bca64344b3b8d8eb7f75d6c4f35-4"></a><span class="w">    </span><span class="k">while</span><span class="p">(</span><span class="n">n</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">0</span><span class="p">){</span>
<a id="rest_code_45ba3bca64344b3b8d8eb7f75d6c4f35-5" name="rest_code_45ba3bca64344b3b8d8eb7f75d6c4f35-5" href="posts/2017/09/cpp11-performance-tip-update-when-to-use-std-pow.html#rest_code_45ba3bca64344b3b8d8eb7f75d6c4f35-5"></a><span class="w">        </span><span class="n">r</span><span class="w"> </span><span class="o">*=</span><span class="w"> </span><span class="n">x</span><span class="p">;</span>
<a id="rest_code_45ba3bca64344b3b8d8eb7f75d6c4f35-6" name="rest_code_45ba3bca64344b3b8d8eb7f75d6c4f35-6" href="posts/2017/09/cpp11-performance-tip-update-when-to-use-std-pow.html#rest_code_45ba3bca64344b3b8d8eb7f75d6c4f35-6"></a><span class="w">        </span><span class="o">--</span><span class="n">n</span><span class="p">;</span>
<a id="rest_code_45ba3bca64344b3b8d8eb7f75d6c4f35-7" name="rest_code_45ba3bca64344b3b8d8eb7f75d6c4f35-7" href="posts/2017/09/cpp11-performance-tip-update-when-to-use-std-pow.html#rest_code_45ba3bca64344b3b8d8eb7f75d6c4f35-7"></a><span class="w">    </span><span class="p">}</span>
<a id="rest_code_45ba3bca64344b3b8d8eb7f75d6c4f35-8" name="rest_code_45ba3bca64344b3b8d8eb7f75d6c4f35-8" href="posts/2017/09/cpp11-performance-tip-update-when-to-use-std-pow.html#rest_code_45ba3bca64344b3b8d8eb7f75d6c4f35-8"></a>
<a id="rest_code_45ba3bca64344b3b8d8eb7f75d6c4f35-9" name="rest_code_45ba3bca64344b3b8d8eb7f75d6c4f35-9" href="posts/2017/09/cpp11-performance-tip-update-when-to-use-std-pow.html#rest_code_45ba3bca64344b3b8d8eb7f75d6c4f35-9"></a><span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">r</span><span class="p">;</span>
<a id="rest_code_45ba3bca64344b3b8d8eb7f75d6c4f35-10" name="rest_code_45ba3bca64344b3b8d8eb7f75d6c4f35-10" href="posts/2017/09/cpp11-performance-tip-update-when-to-use-std-pow.html#rest_code_45ba3bca64344b3b8d8eb7f75d6c4f35-10"></a><span class="p">}</span>
</pre></div>
<p>And now, let's see the performance. I've compiled my benchmark with GCC 4.9.3
and running on my old Sandy Bridge processor. Here are the results for 1000
calls to each functions:</p>
<div id="graph_std_pow_my_pow_1" style="width: 700px; height: 400px;"></div>
<p>We can see that between <code>n=100</code> and <code>n=110</code>, <code>std::pow(x, n)</code>
starts to be faster than <code>my_pow(x, n)</code>. At this point, you should only
use <code>std::pow(x, n)</code>.  Interestingly too, the time for <code>std::pow(x,
n)</code> is decreasing. Let's see how is the performance with higher range of
<code>n</code>:</p>
<div id="graph_std_pow_my_pow_2" style="width: 700px; height: 400px;"></div>
<p>We can see that the pow function time still remains stable while our loop-based
pow function still increases linearly. At <code>n=1000</code>, <code>std::pow</code> is
one order of magnitude faster than <code>my_pow</code>.</p>
<p>Overall, if you do not care much about extreme accuracy, you may consider using
you own pow function for small-ish (integer) <code>n</code> values. After
<code>n=100</code>, it becomes more interesting to use <code>std::pow</code>.</p>
<p>If you want more results on the subject, you take a look at the
<a class="reference external" href="https://baptiste-wicht.com/posts/2017/09/cpp11-performance-tip-when-to-use-std-pow.html">original article</a>.</p>
<p>If you are interested in the code of this benchmark, it's available online:
<a class="reference external" href="https://github.com/wichtounet/articles/blob/master/src/bench_pow_my_pow.cpp">bench_pow_my_pow.cpp</a></p>
<script type="text/javascript" src="https://www.google.com/jsapi"></script><script type="text/javascript">google.load('visualization', '1.0', {'packages':['corechart']});</script><script type="text/javascript">
function draw_graph_pow_my_pow_1(){
var data = google.visualization.arrayToDataTable([
['n', 'my_pow(x, n)', 'std::pow(x, n)'],
['10',   2,     127],
['20',   17,     123],
['30',   26,     127],
['40',   36,     123],
['50',   43,     123],
['60',   55,     123],
['70',   72,     123],
['80',   85,     123],
['90',   102,    126],
['100',  114,    125],
['110',  131,    115],
['120',  144,    111],
['130',  165,    111],
['140',  173,    108],
['150',  189,    107],
['160',  202,    112],
['170',  219,    106],
['180',  232,    105],
['190',  249,    108],
['200',  261,    105],
]);
var graph = new google.visualization.LineChart(document.getElementById('graph_std_pow_my_pow_1'));
var options = {curveType: "function",title: "std::pow(x, 2) (float)",animation: {duration:1200, easing:"in"},width: 700, height: 400,hAxis: {title:"Number of elements", slantedText:true},vAxis: {viewWindow: {min:0}, title:"us"}};
graph.draw(data, options);
}
function draw_graph_pow_my_pow_2(){
var data = google.visualization.arrayToDataTable([
['n', 'my_pow(x, n)', 'std::pow(x, n)'],
['100',  114,    125],
['200',  261,    105],
['300',  410,    104],
['400',  558,    104],
['500',  708,    104],
['600',  855,    104],
['700',  1002,   104],
['800',  1148,   104],
['900',  1300,   104],
['1000', 1442,   104],
]);
var graph = new google.visualization.LineChart(document.getElementById('graph_std_pow_my_pow_2'));
var options = {curveType: "function",title: "std::pow(x, 2) (float)",animation: {duration:1200, easing:"in"},width: 700, height: 400,hAxis: {title:"Number of elements", slantedText:true},vAxis: {viewWindow: {min:0}, title:"us"}};
graph.draw(data, options);
}
function draw_all(){
draw_graph_pow_my_pow_1();
draw_graph_pow_my_pow_2();
}
google.setOnLoadCallback(draw_all);
</script>
</div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/2017/09/how-i-made-deep-learning-library-38-faster-to-compile-optimization-and-cpp17-if-constexpr.html" class="u-url">How I made my Deep Learning Library 38% faster to compile (Optimization and C++17 if constexpr)</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Baptiste Wicht
            </span></p>
            <p class="dateline">
            <a href="posts/2017/09/how-i-made-deep-learning-library-38-faster-to-compile-optimization-and-cpp17-if-constexpr.html" rel="bookmark">
            <time class="published dt-published" datetime="2017-09-21T19:44:34+02:00" itemprop="datePublished" title="2017-09-21 19:44">2017-09-21 19:44</time></a>
            </p>
                <p class="commentline">
    
    <a href="posts/2017/09/how-i-made-deep-learning-library-38-faster-to-compile-optimization-and-cpp17-if-constexpr.html#disqus_thread" data-disqus-identifier="cache/posts/2017/09/how-i-made-deep-learning-library-38-faster-to-compile-optimization-and-cpp17-if-constexpr.html">Comments</a>


        </p>
</div>
    </header><div class="p-summary entry-summary">
    <div>
<p>My Deep Learning Library (DLL) project is a C++ library for training and using
artificial neural networks (you can take a look at
<a class="reference external" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html">this post about DLL</a>
if you want more information).</p>
<p>While I made a lot of effort to make it as fast as possible to train and run
neural networks, the compilation time has been steadily going up and is becoming
quite annoying. This library is heavily templated and all the matrix operations
are done using my Expression Templates Library (ETL) which is more than
template-heavy itself.</p>
<p>In this post, I'll present two techniques with which I've been able to reduce
the total compilation of the DLL unit tests by up to 38%.</p>
<p class="more"><a href="posts/2017/09/how-i-made-deep-learning-library-38-faster-to-compile-optimization-and-cpp17-if-constexpr.html">Read more…</a></p>
</div>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/2017/09/cpp11-performance-tip-when-to-use-std-pow.html" class="u-url">C++11 Performance tip: When to use std::pow ?</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Baptiste Wicht
            </span></p>
            <p class="dateline">
            <a href="posts/2017/09/cpp11-performance-tip-when-to-use-std-pow.html" rel="bookmark">
            <time class="published dt-published" datetime="2017-09-18T07:50:44+02:00" itemprop="datePublished" title="2017-09-18 07:50">2017-09-18 07:50</time></a>
            </p>
                <p class="commentline">
    
    <a href="posts/2017/09/cpp11-performance-tip-when-to-use-std-pow.html#disqus_thread" data-disqus-identifier="cache/posts/2017/09/cpp11-performance-tip-when-to-use-std-pow.html">Comments</a>


        </p>
</div>
    </header><div class="p-summary entry-summary">
    <div>
<p>Update: I've added a new section for larger values of <code>n</code>.</p>
<p>Recently, I've been wondering about the performance of <code>std::pow(x, n)</code>.
I'm talking here about the case when <code>n</code> is an integer. In the case when
<code>n</code> is not an integer, I believe, you should always use <code>std::pow</code>
or use another specialized library.</p>
<p>In case when n is an integer, you can actually replace it with the direct
equivalent (for instance <code>std::pow(x, 3) = x * x x</code>). If n is very large,
you'd rather write a loop of course ;) In practice, we generally use powers of
two and three much more often than power of 29, although that could happen. Of
course, it especially make sense to wonder about this if the pow is used inside
a loop. If you only use it once outside a loop, that won't be any difference on
the overall performance.</p>
<p>Since I'm mostly interested in single precision performance (neural networks are
only about single precision), the first benchmarks will be using <code>float</code>.</p>
<p class="more"><a href="posts/2017/09/cpp11-performance-tip-when-to-use-std-pow.html">Read more…</a></p>
</div>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/2017/09/budgetwarrior-042-budget-summary-improved-fortune-reports.html" class="u-url">budgetwarrior 0.4.2 - Budget summary and improved fortune reports</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Baptiste Wicht
            </span></p>
            <p class="dateline">
            <a href="posts/2017/09/budgetwarrior-042-budget-summary-improved-fortune-reports.html" rel="bookmark">
            <time class="published dt-published" datetime="2017-09-14T20:42:39+02:00" itemprop="datePublished" title="2017-09-14 20:42">2017-09-14 20:42</time></a>
            </p>
                <p class="commentline">
    
    <a href="posts/2017/09/budgetwarrior-042-budget-summary-improved-fortune-reports.html#disqus_thread" data-disqus-identifier="cache/posts/2017/09/budgetwarrior-042-budget-summary-improved-fortune-reports.html">Comments</a>


        </p>
</div>
    </header><div class="p-summary entry-summary">
    <p>Almost three years ago, <a class="reference external" href="https://baptiste-wicht.com/posts/2014/09/budgetwarrior-041-expense-templates-and-year-projection.html">I published the version 0.4.1 of budgetwarrior</a>. Since then, I've been using this tool almost every day to manage my personal budget. This is the only tool I use to keep track of my expenses and earnings and it makes a great tool for me. I recently felt that it was missing a few features and added them and polished a few things as well and release a new version with all the new stuff. This new version is probably nothing fancy, but a nice upgrade of the tool.</p>
<p>Don't pay too much attention to the values in the images since I've randomized
all the data for the purpose of this post (new feature, by the way :P).</p>
<section id="new-summary-view"><h2>New summary view</h2>
<p>I've added a new report with <code>budget summary</code>:</p>
<img alt="/images/budgetwarrior_042_summary.png" src="images/budgetwarrior_042_summary.png"><p>This view gives concise information about the current state of your accounts. It
also gives information about your yearly and monthly objectives. Finally, it
also gives information about the last two fortune values that you've set.
I think this make a great kind of dashboard to view most of the information. If
your terminal is large enough, the three parts will be shown side by side.</p>
</section><section id="improved-fortune-report"><h2>Improved fortune report</h2>
<p>I've made a few improvements to the <code>budget fortune</code> view:</p>
<img alt="/images/budgetwarrior_042_fortune.png" src="images/budgetwarrior_042_fortune.png"><p>It now display the time between the different fortune values and it compute the
average savings (or avg losses) per day in each interval and in average from the
beginning of the first value.</p>
</section><section id="various-changes"><h2>Various changes</h2>
<p>The balance does not propagate over the years anymore. This should mainly change
the behaviour of <code>budget overview</code>. I don't think it was very
smart to propagate it all the time. The balance now starts at zero for each
year. If you want the old system, you can use the multi_year_balance=true option
in the .budgetrc configuration file.</p>
<p>The recurring expenses do not use an internal configuration value. This does not
change anything for the behaviour, but means that if you sync between different
machines, it will avoid a lot of possible conflicts :)</p>
<p>Fixed a few bugs with inconsistency between the different views and reports.
Another bug that was fixed is that <code>budget report</code> was not always displaying the
first month of the year correctly, this is now fixed.</p>
<p>The graphs display in <code>budget report</code> are now automatically adapted to width of
your terminal. Finally, the <code>budget overview</code> command also displays more
information about the comparison with the previous month.</p>
</section><section id="installation"><h2>Installation</h2>
<p>If you are on Gentoo, you can install it using layman:</p>
<pre class="literal-block">layman -a wichtounet
emerge -a budgetwarrior</pre>
<p>If you are on Arch Linux, you can use this <a class="reference external" href="https://github.com/StreakyCobra/aur-budgetwarrior">AUR repository</a>.</p>
<p>For other systems, you'll have to install from sources:</p>
<pre class="literal-block">git clone --recursive git://github.com/wichtounet/budgetwarrior.git
cd budgetwarrior
make
sudo make install</pre>
</section><section id="conclusion-3"><h2>Conclusion</h2>
<p>A brief tutorial is available on Github: <a class="reference external" href="https://github.com/wichtounet/budgetwarrior/wiki/Start-tutorial">Starting guide</a>.</p>
<p>If you are interested by the sources, you can download them on Github:
<a class="reference external" href="https://github.com/wichtounet/budgetwarrior">budgetwarrior</a>.</p>
<p>If you have any suggestion for a new feature or an improvement to the tool or
you found a bug, please post an issue on Github, I'd be glad to help you. You
can post a comment directly on this post :)</p>
<p>If you have any other comment, don't hesitate to contact me, either by letting a
comment on this post or by email.</p>
<p>I hope that this application can be useful to some of you command-line adepts :)</p>
</section>
</div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/2017/09/cpp11-concurrency-tutorial-futures.html" class="u-url">C++11 Concurrency Tutorial - Part 5: Futures</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Baptiste Wicht
            </span></p>
            <p class="dateline">
            <a href="posts/2017/09/cpp11-concurrency-tutorial-futures.html" rel="bookmark">
            <time class="published dt-published" datetime="2017-09-12T15:05:08+02:00" itemprop="datePublished" title="2017-09-12 15:05">2017-09-12 15:05</time></a>
            </p>
                <p class="commentline">
    
    <a href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#disqus_thread" data-disqus-identifier="cache/posts/2017/09/cpp11-concurrency-tutorial-futures.html">Comments</a>


        </p>
</div>
    </header><div class="p-summary entry-summary">
    <p>I've been recently reminded that a long time ago I was doing a series of
tutorial on C++11 Concurrency. For some reason, I haven't continued these
tutorials.  The next post in the series was supposed to be about Futures, so I'm
finally going to do it :)</p>
<p>Here are the links to the current posts of the C++11 Concurrency Tutorial:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://baptiste-wicht.com/posts/2012/03/cpp11-concurrency-part1-start-threads.html">Part 1: Start Threads</a></p></li>
<li><p><a class="reference external" href="https://baptiste-wicht.com/posts/2012/03/cp11-concurrency-tutorial-part-2-protect-shared-data.html">Part 2: Protect Shared Data</a></p></li>
<li><p><a class="reference external" href="https://baptiste-wicht.com/posts/2012/04/c11-concurrency-tutorial-advanced-locking-and-condition-variables.html">Part 3: Advanced Locking and condition variables</a></p></li>
<li><p><a class="reference external" href="https://baptiste-wicht.com/posts/2012/07/c11-concurrency-tutorial-part-4-atomic-type.html">Part 4: Atomic Types</a></p></li>
</ul>
<p>In this post, we are going to talk about futures, more precisely
<code>std::future&lt;T&gt;</code>. What is a future ? It's a very nice and simple mechanism
to work with asynchronous tasks. It also has the advantage of decoupling you
from the threads themselves, you can do multithreading without using
<code>std::thread</code>. The future itself is a structure pointing to a result that
will be computed in the future. How to create a future ? The simplest way is to
use <code>std::async</code> that will create an asynchronous task and return
a <code>std::future</code>.</p>
<p>Let's start with the simplest of the examples:</p>
<div class="code"><pre class="code c++"><a id="rest_code_09747c1a64764a29815371cafca974db-1" name="rest_code_09747c1a64764a29815371cafca974db-1" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_09747c1a64764a29815371cafca974db-1"></a><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;thread&gt;</span>
<a id="rest_code_09747c1a64764a29815371cafca974db-2" name="rest_code_09747c1a64764a29815371cafca974db-2" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_09747c1a64764a29815371cafca974db-2"></a><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;future&gt;</span>
<a id="rest_code_09747c1a64764a29815371cafca974db-3" name="rest_code_09747c1a64764a29815371cafca974db-3" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_09747c1a64764a29815371cafca974db-3"></a><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;iostream&gt;</span>
<a id="rest_code_09747c1a64764a29815371cafca974db-4" name="rest_code_09747c1a64764a29815371cafca974db-4" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_09747c1a64764a29815371cafca974db-4"></a>
<a id="rest_code_09747c1a64764a29815371cafca974db-5" name="rest_code_09747c1a64764a29815371cafca974db-5" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_09747c1a64764a29815371cafca974db-5"></a><span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">(){</span>
<a id="rest_code_09747c1a64764a29815371cafca974db-6" name="rest_code_09747c1a64764a29815371cafca974db-6" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_09747c1a64764a29815371cafca974db-6"></a><span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">future</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">async</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">launch</span><span class="o">::</span><span class="n">async</span><span class="p">,</span><span class="w"> </span><span class="p">[](){</span>
<a id="rest_code_09747c1a64764a29815371cafca974db-7" name="rest_code_09747c1a64764a29815371cafca974db-7" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_09747c1a64764a29815371cafca974db-7"></a><span class="w">        </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">"I'm a thread"</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<a id="rest_code_09747c1a64764a29815371cafca974db-8" name="rest_code_09747c1a64764a29815371cafca974db-8" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_09747c1a64764a29815371cafca974db-8"></a><span class="w">    </span><span class="p">});</span>
<a id="rest_code_09747c1a64764a29815371cafca974db-9" name="rest_code_09747c1a64764a29815371cafca974db-9" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_09747c1a64764a29815371cafca974db-9"></a>
<a id="rest_code_09747c1a64764a29815371cafca974db-10" name="rest_code_09747c1a64764a29815371cafca974db-10" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_09747c1a64764a29815371cafca974db-10"></a><span class="w">    </span><span class="n">future</span><span class="p">.</span><span class="n">get</span><span class="p">();</span>
<a id="rest_code_09747c1a64764a29815371cafca974db-11" name="rest_code_09747c1a64764a29815371cafca974db-11" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_09747c1a64764a29815371cafca974db-11"></a>
<a id="rest_code_09747c1a64764a29815371cafca974db-12" name="rest_code_09747c1a64764a29815371cafca974db-12" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_09747c1a64764a29815371cafca974db-12"></a><span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<a id="rest_code_09747c1a64764a29815371cafca974db-13" name="rest_code_09747c1a64764a29815371cafca974db-13" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_09747c1a64764a29815371cafca974db-13"></a><span class="p">}</span>
</pre></div>
<p>Nothing really special here. <code>std::async</code> will execute the task that we
give it (here a lambda) and return a <code>std::future</code>. Once you use the
<code>get()</code> function on a future, it will wait until the result is available
and return this result to you once it is. The <code>get()</code> function is then
blocking. Since the lambda, is a void lambda, the returned future is of type
<code>std::future&lt;void&gt;</code> and <code>get()</code> returns <code>void</code> as well. It is
very important to know that you cannot call <code>get</code> several times on the
same future. Once the result is consumed, you cannot consume it again! If you
want to use the result several times, you need to store it yourself after you
called <code>get()</code>.</p>
<p>Let's see with something that returns a value and actually takes some time
before returning it:</p>
<div class="code"><pre class="code c++"><a id="rest_code_acc71594ab49426896b458fd29f85dbd-1" name="rest_code_acc71594ab49426896b458fd29f85dbd-1" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_acc71594ab49426896b458fd29f85dbd-1"></a><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;thread&gt;</span>
<a id="rest_code_acc71594ab49426896b458fd29f85dbd-2" name="rest_code_acc71594ab49426896b458fd29f85dbd-2" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_acc71594ab49426896b458fd29f85dbd-2"></a><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;future&gt;</span>
<a id="rest_code_acc71594ab49426896b458fd29f85dbd-3" name="rest_code_acc71594ab49426896b458fd29f85dbd-3" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_acc71594ab49426896b458fd29f85dbd-3"></a><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;iostream&gt;</span>
<a id="rest_code_acc71594ab49426896b458fd29f85dbd-4" name="rest_code_acc71594ab49426896b458fd29f85dbd-4" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_acc71594ab49426896b458fd29f85dbd-4"></a><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;chrono&gt;</span>
<a id="rest_code_acc71594ab49426896b458fd29f85dbd-5" name="rest_code_acc71594ab49426896b458fd29f85dbd-5" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_acc71594ab49426896b458fd29f85dbd-5"></a>
<a id="rest_code_acc71594ab49426896b458fd29f85dbd-6" name="rest_code_acc71594ab49426896b458fd29f85dbd-6" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_acc71594ab49426896b458fd29f85dbd-6"></a><span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">(){</span>
<a id="rest_code_acc71594ab49426896b458fd29f85dbd-7" name="rest_code_acc71594ab49426896b458fd29f85dbd-7" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_acc71594ab49426896b458fd29f85dbd-7"></a><span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">future</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">async</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">launch</span><span class="o">::</span><span class="n">async</span><span class="p">,</span><span class="w"> </span><span class="p">[](){</span>
<a id="rest_code_acc71594ab49426896b458fd29f85dbd-8" name="rest_code_acc71594ab49426896b458fd29f85dbd-8" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_acc71594ab49426896b458fd29f85dbd-8"></a><span class="w">        </span><span class="n">std</span><span class="o">::</span><span class="n">this_thread</span><span class="o">::</span><span class="n">sleep_for</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">seconds</span><span class="p">(</span><span class="mi">5</span><span class="p">));</span>
<a id="rest_code_acc71594ab49426896b458fd29f85dbd-9" name="rest_code_acc71594ab49426896b458fd29f85dbd-9" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_acc71594ab49426896b458fd29f85dbd-9"></a><span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="mi">42</span><span class="p">;</span>
<a id="rest_code_acc71594ab49426896b458fd29f85dbd-10" name="rest_code_acc71594ab49426896b458fd29f85dbd-10" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_acc71594ab49426896b458fd29f85dbd-10"></a><span class="w">    </span><span class="p">});</span>
<a id="rest_code_acc71594ab49426896b458fd29f85dbd-11" name="rest_code_acc71594ab49426896b458fd29f85dbd-11" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_acc71594ab49426896b458fd29f85dbd-11"></a>
<a id="rest_code_acc71594ab49426896b458fd29f85dbd-12" name="rest_code_acc71594ab49426896b458fd29f85dbd-12" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_acc71594ab49426896b458fd29f85dbd-12"></a><span class="w">    </span><span class="c1">// Do something else ?</span>
<a id="rest_code_acc71594ab49426896b458fd29f85dbd-13" name="rest_code_acc71594ab49426896b458fd29f85dbd-13" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_acc71594ab49426896b458fd29f85dbd-13"></a>
<a id="rest_code_acc71594ab49426896b458fd29f85dbd-14" name="rest_code_acc71594ab49426896b458fd29f85dbd-14" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_acc71594ab49426896b458fd29f85dbd-14"></a><span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">future</span><span class="p">.</span><span class="n">get</span><span class="p">()</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<a id="rest_code_acc71594ab49426896b458fd29f85dbd-15" name="rest_code_acc71594ab49426896b458fd29f85dbd-15" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_acc71594ab49426896b458fd29f85dbd-15"></a>
<a id="rest_code_acc71594ab49426896b458fd29f85dbd-16" name="rest_code_acc71594ab49426896b458fd29f85dbd-16" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_acc71594ab49426896b458fd29f85dbd-16"></a><span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<a id="rest_code_acc71594ab49426896b458fd29f85dbd-17" name="rest_code_acc71594ab49426896b458fd29f85dbd-17" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_acc71594ab49426896b458fd29f85dbd-17"></a><span class="p">}</span>
</pre></div>
<p>This time, the future will be of the time <code>std::future&lt;int&gt;</code> and thus
<code>get()</code> will also return an <code>int</code>. <code>std::async</code> will again
launch a task in an asynchronous way and <code>future.get()</code> will wait for the
answer. What is interesting, is that you can do something else before the call
to future.</p>
<p>But <code>get()</code> is not the only interesting function in <code>std::future</code>.
You also have <code>wait()</code> which is almost the same as <code>get()</code> but does
not consume the result. For instance, you can wait for several futures and then
consume their result together. But, more interesting are the
<code>wait_for(duration)</code> and <code>wait_until(timepoint)</code> functions. The
first one wait for the result at most the given time and then returns and the
second one wait for the result at most until the given time point. I think that
<code>wait_for</code> is more useful in practices, so let's discuss it further.
Finally, an interesting function is <code>bool valid()</code>. When you use
<code>get()</code> on the future, it will consume the result, making <code>valid()
returns :code:`false</code>. So, if you intend to check multiple times for a future,
you should use <code>valid()</code> first.</p>
<p>One possible scenario would be if you have several asynchronous tasks, which is
a common scenario. You can imagine that you want to process the results as fast
as possible, so you want to ask the futures for their result several times. If
no result is available, maybe you want to do something else. Here is a possible
implementation:</p>
<div class="code"><pre class="code c++"><a id="rest_code_349e436482c44c638b183f31006c5cf6-1" name="rest_code_349e436482c44c638b183f31006c5cf6-1" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_349e436482c44c638b183f31006c5cf6-1"></a><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;thread&gt;</span>
<a id="rest_code_349e436482c44c638b183f31006c5cf6-2" name="rest_code_349e436482c44c638b183f31006c5cf6-2" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_349e436482c44c638b183f31006c5cf6-2"></a><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;future&gt;</span>
<a id="rest_code_349e436482c44c638b183f31006c5cf6-3" name="rest_code_349e436482c44c638b183f31006c5cf6-3" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_349e436482c44c638b183f31006c5cf6-3"></a><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;iostream&gt;</span>
<a id="rest_code_349e436482c44c638b183f31006c5cf6-4" name="rest_code_349e436482c44c638b183f31006c5cf6-4" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_349e436482c44c638b183f31006c5cf6-4"></a><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;chrono&gt;</span>
<a id="rest_code_349e436482c44c638b183f31006c5cf6-5" name="rest_code_349e436482c44c638b183f31006c5cf6-5" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_349e436482c44c638b183f31006c5cf6-5"></a>
<a id="rest_code_349e436482c44c638b183f31006c5cf6-6" name="rest_code_349e436482c44c638b183f31006c5cf6-6" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_349e436482c44c638b183f31006c5cf6-6"></a><span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">(){</span>
<a id="rest_code_349e436482c44c638b183f31006c5cf6-7" name="rest_code_349e436482c44c638b183f31006c5cf6-7" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_349e436482c44c638b183f31006c5cf6-7"></a><span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">f1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">async</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">launch</span><span class="o">::</span><span class="n">async</span><span class="p">,</span><span class="w"> </span><span class="p">[](){</span>
<a id="rest_code_349e436482c44c638b183f31006c5cf6-8" name="rest_code_349e436482c44c638b183f31006c5cf6-8" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_349e436482c44c638b183f31006c5cf6-8"></a><span class="w">        </span><span class="n">std</span><span class="o">::</span><span class="n">this_thread</span><span class="o">::</span><span class="n">sleep_for</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">seconds</span><span class="p">(</span><span class="mi">9</span><span class="p">));</span>
<a id="rest_code_349e436482c44c638b183f31006c5cf6-9" name="rest_code_349e436482c44c638b183f31006c5cf6-9" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_349e436482c44c638b183f31006c5cf6-9"></a><span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="mi">42</span><span class="p">;</span>
<a id="rest_code_349e436482c44c638b183f31006c5cf6-10" name="rest_code_349e436482c44c638b183f31006c5cf6-10" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_349e436482c44c638b183f31006c5cf6-10"></a><span class="w">    </span><span class="p">});</span>
<a id="rest_code_349e436482c44c638b183f31006c5cf6-11" name="rest_code_349e436482c44c638b183f31006c5cf6-11" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_349e436482c44c638b183f31006c5cf6-11"></a>
<a id="rest_code_349e436482c44c638b183f31006c5cf6-12" name="rest_code_349e436482c44c638b183f31006c5cf6-12" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_349e436482c44c638b183f31006c5cf6-12"></a><span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">f2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">async</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">launch</span><span class="o">::</span><span class="n">async</span><span class="p">,</span><span class="w"> </span><span class="p">[](){</span>
<a id="rest_code_349e436482c44c638b183f31006c5cf6-13" name="rest_code_349e436482c44c638b183f31006c5cf6-13" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_349e436482c44c638b183f31006c5cf6-13"></a><span class="w">        </span><span class="n">std</span><span class="o">::</span><span class="n">this_thread</span><span class="o">::</span><span class="n">sleep_for</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">seconds</span><span class="p">(</span><span class="mi">3</span><span class="p">));</span>
<a id="rest_code_349e436482c44c638b183f31006c5cf6-14" name="rest_code_349e436482c44c638b183f31006c5cf6-14" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_349e436482c44c638b183f31006c5cf6-14"></a><span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="mi">13</span><span class="p">;</span>
<a id="rest_code_349e436482c44c638b183f31006c5cf6-15" name="rest_code_349e436482c44c638b183f31006c5cf6-15" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_349e436482c44c638b183f31006c5cf6-15"></a><span class="w">    </span><span class="p">});</span>
<a id="rest_code_349e436482c44c638b183f31006c5cf6-16" name="rest_code_349e436482c44c638b183f31006c5cf6-16" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_349e436482c44c638b183f31006c5cf6-16"></a>
<a id="rest_code_349e436482c44c638b183f31006c5cf6-17" name="rest_code_349e436482c44c638b183f31006c5cf6-17" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_349e436482c44c638b183f31006c5cf6-17"></a><span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">f3</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">async</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">launch</span><span class="o">::</span><span class="n">async</span><span class="p">,</span><span class="w"> </span><span class="p">[](){</span>
<a id="rest_code_349e436482c44c638b183f31006c5cf6-18" name="rest_code_349e436482c44c638b183f31006c5cf6-18" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_349e436482c44c638b183f31006c5cf6-18"></a><span class="w">        </span><span class="n">std</span><span class="o">::</span><span class="n">this_thread</span><span class="o">::</span><span class="n">sleep_for</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">seconds</span><span class="p">(</span><span class="mi">6</span><span class="p">));</span>
<a id="rest_code_349e436482c44c638b183f31006c5cf6-19" name="rest_code_349e436482c44c638b183f31006c5cf6-19" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_349e436482c44c638b183f31006c5cf6-19"></a><span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="mi">666</span><span class="p">;</span>
<a id="rest_code_349e436482c44c638b183f31006c5cf6-20" name="rest_code_349e436482c44c638b183f31006c5cf6-20" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_349e436482c44c638b183f31006c5cf6-20"></a><span class="w">    </span><span class="p">});</span>
<a id="rest_code_349e436482c44c638b183f31006c5cf6-21" name="rest_code_349e436482c44c638b183f31006c5cf6-21" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_349e436482c44c638b183f31006c5cf6-21"></a>
<a id="rest_code_349e436482c44c638b183f31006c5cf6-22" name="rest_code_349e436482c44c638b183f31006c5cf6-22" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_349e436482c44c638b183f31006c5cf6-22"></a><span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">timeout</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">milliseconds</span><span class="p">(</span><span class="mi">10</span><span class="p">);</span>
<a id="rest_code_349e436482c44c638b183f31006c5cf6-23" name="rest_code_349e436482c44c638b183f31006c5cf6-23" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_349e436482c44c638b183f31006c5cf6-23"></a>
<a id="rest_code_349e436482c44c638b183f31006c5cf6-24" name="rest_code_349e436482c44c638b183f31006c5cf6-24" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_349e436482c44c638b183f31006c5cf6-24"></a><span class="w">    </span><span class="k">while</span><span class="p">(</span><span class="n">f1</span><span class="p">.</span><span class="n">valid</span><span class="p">()</span><span class="w"> </span><span class="o">||</span><span class="w"> </span><span class="n">f2</span><span class="p">.</span><span class="n">valid</span><span class="p">()</span><span class="w"> </span><span class="o">||</span><span class="w"> </span><span class="n">f3</span><span class="p">.</span><span class="n">valid</span><span class="p">()){</span>
<a id="rest_code_349e436482c44c638b183f31006c5cf6-25" name="rest_code_349e436482c44c638b183f31006c5cf6-25" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_349e436482c44c638b183f31006c5cf6-25"></a><span class="w">        </span><span class="k">if</span><span class="p">(</span><span class="n">f1</span><span class="p">.</span><span class="n">valid</span><span class="p">()</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">f1</span><span class="p">.</span><span class="n">wait_for</span><span class="p">(</span><span class="n">timeout</span><span class="p">)</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">future_status</span><span class="o">::</span><span class="n">ready</span><span class="p">){</span>
<a id="rest_code_349e436482c44c638b183f31006c5cf6-26" name="rest_code_349e436482c44c638b183f31006c5cf6-26" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_349e436482c44c638b183f31006c5cf6-26"></a><span class="w">            </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">"Task1 is done! "</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">f1</span><span class="p">.</span><span class="n">get</span><span class="p">()</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<a id="rest_code_349e436482c44c638b183f31006c5cf6-27" name="rest_code_349e436482c44c638b183f31006c5cf6-27" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_349e436482c44c638b183f31006c5cf6-27"></a><span class="w">        </span><span class="p">}</span>
<a id="rest_code_349e436482c44c638b183f31006c5cf6-28" name="rest_code_349e436482c44c638b183f31006c5cf6-28" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_349e436482c44c638b183f31006c5cf6-28"></a>
<a id="rest_code_349e436482c44c638b183f31006c5cf6-29" name="rest_code_349e436482c44c638b183f31006c5cf6-29" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_349e436482c44c638b183f31006c5cf6-29"></a><span class="w">        </span><span class="k">if</span><span class="p">(</span><span class="n">f2</span><span class="p">.</span><span class="n">valid</span><span class="p">()</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">f2</span><span class="p">.</span><span class="n">wait_for</span><span class="p">(</span><span class="n">timeout</span><span class="p">)</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">future_status</span><span class="o">::</span><span class="n">ready</span><span class="p">){</span>
<a id="rest_code_349e436482c44c638b183f31006c5cf6-30" name="rest_code_349e436482c44c638b183f31006c5cf6-30" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_349e436482c44c638b183f31006c5cf6-30"></a><span class="w">            </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">"Task2 is done! "</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">f2</span><span class="p">.</span><span class="n">get</span><span class="p">()</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<a id="rest_code_349e436482c44c638b183f31006c5cf6-31" name="rest_code_349e436482c44c638b183f31006c5cf6-31" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_349e436482c44c638b183f31006c5cf6-31"></a><span class="w">        </span><span class="p">}</span>
<a id="rest_code_349e436482c44c638b183f31006c5cf6-32" name="rest_code_349e436482c44c638b183f31006c5cf6-32" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_349e436482c44c638b183f31006c5cf6-32"></a>
<a id="rest_code_349e436482c44c638b183f31006c5cf6-33" name="rest_code_349e436482c44c638b183f31006c5cf6-33" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_349e436482c44c638b183f31006c5cf6-33"></a><span class="w">        </span><span class="k">if</span><span class="p">(</span><span class="n">f3</span><span class="p">.</span><span class="n">valid</span><span class="p">()</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">f3</span><span class="p">.</span><span class="n">wait_for</span><span class="p">(</span><span class="n">timeout</span><span class="p">)</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">future_status</span><span class="o">::</span><span class="n">ready</span><span class="p">){</span>
<a id="rest_code_349e436482c44c638b183f31006c5cf6-34" name="rest_code_349e436482c44c638b183f31006c5cf6-34" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_349e436482c44c638b183f31006c5cf6-34"></a><span class="w">            </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">"Task3 is done! "</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">f3</span><span class="p">.</span><span class="n">get</span><span class="p">()</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<a id="rest_code_349e436482c44c638b183f31006c5cf6-35" name="rest_code_349e436482c44c638b183f31006c5cf6-35" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_349e436482c44c638b183f31006c5cf6-35"></a><span class="w">        </span><span class="p">}</span>
<a id="rest_code_349e436482c44c638b183f31006c5cf6-36" name="rest_code_349e436482c44c638b183f31006c5cf6-36" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_349e436482c44c638b183f31006c5cf6-36"></a>
<a id="rest_code_349e436482c44c638b183f31006c5cf6-37" name="rest_code_349e436482c44c638b183f31006c5cf6-37" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_349e436482c44c638b183f31006c5cf6-37"></a><span class="w">        </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">"I'm doing my own work!"</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<a id="rest_code_349e436482c44c638b183f31006c5cf6-38" name="rest_code_349e436482c44c638b183f31006c5cf6-38" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_349e436482c44c638b183f31006c5cf6-38"></a><span class="w">        </span><span class="n">std</span><span class="o">::</span><span class="n">this_thread</span><span class="o">::</span><span class="n">sleep_for</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">seconds</span><span class="p">(</span><span class="mi">1</span><span class="p">));</span>
<a id="rest_code_349e436482c44c638b183f31006c5cf6-39" name="rest_code_349e436482c44c638b183f31006c5cf6-39" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_349e436482c44c638b183f31006c5cf6-39"></a><span class="w">        </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">"I'm done with my own work!"</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<a id="rest_code_349e436482c44c638b183f31006c5cf6-40" name="rest_code_349e436482c44c638b183f31006c5cf6-40" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_349e436482c44c638b183f31006c5cf6-40"></a><span class="w">    </span><span class="p">}</span>
<a id="rest_code_349e436482c44c638b183f31006c5cf6-41" name="rest_code_349e436482c44c638b183f31006c5cf6-41" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_349e436482c44c638b183f31006c5cf6-41"></a>
<a id="rest_code_349e436482c44c638b183f31006c5cf6-42" name="rest_code_349e436482c44c638b183f31006c5cf6-42" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_349e436482c44c638b183f31006c5cf6-42"></a><span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">"Everything is done, let's go back to the tutorial"</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<a id="rest_code_349e436482c44c638b183f31006c5cf6-43" name="rest_code_349e436482c44c638b183f31006c5cf6-43" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_349e436482c44c638b183f31006c5cf6-43"></a>
<a id="rest_code_349e436482c44c638b183f31006c5cf6-44" name="rest_code_349e436482c44c638b183f31006c5cf6-44" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_349e436482c44c638b183f31006c5cf6-44"></a><span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<a id="rest_code_349e436482c44c638b183f31006c5cf6-45" name="rest_code_349e436482c44c638b183f31006c5cf6-45" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_349e436482c44c638b183f31006c5cf6-45"></a><span class="p">}</span>
</pre></div>
<p>The three tasks are started asynchronously with <code>std::async</code> and the
resulting <code>std::future</code> are stored. Then, as long as one of the tasks is
not complete, we query each three task and try to process its result. If no
result is available, we simply do something else. This example is important to
understand, it covers pretty much every concept of the futures.</p>
<p>One interesting thing that remains is that you can pass parameters to your task
via <code>std::async</code>. Indeed, all the extra parameters that you pass to
<code>std::async</code> will be passed to the task itself. Here is an example of
spawning tasks in a loop with different parameters:</p>
<div class="code"><pre class="code c++"><a id="rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-1" name="rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-1" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-1"></a><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;thread&gt;</span>
<a id="rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-2" name="rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-2" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-2"></a><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;future&gt;</span>
<a id="rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-3" name="rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-3" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-3"></a><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;iostream&gt;</span>
<a id="rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-4" name="rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-4" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-4"></a><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;chrono&gt;</span>
<a id="rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-5" name="rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-5" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-5"></a><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;vector&gt;</span>
<a id="rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-6" name="rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-6" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-6"></a>
<a id="rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-7" name="rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-7" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-7"></a><span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">(){</span>
<a id="rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-8" name="rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-8" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-8"></a><span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">future</span><span class="o">&lt;</span><span class="kt">size_t</span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="n">futures</span><span class="p">;</span>
<a id="rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-9" name="rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-9" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-9"></a>
<a id="rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-10" name="rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-10" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-10"></a><span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">size_t</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">10</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<a id="rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-11" name="rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-11" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-11"></a><span class="w">        </span><span class="n">futures</span><span class="p">.</span><span class="n">emplace_back</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">async</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">launch</span><span class="o">::</span><span class="n">async</span><span class="p">,</span><span class="w"> </span><span class="p">[](</span><span class="kt">size_t</span><span class="w"> </span><span class="n">param</span><span class="p">){</span>
<a id="rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-12" name="rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-12" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-12"></a><span class="w">            </span><span class="n">std</span><span class="o">::</span><span class="n">this_thread</span><span class="o">::</span><span class="n">sleep_for</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">seconds</span><span class="p">(</span><span class="n">param</span><span class="p">));</span>
<a id="rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-13" name="rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-13" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-13"></a><span class="w">            </span><span class="k">return</span><span class="w"> </span><span class="n">param</span><span class="p">;</span>
<a id="rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-14" name="rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-14" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-14"></a><span class="w">        </span><span class="p">},</span><span class="w"> </span><span class="n">i</span><span class="p">));</span>
<a id="rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-15" name="rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-15" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-15"></a><span class="w">    </span><span class="p">}</span>
<a id="rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-16" name="rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-16" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-16"></a>
<a id="rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-17" name="rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-17" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-17"></a><span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">"Start querying"</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<a id="rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-18" name="rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-18" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-18"></a>
<a id="rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-19" name="rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-19" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-19"></a><span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="k">auto</span><span class="w"> </span><span class="o">&amp;</span><span class="n">future</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">futures</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<a id="rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-20" name="rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-20" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-20"></a><span class="w">      </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">future</span><span class="p">.</span><span class="n">get</span><span class="p">()</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<a id="rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-21" name="rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-21" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-21"></a><span class="w">    </span><span class="p">}</span>
<a id="rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-22" name="rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-22" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-22"></a>
<a id="rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-23" name="rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-23" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-23"></a><span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<a id="rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-24" name="rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-24" href="posts/2017/09/cpp11-concurrency-tutorial-futures.html#rest_code_bc33abdc6c2d46fdab68396b2e2ccf30-24"></a><span class="p">}</span>
</pre></div>
<p>Pretty practical :) All The created <code>std::future&lt;size_t&gt;</code> are stored in
a <code>std::vector</code> and then are all queried for their result.</p>
<p>Overall, I think <code>std::future</code> and <code>std::async</code> are great tool that
can simplify your asynchronous code a lot. They allow you to make pretty
advanced stuff while keeping the complexity of the code to a minimum.</p>
<p>I hope this long-due post is going to be interesting to some of you :)
The code for this post is available <a class="reference external" href="https://github.com/wichtounet/articles/tree/master/src/threads/part5">on Github</a></p>
<p>I do not yet know if there will be a next installment in the series. I've
covered pretty much everything that is available in C++11 for concurrency. I may
cover the parallel algorithms of C++17 in a following post. If you have any
suggestion for the next post, don't hesitate to post a comment or contact me
directly by email.</p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html" class="u-url">Simplify your type traits with C++14 variable templates</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Baptiste Wicht
            </span></p>
            <p class="dateline">
            <a href="posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html" rel="bookmark">
            <time class="published dt-published" datetime="2017-08-22T14:45:11+02:00" itemprop="datePublished" title="2017-08-22 14:45">2017-08-22 14:45</time></a>
            </p>
                <p class="commentline">
    
    <a href="posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#disqus_thread" data-disqus-identifier="cache/posts/2017/08/simplify-your-type-traits-with-c++14-variable-templates.html">Comments</a>


        </p>
</div>
    </header><div class="p-summary entry-summary">
    <p>Often if you write templated code, you have to write and use a lot of different
traits. In this article, I'll focus on the traits that are representing values,
typically a boolean value. For instance, std::is_const, std::is_same or
std::is_reference are type traits provided by the STL. They are giving you some
information at compile time for a certain type. If you need to write a type
traits, let's say is_float, here is how you would maybe do it in C++11:</p>
<div class="code"><pre class="code c++"><a id="rest_code_d2cb1dfd16574590ba167f67818f1fc4-1" name="rest_code_d2cb1dfd16574590ba167f67818f1fc4-1" href="posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_d2cb1dfd16574590ba167f67818f1fc4-1"></a><span class="k">template</span><span class="w"> </span><span class="o">&lt;</span><span class="k">typename</span><span class="w"> </span><span class="nc">T</span><span class="o">&gt;</span>
<a id="rest_code_d2cb1dfd16574590ba167f67818f1fc4-2" name="rest_code_d2cb1dfd16574590ba167f67818f1fc4-2" href="posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_d2cb1dfd16574590ba167f67818f1fc4-2"></a><span class="k">struct</span><span class="w"> </span><span class="nc">is_float</span><span class="w"> </span><span class="p">{</span>
<a id="rest_code_d2cb1dfd16574590ba167f67818f1fc4-3" name="rest_code_d2cb1dfd16574590ba167f67818f1fc4-3" href="posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_d2cb1dfd16574590ba167f67818f1fc4-3"></a><span class="w">    </span><span class="k">static</span><span class="w"> </span><span class="k">constexpr</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">value</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">is_same</span><span class="o">&lt;</span><span class="n">T</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="o">&gt;::</span><span class="n">value</span><span class="p">;</span>
<a id="rest_code_d2cb1dfd16574590ba167f67818f1fc4-4" name="rest_code_d2cb1dfd16574590ba167f67818f1fc4-4" href="posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_d2cb1dfd16574590ba167f67818f1fc4-4"></a><span class="p">};</span>
</pre></div>
<p>or a bit nicer with a template type alias and std::integral constant:</p>
<div class="code"><pre class="code c++"><a id="rest_code_2827348e004742308d82d8a29d7a438c-1" name="rest_code_2827348e004742308d82d8a29d7a438c-1" href="posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_2827348e004742308d82d8a29d7a438c-1"></a><span class="k">template</span><span class="w"> </span><span class="o">&lt;</span><span class="k">typename</span><span class="w"> </span><span class="nc">T</span><span class="o">&gt;</span>
<a id="rest_code_2827348e004742308d82d8a29d7a438c-2" name="rest_code_2827348e004742308d82d8a29d7a438c-2" href="posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_2827348e004742308d82d8a29d7a438c-2"></a><span class="k">using</span><span class="w"> </span><span class="n">is_float</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">integral_constant</span><span class="o">&lt;</span><span class="kt">bool</span><span class="p">,</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">is_same</span><span class="o">&lt;</span><span class="n">T</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="o">&gt;::</span><span class="n">value</span><span class="o">&gt;</span><span class="p">;</span>
</pre></div>
<p>or since is_same is itself a type traits, you can also directly alias it:</p>
<div class="code"><pre class="code c++"><a id="rest_code_86c715b288354d0a96c44f400b9add0e-1" name="rest_code_86c715b288354d0a96c44f400b9add0e-1" href="posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_86c715b288354d0a96c44f400b9add0e-1"></a><span class="k">template</span><span class="w"> </span><span class="o">&lt;</span><span class="k">typename</span><span class="w"> </span><span class="nc">T</span><span class="o">&gt;</span>
<a id="rest_code_86c715b288354d0a96c44f400b9add0e-2" name="rest_code_86c715b288354d0a96c44f400b9add0e-2" href="posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_86c715b288354d0a96c44f400b9add0e-2"></a><span class="k">using</span><span class="w"> </span><span class="n">is_float</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">is_same</span><span class="o">&lt;</span><span class="n">T</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="o">&gt;</span><span class="p">;</span>
</pre></div>
<p>This makes for some very nice syntax, but we still have a type rather than a value.</p>
<p>Note that in some cases, you cannot use the using technique since it cannot be
specialized and you often need specialization to write some more advanced
traits.</p>
<p>And then you would use your traits to do something specific based on that
information. For instance with a very basic example:</p>
<div class="code"><pre class="code C++"><a id="rest_code_f4bbd1e0d86444ad9d1f20ac51e95698-1" name="rest_code_f4bbd1e0d86444ad9d1f20ac51e95698-1" href="posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_f4bbd1e0d86444ad9d1f20ac51e95698-1"></a><span class="k">template</span><span class="w"> </span><span class="o">&lt;</span><span class="k">typename</span><span class="w"> </span><span class="nc">T</span><span class="o">&gt;</span>
<a id="rest_code_f4bbd1e0d86444ad9d1f20ac51e95698-2" name="rest_code_f4bbd1e0d86444ad9d1f20ac51e95698-2" href="posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_f4bbd1e0d86444ad9d1f20ac51e95698-2"></a><span class="kt">void</span><span class="w"> </span><span class="n">test</span><span class="p">(</span><span class="n">T</span><span class="w"> </span><span class="n">t</span><span class="p">){</span>
<a id="rest_code_f4bbd1e0d86444ad9d1f20ac51e95698-3" name="rest_code_f4bbd1e0d86444ad9d1f20ac51e95698-3" href="posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_f4bbd1e0d86444ad9d1f20ac51e95698-3"></a><span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">is_float</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;::</span><span class="n">value</span><span class="p">){</span>
<a id="rest_code_f4bbd1e0d86444ad9d1f20ac51e95698-4" name="rest_code_f4bbd1e0d86444ad9d1f20ac51e95698-4" href="posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_f4bbd1e0d86444ad9d1f20ac51e95698-4"></a><span class="w">        </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">"I'm a float"</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<a id="rest_code_f4bbd1e0d86444ad9d1f20ac51e95698-5" name="rest_code_f4bbd1e0d86444ad9d1f20ac51e95698-5" href="posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_f4bbd1e0d86444ad9d1f20ac51e95698-5"></a><span class="w">    </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">{</span>
<a id="rest_code_f4bbd1e0d86444ad9d1f20ac51e95698-6" name="rest_code_f4bbd1e0d86444ad9d1f20ac51e95698-6" href="posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_f4bbd1e0d86444ad9d1f20ac51e95698-6"></a><span class="w">        </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">"I'm not a float"</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<a id="rest_code_f4bbd1e0d86444ad9d1f20ac51e95698-7" name="rest_code_f4bbd1e0d86444ad9d1f20ac51e95698-7" href="posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_f4bbd1e0d86444ad9d1f20ac51e95698-7"></a><span class="w">    </span><span class="p">}</span>
<a id="rest_code_f4bbd1e0d86444ad9d1f20ac51e95698-8" name="rest_code_f4bbd1e0d86444ad9d1f20ac51e95698-8" href="posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_f4bbd1e0d86444ad9d1f20ac51e95698-8"></a><span class="p">}</span>
</pre></div>
<p>Really nothing fancy here, but that will be enough as examples.</p>
<p>Even though all this works pretty, it can be made better on two points. First,
every time you use a traits, you need to use the value member (via ::value).
Secondly, every time you declare a new traits, you have to declare a new type or
a type alias. But all you want is a boolean value.</p>
<p>C++14 introduced a new feature, variable templates. As their name indicates,
they are variables, parametrized with a type. This allows us to write type
traits without using a type alias or struct, meaning we have a real value
instead of a type. If we rewrite our is_float traits with variable templates, we
have the following:</p>
<div class="code"><pre class="code c++"><a id="rest_code_64208707d9084f35a486b35b7750c201-1" name="rest_code_64208707d9084f35a486b35b7750c201-1" href="posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_64208707d9084f35a486b35b7750c201-1"></a><span class="k">template</span><span class="w"> </span><span class="o">&lt;</span><span class="k">typename</span><span class="w"> </span><span class="nc">T</span><span class="o">&gt;</span>
<a id="rest_code_64208707d9084f35a486b35b7750c201-2" name="rest_code_64208707d9084f35a486b35b7750c201-2" href="posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_64208707d9084f35a486b35b7750c201-2"></a><span class="k">constexpr</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">is_float</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">is_same</span><span class="o">&lt;</span><span class="n">T</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="o">&gt;::</span><span class="n">value</span><span class="p">;</span>
</pre></div>
<p>I think it's much nicer, the intent is clearly stated and there is no
unnecessary code. Moreover, it's also nicer to use:</p>
<div class="code"><pre class="code C++"><a id="rest_code_4ea8dffa324a471e8efc5f293513d4c3-1" name="rest_code_4ea8dffa324a471e8efc5f293513d4c3-1" href="posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_4ea8dffa324a471e8efc5f293513d4c3-1"></a><span class="k">template</span><span class="w"> </span><span class="o">&lt;</span><span class="k">typename</span><span class="w"> </span><span class="nc">T</span><span class="o">&gt;</span>
<a id="rest_code_4ea8dffa324a471e8efc5f293513d4c3-2" name="rest_code_4ea8dffa324a471e8efc5f293513d4c3-2" href="posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_4ea8dffa324a471e8efc5f293513d4c3-2"></a><span class="kt">void</span><span class="w"> </span><span class="n">test</span><span class="p">(</span><span class="n">T</span><span class="w"> </span><span class="n">t</span><span class="p">){</span>
<a id="rest_code_4ea8dffa324a471e8efc5f293513d4c3-3" name="rest_code_4ea8dffa324a471e8efc5f293513d4c3-3" href="posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_4ea8dffa324a471e8efc5f293513d4c3-3"></a><span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">is_float</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span><span class="p">){</span>
<a id="rest_code_4ea8dffa324a471e8efc5f293513d4c3-4" name="rest_code_4ea8dffa324a471e8efc5f293513d4c3-4" href="posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_4ea8dffa324a471e8efc5f293513d4c3-4"></a><span class="w">        </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">"I'm a float"</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<a id="rest_code_4ea8dffa324a471e8efc5f293513d4c3-5" name="rest_code_4ea8dffa324a471e8efc5f293513d4c3-5" href="posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_4ea8dffa324a471e8efc5f293513d4c3-5"></a><span class="w">    </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">{</span>
<a id="rest_code_4ea8dffa324a471e8efc5f293513d4c3-6" name="rest_code_4ea8dffa324a471e8efc5f293513d4c3-6" href="posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_4ea8dffa324a471e8efc5f293513d4c3-6"></a><span class="w">        </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">"I'm not a float"</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<a id="rest_code_4ea8dffa324a471e8efc5f293513d4c3-7" name="rest_code_4ea8dffa324a471e8efc5f293513d4c3-7" href="posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_4ea8dffa324a471e8efc5f293513d4c3-7"></a><span class="w">    </span><span class="p">}</span>
<a id="rest_code_4ea8dffa324a471e8efc5f293513d4c3-8" name="rest_code_4ea8dffa324a471e8efc5f293513d4c3-8" href="posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_4ea8dffa324a471e8efc5f293513d4c3-8"></a><span class="p">}</span>
</pre></div>
<p>No more ::value everywhere :) I think it's really cool.</p>
<p>Note that, unlike type alias template, they can be specialized, either fully or
partially, so no more limitation on that side.</p>
<p>Interestingly, variable templates are used in C++17 to provide helpers for each
type traits with values. For instance, std::is_same will have a std::is_same_v
helper that is a variable template. With that, we can simplify our traits a bit
more:</p>
<div class="code"><pre class="code c++"><a id="rest_code_756ff217100847ac9873464434c75358-1" name="rest_code_756ff217100847ac9873464434c75358-1" href="posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_756ff217100847ac9873464434c75358-1"></a><span class="k">template</span><span class="w"> </span><span class="o">&lt;</span><span class="k">typename</span><span class="w"> </span><span class="nc">T</span><span class="o">&gt;</span>
<a id="rest_code_756ff217100847ac9873464434c75358-2" name="rest_code_756ff217100847ac9873464434c75358-2" href="posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_756ff217100847ac9873464434c75358-2"></a><span class="k">constexpr</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">is_float</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">is_same_v</span><span class="o">&lt;</span><span class="n">T</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="o">&gt;</span><span class="p">;</span>
</pre></div>
<p>Personally, I replaced all the type traits inside ETL using variable templates.
If you don't want to do it, you can also introduce helpers like in the C++17 STL
and start using the wrappers when you see fit so that you don't break any code.</p>
<p>If you want to use this feature, you need a C++14 compiler, such as any version
from GCC5 family or clang 3.6. Although I haven't tested, it should also work on
Microsoft VS2015 Update 2.</p>
<p>Unfortunately there is a bug in both clang (fixed in clang 3.7) and GCC (fixed
in GCC 6 only) that you may encounter if you start using variable templates in
template classes or variable templates used in another variable templates. If
you plan to use variable templates inside a template, such as something like
this:</p>
<div class="code"><pre class="code c++"><a id="rest_code_4ab385cabd0a4801a4ba5d69614b120f-1" name="rest_code_4ab385cabd0a4801a4ba5d69614b120f-1" href="posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_4ab385cabd0a4801a4ba5d69614b120f-1"></a><span class="k">template</span><span class="w"> </span><span class="o">&lt;</span><span class="k">typename</span><span class="w"> </span><span class="nc">T</span><span class="o">&gt;</span>
<a id="rest_code_4ab385cabd0a4801a4ba5d69614b120f-2" name="rest_code_4ab385cabd0a4801a4ba5d69614b120f-2" href="posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_4ab385cabd0a4801a4ba5d69614b120f-2"></a><span class="k">struct</span><span class="w"> </span><span class="nc">outer_traits</span><span class="w"> </span><span class="p">{</span>
<a id="rest_code_4ab385cabd0a4801a4ba5d69614b120f-3" name="rest_code_4ab385cabd0a4801a4ba5d69614b120f-3" href="posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_4ab385cabd0a4801a4ba5d69614b120f-3"></a><span class="w">    </span><span class="k">template</span><span class="w"> </span><span class="o">&lt;</span><span class="k">typename</span><span class="w"> </span><span class="nc">X</span><span class="o">&gt;</span>
<a id="rest_code_4ab385cabd0a4801a4ba5d69614b120f-4" name="rest_code_4ab385cabd0a4801a4ba5d69614b120f-4" href="posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_4ab385cabd0a4801a4ba5d69614b120f-4"></a><span class="w">    </span><span class="k">static</span><span class="w"> </span><span class="k">constexpr</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">sub_traits</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">is_same</span><span class="o">&lt;</span><span class="n">T</span><span class="p">,</span><span class="w"> </span><span class="n">X</span><span class="o">&gt;::</span><span class="n">value</span><span class="p">;</span>
<a id="rest_code_4ab385cabd0a4801a4ba5d69614b120f-5" name="rest_code_4ab385cabd0a4801a4ba5d69614b120f-5" href="posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_4ab385cabd0a4801a4ba5d69614b120f-5"></a><span class="p">};</span>
<a id="rest_code_4ab385cabd0a4801a4ba5d69614b120f-6" name="rest_code_4ab385cabd0a4801a4ba5d69614b120f-6" href="posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_4ab385cabd0a4801a4ba5d69614b120f-6"></a>
<a id="rest_code_4ab385cabd0a4801a4ba5d69614b120f-7" name="rest_code_4ab385cabd0a4801a4ba5d69614b120f-7" href="posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_4ab385cabd0a4801a4ba5d69614b120f-7"></a><span class="k">template</span><span class="w"> </span><span class="o">&lt;</span><span class="k">typename</span><span class="w"> </span><span class="nc">T</span><span class="p">,</span><span class="w"> </span><span class="k">typename</span><span class="w"> </span><span class="nc">X</span><span class="o">&gt;</span>
<a id="rest_code_4ab385cabd0a4801a4ba5d69614b120f-8" name="rest_code_4ab385cabd0a4801a4ba5d69614b120f-8" href="posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_4ab385cabd0a4801a4ba5d69614b120f-8"></a><span class="k">constexpr</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">outer_helper</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">outer_traits</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;::</span><span class="k">template</span><span class="w"> </span><span class="n">sub_traits</span><span class="o">&lt;</span><span class="n">X</span><span class="o">&gt;</span><span class="p">;</span>
<a id="rest_code_4ab385cabd0a4801a4ba5d69614b120f-9" name="rest_code_4ab385cabd0a4801a4ba5d69614b120f-9" href="posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_4ab385cabd0a4801a4ba5d69614b120f-9"></a>
<a id="rest_code_4ab385cabd0a4801a4ba5d69614b120f-10" name="rest_code_4ab385cabd0a4801a4ba5d69614b120f-10" href="posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_4ab385cabd0a4801a4ba5d69614b120f-10"></a><span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">(){</span>
<a id="rest_code_4ab385cabd0a4801a4ba5d69614b120f-11" name="rest_code_4ab385cabd0a4801a4ba5d69614b120f-11" href="posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_4ab385cabd0a4801a4ba5d69614b120f-11"></a><span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">outer_helper</span><span class="o">&lt;</span><span class="kt">float</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="o">&gt;</span><span class="p">;</span>
<a id="rest_code_4ab385cabd0a4801a4ba5d69614b120f-12" name="rest_code_4ab385cabd0a4801a4ba5d69614b120f-12" href="posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_4ab385cabd0a4801a4ba5d69614b120f-12"></a>
<a id="rest_code_4ab385cabd0a4801a4ba5d69614b120f-13" name="rest_code_4ab385cabd0a4801a4ba5d69614b120f-13" href="posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_4ab385cabd0a4801a4ba5d69614b120f-13"></a><span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<a id="rest_code_4ab385cabd0a4801a4ba5d69614b120f-14" name="rest_code_4ab385cabd0a4801a4ba5d69614b120f-14" href="posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_4ab385cabd0a4801a4ba5d69614b120f-14"></a><span class="p">}</span>
</pre></div>
<p>You will encounter a not-helpful at all error message with GCC5 family, such as:</p>
<div class="code"><pre class="code text"><a id="rest_code_3a2f680ce7604df69214b29bf4568c4a-1" name="rest_code_3a2f680ce7604df69214b29bf4568c4a-1" href="posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_3a2f680ce7604df69214b29bf4568c4a-1"></a>test.cpp: In instantiation of ‘constexpr const bool outer_helper&lt;float, float&gt;’:
<a id="rest_code_3a2f680ce7604df69214b29bf4568c4a-2" name="rest_code_3a2f680ce7604df69214b29bf4568c4a-2" href="posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_3a2f680ce7604df69214b29bf4568c4a-2"></a>test.cpp:14:22:   required from here
<a id="rest_code_3a2f680ce7604df69214b29bf4568c4a-3" name="rest_code_3a2f680ce7604df69214b29bf4568c4a-3" href="posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_3a2f680ce7604df69214b29bf4568c4a-3"></a>test.cpp:11:20: error: ‘template&lt;class X&gt; constexpr const bool outer_traits&lt;float&gt;::sub_traits&lt;X&gt;’ is not a function template
<a id="rest_code_3a2f680ce7604df69214b29bf4568c4a-4" name="rest_code_3a2f680ce7604df69214b29bf4568c4a-4" href="posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_3a2f680ce7604df69214b29bf4568c4a-4"></a>     constexpr bool outer_helper = outer_traits&lt;T&gt;::template sub_trait
<a id="rest_code_3a2f680ce7604df69214b29bf4568c4a-5" name="rest_code_3a2f680ce7604df69214b29bf4568c4a-5" href="posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_3a2f680ce7604df69214b29bf4568c4a-5"></a>                    ^
<a id="rest_code_3a2f680ce7604df69214b29bf4568c4a-6" name="rest_code_3a2f680ce7604df69214b29bf4568c4a-6" href="posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_3a2f680ce7604df69214b29bf4568c4a-6"></a>test.cpp:11:20: error: ‘sub_traits&lt;X&gt;’ is not a member of ‘outer_traits&lt;float&gt;’
</pre></div>
<p>It comes from a bug in the handling of variable templates as dependent names. If
you don't come in this cases, you can use GCC5 family directly, otherwise,
you'll have to use GCC6 family only.</p>
<p>I hope this can help some of you to improve your type traits or at least to
discover the power of the new variable templates. Personally, I've rewritten all
the traits from the ETL library using this new feature and I'm pretty satisfied
with the result. Of course, that means that the compiler support was reduced,
but since I don't have many users, it's not a real issue.</p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/2017/08/how-to-fix-mdadm-raid5-raid6-growing-stuck-at-0ks.html" class="u-url">How to fix mdadm RAID5 / RAID6 growing stuck at 0K/s ?</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Baptiste Wicht
            </span></p>
            <p class="dateline">
            <a href="posts/2017/08/how-to-fix-mdadm-raid5-raid6-growing-stuck-at-0ks.html" rel="bookmark">
            <time class="published dt-published" datetime="2017-08-12T12:28:43+02:00" itemprop="datePublished" title="2017-08-12 12:28">2017-08-12 12:28</time></a>
            </p>
                <p class="commentline">
    
    <a href="posts/2017/08/how-to-fix-mdadm-raid5-raid6-growing-stuck-at-0ks.html#disqus_thread" data-disqus-identifier="cache/posts/2017/08/how-to-fix-mdadm-raid5-raid6-growing-stuck-at-0ks.html">Comments</a>


        </p>
</div>
    </header><div class="p-summary entry-summary">
    <p>I just started growing again my RAID6 array from 12 to 13 disks and
I encountered a new issue. The reshape started, but with a speed of 0K/s. After
some searching, I found a very simple solution:</p>
<div class="code"><pre class="code bash"><a id="rest_code_f38ecd058eb6430f994ec31999ae5e9a-1" name="rest_code_f38ecd058eb6430f994ec31999ae5e9a-1" href="posts/2017/08/how-to-fix-mdadm-raid5-raid6-growing-stuck-at-0ks.html#rest_code_f38ecd058eb6430f994ec31999ae5e9a-1"></a><span class="nb">echo</span><span class="w"> </span>max<span class="w"> </span>&gt;<span class="w"> </span>/sys/block/md0/md/sync_max
</pre></div>
<p>And the reshape started directly at 50M/s :)</p>
<p>The solution is the same if you are growing any type of RAID level with parity
(RAID5, RAID6, ...).</p>
<p>Normally, the issues I have are related to speed not very good. I've written
a post in the post about
<a class="reference external" href="https://baptiste-wicht.com/posts/2015/03/how-to-speed-up-raid-5-6-growing-with-mdadm.html">how to speed up RAID5 / RAID6 growing with mdadm</a>.
Although RAID5 / RAID6 growing, or another reshape operation, will never be very
fast, you can still speed up the process a lot from a few days to a few hours.
Currently, my reshape is working at 48M/s and I'm looking at around 16 hours of
reshape, but I have 13 disks of 3To, so it's not so bad.</p>
<p>I hope this very simple tip can be helpful to some of you :)</p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/2017/08/dll-blazing-fast-neural-network-library.html" class="u-url">DLL: Blazing Fast Neural Network Library</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Baptiste Wicht
            </span></p>
            <p class="dateline">
            <a href="posts/2017/08/dll-blazing-fast-neural-network-library.html" rel="bookmark">
            <time class="published dt-published" datetime="2017-08-11T11:09:14+02:00" itemprop="datePublished" title="2017-08-11 11:09">2017-08-11 11:09</time></a>
            </p>
                <p class="commentline">
    
    <a href="posts/2017/08/dll-blazing-fast-neural-network-library.html#disqus_thread" data-disqus-identifier="cache/posts/2017/08/dll-blazing-fast-neural-network-library.html">Comments</a>


        </p>
</div>
    </header><div class="p-summary entry-summary">
    <p>A few weeks ago, I talked about all
<a class="reference external" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html">the new features of my Deep Learning Library (DLL)</a>
project. I've mentioned that, on several experiments, DLL was always
significantly faster than some popular deep learning frameworks such as
TensorFlow. I'll now go into more details into this comparison and provide all
the results. So far, the paper we wrote about these results has not been
published, so I'll not provide the paper directly yet.</p>
<p>For those that may not know, DLL is the project I've been developing to support
my Ph.D. thesis. This is a neural network framework  that supports
Fully-Connected Neural Network (FCNN), Convolutional Neural Network (CNN),
Restricted Boltzmann Machine (RBM), Deep Belief Network (DBN), Convolutional RBM
(CRBM) and Convolutional DBN (CDBN). It also supports a large variety of options
such as Dropout, Batch Normalization and Adaptive Learning Rates. You can read
read the
<a class="reference external" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html">previous post</a>
if you want more information about the new features of the framework. And, as those of
you that read my blog frequently may know, I'm a bit obsessed with performance
optimization, so I've spent a considerable amount of time optimizing
the performance of neural network training, on CPU. Since, at the beginning of my
thesis, I had no access to GPU for training, I've focused on CPU. Although there
is now support for GPU, the gains are not yet important enough.</p>
<section id="evaluation"><h2>Evaluation</h2>
<p>To see how fast, or not, the library was, it was compared against five popular
machine learning libraries:</p>
<ol class="arabic simple">
<li><p>Caffe, installed from sources</p></li>
<li><p>TensorFlow 1.0, from pip</p></li>
<li><p>Keras 2.0, from pip</p></li>
<li><p>Torch, installed from sources</p></li>
<li><p>DeepLearning4J 0.7, from Maven</p></li>
</ol>
<p>I've run four different experiments with all these frameworks and compared the
efficiency of each of them for training the same neural networks with the same
options. In each case, the training or testing error have also been compared to
ensure that each framework is doing roughly the same. I wont present here the
details, but in each experiment DLL showed around the same accuracies as the
other frameworks. I will only focus on the speed results in this article.</p>
<p>Each experiment is done once with only CPU and once with a GPU. For DLL, I only
report the CPU time in both modes, since it's more stable and more optimized.</p>
<p>The code for the evaluation is available online on the
<a class="reference external" href="https://github.com/wichtounet/frameworks">Github repository of the frameworks project</a>.</p>
</section><section id="mnist-fully-connected-neural-network"><h2>MNIST: Fully Connected Neural Network</h2>
<p>The first experiment is performed on The MNIST data set. It consists of 60'000
grayscale images of size 28x28. The goal is to classify each image of a digit
from 0 to 9. To solve this task, I trained a very small fully-connected neural
network with 500 hidden units in the first layer, 250 in the second and 10 final
hidden units (or output units) for classification. The first two layers are
using the logistic sigmoid activation function and the last layer is using the
softmax activation function. The network is trained for 50 epochs with a
categorical cross entropy loss, with mini-batches of 100 images. Here are
results of this experiment:</p>
<figure class="align-center"><img alt="Training time performance for the different frameworks on the Fully-Connected Neural Network experiment, on MNIST." src="images/dll_fcnn.png"><figcaption><p>Training time performance for the different frameworks on the Fully-Connected
Neural Network experiment, on MNIST. All the times are in seconds.</p>
</figcaption></figure><p>In DLL mode, the DLL framework is the clear winner here! It's about 35% faster
than TensorFlow and Keras which are coming at the second place. DLL is more than
four times slower than DLL and the last two frameworks (Caffe and
DeepLearning4J) are five times slower than DLL! Once we add a GPU to the system,
the results are very different. Caffe is now the fastest framework, three times
faster than DLL. DLL is less than two times slower than Keras and TensorFlow.
Interestingly, DLL is still faster than Torch and DeepLearning4J.</p>
</section><section id="mnist-convolutional-neural-network"><h2>MNIST: Convolutional Neural Network</h2>
<p>Although a Fully-Connected Neural Network is an interesting tool, the trend now
is to use Convolutional Neural Network which have proved very efficient at
solving a lot of problems. The second experiment is also using the same data
set. Again, it's a rather small network. The first layer is a convolutional
layer with 8 5x5 kernels, followed by max pooling layer with 2x2 kernel. They
are followed by one more convolutional layers with 8 5x5 kernels and a 2x2 max
pooling layer. These first four layers are followed by two fully-connected
layers, the first with 150 hidden units and the last one with 10 output units.
The activation functions are the same as for the first network, as is the
training procedure. This takes significantly longer to train than the first
network because of the higher complexity of the convolutional layers compared to
the fully-connected layers even though they have much less weights. The results
are present in the next figure:</p>
<figure class="align-center"><img alt="Training time performance for the different frameworks on the Convolutional Neural Network experiment, on MNIST." src="images/dll_cnn.png"><figcaption><p>Training time performance for the different frameworks on the Convolutional
Neural Network experiment, on MNIST. All the times are in seconds.</p>
</figcaption></figure><p>Again, on CPU, DLL is the clear winner, by a lot! It's already 3.6 times faster
than the second frameworks Keras and TensorFlow, more than four times faster
than Caffe and Torch and 8 times faster than DeepLearning4J that is proving very
slow on this experiment. Once a GPU is added, Keras and TensorFlow are about
twice faster than DLL. However, DLL is still faster than the other frameworks
even though they are taking advantage of the GPU.</p>
</section><section id="cifar-10"><h2>CIFAR-10</h2>
<p>The second data set that is tested is the CIFAR-10 data set. It's an object
recognition with 10 classes for classification. The training set is composed of
50'000 colour images for 32x32 pixels. The network that is used for this data
set is similar in architecture than the first network, but has more parameters.
The first convolutional layer now has 12 5x5 kernels and the second
convolutional layer has 24 3x3 kernels. The pooling layers are the same. The
first fully-connected has 64 hidden units and the last one has 10 output units.
The last layer again use a softmax activation function while the other layers
are using Rectifier Linear Units (ReLU). The training is done in the same manner
as for the two first networks. Unfortunately, it was not possible to train
DeepLearning4J on this data set, even though there is official support for this
data set. Since I've had no answer to my question regarding this issue, the
results are simply removed from this experiment. It may not seem so but it's
considerably longer to train this network because of the larger number of input
channels and larger number of convolutional kernels in each layer. Let's get to
the results now:</p>
<figure class="align-center"><img alt="Training time performance for the different frameworks on the Convolutional Neural Network experiment, on CIFAR-10." src="images/dll_cifar10.png"><figcaption><p>Training time performance for the different frameworks on the Convolutional
Neural Network experiment, on CIFAR-10. All the times are in seconds.</p>
</figcaption></figure><p>DLL is still the fastest on CPU, but the margin is less than before. It's about
40% faster than TensorFlow and Keras, twice faster than Torch and 2.6 times
faster than Caffe. Once a GPU is added, DLL is about as fast as Torch but slower
than the other three frameworks. TensorFlow and Keras are about four times
faster than DLL while Caffe is about twice faster than DLL. We can see that
with this larger network, the GPU becomes more interesting and that there is
a smaller margin for improvements compared to the other frameworks.</p>
</section><section id="imagenet"><h2>ImageNet</h2>
<p>The last experiment is made on the ImageNet data set. I used the ILSVRC 2012
subset, that consists "only" of about 1.2 million images for training. I've
resized all the images to 256x256 pixels, this makes for 250 times more colour
values than a MNIST image. This dimension and the number of images makes it
impractical to keep the dataset in memory. The images must be loaded in batch
from the disk. No random cropping or mirroring was performed. The network is
much larger to solve this task. The network starts with 5 pairs of convolutional
layers and max pooling layers. The convolutional layers have 3x3 kernels, 16 for
the first two layers and 32 for the three following one. The five max pooling
layers use 2x2 kernels. Each convolutional layer uses zero-padding so that their
output features are the same dimensions as the input. They are followed by two
fully-connected layer. The first one with 2048 hidden units and the last one
with 1000 output units (one for each class). Except for the last layer, using
softmax, the layers all uses ReLU. The network is trained with mini-batches of
128 images (except for DeepLearning4J and Torch, which can only use 64 images on
the amount of RAM available on my machine). To ease the comparison, I report the
time necessary to train one batch of data (or two for DeepLearning4J and Torch).
The results, presented in logarithmic scale because of DeepLearning4J disastrous
results, are as follows:</p>
<figure class="align-center"><img alt="Training time performance for the different frameworks on the Convolutional Neural Network experiment, on ImageNet." src="images/dll_imagenet.png"><figcaption><p>Training time performance for the different frameworks on the Convolutional
Neural Network experiment, on ImageNet. The times are the time necessary to
train a batch of 128 images. All the times are in milliseconds.</p>
</figcaption></figure><p>For this final experiment, DLL is again significantly faster than all the other
frameworks. It's about 40% faster than Keras, twice faster than TensorFlow and
Caffe and more than three times faster than Torch. Although 40% may seem not
that much, don't forget that this kind of training may take days, so it can save
you a lot of time. All the frameworks are much faster than DeepLearning4J. Based
on several posts on the internet, I suspect that this comes from the model of
GPU I have been used (GTX 960), but all the other frameworks seem to handle this
card pretty well.</p>
</section><section id="conclusion-2"><h2>Conclusion</h2>
<p>I hope this is not too much of a bragging post :P We can see that my efforts to
make the code as fast as possible have paid :) As was shown in the experiments,
my DLL framework is always the fastest framework when the neural network is
trained on CPU. I'm quite pleased with the results since I've done a lot of work
to optimize the speed as much as possible and since I'm competing with
well-known libraries that have been developed by several persons.  Moreover, the
accuracies of the trained networks is similar to that of the networks trained
with the other frameworks. Even when the other frameworks are using GPU, the
library still remains competitive, although never the fastest.</p>
<p>In the next step (I've no idea when I'll have the time though), I will want to
focus on GPU speed. This will mostly come from a better support of the GPU in
the ETL library on which DLL is based. I have many ideas to improve it a lot,
but it will take me a lot of time.</p>
<p>If you want more information on the DLL library, you can have a look at
<a class="reference external" href="https://github.com/wichtounet/dll">its Github repository</a> and especially at
<a class="reference external" href="https://github.com/wichtounet/dll/tree/master/examples/src">the few examples</a>.
You can also have a look at <a class="reference external" href="https://baptiste-wicht.com/categories/dll.html">my posts about DLL</a>.
Finally, don't hesitate to comment or contact me through Github issues if you
have comments or problems with this post, the library or anything ;)</p>
</section>
</div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/2017/08/compiler-benchmark-gcc-clang-cpp-library-etl.html" class="u-url">Compiler benchmark GCC and Clang on C++ library (ETL)</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Baptiste Wicht
            </span></p>
            <p class="dateline">
            <a href="posts/2017/08/compiler-benchmark-gcc-clang-cpp-library-etl.html" rel="bookmark">
            <time class="published dt-published" datetime="2017-08-07T09:16:21+02:00" itemprop="datePublished" title="2017-08-07 09:16">2017-08-07 09:16</time></a>
            </p>
                <p class="commentline">
    
    <a href="posts/2017/08/compiler-benchmark-gcc-clang-cpp-library-etl.html#disqus_thread" data-disqus-identifier="cache/posts/2017/08/compiler-benchmark-gcc-clang-cpp-library-etl.html">Comments</a>


        </p>
</div>
    </header><div class="p-summary entry-summary">
    <p>It's been a while since I've done a benchmark of different compilers on C++
code. Since I've recently
<a class="reference external" href="https://baptiste-wicht.com/posts/2017/08/expression-templates-library-etl-11.html">released the version 1.1 of my ETL project</a>
(an optimized matrix/vector computation library with expression templates), I've
decided to use it as the base of my benchmark. It's a C++14 library with a lot
of templates. I'm going to compile the full test suite (124 test cases). This is
done directly on the last release (1.1) code. I'm going to compile once in debug
mode and once in release_debug (release plus debug symbols and assertions) and
record the times for each compiler. The tests were compiled with support for
every option in ETL to account to maximal compilation time. Each compilation was
made using four threads (make -j4). I'm also going to test a few of the
benchmarks to see the difference in runtime performance between the code
generated by each compiler. The benchmark will be compiled in release mode and
its compilation time recorded as well.</p>
<p>I'm going to test the following compilers:</p>
<ul class="simple">
<li><p>GCC-4.9.4</p></li>
<li><p>GCC-5.4.0</p></li>
<li><p>GCC-6.3.0</p></li>
<li><p>GCC-7.1.0</p></li>
<li><p>clang-3.9.1</p></li>
<li><p>clang-4.0.1</p></li>
<li><p>zapcc-1.0 (commercial, based on clang-5.0 trunk)</p></li>
</ul>
<p>All have been installed directly using Portage (Gentoo package manager) except
for clang-4.0.1 that has been installed from sources and zapcc since it does not
have a Gentoo package. Since clang package on Gentoo does not support
multislotting, I had to install one version from source and the other from the
package manager. This is also the reason I'm testing less versions of clang,
simply less practical.</p>
<p>For the purpose of these tests, the exact same options have been used throughout
all the compilers. Normally, I use different options for clang than for GCC
(mainly more aggressive vectorization options on clang). This may not lead to
the best performance for each compiler, but allows for comparison between the
results with defaults optimization level. Here are the main options used:</p>
<ul class="simple">
<li><p>In debug mode: -g</p></li>
<li><p>In release_debug mode: -g -O2</p></li>
<li><p>In release mode: -g -O3 -DNDEBUG -fomit-frame-pointer</p></li>
</ul>
<p>In each case, a lot of warnings are enabled and the ETL options are the same.</p>
<p>All the results have been gathered on a Gentoo machine running on Intel Core
i7-2600 (Sandy Bridge...) @3.4GHz with 4 cores and 8 threads, 12Go of RAM and
a SSD. I do my best to isolate as much as possible the benchmark from
perturbations and that my benchmark code is quite sound, it may well be that
some results are not totally accurate. Moreover, some of the benchmarks are
using multithreading, which may add some noise and unpredictability. When I was
not sure about the results, I ran the benchmarks several time to confirm them
and overall I'm confident of the results.</p>
<section id="compilation-time"><h2>Compilation Time</h2>
<p>Let's start with the results of the performance of the compilers themselves:</p>
<table>
<thead><tr>
<th class="head"><p>Compiler</p></th>
<th class="head"><p>Debug</p></th>
<th class="head"><p>Release_Debug</p></th>
<th class="head"><p>Benchmark</p></th>
</tr></thead>
<tbody>
<tr>
<td><p>g++-4.9.4</p></td>
<td><p>402s</p></td>
<td><p>616s</p></td>
<td><p>100s</p></td>
</tr>
<tr>
<td><p>g++-5.4.0</p></td>
<td><p>403s</p></td>
<td><p>642s</p></td>
<td><p>95s</p></td>
</tr>
<tr>
<td><p>g++-6.3.0</p></td>
<td><p>399s</p></td>
<td><p>683s</p></td>
<td><p>102s</p></td>
</tr>
<tr>
<td><p>g++-7.1.0</p></td>
<td><p>371s</p></td>
<td><p>650s</p></td>
<td><p>105s</p></td>
</tr>
<tr>
<td><p>clang++-3.9.1</p></td>
<td><p>380s</p></td>
<td><p>807s</p></td>
<td><p>106s</p></td>
</tr>
<tr>
<td><p>clang++-4.0.1</p></td>
<td><p>260s</p></td>
<td><p>718s</p></td>
<td><p>92s</p></td>
</tr>
<tr>
<td><p>zapcc++-1.0</p></td>
<td><p>221s</p></td>
<td><p>649s</p></td>
<td><p>108s</p></td>
</tr>
</tbody>
</table>
<p>Note: For Release_Debug and Benchmark, I only use three threads with zapcc,
because 12Go of RAM is not enough memory for four threads.</p>
<p>There are some very significant differences between the different compilers.
Overall, clang-4.0.1 is by far the fastest free compiler for Debug mode. When
the tests are compiled with optimizations however, clang is falling behind.
It's quite impressive how clang-4.0.1 manages to be so much faster than
clang-3.9.1 both in debug mode and release mode. Really great work by the clang
team here! With these optimizations, clang-4.0.1 is almost on par with gcc-7.1
in release mode.  For GCC, it seems that the cost of optimization has been going
up quite significantly. However, GCC 7.1 seems to have made optimization faster
and standard compilation much faster as well. If we take into account zapcc,
it's the fastest compiler on debug mode, but it's slower than several gcc
versions on release mode.</p>
<p>Overall, I'm quite impressed by the performance of clang-4.0.1 which seems
really fast! I'll definitely make more tests with this new version of the
compiler in the near future. It's also good to see that g++-7.1 also did make
the build faster than gcc-6.3. However, the fastest gcc version for optimization
is still gcc-4.9.4 which is already an old branch with low C++ standard support.</p>
</section><section id="runtime-performance"><h2>Runtime Performance</h2>
<p>Let's now take a look at the quality of the generated code. For some of the
benchmarks, I've included two versions of the algorithm. <em>std</em> is the most
simple algorithm (the naive one) and <em>vec</em> is the hand-crafted vectorized and
optimized implementation. All the tests were done on single-precision floating
points.</p>
<section id="dot-product"><h3>Dot product</h3>
<p>The first benchmark that is run is to compute the dot product between two
vectors. Let's look first at the naive version:</p>
<table>
<thead><tr>
<th class="head"><p>dot (std)</p></th>
<th class="head"><p>100</p></th>
<th class="head"><p>500</p></th>
<th class="head"><p>1000</p></th>
<th class="head"><p>10000</p></th>
<th class="head"><p>100000</p></th>
<th class="head"><p>1000000</p></th>
<th class="head"><p>2000000</p></th>
<th class="head"><p>3000000</p></th>
<th class="head"><p>4000000</p></th>
<th class="head"><p>5000000</p></th>
<th class="head"><p>10000000</p></th>
</tr></thead>
<tbody>
<tr>
<td><p>g++-4.9.4</p></td>
<td><p>64.96ns</p></td>
<td><p>97.12ns</p></td>
<td><p>126.07ns</p></td>
<td><p>1.89us</p></td>
<td><p>25.91us</p></td>
<td><p>326.49us</p></td>
<td><p>1.24ms</p></td>
<td><p>1.92ms</p></td>
<td><p>2.55ms</p></td>
<td><p>3.22ms</p></td>
<td><p>6.36ms</p></td>
</tr>
<tr>
<td><p>g++-5.4.0</p></td>
<td><p>72.96ns</p></td>
<td><p>101.62ns</p></td>
<td><p>127.89ns</p></td>
<td><p>1.90us</p></td>
<td><p>23.39us</p></td>
<td><p>357.63us</p></td>
<td><p>1.23ms</p></td>
<td><p>1.91ms</p></td>
<td><p>2.57ms</p></td>
<td><p>3.20ms</p></td>
<td><p>6.32ms</p></td>
</tr>
<tr>
<td><p>g++-6.3.0</p></td>
<td><p>73.31ns</p></td>
<td><p>102.88ns</p></td>
<td><p>130.16ns</p></td>
<td><p>1.89us</p></td>
<td><p>24.314us</p></td>
<td><p>339.13us</p></td>
<td><p>1.47ms</p></td>
<td><p>2.16ms</p></td>
<td><p>2.95ms</p></td>
<td><p>3.70ms</p></td>
<td><p>6.69ms</p></td>
</tr>
<tr>
<td><p>g++-7.1.0</p></td>
<td><p>70.20ns</p></td>
<td><p>104.09ns</p></td>
<td><p>130.98ns</p></td>
<td><p>1.90us</p></td>
<td><p>23.96us</p></td>
<td><p>281.47us</p></td>
<td><p>1.24ms</p></td>
<td><p>1.93ms</p></td>
<td><p>2.58ms</p></td>
<td><p>3.19ms</p></td>
<td><p>6.33ms</p></td>
</tr>
<tr>
<td><p>clang++-3.9.1</p></td>
<td><p>64.69ns</p></td>
<td><p>98.69ns</p></td>
<td><p>128.60ns</p></td>
<td><p>1.89us</p></td>
<td><p>23.33us</p></td>
<td><p>272.71us</p></td>
<td><p>1.24ms</p></td>
<td><p>1.91ms</p></td>
<td><p>2.56ms</p></td>
<td><p>3.19ms</p></td>
<td><p>6.37ms</p></td>
</tr>
<tr>
<td><p>clang++-4.0.1</p></td>
<td><p>60.31ns</p></td>
<td><p>96.34ns</p></td>
<td><p>128.90ns</p></td>
<td><p>1.89us</p></td>
<td><p>22.87us</p></td>
<td><p>270.21us</p></td>
<td><p>1.23ms</p></td>
<td><p>1.91ms</p></td>
<td><p>2.55ms</p></td>
<td><p>3.18ms</p></td>
<td><p>6.35ms</p></td>
</tr>
<tr>
<td><p>zapcc++-1.0</p></td>
<td><p>61.14ns</p></td>
<td><p>96.92ns</p></td>
<td><p>125.95ns</p></td>
<td><p>1.89us</p></td>
<td><p>23.84us</p></td>
<td><p>285.80us</p></td>
<td><p>1.24ms</p></td>
<td><p>1.92ms</p></td>
<td><p>2.55ms</p></td>
<td><p>3.16ms</p></td>
<td><p>6.34ms</p></td>
</tr>
</tbody>
</table>
<p>The differences are not very significant between the different compilers. The
clang-based compilers seem to be the compilers producing the fastest code.
Interestingly, there seem to have been a big regression in gcc-6.3 for large
containers, but that has been fixed in gcc-7.1.</p>
<table>
<thead><tr>
<th class="head"><p>dot (vec)</p></th>
<th class="head"><p>100</p></th>
<th class="head"><p>500</p></th>
<th class="head"><p>1000</p></th>
<th class="head"><p>10000</p></th>
<th class="head"><p>100000</p></th>
<th class="head"><p>1000000</p></th>
<th class="head"><p>2000000</p></th>
<th class="head"><p>3000000</p></th>
<th class="head"><p>4000000</p></th>
<th class="head"><p>5000000</p></th>
<th class="head"><p>10000000</p></th>
</tr></thead>
<tbody>
<tr>
<td><p>g++-4.9.4</p></td>
<td><p>48.34ns</p></td>
<td><p>80.53ns</p></td>
<td><p>114.97ns</p></td>
<td><p>1.72us</p></td>
<td><p>22.79us</p></td>
<td><p>354.20us</p></td>
<td><p>1.24ms</p></td>
<td><p>1.89ms</p></td>
<td><p>2.52ms</p></td>
<td><p>3.19ms</p></td>
<td><p>6.55ms</p></td>
</tr>
<tr>
<td><p>g++-5.4.0</p></td>
<td><p>47.16ns</p></td>
<td><p>77.70ns</p></td>
<td><p>113.66ns</p></td>
<td><p>1.72us</p></td>
<td><p>22.71us</p></td>
<td><p>363.86us</p></td>
<td><p>1.24ms</p></td>
<td><p>1.89ms</p></td>
<td><p>2.52ms</p></td>
<td><p>3.19ms</p></td>
<td><p>6.56ms</p></td>
</tr>
<tr>
<td><p>g++-6.3.0</p></td>
<td><p>46.39ns</p></td>
<td><p>77.67ns</p></td>
<td><p>116.28ns</p></td>
<td><p>1.74us</p></td>
<td><p>23.39us</p></td>
<td><p>452.44us</p></td>
<td><p>1.45ms</p></td>
<td><p>2.26ms</p></td>
<td><p>2.87ms</p></td>
<td><p>3.49ms</p></td>
<td><p>7.52ms</p></td>
</tr>
<tr>
<td><p>g++-7.1.0</p></td>
<td><p>49.70ns</p></td>
<td><p>80.40ns</p></td>
<td><p>115.77ns</p></td>
<td><p>1.71us</p></td>
<td><p>22.46us</p></td>
<td><p>355.16us</p></td>
<td><p>1.21ms</p></td>
<td><p>1.85ms</p></td>
<td><p>2.49ms</p></td>
<td><p>3.14ms</p></td>
<td><p>6.47ms</p></td>
</tr>
<tr>
<td><p>clang++-3.9.1</p></td>
<td><p>46.13ns</p></td>
<td><p>78.01ns</p></td>
<td><p>114.70ns</p></td>
<td><p>1.66us</p></td>
<td><p>22.82us</p></td>
<td><p>359.42us</p></td>
<td><p>1.24ms</p></td>
<td><p>1.88ms</p></td>
<td><p>2.53ms</p></td>
<td><p>3.16ms</p></td>
<td><p>6.50ms</p></td>
</tr>
<tr>
<td><p>clang++-4.0.1</p></td>
<td><p>45.59ns</p></td>
<td><p>74.90ns</p></td>
<td><p>111.29ns</p></td>
<td><p>1.57us</p></td>
<td><p>22.47us</p></td>
<td><p>351.31us</p></td>
<td><p>1.23ms</p></td>
<td><p>1.85ms</p></td>
<td><p>2.49ms</p></td>
<td><p>3.12ms</p></td>
<td><p>6.45ms</p></td>
</tr>
<tr>
<td><p>zapcc++-1.0</p></td>
<td><p>45.11ns</p></td>
<td><p>75.04ns</p></td>
<td><p>111.28ns</p></td>
<td><p>1.59us</p></td>
<td><p>22.46us</p></td>
<td><p>357.32us</p></td>
<td><p>1.25ms</p></td>
<td><p>1.89ms</p></td>
<td><p>2.53ms</p></td>
<td><p>3.15ms</p></td>
<td><p>6.47ms</p></td>
</tr>
</tbody>
</table>
<p>If we look at the optimized version, the differences are even slower. Again, the
clang-based compilers are producing the fastest executables, but are closely
followed by gcc, except for gcc-6.3 in which we can still see the same
regression as before.</p>
</section><section id="logistic-sigmoid"><h3>Logistic Sigmoid</h3>
<p>The next test is to check the performance of the sigmoid operation. In that
case, the evaluator of the library will try to use parallelization and
vectorization to compute it. Let's see how the different compilers fare:</p>
<table>
<thead><tr>
<th class="head"><p>sigmoid</p></th>
<th class="head"><p>10</p></th>
<th class="head"><p>100</p></th>
<th class="head"><p>1000</p></th>
<th class="head"><p>10000</p></th>
<th class="head"><p>100000</p></th>
<th class="head"><p>1000000</p></th>
</tr></thead>
<tbody>
<tr>
<td><p>g++-4.9.4</p></td>
<td><p>8.16us</p></td>
<td><p>5.23us</p></td>
<td><p>6.33us</p></td>
<td><p>29.56us</p></td>
<td><p>259.72us</p></td>
<td><p>2.78ms</p></td>
</tr>
<tr>
<td><p>g++-5.4.0</p></td>
<td><p>7.07us</p></td>
<td><p>5.08us</p></td>
<td><p>6.39us</p></td>
<td><p>29.44us</p></td>
<td><p>266.27us</p></td>
<td><p>2.96ms</p></td>
</tr>
<tr>
<td><p>g++-6.3.0</p></td>
<td><p>7.13us</p></td>
<td><p>5.32us</p></td>
<td><p>6.45us</p></td>
<td><p>28.99us</p></td>
<td><p>261.81us</p></td>
<td><p>2.86ms</p></td>
</tr>
<tr>
<td><p>g++-7.1.0</p></td>
<td><p>7.03us</p></td>
<td><p>5.09us</p></td>
<td><p>6.24us</p></td>
<td><p>28.61us</p></td>
<td><p>252.78us</p></td>
<td><p>2.71ms</p></td>
</tr>
<tr>
<td><p>clang++-3.9.1</p></td>
<td><p>7.30us</p></td>
<td><p>5.25us</p></td>
<td><p>6.57us</p></td>
<td><p>30.24us</p></td>
<td><p>256.75us</p></td>
<td><p>1.99ms</p></td>
</tr>
<tr>
<td><p>clang++-4.0.1</p></td>
<td><p>7.47us</p></td>
<td><p>5.14us</p></td>
<td><p>5.77us</p></td>
<td><p>26.03us</p></td>
<td><p>235.87us</p></td>
<td><p>1.81ms</p></td>
</tr>
<tr>
<td><p>zapcc++-1.0</p></td>
<td><p>7.51us</p></td>
<td><p>5.26us</p></td>
<td><p>6.48us</p></td>
<td><p>28.86us</p></td>
<td><p>258.31us</p></td>
<td><p>1.95ms</p></td>
</tr>
</tbody>
</table>
<p>Interestingly, we can see that gcc-7.1 is the fastest for small vectors while
clang-4.0 is the best for producing code for larger vectors. However, except for
the biggest vector size, the difference is not really significantly. Apparently,
there is a regression in zapcc (or clang-5.0) since it's slower than clang-4.0
at the same level as clang-3.9.</p>
</section><section id="y-alpha-x-y-axpy"><h3>y = alpha * x + y (axpy)</h3>
<p>The third benchmark is the well-known axpy (y = alpha * x + y). This is entirely
resolved by expressions templates in the library, no specific algorithm is used.
Let's see the results:</p>
<table>
<thead><tr>
<th class="head"><p>saxpy</p></th>
<th class="head"><p>10</p></th>
<th class="head"><p>100</p></th>
<th class="head"><p>1000</p></th>
<th class="head"><p>10000</p></th>
<th class="head"><p>100000</p></th>
<th class="head"><p>1000000</p></th>
</tr></thead>
<tbody>
<tr>
<td><p>g++-4.9.4</p></td>
<td><p>38.1ns</p></td>
<td><p>61.6ns</p></td>
<td><p>374ns</p></td>
<td><p>3.65us</p></td>
<td><p>40.8us</p></td>
<td><p>518us</p></td>
</tr>
<tr>
<td><p>g++-5.4.0</p></td>
<td><p>35.0ns</p></td>
<td><p>58.1ns</p></td>
<td><p>383ns</p></td>
<td><p>3.87us</p></td>
<td><p>43.2us</p></td>
<td><p>479us</p></td>
</tr>
<tr>
<td><p>g++-6.3.0</p></td>
<td><p>34.3ns</p></td>
<td><p>59.4ns</p></td>
<td><p>371ns</p></td>
<td><p>3.57us</p></td>
<td><p>40.4us</p></td>
<td><p>452us</p></td>
</tr>
<tr>
<td><p>g++-7.1.0</p></td>
<td><p>34.8ns</p></td>
<td><p>59.7ns</p></td>
<td><p>399ns</p></td>
<td><p>3.78us</p></td>
<td><p>43.1us</p></td>
<td><p>547us</p></td>
</tr>
<tr>
<td><p>clang++-3.9.1</p></td>
<td><p>32.3ns</p></td>
<td><p>53.8ns</p></td>
<td><p>297ns</p></td>
<td><p>3.21us</p></td>
<td><p>38.3us</p></td>
<td><p>466us</p></td>
</tr>
<tr>
<td><p>clang++-4.0.1</p></td>
<td><p>32.4ns</p></td>
<td><p>59.8ns</p></td>
<td><p>296ns</p></td>
<td><p>3.31us</p></td>
<td><p>38.2us</p></td>
<td><p>475us</p></td>
</tr>
<tr>
<td><p>zapcc++-1.0</p></td>
<td><p>32.0ns</p></td>
<td><p>54.0ns</p></td>
<td><p>333ns</p></td>
<td><p>3.32us</p></td>
<td><p>38.7us</p></td>
<td><p>447us</p></td>
</tr>
</tbody>
</table>
<p>Even on the biggest vector, this is a very fast operation, once vectorized and
parallelized. At this speed, some of the differences observed may not be highly
significant. Again clang-based versions are the fastest versions on this code,
but by a small margin.  There also seems to be a slight regression in gcc-7.1,
but again quite small.</p>
</section><section id="matrix-matrix-multiplication-gemm"><h3>Matrix Matrix multiplication (GEMM)</h3>
<p>The next benchmark is testing the performance of a Matrix-Matrix Multiplication,
an operation known as GEMM in the BLAS nomenclature. In that case, we test both
the naive and the optimized vectorized implementation. To save some horizontal
space, I've split the tables in two.</p>
<table>
<thead><tr>
<th class="head"><p>sgemm (std)</p></th>
<th class="head"><p>10</p></th>
<th class="head"><p>20</p></th>
<th class="head"><p>40</p></th>
<th class="head"><p>60</p></th>
<th class="head"><p>80</p></th>
<th class="head"><p>100</p></th>
</tr></thead>
<tbody>
<tr>
<td><p>g++-4.9.4</p></td>
<td><p>7.04us</p></td>
<td><p>50.15us</p></td>
<td><p>356.42us</p></td>
<td><p>1.18ms</p></td>
<td><p>3.41ms</p></td>
<td><p>5.56ms</p></td>
</tr>
<tr>
<td><p>g++-5.4.0</p></td>
<td><p>8.14us</p></td>
<td><p>74.77us</p></td>
<td><p>513.64us</p></td>
<td><p>1.72ms</p></td>
<td><p>4.05ms</p></td>
<td><p>7.92ms</p></td>
</tr>
<tr>
<td><p>g++-6.3.0</p></td>
<td><p>8.03us</p></td>
<td><p>64.78us</p></td>
<td><p>504.41us</p></td>
<td><p>1.69ms</p></td>
<td><p>4.02ms</p></td>
<td><p>7.87ms</p></td>
</tr>
<tr>
<td><p>g++-7.1.0</p></td>
<td><p>7.95us</p></td>
<td><p>65.00us</p></td>
<td><p>508.84us</p></td>
<td><p>1.69ms</p></td>
<td><p>4.02ms</p></td>
<td><p>7.84ms</p></td>
</tr>
<tr>
<td><p>clang++-3.9.1</p></td>
<td><p>3.58us</p></td>
<td><p>28.59us</p></td>
<td><p>222.36us</p></td>
<td><p>0.73ms</p></td>
<td><p>1.77us</p></td>
<td><p>3.41ms</p></td>
</tr>
<tr>
<td><p>clang++-4.0.1</p></td>
<td><p>4.00us</p></td>
<td><p>25.47us</p></td>
<td><p>190.56us</p></td>
<td><p>0.61ms</p></td>
<td><p>1.45us</p></td>
<td><p>2.80ms</p></td>
</tr>
<tr>
<td><p>zapcc++-1.0</p></td>
<td><p>4.00us</p></td>
<td><p>25.38us</p></td>
<td><p>189.98us</p></td>
<td><p>0.60ms</p></td>
<td><p>1.43us</p></td>
<td><p>2.81ms</p></td>
</tr>
</tbody>
</table>
<table>
<thead><tr>
<th class="head"><p>sgemm (std)</p></th>
<th class="head"><p>200</p></th>
<th class="head"><p>300</p></th>
<th class="head"><p>400</p></th>
<th class="head"><p>500</p></th>
<th class="head"><p>600</p></th>
<th class="head"><p>700</p></th>
<th class="head"><p>800</p></th>
<th class="head"><p>900</p></th>
<th class="head"><p>1000</p></th>
<th class="head"><p>1200</p></th>
</tr></thead>
<tbody>
<tr>
<td><p>g++-4.9.4</p></td>
<td><p>44.16ms</p></td>
<td><p>148.88ms</p></td>
<td><p>455.81ms</p></td>
<td><p>687.96ms</p></td>
<td><p>1.47s</p></td>
<td><p>1.98s</p></td>
<td><p>2.81s</p></td>
<td><p>4.00s</p></td>
<td><p>5.91s</p></td>
<td><p>9.52s</p></td>
</tr>
<tr>
<td><p>g++-5.4.0</p></td>
<td><p>63.17ms</p></td>
<td><p>213.01ms</p></td>
<td><p>504.83ms</p></td>
<td><p>984.90ms</p></td>
<td><p>1.70s</p></td>
<td><p>2.70s</p></td>
<td><p>4.03s</p></td>
<td><p>5.74s</p></td>
<td><p>7.87s</p></td>
<td><p>14.905</p></td>
</tr>
<tr>
<td><p>g++-6.3.0</p></td>
<td><p>64.04ms</p></td>
<td><p>212.12ms</p></td>
<td><p>502.95ms</p></td>
<td><p>981.74ms</p></td>
<td><p>1.69s</p></td>
<td><p>2.69s</p></td>
<td><p>4.13s</p></td>
<td><p>5.85s</p></td>
<td><p>8.10s</p></td>
<td><p>14.08s</p></td>
</tr>
<tr>
<td><p>g++-7.1.0</p></td>
<td><p>62.57ms</p></td>
<td><p>210.72ms</p></td>
<td><p>499.68ms</p></td>
<td><p>974.94ms</p></td>
<td><p>1.68s</p></td>
<td><p>2.67s</p></td>
<td><p>3.99s</p></td>
<td><p>5.68s</p></td>
<td><p>7.85s</p></td>
<td><p>13.49s</p></td>
</tr>
<tr>
<td><p>clang++-3.9.1</p></td>
<td><p>27.48ms</p></td>
<td><p>90.85ms</p></td>
<td><p>219.34ms</p></td>
<td><p>419.53ms</p></td>
<td><p>0.72s</p></td>
<td><p>1.18s</p></td>
<td><p>1.90s</p></td>
<td><p>2.44s</p></td>
<td><p>3.36s</p></td>
<td><p>5.84s</p></td>
</tr>
<tr>
<td><p>clang++-4.0.1</p></td>
<td><p>22.01ms</p></td>
<td><p>73.90ms</p></td>
<td><p>175.02ms</p></td>
<td><p>340.70ms</p></td>
<td><p>0.58s</p></td>
<td><p>0.93s</p></td>
<td><p>1.40s</p></td>
<td><p>1.98s</p></td>
<td><p>2.79s</p></td>
<td><p>4.69s</p></td>
</tr>
<tr>
<td><p>zapcc++-1.0</p></td>
<td><p>22.33ms</p></td>
<td><p>75.80ms</p></td>
<td><p>181.27ms</p></td>
<td><p>359.13ms</p></td>
<td><p>0.63s</p></td>
<td><p>1.02s</p></td>
<td><p>1.52s</p></td>
<td><p>2.24s</p></td>
<td><p>3.21s</p></td>
<td><p>5.62s</p></td>
</tr>
</tbody>
</table>
<p>This time, the differences between the different compilers are very significant.
The clang compilers are leading the way by a large margin here, with clang-4.0
being the fastest of them (by another nice margin). Indeed, clang-4.0.1 is
producing code that is, on average, about twice faster than the code generated
by the best GCC compiler. Very interestingly as well, we can see a huge
regression starting from GCC-5.4 and that is still here in GCC-7.1. Indeed, the
best GCC version, in the tested versions, is again GCC-4.9.4. Clang is really
doing an excellent job of compiling the GEMM code.</p>
<table>
<thead><tr>
<th class="head"><p>sgemm (vec)</p></th>
<th class="head"><p>10</p></th>
<th class="head"><p>20</p></th>
<th class="head"><p>40</p></th>
<th class="head"><p>60</p></th>
<th class="head"><p>80</p></th>
<th class="head"><p>100</p></th>
</tr></thead>
<tbody>
<tr>
<td><p>g++-4.9.4</p></td>
<td><p>264.27ns</p></td>
<td><p>0.95us</p></td>
<td><p>3.28us</p></td>
<td><p>14.77us</p></td>
<td><p>23.50us</p></td>
<td><p>60.37us</p></td>
</tr>
<tr>
<td><p>g++-5.4.0</p></td>
<td><p>271.41ns</p></td>
<td><p>0.99us</p></td>
<td><p>3.31us</p></td>
<td><p>14.811us</p></td>
<td><p>24.116us</p></td>
<td><p>61.00us</p></td>
</tr>
<tr>
<td><p>g++-6.3.0</p></td>
<td><p>279.72ns</p></td>
<td><p>1.02us</p></td>
<td><p>3.27us</p></td>
<td><p>15.39us</p></td>
<td><p>24.29us</p></td>
<td><p>61.99us</p></td>
</tr>
<tr>
<td><p>g++-7.1.0</p></td>
<td><p>273.74ns</p></td>
<td><p>0.96us</p></td>
<td><p>3.81us</p></td>
<td><p>15.55us</p></td>
<td><p>31.35us</p></td>
<td><p>71.11us</p></td>
</tr>
<tr>
<td><p>clang++-3.9.1</p></td>
<td><p>296.67ns</p></td>
<td><p>1.34us</p></td>
<td><p>4.18us</p></td>
<td><p>19.93us</p></td>
<td><p>33.15us</p></td>
<td><p>82.60us</p></td>
</tr>
<tr>
<td><p>clang++-4.0.1</p></td>
<td><p>322.68ns</p></td>
<td><p>1.38us</p></td>
<td><p>4.17us</p></td>
<td><p>20.19us</p></td>
<td><p>34.17us</p></td>
<td><p>83.64us</p></td>
</tr>
<tr>
<td><p>zapcc++-1.0</p></td>
<td><p>307.49ns</p></td>
<td><p>1.41us</p></td>
<td><p>4.10us</p></td>
<td><p>19.72us</p></td>
<td><p>33.72us</p></td>
<td><p>84.80us</p></td>
</tr>
</tbody>
</table>
<table>
<thead><tr>
<th class="head"><p>sgemm (vec)</p></th>
<th class="head"><p>200</p></th>
<th class="head"><p>300</p></th>
<th class="head"><p>400</p></th>
<th class="head"><p>500</p></th>
<th class="head"><p>600</p></th>
<th class="head"><p>700</p></th>
<th class="head"><p>800</p></th>
<th class="head"><p>900</p></th>
<th class="head"><p>1000</p></th>
<th class="head"><p>1200</p></th>
</tr></thead>
<tbody>
<tr>
<td><p>g++-4.9.4</p></td>
<td><p>369.52us</p></td>
<td><p>1.62ms</p></td>
<td><p>2.91ms</p></td>
<td><p>7.17ms</p></td>
<td><p>11.74ms</p></td>
<td><p>22.91ms</p></td>
<td><p>34.82ms</p></td>
<td><p>51.67ms</p></td>
<td><p>64.36ms</p></td>
<td><p>111.15ms</p></td>
</tr>
<tr>
<td><p>g++-5.4.0</p></td>
<td><p>387.54us</p></td>
<td><p>1.60ms</p></td>
<td><p>2.97ms</p></td>
<td><p>7.36ms</p></td>
<td><p>12.11ms</p></td>
<td><p>24.37ms</p></td>
<td><p>35.37ms</p></td>
<td><p>52.27ms</p></td>
<td><p>65.72ms</p></td>
<td><p>112.74ms</p></td>
</tr>
<tr>
<td><p>g++-6.3.0</p></td>
<td><p>384.43us</p></td>
<td><p>1.74ms</p></td>
<td><p>3.12ms</p></td>
<td><p>7.16ms</p></td>
<td><p>12.44ms</p></td>
<td><p>24.15ms</p></td>
<td><p>34.87ms</p></td>
<td><p>52.59ms</p></td>
<td><p>70.074ms</p></td>
<td><p>119.22ms</p></td>
</tr>
<tr>
<td><p>g++-7.1.0</p></td>
<td><p>458.05us</p></td>
<td><p>1.81ms</p></td>
<td><p>3.44ms</p></td>
<td><p>7.86ms</p></td>
<td><p>13.43ms</p></td>
<td><p>24.70ms</p></td>
<td><p>36.54ms</p></td>
<td><p>53.47ms</p></td>
<td><p>66.87ms</p></td>
<td><p>117.25ms</p></td>
</tr>
<tr>
<td><p>clang++-3.9.1</p></td>
<td><p>494.52us</p></td>
<td><p>1.96ms</p></td>
<td><p>4.80ms</p></td>
<td><p>8.88ms</p></td>
<td><p>18.20ms</p></td>
<td><p>29.37ms</p></td>
<td><p>41.24ms</p></td>
<td><p>60.72ms</p></td>
<td><p>72.28ms</p></td>
<td><p>123.75ms</p></td>
</tr>
<tr>
<td><p>clang++-4.0.1</p></td>
<td><p>511.24us</p></td>
<td><p>2.04ms</p></td>
<td><p>4.11ms</p></td>
<td><p>9.46ms</p></td>
<td><p>15.34ms</p></td>
<td><p>27.23ms</p></td>
<td><p>38.27ms</p></td>
<td><p>58.14ms</p></td>
<td><p>72.78ms</p></td>
<td><p>128.60ms</p></td>
</tr>
<tr>
<td><p>zapcc++-1.0</p></td>
<td><p>492.28us</p></td>
<td><p>2.03ms</p></td>
<td><p>3.90ms</p></td>
<td><p>9.00ms</p></td>
<td><p>14.31ms</p></td>
<td><p>25.72ms</p></td>
<td><p>37.09ms</p></td>
<td><p>55.79ms</p></td>
<td><p>67.88ms</p></td>
<td><p>119.92ms</p></td>
</tr>
</tbody>
</table>
<p>As for the optimized version, it seems that the two families are reversed.
Indeed, GCC is doing a better job than clang here, and although the margin is
not as big as before, it's still significant. We can still observe a small
regression in GCC versions because the 4.9 version is again the fastest. As for
clang versions, it seems that clang-5.0 (used in zapcc) has had some performance
improvements for this case.</p>
<p>For this case of matrix-matrix multiplication, it's very impressive that the
differences in the non-optimized code are so significant. And it's also
impressive that each family of compilers has its own strength, clang being
seemingly much better at handling unoptimized code while GCC is better at
handling vectorized code.</p>
</section><section id="convolution-2d"><h3>Convolution (2D)</h3>
<p>The last benchmark that I considered is the case of the valid convolution on 2D
images. The code is quite similar to the GEMM code but more complicated to
optimized due to cache locality.</p>
<table>
<thead><tr>
<th class="head"><p>sconv2_valid (std)</p></th>
<th class="head"><p>100x50</p></th>
<th class="head"><p>105x50</p></th>
<th class="head"><p>110x55</p></th>
<th class="head"><p>115x55</p></th>
<th class="head"><p>120x60</p></th>
<th class="head"><p>125x60</p></th>
<th class="head"><p>130x65</p></th>
<th class="head"><p>135x65</p></th>
<th class="head"><p>140x70</p></th>
</tr></thead>
<tbody>
<tr>
<td><p>g++-4.9.4</p></td>
<td><p>27.93ms</p></td>
<td><p>33.68ms</p></td>
<td><p>40.62ms</p></td>
<td><p>48.23ms</p></td>
<td><p>57.27ms</p></td>
<td><p>67.02ms</p></td>
<td><p>78.45ms</p></td>
<td><p>92.53ms</p></td>
<td><p>105.08ms</p></td>
</tr>
<tr>
<td><p>g++-5.4.0</p></td>
<td><p>37.60ms</p></td>
<td><p>44.94ms</p></td>
<td><p>54.24ms</p></td>
<td><p>64.45ms</p></td>
<td><p>76.63ms</p></td>
<td><p>89.75ms</p></td>
<td><p>105.08ms</p></td>
<td><p>121.66ms</p></td>
<td><p>140.95ms</p></td>
</tr>
<tr>
<td><p>g++-6.3.0</p></td>
<td><p>37.10ms</p></td>
<td><p>44.99ms</p></td>
<td><p>54.34ms</p></td>
<td><p>64.54ms</p></td>
<td><p>76.54ms</p></td>
<td><p>89.87ms</p></td>
<td><p>105.35ms</p></td>
<td><p>121.94ms</p></td>
<td><p>141.20ms</p></td>
</tr>
<tr>
<td><p>g++-7.1.0</p></td>
<td><p>37.55ms</p></td>
<td><p>45.08ms</p></td>
<td><p>54.39ms</p></td>
<td><p>64.48ms</p></td>
<td><p>76.51ms</p></td>
<td><p>92.02ms</p></td>
<td><p>106.16ms</p></td>
<td><p>125.67ms</p></td>
<td><p>143.57ms</p></td>
</tr>
<tr>
<td><p>clang++-3.9.1</p></td>
<td><p>15.42ms</p></td>
<td><p>18.59ms</p></td>
<td><p>22.21ms</p></td>
<td><p>26.40ms</p></td>
<td><p>31.03ms</p></td>
<td><p>36.26ms</p></td>
<td><p>42.35ms</p></td>
<td><p>48.87ms</p></td>
<td><p>56.29ms</p></td>
</tr>
<tr>
<td><p>clang++-4.0.1</p></td>
<td><p>15.48ms</p></td>
<td><p>18.67ms</p></td>
<td><p>22.34ms</p></td>
<td><p>26.50ms</p></td>
<td><p>31.27ms</p></td>
<td><p>36.58ms</p></td>
<td><p>42.61ms</p></td>
<td><p>49.33ms</p></td>
<td><p>56.80ms</p></td>
</tr>
<tr>
<td><p>zapcc++-1.0</p></td>
<td><p>15.29ms</p></td>
<td><p>18.37ms</p></td>
<td><p>22.00ms</p></td>
<td><p>26.10ms</p></td>
<td><p>30.75ms</p></td>
<td><p>35.95ms</p></td>
<td><p>41.85ms</p></td>
<td><p>48.42ms</p></td>
<td><p>55.74ms</p></td>
</tr>
</tbody>
</table>
<p>In that case, we can observe the same as for the GEMM. The clang-based versions
are much producing significantly faster code than the GCC versions. Moreover, we
can also observe the same large regression starting from GCC-5.4.</p>
<table>
<thead><tr>
<th class="head"><p>sconv2_valid (vec)</p></th>
<th class="head"><p>100x50</p></th>
<th class="head"><p>105x50</p></th>
<th class="head"><p>110x55</p></th>
<th class="head"><p>115x55</p></th>
<th class="head"><p>120x60</p></th>
<th class="head"><p>125x60</p></th>
<th class="head"><p>130x65</p></th>
<th class="head"><p>135x65</p></th>
<th class="head"><p>140x70</p></th>
</tr></thead>
<tbody>
<tr>
<td><p>g++-4.9.4</p></td>
<td><p>878.32us</p></td>
<td><p>1.07ms</p></td>
<td><p>1.20ms</p></td>
<td><p>1.68ms</p></td>
<td><p>2.04ms</p></td>
<td><p>2.06ms</p></td>
<td><p>2.54ms</p></td>
<td><p>3.20ms</p></td>
<td><p>4.14ms</p></td>
</tr>
<tr>
<td><p>g++-5.4.0</p></td>
<td><p>853.73us</p></td>
<td><p>1.03ms</p></td>
<td><p>1.15ms</p></td>
<td><p>1.36ms</p></td>
<td><p>1.76ms</p></td>
<td><p>2.05ms</p></td>
<td><p>2.44ms</p></td>
<td><p>2.91ms</p></td>
<td><p>3.13ms</p></td>
</tr>
<tr>
<td><p>g++-6.3.0</p></td>
<td><p>847.95us</p></td>
<td><p>1.02ms</p></td>
<td><p>1.14ms</p></td>
<td><p>1.35ms</p></td>
<td><p>1.74ms</p></td>
<td><p>1.98ms</p></td>
<td><p>2.43ms</p></td>
<td><p>2.90ms</p></td>
<td><p>3.12ms</p></td>
</tr>
<tr>
<td><p>g++-7.1.0</p></td>
<td><p>795.82us</p></td>
<td><p>0.93ms</p></td>
<td><p>1.05ms</p></td>
<td><p>1.24ms</p></td>
<td><p>1.60ms</p></td>
<td><p>1.77ms</p></td>
<td><p>2.20ms</p></td>
<td><p>2.69ms</p></td>
<td><p>2.81ms</p></td>
</tr>
<tr>
<td><p>clang++-3.9.1</p></td>
<td><p>782.46us</p></td>
<td><p>0.93ms</p></td>
<td><p>1.05ms</p></td>
<td><p>1.26ms</p></td>
<td><p>1.60ms</p></td>
<td><p>1.84ms</p></td>
<td><p>2.21ms</p></td>
<td><p>2.65ms</p></td>
<td><p>2.84ms</p></td>
</tr>
<tr>
<td><p>clang++-4.0.1</p></td>
<td><p>767.58us</p></td>
<td><p>0.92ms</p></td>
<td><p>1.04ms</p></td>
<td><p>1.25ms</p></td>
<td><p>1.59ms</p></td>
<td><p>1.83ms</p></td>
<td><p>2.20ms</p></td>
<td><p>2.62ms</p></td>
<td><p>2.83ms</p></td>
</tr>
<tr>
<td><p>zapcc++-1.0</p></td>
<td><p>782.49us</p></td>
<td><p>0.94ms</p></td>
<td><p>1.06ms</p></td>
<td><p>1.27ms</p></td>
<td><p>1.62ms</p></td>
<td><p>1.83ms</p></td>
<td><p>2.24ms</p></td>
<td><p>2.65ms</p></td>
<td><p>2.85ms</p></td>
</tr>
</tbody>
</table>
<p>This time, clang manages to produce excellent results. Indeed, all the produced
executables are significantly faster than the versions produced by GCC, except
for GCC-7.1 which is producing similar results. The other versions of GCC are
falling behind it seems. It seems that it was only for the GEMM that clang was
having a lot of troubles handling the optimized code.</p>
</section></section><section id="conclusion"><h2>Conclusion</h2>
<p>Clang seems to have recently done a lot of optimizations regarding compilation
time. Indeed, clang-4.0.1 is much faster for compilation than clang-3.9.
Although GCC-7.1 is faster than GCC-6.3, all the GCC versions are slower than
GCC-4.9.4 which is the fastest at compiling code with optimizations. GCC-7.1 is
the fastest GCC version for compiling code in debug mode.</p>
<p>In some cases, there is almost no difference between different compilers in the
generated code. However, in more  complex algorithms such as the matrix-matrix
multiplication or the two-dimensional convolution, the differences can be quite
significant. In my tests, Clang have shown to be much better at compiling
unoptimized code. However, and especially in the GEMM case, it seems to be worse
than GCC at handling hand-optimized. I will investigate that case and try to
tailor the code so that clang is having a better time with it.</p>
<p>For me, it's really weird that the GCC regression, apparently starting from
GCC-5.4, has still not been fixed in GCC 7.1. I was thinking of dropping support
for GCC-4.9 in order to go full C++14 support, but now I may have to reconsider
my position. However, seeing that GCC is generally the best at handling
optimized code (especially for GEMM), I may be able to do the transition, since
the optimized code will be used in most cases.</p>
<p>As for zapcc, although it is still the fastest compiler in debug mode, with the
new speed of clang-4.0.1, its margin is quite small. Moreover, on optimized
build, it's not as fast as GCC. If you use clang and can have access to zapcc,
it's still quite a good option to save some time.</p>
<p>Overall, I have been quite pleased by clang-4.0.1 and GCC-7.1, the most recent
versions I have been testing. It seems that they did quite some good work.
I will definitely run some more tests with them and try to adapt the code. I'm
still considering whether I will drop support for some older compilers.</p>
<p>I hope this comparison was interesting :) My next post will probably be about
the difference in performance between my machine learning framework and other
frameworks to train neural networks.</p>
</section>
</div>
    </article>
</div>

        <nav class="postindexpager"><ul class="pager">
<li class="previous">
                <a href="index-33.html" rel="prev">Newer posts</a>
            </li>
            <li class="next">
                <a href="index-31.html" rel="next">Older posts</a>
            </li>
        </ul></nav><script>var disqus_shortname="blogwichtounet";(function(){var a=document.createElement("script");a.async=true;a.src="https://"+disqus_shortname+".disqus.com/count.js";(document.getElementsByTagName("head")[0]||document.getElementsByTagName("body")[0]).appendChild(a)}());</script>
</div>
        <!--End of body content-->

        <footer id="footer">
            Contents © 2023         <a href="mailto:baptistewicht@gmail.com">Baptiste Wicht</a> - Powered by         <a href="http://getnikola.com" rel="nofollow">Nikola</a>         - License: 
<a rel="license" href="http://creativecommons.org/licenses/by/4.0/"><img alt="Creative Commons License" style="padding-left:5px;border-width:0" src="assets/img/cc.png"></a>
            
        </footer>
</div>
</div>


            <script src="assets/js/all-nocdn.js"></script><!-- fancy dates --><script>
    moment.locale("en");
    fancydates(0, "YYYY-MM-DD HH:mm");
    </script><!-- end fancy dates --><script>
    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element) {
            return element.getElementsByTagName('img')[0].alt;
    }});
    </script>
</body>
</html>