{
  "pages": [
    {
      "loc": "/stories/search.html", 
      "title": "Search results", 
      "text": "$(document).ready(function() {\n        $('#tipue_search_input').tipuesearch({\n        'mode': 'json',\n        'contentLocation': '/assets/js/tipuesearch_content.json',\n        'showUrl': false\n        });\n        });", 
      "tags": ""
    }, 
    {
      "loc": "/posts/2014/02/budgetwarrior-0-3-0-objective-wish-management.html", 
      "title": "budgetwarrior 0.3.0 - Objective and wish management", 
      "text": "I'm pleased to announce the release of another budgetwarrior release, the version 0.3.0.\nChanges\nThis version contains several important changes.\nThe first one is the addition of a new module to manage objectives. You can add objective with budget objective add). For instance, you can add an objective saying you want to save 10000$ a year or 200$ a month. When you set your objectives, budget warrior computes how well you complete them. For instance, here is the status of my objectives:\n\nAnother module has been added to manage wishes. You can add wishes to budgetwarrrior (budget wish add) and then budgetwarrior will tell you if it is a good time to buy them. Here is an example of wish status:\n Wish Status\nThe diagnostics tells you where the money will be taken: On savings, on year savings or on month savings (ideal case). It also checks the objectives to see if the payment doesn't break the fulfillment of some of them.\nFor complete diagnostics, it is necessary to you register your fortune (budget fortune check), ideally once a month.\nOf course, this is only a tool, you should not only use that to decide when to buy something, but it may have a good point of view ;)\nMoreover, the version also have other smaller changes:\n\nWhen you make an error when creating a new item (expense, earning, ...), the tool now lets you retry without losing what you typed before.\nConfirmation messages are now shown after each modification command (delete, add and edit).\nThe license has been changed from Boost to MIT. The sense is almost the same, but the MIT is more well known and I thought it would be easier for people to know what this means.\nThere have several changes to the code base, but that doesn't impact the usage of the tool.\n\nConclusion\nI hope you'll found these changes interesting :)\nIf you are interested by the tool, you can download it on Github:\u00a0budgetwarrior\n\nThere is now Gentoo and Arch Linux installation packages available for ease of installation\n\nIf you have a suggestion or you found a bug, please post an issue on the github project:\u00a0https://github.com/wichtounet/budgetwarrior.\nIf you have any comment, don't hesitate to contact me, either by letting a comment on this post or by email.", 
      "tags": "budgetwarrior,C++,Linux,projects"
    }, 
    {
      "loc": "/posts/2014/01/budgetwarrior-0-2-1-minor-changes-gentoo-ebuild.html", 
      "title": "budgetwarrior 0.2.1 - Minor changes and Gentoo ebuild", 
      "text": "I've released a new version of budgetwarrior, the release 0.2.1. budgetwarrior is a simple command line application to manage a personal budget.\nThe version 0.2.1 contains several bug fixes about archived accounts and bug fixes for budget across several years.\nThe application as well as the source code is available online:\u00a0https://github.com/wichtounet/budgetwarrior\nI've created Gentoo ebuilds for this application. They are available on my Portage overlay:\u00a0https://github.com/wichtounet/portage-overlay\nGentoo Installation\n\n\n    Edit overlays section of /etc/layman/layman.cfg. Here's an example:\n\n\noverlays: http://www.gentoo.org/proj/en/overlays/repositories.xml\n           http://github.com/wichtounet/portage-overlay/raw/master/repository.xml\n\n    Sync layman\n\nlayman -S\n\n\n    Add the overlay:\n\n\nlayman -a wichtounet\n\n\n    Install budgetwarrior\n\n\nemerge budgetwarrior\n\nConclusion\n\nIf you find any issues with the tool, don't hesitate to post an issue on Github. If you have comments about it, you can post a comment on this post or contact me by email.", 
      "tags": "budgetwarrior,Gentoo,Linux,Tools"
    }, 
    {
      "loc": "/posts/2014/01/home-server-adventure-step-3.html", 
      "title": "Home Server Adventure \u2013 Step 3", 
      "text": "Here are some news about my home server installation project.In the past, I already installed a server in a custom Norco case. I wanted to replace my QNAP NAS with a better server, the QNAP being too slow and not extensible enough for my needs.\nHere is it how it looks right now (sorry about the photo qualitiy :( my phone does not seem to focus anymore...):\n\nSo I replaced my QNAP NAS with a custom-built NAS. Again, I bought a NORCO case, the RPC-4220. This case has 20 SATA/SAS bays. I bought it with a replacement of the SAS backplane by a SATA one. I also ordered some fan replacement to make it less noisy. I installed my 6 hard disk in Raid 5, managed with mdadm, with LVM partitions on top of the array.\nI also added an APC UPS which allows me to go through all the minor power issues that there is in my old apartment and which also me about 10 minutes of backup when there is a power outage.\nI haven't added a lot of services on the server. I now run Owncloud on the server and that completely replaces my Dropbox account. I also improved by Sabnzbd installation with other newsgroup automation tools.\nNot directly related to my rack, but I also installed a custom XBMC server for my TV. It reads from the NAS server. And of course, it runs Gentoo too.\nIn the future, I'll add a new simple server as a front firewall to manage security a bit more than here and avoid having to configure redirection in my shitty router (which I would like to replace, but there are not a lot of compatible rack router for my ISP unfortunately). It will probably use a Norco case too.\nIf you have any question about my build, don't hesitate ;)", 
      "tags": "Gentoo,Hardware,Home Server,Server"
    }, 
    {
      "loc": "/posts/2013/12/zabbix-low-level-discovery-cores-cpus-hard-disk.html", 
      "title": "Zabbix - Low Level Discovery of cores, CPUs and Hard Disk", 
      "text": "At home, I'm using Zabbix to monitor my servers, it has plenty of interesting features and can be extended a lot by using User Parameter.\nIn this post, I'm gonna talk about Low Level Discovery (LLD). If you are only interested in the final result, go the Conclusion section, you can download my template containing all the rules ;)\nLow Level Discovery (LLD)\n\nLLD is a feature to automatically discover some properties of the monitored host and create items, triggers and graphs.\nBy default, Zabbix support three types of item discovery:\n\n    Mounted filesystems\n    Network interface\n    SNMP's OIDs\n\n\nThe first two are very useful, since they will give you by default, for instance, the free space of each mounted file system or the bandwith going in and out of each network interface. As I only monitor Linux servers, I don't use the last one, but it will eventually interest other people.\nAnother very interesting thing about this feature is that you can extend it by discovering more items. In this article, I will show how to discover CPUs, CPU Cores and Hard Disk.\nThe most important part of custom discovery is to create a script on the monitored machines that can \"discover\" something. It can be any executable, the only thing important is that it outputs data in the correct format. I have to say that the format is quite ugly, but that is probably not very important ;) Here is the output of my hard disk discovery script:\n{\n\"data\":[\n    {\"{#DISKNAME}\":\"/dev/sda\",\"{#SHORTDISKNAME}\":\"sda\"},\n    {\"{#DISKNAME}\":\"/dev/sdb\",\"{#SHORTDISKNAME}\":\"sdb\"},\n    {\"{#DISKNAME}\":\"/dev/sdc\",\"{#SHORTDISKNAME}\":\"sdc\"},\n    {\"{#DISKNAME}\":\"/dev/sdd\",\"{#SHORTDISKNAME}\":\"sdd\"},\n    {\"{#DISKNAME}\":\"/dev/sde\",\"{#SHORTDISKNAME}\":\"sde\"},\n    {\"{#DISKNAME}\":\"/dev/sdf\",\"{#SHORTDISKNAME}\":\"sdf\"},\n    {\"{#DISKNAME}\":\"/dev/sdg\",\"{#SHORTDISKNAME}\":\"sdg\"},\n]\n}\n\n\n\nYou can have as many keys for each discovered items, but the format must remains the same. In the item, trigger and graph prototypes, you will then use {#DISKNAME} or {#SHORTDISKNAME} to use the discovered values. \nOnce you have created your scripts, you have to register it in the zabbix configuration as a user parameter. For instance, if you use the zabbix daemon, you need these lines in /etc/zabbix/zabbix_agentd.conf: \nEnableRemoteCommands=1\n...\nUnsafeUserParameters=1\n...\nUserParameter=discovery.hard_disk,/scripts/discover_hdd.sh\n\n\n\nNow, when you will create the discovery rule, you can use discovery.hard_disk as the key. \nA discovery rule in itself is useful without prototypes, you can create three types of prototypes: \n\n    Item Prototype: This will create a new item for each discovered entity\n    Trigger Prototype: This will create a new trigger for each discovered entity. \n    Graph Prototype: This will create a graph for each discovered entity. \n\n\nThe most useful are by far the item and trigger prototypes. The biggest problem with graphs is that you cannot create an aggregate graph of each discovered items. For instance, if you record the temperature of your CPU cores, you cannot automatically create a graph with the temperature of each discovered cores. For that, you have to create the graph in each host. Which makes, imho, graph prototypes pretty useless. Anyway...\nIn the next section, I'll show how I have created discovery rules for Hard Disk, CPU and CPU cores. \nDiscover Hard Disk\n\nThe discovery script is really simple: \n#!/bin/bash\ndisks=`ls -l /dev/sd* | awk '{print $NF}' | sed 's/[0-9]//g' | uniq`\necho \"{\"\necho \"\\\"data\\\":[\"\nfor disk in $disks\ndo\n    echo \"    {\\\"{#DISKNAME}\\\":\\\"$disk\\\",\\\"{#SHORTDISKNAME}\\\":\\\"${disk:5}\\\"},\"\ndone\necho \"]\"\necho \"}\"\n\n\n\nIt just lists all the /dev/sdX devices, remove the partition number and remove the duplicates, to have only the hard disk at the end. \nI've created several item prototypes for each hard disk. Here are some examples using S.M.A.R.T. (you can download the template with all the items in the Conclusion section): \n\n    Raw Read Error Rate\n    Spin Up Time\n    SSD Life Left\n    Temperature\n    ...\n\n\nYou may notice that some of them only make sense for SSD (SSD Life Left) and some others do not make any sense for SSD (Spin Up Time). This is not a problem since they will just be marked as Not Supported by Zabbix. \nAll these datas are collected using the smartctl utility. \nI've also created some trigger to indicate the coming failure of an hard disk: \n\n    SSD Life Left too low\n    Reallocated Sector Count too low\n    ...\n\n\nI've just used the threshold reported by smartctl, they may be different from one disk manufacturers to another. I don't put a lot of faith on these values, since disk generally fail before going to threshold, but it could be a good indicator anyway. \nDiscover CPUs\n\nHere is the script to discover CPUs: \n#!/bin/bash\ncpus=`lscpu | grep \"CPU(s):\" | head -1 | awk '{print $NF}'`\ncpus=$(($cpus-1))\necho \"{\"\necho \"\\\"data\\\":[\"\nfor cpu in $(seq 0 $cpus)\ndo\n    echo \"    {\\\"{#CPUID}\\\":\\\"$cpu\\\"},\"\ndone\necho \"]\"\necho \"}\"\n\n\n\nIt just uses lscpu and parses its output to find the number of CPU and then create an entry for each CPUs. \nI just have one item for each CPU: The CPU Utilization. \nI haven't created any trigger here. \nDiscover CPU Cores\n\nJust before, we discovered the CPUs, but it is also interesting to discover the cores. If you don't have Hyperthreading, the result will be the same. It is especially interesting to get the temperature of each core. Here is the script: \n#!/bin/bash\ncores=`lscpu | grep \"Core(s) per socket:\" | awk '{print $NF}'`\ncores=$(($cores-1))\necho \"{\"\necho \"\\\"data\\\":[\"\nfor core in $(seq 0 $cores)\ndo\n    echo \"    {\\\"{#COREID}\\\":\\\"$core\\\"},\"\ndone\necho \"]\"\necho \"}\"\n\n\n\nIt works in the same way as the previous script. \nI've only created one item prototype, to get the temperature of each core with lm_sensors. \nWrap-Up\n\nHere are all the UserParameter necessary to make the discovery and the items works: \n### System Temperature ###\nUserParameter=system.temperature.core[*],sensors|grep Core\\ $1 |cut -d \"(\" -f 1|cut -d \"+\" -f 2|cut -c 1-4\n### DISK I/O###\nUserParameter=custom.vfs.dev.read.ops[*],cat /proc/diskstats | egrep $1 | head -1 | awk '{print $$4}'\nUserParameter=custom.vfs.dev.read.ms[*],cat /proc/diskstats | egrep $1 | head -1 | awk '{print $$7}'\nUserParameter=custom.vfs.dev.write.ops[*],cat /proc/diskstats | egrep $1 | head -1 | awk '{print $$8}'\nUserParameter=custom.vfs.dev.write.ms[*],cat /proc/diskstats | egrep $1 | head -1 | awk '{print $$11}'\nUserParameter=custom.vfs.dev.io.active[*],cat /proc/diskstats | egrep $1 | head -1 | awk '{print $$12}'\nUserParameter=custom.vfs.dev.io.ms[*],cat /proc/diskstats | egrep $1 | head -1 y| awk '{print $$13}'\nUserParameter=custom.vfs.dev.read.sectors[*],cat /proc/diskstats | egrep $1 | head -1 | awk '{print $$6}'\nUserParameter=custom.vfs.dev.write.sectors[*],cat /proc/diskstats | egrep $1 | head -1 | awk '{print $$10}'\nUserParameter=system.smartd_raw[*],sudo smartctl -A $1| egrep $2| tail -1| xargs| awk '{print $$10}'\nUserParameter=system.smartd_value[*],sudo smartctl -A $1| egrep $2| tail -1| xargs| awk '{print $$4}'\n### Discovery ###\nUserParameter=discovery.hard_disk,/scripts/discover_hdd.sh\nUserParameter=discovery.cpus,/scripts/discover_cpus.sh\nUserParameter=discovery.cores,/scripts/discover_cores.sh\n\n\n\n(it must be set in zabbix_agentd.conf)\nYou also need to give zabbix the right to use sudo with smartctl. For that, you have to edit your /etc/sudoers file and add this line: \nALL ALL=(ALL)NOPASSWD: /usr/sbin/smartctl\n\nConclusion and Download\n\nI hope that this helps some people to use Low Level Discovery in their Zabbix Monitoring Installation. \nLLD eases a lot the creation of multiple items discovery for hosts with different hardware or configuration. However, it has some problems for which I have not yet found a proper solution. First, you have to duplicate the client scripts on each host (or at least have them on a share available from each of them). Then, the configuration of each agent is also duplicated in the configuration of each host. The biggest problem I think is the fact that you cannot automatically create graph with the generated items of each discovered entities. For instance, I had to create a CPU Temperature graph in each of my host. If you have few hosts, like many, it is acceptable, but if you have hundreds of hosts, you just don't do it. \nAll the scripts and the template export file are available in the zabbix-lld repository. For everything to work, you need the lscpu, lm_sensors and smartmontools utilities. \nIf you have any question or if something doesn't work (I don't offer any guarantee, but it should work on most recent Linux machines), don't hesitate to comment on this post.", 
      "tags": "Linux,Others,Server,zabbix"
    }, 
    {
      "loc": "/posts/2013/12/thor-os-boot-process.html", 
      "title": "Thor OS: Boot Process", 
      "text": "Some time ago, I started a hobby project: writing a new operating system. I'm not trying to create a concurrent to Linux, I'm just trying to learn some more stuff about operating systems. I'm gonna try to write some posts about this kernel on this blog.\nIn this post, I'll describe the boot process I've written for this operating system.\nBootloader Step\n\nThe first step is of course the bootloader. The bootloader is in the MBR and is loaded by the system at 0x7C00.\nI'm doing the bootloading in two stages. The first stage (one sector) print some messages and then load the second stage (one sector) from floppy at 0x900. The goal of doing it in two stages is just to be able to overwrite the bootloader memory by the stage. The second stage loads the kernel into memory from floppy. The kernel is loaded at 0x1000 and then run directly.\nThe bootloader stages are written in assembly.\nReal mode\n\nWhen the processor, it boots in real mode (16 bits) and you have to setup plenty of things before you can go into long mode (64 bits). So the first steps of the kernel are running in 16 bits. The kernel is mostly written in C++ with some inline assembly.\nHere are all the things that are done in this mode:\n\n    The memory is inspected using BIOS E820 function. It is necessary to do that at this point since BIOS function calls are not available after going to protected mode. This function gives a map of the available memory. The map is used later by the dynamic memory allocator.\n    The interrupts are disabled and a fake Interrupt Descriptor Table is configured to make sure no interrupt are thrown in protected mode\n    The Global Descriptor Table is setup. This table describes the different portion of the memory and what each process can do with each portion of the memory. I have three descriptors: a 32bit code segment, a data segment and a 64bit code segment.\n    Protected mode is activated by setting PE bit of CR0 control register.\n    Disable paging\n    Jump to the next step. It is necessary to use a far jump so that the code segment is changed.\n\n\nProtected Mode\n\nAt this point, the processor is running in protected mode (32 bits). BIOS interrupts are not available anymore.\nAgain, several steps are necessary:\n\n    To be able to use all memory, Physical Address Extensions are activated.\n    Long Mode is enabled by setting the EFER.LME bit.\n    Paging is setup, the first MiB of memory is mapped to the exact same virtual addresses.\n    The address of the Page-Map Level 4 Table is set in the CR0 register.\n    Finally paging is activated.\n    Jump to the real mode kernel, again by using a far jump to change code segment.\n\n\nReal Mode\n\nThe kernel finally runs in 64 bits.\nThere are still some initialization steps that needs to be done:\n\n    SSE extensions are enabled.\n    The final Interrupt Descriptor Table is setup.\n    ISRs are created for each possible processor exception\n    The IRQs are installed in the IDT\n    Interrupts are enabled\n\n\nAt this point, is kernel is fully loaded and starts initialization stuff like loading drivers, preparing memory, setting up timers...\nIf you want more information about this process, you can read the different source files involved (stage1.asm, stage2.asm, boot_16.cpp, boot_32.cpp and kernel.cpp) and if you have any question, you can comment on this post.", 
      "tags": "Assembly,C++,Operating Systems,osdev,thor"
    }, 
    {
      "loc": "/posts/2013/12/new-hobby-project-thor-os-64bit-operating-system-c.html", 
      "title": "New hobby project: Thor-OS, 64bit Operating System in C++", 
      "text": "It's been a long time since I have posted on this blog about a project. A bit more than two months ago, I started a new project: thor-os\nThis project is a simple 64bit operating system, written in C++. After having written a compiler, I decided it could be fun to try with an operating system. And it is fun indeed :) It is a really exciting project and there are plenty of things to do in every directions.\nI've also written the bootloader myself, but it is a very simple one. It just reads the kernel from the floppy. loads it in memory and then jumps to it and nothing else.\nFeatures\n\nRight now, the project is fairly modest. Here are the features of the kernel:\n\n    Serial Text Console\n    Keyboard driver\n    Timer driver (PIT)\n    Dynamic Memory Allocation\n    ATA driver\n    FAT32 driver (Work In progress)\n    Draft of an ACPI support (only for shutdown)\n\n\nAll the commands are accessible with a simple shell integrated directly in the kernel.\nTesting\n\nAll the testing is made in Bochs and Qemu. I don't have any other computer available to test in real right now but that is something I really want to do. But for now, my bootloader only supports floppy, so it will need to be improved to load the kernel from a disk, since it is not likely that I will have a floppy disk to test :D\nHere is a screenshot of the OS in action:\n\nFuture\n\nThe next thing that I will improve is the FAT32 driver to have a complete implementation including creating and writing to files.\nAfter that, I still don't know whether I will try to implement a simple Framebuffer or start implement user space.\nAs for all my projects, you can find the complete source code on Github:\u00a0https://github.com/wichtounet/thor-os\nDon't hesitate to comment if you have any question or suggestion for this project ;) I will try to write some posts about it on the future, again if you have idea of subject for these posts, don't hesitate. The first will probably be about the boot process.", 
      "tags": "Assembly,C++,Operating Systems,osdev,thor"
    }, 
    {
      "loc": "/posts/2013/12/gentoo-tips-avoid-gnome-3-8-emerged-automatically.html", 
      "title": "Gentoo Tips: Avoid Gnome 3.8 from being emerged automatically", 
      "text": "Since Gnome 3.8 has been out in the portage tree, a lot of problems arise when you try to emerge something. If it was only when you update the system, it would be OK, but this arises every time you try to install something.\nFor instance, if I try to update vim on my system, it tries to update empathy to version 3.8 and then pulls some other dependencies causing blocks and other USE problems. I personally don't think empathy should be emerged when emerging vim. Fortunately, you can disable this behavior by using emerge in this way:\nemerge --ignore-built-slot-operator-deps=y ...\n\nWith that, when you emerge vim, it doesn't emerge Gnome 3.8. It is very useful if you want to stay with Gnome 3.6 for the moment.\nI already used this tip several times. I hope that this will be useful to other people.", 
      "tags": "Gentoo,Linux,Tips"
    }, 
    {
      "loc": "/posts/2013/10/budgetwarrior-0-2-visual-reports-fortune-status-expenses-aggregates.html", 
      "title": "budgetwarrior 0.2 - Visual reports, fortune status and expenses aggregates", 
      "text": "I've released a new version of budgetwarrior the version 0.2.\nI've several new features to the tool. First, I've added a graph of the expenses/earnings/balances of each month for a given year in the form of a bar plot. You can see an example in practice here:\n\nNothing fancy, but it gives a good overview of the current state of your budget.\nI've added a new module, called fortune, that lets you enter your total fortune and then computes the difference between the entered fortune statuses. For now, it doesn't do anything else with this data. But in the future, I want to correlate this data with the balances to check the difference between the filled expenses and earnings and the fortune evolution.\nI've also added a more convenient way of creating expenses and earnings. Just type \"budget expense add\" and you'll be able to fill all the fields one by one. Of course, the command line commands are still available.\nThe last new feature I've added is an aggregate report (budget overview aggregate). This view simply groups all the expenses with the same name of a year together. If you always use the same expense title for your groceries, you'll see the total you spent in groceries for a year. You can also name your expenses with the format \"Category/Expenses\" and all the expenses with the same category will be grouped together in the aggregate view. That allows you to still have enough details in the monthly overview but to logically groups your expenses together in the aggregate view.\nThe other changes are minor. I've improved the monthly overview to sort the expenses and earnings by date. To facilitate the storage of the files in a service like Dropbox, the data and configuration files are now only written if they have been modified. The mean in the current overview has been changed to reflect only the months up to the current month and not the future (which was just ruining the means).\nIf you are interested by the tool, you can download it on Github: budgetwarrior\nI hope this tool will be useful to some people. If you've any question, just let a comment on this post or contact me directly by email. I'll be glad to help.", 
      "tags": "budgetwarrior,C++,Others,projects"
    }, 
    {
      "loc": "/posts/2013/08/home-server-adventure-step-2.html", 
      "title": "Home Server Adventure - Step 2", 
      "text": "If you remember, I talked about my home server project in a previous post. I had installed an old Dell Poweredge server, a 3com gigabit switch and a monitoring console. The problem with this configuration was that it was too noisy as the rack is installed in my apartment.\nThe first thing I did was to replace my old 3Com switch with a Zyxel managed fanless switch. Being fanless, this switch is completely silent which makes a good difference :)\nAfter that, I have replaced the Dell server with a custom installation in a Norco-RPC 230 case. The basic case comes with two 80mm fans in the front. These two fans are very powerful, but they are quite noisy. I replaced them with two\u00a0Enermax T.B. Silence 80mm fans. They are almost silent, it is really great. It is probably not enough airflow for a large configuration, but in my case, I think that this will be largely enough.\nI've already installed several services on my server:\n\n    Tiny Tiny RSS: a web-based news feed reader and aggregator. I use it to replace Feedly which I was getting less and less fond to.\u00a0\n    Sabnzbd: I already had this NZB download on my desktop, but now as it is on the server, it can download even when I'm not at home.\n    Zabbix: a monitoring application that manages all my appliances and server (the new server, the NAS, the switch and the router). It is my first attempt with Zabbix. It is a bit cryptic to conigure, but the features are very numerous.\n    Teamspeak and Mumble: They already were installed on the previous server.\n\n\nI plan to install new services on the future, but I have no plans for now.\nHere is a picture of the rack in its current state:\n\nI have also installed my router and the NAS on a layer in the rack.\nYou can't see it, but I have also added to rackable PDU on the back to have to organize a bit the cables. Even if it still not perfect, it is already better than before.\nFor now, I think that my system in in good shape. When I will have some more budget, I will replace QNAP NAS with a custom server, probably again with a Norco case.", 
      "tags": "Gentoo,Hardware,Home Server,Server"
    }, 
    {
      "loc": "/posts/2013/08/budgetwarrior-command-line-personal-budgeting.html", 
      "title": "budgetwarrior 0.1.0 - command-line personal budgeting tool", 
      "text": "Being bored by using Google spreadsheets for my personal budgeting, I decided to write an application to do that. Being a huge fan of taskwarrior, I decided to write a kind of similar application for my personal budget, budgetwarrior was born. I use it since two months and I thought that it could be useful for other persons. The application is developed in C++. More information is available on Github: https://github.com/wichtounet/budgetwarrior.\nbudgetwarrior 0.1.0 is a command-line only tool. It works on this principle: you create a set of accounts with a certain limit and then you declare your expenses in each of these accounts. You can also manage earnings that are not each month in each account. You can also keeps track of your debts via this application. It also supports automatic creation of recurring expenses, for instance when you pay the rent (for now, only monthly expenses are supported).\nOnce you've put all your data in the application, it provides you report on the state of your budget by month or by year. For instance, here is my current monthly report:\n\nYou can see directly which accounts are in a good shape and which are not.\nHere is the current yearly report:\n\nIn this view, you can see directly how your accounts evolve during the year and where are your biggest expenses and earnings.\nAs everything is displayed horizontally, the more accounts you have the larger the view become. With the 7 accounts I have, it takes about 1600 pixels of width to display it. I will try to improve that in the future if some people are interested in making it work on smaller screens.\nInstallation\n\nYou can install budgetwarrior directly from the sources:\ngit clone -b master git://github.com/wichtounet/budgetwarrior.git\ncd budgetwarrior\ncmake .\nmake\nsudo make install\n\nAfter that, you can use budgetwarrior by using the command budget.\nThe usage is fairly simple, you can use budget help to have the list of the commands that you have to use to create expenses and earnings and display overviews.\nThe project\n\nIf you have any question on the project, don't hesitate to contact me or to post a comment to this post. If there are people interested, I can write a more complete help.\nIf you have a suggestion or you found a bug, please post an issue on the github project: https://github.com/wichtounet/budgetwarrior.", 
      "tags": "budgetwarrior,C++,projects"
    }, 
    {
      "loc": "/posts/2013/08/norco-rpc-230-case-review.html", 
      "title": "Norco RPC 230 Case Review", 
      "text": "As my previous Dell 1U server was too noisy for my home server installation. I invested in a case, a Norco RPC 230 model. This case is a 2U standard case for 19\" rack. It supports micro-ATX motherboard and ATX power supply. These components are easy too find, so that makes it a very interesting case for a home server installation.\nI ordered the case at Ri-Vier Automatisering, which is the Norco european distributor. I directly ordered it with the RL-26 rails for the rack and the ATX power supply that is provided by Ri-Vier. For the case, I also bought a micro-ATX Gigabyte G41M-Combo\u00a0motherboard. I already had 4GB of DDR2 RAM and a Core 2 Duo processor from a previous configuration. I also took my old 120GB Samung SSD for this server. This would be largely sufficient for what I plan to run on this server.\nThe case has four 3.5\" drive bays and one 5.25\" drive bay. The air flow is provided with two 80mm fans on the front panel.\nPackage\n\nI received the package very quickly from Ri-Vier. The case is packaged in double box and everything in the package is well ordered. The power supply was already in the box itself. Here is a picture of the content of the package:\n\nIt contains only the case and the necessary screws. The rails are not on this picture, since I already had installed them in my rack. As you see, there are no manual, which may be a bit frustrating. Once you remove the top panel (4 screws to remove), you can see the inside of the case:\n\nOn the top are the four bays for the drives. They are removable. As you can see on the picture, the power supply has plenty of cables. I would have expected a power supply with less cables to come with this case as there is not much room.\nHere is a view of the front panel:\n\nThere are two USB ports on the front, the Power and Reset buttons as well as LEDS.\nInstallation\n\nEven without any manual, the installation is fairly easy. The top panel can be removed by unscrewing 4 four screws on the side.\u00a0I strongly recommend to remove the 4 drive bays before installing the other components to make some room. Once it is done, the motherboard can be screwed in place. The power supply is attached by four screws on the back panel.\nI installed a SSD 2.5\" in the leftmost disk bay. I had some issues with this installation as the bays do not have any screws on the side, only on the bottom. They are really not made for anything else than 3.5\" drives.\nHere is a picture of my installation once finished:\n\nI managed to make it looks nice with the cables, but only because I have not installed any CD-Rom, so I did put a lot of cables in its place.\nOnce it is done, I have installed it in my rack. It is not straightforward without a manual, but I was able to screw it to the rails. I did put two screws on each side:\n\nOnce in place, it looks quite good:\n\nHowever, I don't know if I have done something wrong, but the rails are not sliding smoothly, they are blocking at two places and the last part is quite hard to push. Anyway, as I won't be moving it a lot, I think it is ok. You also have to remember that even if it is a short depth case, the RL-26 rails are not short at all, they are not made for short depth racks.\nOnce it is launched, the server is quite busy due to the two 80mm fans. However, the airflow is quite strong, which is what most customers want. It is still more silent than my Dell server, but not enough for a home experience. I will try to replace them with more silent fans in the future.\nConclusion\n\nPros\n\n    Enough bays for a simple server\n    Support standard\u00a0formats\n    Enough air flow\n    Very short depth\n    Seems of heavy duty construction\n    Looks nice\n    Not too expensive\n    Should fit in most racks\n\n\nCons\n\n    No manuals at all\n    Disk bays not very convenient\n    The provided power supply is not very adapted to the case.\n    The provided rails seems to not slide smoothly\n\n\nTo conclude, I would say that this case is very fit to a custom installation as all the components are standards. I would recommend it for a similar usage than mine.", 
      "tags": "Gentoo,Hardware,Home Server,Server"
    }, 
    {
      "loc": "/posts/2013/07/zyxel-gs1910-managed-gigabit-switch-review.html", 
      "title": "ZyXEL GS1910-24 Managed Gigabit Switch Review", 
      "text": "A short time ago, I decided to install servers in a rack at my home. Although working very well, my 3Com managed was too much noisy for being at home. That is why I decided to change it for fanless switch. After some research, I finally chose a\u00a0ZyXEL GS1910-24. It is a web-manageable gigabit switch. I chose the 24 ports version. This version has also 4 SFPs that replace 4 normal ports if enabled. I don't think I will ever need the SFPs, but it is nice to know that there are here if necessary. This switch has a lot of cool features, it supports IPV6, QoS, VLANs, filtering, RADIUS and so on.\nThe package\n\nThe package does not contains a lot of things, but does contain the essential:\n\n    The switch itself\n    A power code\n    Rack mounting brackets and screws\n    Manuals\n\n\nHere is a picture on the package:\n\nThe switch is really small, twice narrower than my 3Com switch and more than twice lighter.\nNothing special to say about the package, it is neatly done and has everything that is necessary.\nInstallation\n\nThe installation inside a rack is really easy. Each bracket is mounted with 4 screws onto the switch and then two screws are holding each bracket into place in the rack. Here is a picture of the rack:\n\nOnce you put the power cord, it directly starts up and everything already works fine. The state of each port is represented by a led. Orange indicates a 100Mbit/s connection while green indicates 1Gbit/s connection.\nThe switch does not make a single noise and does not vibrate, it is really good\nConfiguration\n\nThe easiest way to configure the switch is to use the web configurator. By default, the switch IP is 192.168.1.1. As my router had the same IP, I had to disable it temporarily before changing the IP of the switch.\nThe web configuration is very complete, you can change absolutely everything from here. You have also access to a lot of monitoring tools from here. The most useful being of course the port monitoring interface:\n\nI recommend changing the default IP address and the server password as first things on the switch.\nI won't make the list of everything that is configurable on this switch, but the list is pretty impressive.\nConclusion\n\nI'm really impressed by this switch. The switch is highly configurable and seems to perfectly fit my need. I would totally recommend this switch for rack installation at home. You can also totally use it as a desktop switch if you needs for a big switch on your desktop too", 
      "tags": "Hardware,Home Server,Network,Server"
    }, 
    {
      "loc": "/posts/2013/07/home-server-adventure-step-1.html", 
      "title": "Home Server Adventure - Step 1", 
      "text": "For years now, I've almost always had a server running at home. First it was an old desktop computer and then it was a QNAP NAS. The problem with the QNAP is that it is not fast at all and not as flexible as I would like it to be. Moreover, I was also running a Teamspeak server on my desktop for when my friends and I were playing together. So I decided to first install a simple server to replace my teamspeak server and I would services of my NAS with my new server. But this time, I decided to go for the complete option: A 19\" rack :)\nHardware\n\nSo I bought all I needed to install my 19\" rack at home. I bought everything already used on auctions on Ricardo/Anibis (Switzerland Ebay equivalents) and Ebay. Here is what I got:\n\n    A 19\" inch rack with 40 HE of the mark\u00a0GURTNER + SCHNIEPP AG\n    A old Dell Poweredge 1850 server\n    A 8-ports Compaq KVM switch\n    A monitor/keyboard console for administrating the servers\n    A 3Com managed Gigabit switch\n\n\nI got that for less than 500$. It is probably possible to get a similar configuration for less than that in the United States.\nHere are some pictures (sorry for the poor quality):\n\n\nFor now, it is kind of empty. I will also put my NAS and my internet provider router in the rack in the future.\nA this time, the cables are not very good organized, I will try to purchase some guides to make that look better and I will also try to find a rack PDU to distribute power without cables everywhere.\nI also need to find two 120mm fans for the top of my case to improve air circulation. Very quiet 120mm can be found, so noise won't be a problem I think.\nIn the future, I also plan to find an UPS, but they are very expensive, so I will continue looking at auctions for them. The problem being that the battery should not be too old.\nSoftware\n\nOf course, I've installed Gentoo on the server. At first, I wanted to install a Gentoo Hardened distribution with Selinux, but it turned out that it was too much of a hassle. After more than 10 hours of trying to make it work, I started again and in less than two hours my Gentoo installation was working. I will probably try again in the future, at least to harden the server and I hope it will go with less problems. The server is of course gui-less, only console access is more than sufficient.\nFor now on, I have only a Teamspeak server and a Mumble server installed on the server, but I plan to add new services on it, Sabnzb for instance.\nI also installed iptables to add some layer of protection, even if I don't think that it is necessary in my case.\nFinally, I used dyndns to map my public ip to a domain name to make it easier to reach. For now, I haven't installed an update client, but I plan to try ddclient.\nProblems\n\nI made some mistake when choosing the components for my installation. First of all, they are too noisy. The server and the switch are a real problem. They are both made for professional installations. Generally 1U server have very small fans (40mm generally) which are very noisy. So I decided to upgrade my configurations with two changes:\n\n    I will buy a fanless switch, probably unmanaged. They are plenty of very good fanless switches, even managed one for a reasonable price. I will try to first find a used one on auction, but I may consider buying a new one, as there exists some for about a hundred dollars.\u00a0\n    I will replace the Dell server with a custom server. I found some very good cases made by Norco. I'll buy a Micro ATX motherboard and install my old computer configuration (the one I had before) on it. It won't cost too much I think, although much more than the 30$ Dell server I have now ;)\n\n\nThe other problem being that the Dell server is too deep for my rack, so I can't close the back part as you can see on the pictures, but replacing it with the Norco case will solve the problem :)\nConclusion\n\nIt might sound crazy to have a complete rack at home, but I thing that it is a great way to experience with servers and network. It is also quite practical if you plan to have several servers.\nI plan to post some posts on the subject on the future, so I hope \u00a0that it interests some people.", 
      "tags": "Gentoo,Hardware,Home Server,Network,Server"
    }, 
    {
      "loc": "/posts/2013/07/why-how-left-windows-for-linux.html", 
      "title": "Why and how I completely left Windows for Linux", 
      "text": "For years now, I always kept a dual-boot at home with a Linux system (currently Gentoo) and a Windows system. At work, I only use Gentoo. This week-end, I decided to completely remove it and migrate the applications I used on Windows to my Gentoo system.\nWhy Windows ?\n\nSo first things first, why was I keeping the Windows system ? For several reasons:\n\n    Games :) Unfortunately, most of the games I play are not natively compatible with Linux.\n    Office. I always liked Microsoft Office. As I hate OpenOffice/LibreOffice, I never wanted to remove it For schools we always had several teachers forcing us to use Microsoft document formats.\n    Hardware support. I always found that hardware support in Windows was great. Most of the time when you add new peripheral, there is nothing, it just works, which is great.\n    Applications. I always had some applications that I didn't found good enough Linux equivalents for. For instance, Newsleecher, iTunes or TaggedFrog.\n\n\nOn the other hand, I work on Linux for years now and I would like to have to work on Windows again.\nWhat Changed ?\n\nThis weekend I upgraded my hardware configuration (Motherboard, CPU and RAM). I was afraid that I had to reinstall my Linux configurations (because of Gentoo compiled with march=native), but I never thought that I would have to reinstall Windows. I turned out the contrary: my Gentoo installation worked just fine and my Windows totally crashed (BSOD at each startup). I finally made it through Windows after disabled AHCI mode on my motherboard, but then activation was invalidated (of course...) and online activation was not working. I decided to install the new chipset drivers and launch the Windows update and after that, Windows decided to boot without any USB support (WTF...). After that, I decided that Windows what not so great at all for \u00a0 hardware support...\nAnother reason I left Windows is Windows 8. I find that Window 7 was really great, but I really don't like Windows 8 and I would never have upgraded my Seven to it. Moreover, I recently bought Microsoft Office 2013 and it turned that I had to create an account at Microsoft to install it... Seriously ??? And moreover, it turned out to be worse thant Office 2010 (which, again, was great).\nSo all these reasons made me remove Windows.\nHow to migrate everything to Linux ?\n\nFirst, I had no problem with my data. Most of my data are on a personal NAS and the remaining is on Dropbox, so no problem on this side.\nI still had some problems to resolve. First of all, I needed my games to run on Linux. I currently play only Diablo III. As I had received a year free of Crossover, I decided to give it a try. Crossover is based on Wine and ensures that some software are running correctly under it and provide technical support. After some tuning, Diablo III was running almost flawlessly on my Gentoo machine :) Problem 1 solved. I will totally buy a license of Crossover, once my free year is over.\nI still add some applications to replace. I use iTunes as my main music player and library manager. Some time ago, I tried a lot of programs like Amarok/Rythmbox/Banshee, but I didn't liked them a lot and they were not running very well on large library of music files. This time, I tried Clementine. Even if not very beautiful, it had all the features I needed and worked very well. I decided to stick with it. Another program I like a lot on Windows is TaggedFrog. It is a very simple program allowing to put tags on any file on the system and then search by tag on them. I haven't found a total equivalent. I first tried Tracker that is a Gnome project, but I was not satisfied with the search interface. After that, I tried the very simple TMSU. It is a command-line based tagging manager. All the tagging must be done in command line. In my case, it is not a problem, as I don't mind using the command-line and I don't tag files very often. What is very interesting about TMSU is that it can create a virtual file system (based on FUSE). In this file system, you have all your tags\u00a0\u00a0as folder and you can see directly all the files of each tag. Moreover, you can directly make cross search (has tag X and Y and Z) by just going down in the tag folder. It is really great and has everything I needed. Finally, I also needed something to replace Newsleecher. I haven't found something as great (especially no replacement for the Supersearch function), but I installed Sabnzbd\u00a0which works really well and is very simple. For now, I just use the web interface and haven't installed any other front-end, but that will perhaps change in the future.\nI haven't replaced Office for now on. It occurred to me that since I left school, I haven't used it a lot, so that will probably not be a problem anymore. I will change to write the few letters I have to write on Latex and if I have Office documents, I'll probably read them on Google Drive.\nConclusion\n\nEven if I lost a lot of time with all that, I think it is a great think. It makes one less configuration to maintain and some less costs on the future. Moreover, I will save some time, because I won't have to switch between Linux and Windows for different tasks. And now, I have a second SSD ready for something else, either for RAID 1 to ensure redundancy on Linux or to mount on a server, I'll see later.\nI will probably have some more problems in the future, but I'm convinced that there will be Linux solutions to it :)", 
      "tags": "Gentoo,Linux,Others,Personal,Windows"
    }, 
    {
      "loc": "/posts/2013/06/improving-eddic-boost-spirit-parser-performances.html", 
      "title": "Improving eddic Boost Spirit parser performances", 
      "text": "After the last changes on the data-flow framework, the parsing pass of the eddic compiler became the slowest one. I was sure there was some area of optimizations, so I decided to improve its performances.\nIn this post, I will present the different techniques I applied and their results.\nStatic grammar\n\nThe first optimization that I tried was to make the grammar static, meaning that we can declare it static and it will be constructed only once and will be allocated on the data segment.It is indeed heavy to build the lexer especially but also the grammar. I would like to thank sehe for this optimization, he found it after I posted a question on Stackoverflow.\nThe lexer was very easy to make static (only add static keyword :) ), but the parser was a bit more complicated because it needs the lexer iterator to get the current position in the file. This problem has been resolved by saving the iterator into the qi::locals of the rules.\nThe result of this optimization are amazing. It saved 33% of the time.\nExpectation points\n\nExpectation points have the interesting point that they disallow backtracking and so can improve performances in some cases. Moreover, they are always interesting because they make the grammar clearer and the error messages much better.\nI tried adding more expectation points to the grammar. Unfortunately, there weren't a lot of them to add. Moreover, it seems that there are some quite weird behavior with them because some times it is impossible to add them (causes compilation failure) and sometimes it just make the code don't work anymore the same way, though I don't understand why.\nAnyway, I have been able to add some to the grammar. These changes improve the performance by a bit more than 1%. It is not a lot, but it is still an improvement. Moreover, I'm quite sure that there are more expectation points that can be added to the code. I will take some time again later to try to add more and to understand them better.\nLess skips\n\nIn my grammar, I've a special parser for getting the current position in the file to add \"debug information\" to the AST. This special parser was skipping over its content, but it has no content, since it is artificial. Removing it improved the performance by about half a percent.\nImprove Position (debug information)\n\nAs said before, there is a special parser to get the current position in the file. This information is then stored into an eddic::ast::Position structure. This structure was holding the line number, the column, the file name and the contents of the line. The first two were ints and the last two were std::string. Each time, a copy of the strings were necessary.\nI avoided storing the std::string directly by storing only the number of the line as well as the index of the file. Then, the content of the file is stored in the global context and can be accessed if it is necessary to display the line where the error happened.\nThis change gave an increase of 10% of the parsing performance.\nAuto Rules\n\nRules in Boost Spirit have an overhead due to the cost of the virtual calls that are necessary. In theory, auto rules can improve the efficiency of the rules by removing the cost of virtual calls. Moreover, auto rules should also avoid code bloat when the rules are compiled. The rules can be inlined and better optimized.\nI transformed some rules to auto rules to improve performances. Unfortunately, I found that this did not improve the performances. Moreover, transforming some rules to auto rules made the performance worse. I still did let some of the rules as auto rules. I have to say that I was very disappointed by this result, I was really expecting more from this :(\nGenerated Static Lexer\n\nThe first time the lexer is used, it has to generate the Deterministic Finite Automaton (DFA) that is used to identify the different tokens. This process takes time. There is way to avoid this by using the static model of Boost Spirit Lex. With that, the code is generated with the complete DFA and then it doesn't have to be initialized again.\nI was not expecting a lot from this because the lexer was already static and so was initialized only once. Indeed, it resulted in less than half a percent improvement.\nConclusion\n\nEven if I've been able to largely reduce the overhead of the parsing by more than 40%, it still has a big overhead. Indeed, it still represents 36 percent of the whole process of compiling a source file. I think it is still too much.\nMoreover, an interesting fact is that the optimization I would have thought to be very effective (auto rules especially) did not have the expected effect, but making the grammar static, which I would not have thought of, was very effective.\nWhen profiled, the final version shows that quite some time is spent in destructing the multi_pass, which is quite odd. And it also seems that transforming the string operators to ast::Operator is not very effective, but I do not know how to improve that at this point.\nI won't probably work on that again for the version 1.2.4 of eddic, but I will eventually take some time again for the version 1.3.0 to improve it again.", 
      "tags": "Benchmarks,Boost,C++11,Compilers,EDDI,Performances"
    }, 
    {
      "loc": "/posts/2013/06/some-news.html", 
      "title": "Some news", 
      "text": "No, I'm not dead ;)\nAfter having finished my Master thesis in March, I took a break from my personal projects including this project. I then started a job in my school, waiting for a Ph.D thesis. I'm now working on a very interesting Machine Learning project about Speech, unfortunately in Java ;)\nI just started again working on eddic this week. I'm gonna try to improve as much as possible the performances of the parser. I will also try to post again some articles on this blog, although I don't know about what.", 
      "tags": "C++,EDDI,Java,Machine Learning,Others"
    }, 
    {
      "loc": "/posts/2013/03/eddic-1-2-3-better-data-flow-analysis.html", 
      "title": "eddic 1.2.3 - Better data-flow analysis", 
      "text": "I finally finished the version 1.2.3 of eddic. I have been quite busy finishing my master thesis in february and then taking some vacations in United States, so this version came later than I wanted. \nThe main change is about the speed of the data-flow optimizations. I refactored a lot the data-flow to make it much faster. Some test cases are up to 10 times faster :)\nThere are still some work to do for speed of optimizations, but it is much better now. Dead Code Elimination and Constant Propagation still have to be made faster, but now the main bottleneck. In the next version of eddic, the parsing performance will be improved. \nInlining performance has also been greatly improved. The functions are considered in topological order of the call graph. This makes it much faster and moreover the resulting code is more efficient too. \nThere are also some improvements of the language. char and bool types now takes only one byte each. Copy constructors for structures containing field of structure type are now automatically generated. The grammar has been enhanced to support postfix operations in for loops. \nOther improvements have been made to the optimization engine. A new optimization has been implemented: Loop Unswitching. This optimization transforms a code like that: \nfor(int i = 0; i &lt; X; ++i){\n    if(a){\n        //Something\n    } else {\n        //Something else\n    }\n}\n\n\n\nIn some code like that: \nif(a){\n    for(int i = 0; i &lt; X; ++i){\n        //Something\n    }\n} else {\n    for(int i = 0; i &lt; X; ++i){\n        //Something else\n    }\n}\n\n\n\nwhen a doesn't depend on the loop body. The body of the loops is much faster in the second version. \nThe induction variable analysis is now able to handle loops with induction variable divided in each iteration. With that new feature, the call: \nprint(123);\n\n\n\nis reduced to\nprint('1');\nprint('2');\nprint('3');\n\n\n\nAnother small optimization is that variables contributing only to themselves are now correctly identified as dead. \nOn the compiler side, the timing system has been greatly improved to contains almost all part of the compilation process. The timings for the complete compilation is available on the wiki. \nFuture Work\n\nThe next version of the EDDI compiler (eddic) will be the version 1.2.4. \nPerformances will stil be focused for this version. The first change will be to improve the performances of the parsing. Then, I'm gonna try to improve register allocation performances by improving handling of bound registers which I believe is a bottleneck. \nThere are also several refactorings that I think of doing to the code. I will probably also implement new minor language features, but I still don't know what. \nMoreover, I have to serve in the army the next three weeks, so there won't be any progress these weeks. \nDownload\n\nYou can find the EDDI Compiler sources on the Github repository: https://github.com/wichtounet/eddic\nThe version is available in the v1.2.3 tag available in the GitHub or directly in the master branch.", 
      "tags": "Compilers,EDDI,Optimization,projects,Releases"
    }, 
    {
      "loc": "/posts/2013/01/eddic-1-2-2-performances-optimization-library.html", 
      "title": "eddic 1.2.2 - Performances, improved optimizations and additions to standard library", 
      "text": "These last weeks, I had more work than expected with my Master thesis so it took me longer to finish this new version of eddic. Moreover, I included more stuff than I though in this version. Anyway, I'm happy to announce the version 1.2.2 of eddic.\nIt is a minor version regarding the language itself. On the other, there are a lot of changes in the compiler itself.\nFor the language:\n\n    Structures are now correclty copy constructed when passed by value\n    When the same header is included several times accross the program, it is not parsed again\n    The vector structure has now functions to insert and remove elements in arbitrary positions\n    The functions to print bools, floats and integers are now written in EDDI directly. Only the functions to print chars and raw string are now written in assembly\n\n\nI worked on improving the performances by improving the constant propagation pass that runs less times now and by tuning a bit the data-flow framework, avoiding virtual calls.\nAnother improvement is that all the mtac::Statement types have been merged in mtac::Quadruple, this removes one level of indirection and simplifies several passes. Moreover, there are now directly stored inside a vector and not allocated via shared_ptr. This removes another level of indirection.\nPut together, these two optimizations improved the performances of the compiler by about 15%. On the other hand, now that printF and printI are written in EDDI, it takes much longer to compile. I will work on that for the next version too. One way to improve the performances will be to tune the ordering of passes and also to tune the passes themselves so that they do more work at once. I will also try to merge constant propagation and offset constant propagation together. They perform very similar work.\nThere are also several improvements in the optimization engine:\n\n    The loop analysis has been fixed to handle loops bigger than one basic block. There was a problem in my implement of Lengauer and Tarjan making that dominators were not computed.\n    The optimization engine now create a call graph of the program. This call graph is used to remove unused functions that are called but not reachable from the main function.\n    A new analysis pass has been added: pure_analysis. This pass test if a function is pure (no write to pointers or global variables) and thus avoid creating a basic block for it\n    The Loop Invariant Code Motion algorithm has been improved to handle more invariants\n    The Common Subexpression Elimination algorithm has been improved to handle more expression\n    The Induction Variables analysis has been reviewed and several bugs have been corrected. It is now a bit complicated.\n\n\nA big bug has been fixed in the handling of the MEMSET LTAC instruction. This will be completely reviewed in the next version (See Future Work).\nSome analysis starts to become quite complicated. I'm thinking of using SSA in MTAC in order to simplify some of the passes and to easily compute ud-chains. Another thing that I'm thinking is to add a powerful and complete alias analysis that would really improve the efficiency of some passes (offset constant propagation for instance) by making them less conservative.\nI also have removed some memory leaks (will try to remove all of them in the next version). I added a new optimization level: O3. This level enables loop unrolling and complete loop peeling.\nFuture Work\n\nThe next version of the EDDI compiler (eddic) will be the version 1.2.3. The inliner will be improved to work directly in the call graph in postorder. That should produce better code. I will also try to improve the inlining heuristics. A first basic version of loop unswitching will be added as well. I will add a small local constant propagation pass for globals. I will also continue to work on the performances of the passes to avoid repeating them too much. MEMSET will be completely reviewed. That should produce smaller and faster code. Until now, the sizes of the types bool and chars were the same as int. They will be optimized to take only 1 byte.\nI will also continue the improvements of the data structures by merging all ltac::Statement into ltac::Instruction and storing them directly.\nAnd there will probably be some bug fixing as well.\nDownload\n\nYou can find the EDDI Compiler sources on the Github repository: https://github.com/wichtounet/eddic\nThe version is available in the v1.2.2 tag available in the GitHub or directly in the master branch.", 
      "tags": "C++11,EDDI,Releases"
    }, 
    {
      "loc": "/posts/2012/12/eddic-1-2-1-string-concatenation-and-vector.html", 
      "title": "eddic 1.2.1 - string, concatenation and vector", 
      "text": "Before preparing myself for New Year's Eve, I decided to finish eddic 1.2.1, and it's done !\nThis version is a small one, but add several improvements to the language and to the standard library. Many bugs have been fixed especially in the support of dynamic arrays and structures. \nThe first important change is that string has been renamed to str and that a new struct is available: string. Indeed, str is now a simple raw string where string has more capabilities like concatenation. This new version also supports concatenation of string and int, which was not possible before. In the future, I'll try to add more features to the string class. \nAnother improvement of the standard library is the inclusion of a vector structure. The vector is a dynamic arrays, which means that it can be automatically resized when necessary. For now, the operations available on vector are very few, but more will be added later. Especially, it is not possible now to add elements in the middle of the array, but it will be done, perhaps in the next eddic version or the next after this one. Adding the vector has also meant to add new features to the language. \nDynamic arrays of structures is now supported. And, the delete operator can be applied on any left value now, not only variables. It means that \"delete a[9];\" is now a valid code. \nFinally, in the side of the language, printB has been rewritten in EDDI instead of raw assembly. In the next versions, I will continue to rewrite as much as possible of the assembly stuff into EDDI. There are several advantages. The first one is that I don't have to maintain two versions (one for 32 bits and one for 64 bits). Another advantage is that it can profit from the eddic optimizations. And it is more readable and maintainable in EDDI. \nA new optimization is now available. If a function is always called with the same value for one of its parameters, the value is propagated inside the function. In the future, it will be improved to suppport propagation for instance in more than X% of the case, creating several versions of the function. The optimizations have also been a bit improved in terms of performance, making some samples much faster to compile than before. Essentially, the removal of dead basic blocks is now made in a way that it doesn't need to be run several times to remove all the dead basic blocks. \nThe warnings have been improved. Now, no warnings are emitted if some parts of a include are not used. And, if no elements of an included header is used, it will be warned that the include is not necessary. \nThe error reporting has also been improved a bit. It can now display several errors. For now, it is limited to one error by function. Doing better error reporting, would mean lots of changes in the AST passes which I don't want to do right now. \nThe hangman application has been fixed. It was a bug in the inliner that was causing this problem. There are now new test cases that verify that the optimizations are done. For instance, there is a test case verifying that the correct loops are removed when necessary. This is done by keeping tracks of counters like removed functions during the optimization. \nThe source code has also been improved. I now use less shared_ptr and rather rely in storing the elements in standard container and using references directly. It result in much better code. This also improves a bit the performances by having a better data locality. For now, I have handled the given classes: eddic::Function, mtac::Function and mtac::Program, but the next version will handle more critical structures like the basic blocks and the MTAC statements which could improve the performances of the optimization by making iteration faster. \nDon't hesitate to comment or to contact me if you have any suggestion (or other) about this release or for the future versions of eddic. \nAnd happy new year !\nFuture Work\n\nThe next version of the EDDI compiler (eddic) will be the version 1.2.2. In this version, I willl continue the work that I've done by using less shared_ptr and relying on references. I will also continue to improve the interfaces of the different class used. This version will also fix the memory leaks that I spotted in the application. There will also be new improvements on the language side, but minor one and I don't know now which ones I will pick. \nDownload\n\nYou can find the EDDI Compiler sources on the Github repository: https://github.com/wichtounet/eddic\nThe version is available in the v1.2.1 tag available in the GitHub or directly in the master branch.", 
      "tags": "EDDI,Releases"
    }, 
    {
      "loc": "/posts/2012/12/christmas-offer-buy-packt-publishing-ebooks.html", 
      "title": "Christmas offer - Buy 2 or more Packt Publishing eBooks for $5 each", 
      "text": "For Christmas, Packt Publishing has an awesome offer available to everybody :)\nAll eBooks from Packt Publishing are now available for only 5$ (\u20ac4 | \u00a33 | AUS$5) each when you buy two or more eBooks. \nThe offer is available until Thursday 3rd Jan 2013.\nMore information about the promotion: Stock your reader this christmas.", 
      "tags": "Books,Programming,Promotion"
    }, 
    {
      "loc": "/posts/2012/12/eddic-1-2-0-single-inheritance-copy-constructor.html", 
      "title": "eddic 1.2.0 - Single inheritance, copy construction", 
      "text": "I'm happy to release the version 1.2.0 of the EDDI Compiler (eddic).\nThis new version introduces several major changes to the language. \nFirst of all, structures can now inherits from another structure. When it is done, the structure can use the members of the parent class. Below is an example of single inheritance in EDDI: \nstruct A {\n    float a;\n\n    void init_a(){\n        a = 55.2;\n    }\n\n    void test_a(){\n        a += 1.1;\n    }\n}\n\nstruct B extends A {\n    char a;\n\n    void init_b(){\n        a = 'B';\n        init_a();\n    }\n\n    void test_b(){\n        test_a();\n    }\n}\n\n\n\nFor now, the support remains basic, but it will be improved over time. I will probably add support for virtual functions in the future. \nAnother major improvement to the language is that variable of a custom type can now be assignment, resulting in a call to the copy constructor. If no copy constructor is defined in a structure, it is automatically generated by the compiler. Another improvement to structures is that structures can now contains arrays. Moreover, the members of a structure (fields, constructors, functions, ...) can now be present in any order. \nA major change has been made to pointers. The conversions from variables to pointers is no more implicit, it is necessary to use the new & operator to take the address of a variable. I found that this implicit conversions was not really making any sense.\nA function can now return a structure by value. And, member functions can be called from any valid left value. For instance: \narray[5].function(5).function(9);\n\n\n\nis now valid code.  \nFinally, the switch construct can be used with strings too. This uses the str_equals functions to test which case is valid. \nThere are no big changes in the optimization engine. A new optimization pass has been added performing loop unrolling for loop with known iteration count. The pointer propagation has been fixed to handle pointers on structures resulting in much better code for several samples. The last improvement here is that conditions can be propagated into branches when necessary. \nThe loop analysis has been improved to directly calculate the number of iterations of each loop and store this result. The list of induction variables is only calculated once now. \nThe code generation has been slightly improved by saving fewer registers when calling another function. \nFinally, there are also some internal changes. The template instantiation depth limit can now configured. Before, infinite template recursion would just fail. The time spent in each optimization can now be computed with the new --timing option. There have been great improvements on the side of the Abstract Syntax Tree. A good part of the expression grammar has been rewritten. With these changes, the grammar is much more powerful than before. \nDon't hesitate to comment or to contact me if you have any suggestion (or other) about this release or for the future versions of eddic. \nI'd also like to thank TyRoXx who has made some improvements in the assembly generation module. \nFuture Work\n\nThe next version of the EDDI compiler (eddic) will be the version 1.2.1. This version will specifically focus on two points. First the usage of strings will be improved with a string class adding features to literal string. The second point will be the performances of the compiler. At this point, the optimization engine is clearly too slow. I will try to make it faster. The list of issues is available on Github.  \nDownload\n\nYou can find the EDDI Compiler sources on the Github repository: https://github.com/wichtounet/eddic\nThe version is available in the v1.2.0 tag available in the GitHub or directly in the master branch.", 
      "tags": "C++,Compilers,EDDI,Releases"
    }, 
    {
      "loc": "/posts/2012/12/cpp-benchmark-std-list-boost-intrusive-list.html", 
      "title": "C++ Benchmark - std::list VS boost::intrusive::list", 
      "text": "google.load('visualization','1',{packages:['corechart']});\n\nRecently, we saw that the std::list performance was not really good when it comes to searching it or iterating through it.In this post, we will see an alternative to the std::list: the boost::intrusive::list from the Boost C++ libraries. It is not a well known library but it can be useful in some specific cases. I will focus on how this implementation performs compared to an std::list.\nAn intrusive list does not store copies of the object but the objects itself. Because it stores the objects, it is necessary to add information to the object data structure directly to link them together, that is why it is called an\u00a0intrusive\u00a0list. This has a big advantage, the list does not have to allocate any memory at all to insert objects. In a std::list if you insert an object, a node object will be created containing a copy of the object, but not in an intrusive list where only the pointers to the next and to the previous element of the inserted object are updated. Another advantage is that if you have a reference to an object you can directly obtain an iterator to this object in O(1), an operation that would be in O(n) with a std::list. Iteration is faster because it needs less memory accesses.\nOn the other hand, an intrusive list has also several drawbacks. First of all, it is intrusive. It means that you have to change the definition of the type that is stored inside the intrusive list. Then, and it be very complicated, it is up to the developer to manage the life time of the objects. It means that it is up to you to allocate and deallocate memory for each objects that you want to put in your collection. For instance, if you store an object into an intrusive list and later delete this object without removing it from the list, you will have broken you list. It is also less safe because the container can be modified from outside simply by modifying the pointers directly inside the objects.\nThis article is not a tutorial for Boost intrusive collections, I will just focus on the performance aspect, if you want to learn how to use them, you can consult the official documentation. \nA boost::intrusive::list can be configured in three mode:\n\n    Normal mode: No special features\n    Safe mode: The hook is initialized to a default safe state and the container check this state before inserting a value. The state of a removed node is also updated correctly. It can be used to detect programming errors. It implies a small performance overhead. This is the default mode.\n    Auto unlink mode: When an object gets destructed it is automatically removed from the container. This mode has also the properties of the safe mode.\n\n\nThe mode is chosen at constant time by configuring the hook of the data type. In this article, all three mode will be tested. Here are the four types that will be tested:\n\n    list : std::list\n    normal_ilist : boost::intrusive::list in normal mode\n    safe_ilist : boost::intrusive::list in safe mode\n    auto_unlink_ilist : boost::intrusive::list in auto unlink mode\n\n\nThe data types are varying in size, they hold an array of longs and the size of the array varies to change the size of the data type. In each graph, the size of the data type is indicated. It is the size of the normal data type. The intrusive data types are always 16 bytes bigger than the normal data types. \nIn the graphs and in the text,\u00a0n\u00a0is used to refer to the number of elements of the collection.\nAll the tests performed have been performed on an Intel Core i7 Q 820 \u00a0@ 1.73GHz. The code has been compiled in 64 bits with GCC 4.7.2 with the given options:\u00a0-std=c++11 -O2 -fomit-frame-pointer -march=native\nFor each graph, the vertical axis represent the amount of time necessary to perform the operations, so the lower values are the better. The horizontal axis is always the number of elements of the collection. For some graph, the logarithmic scale could be clearer, a button is available after each graph to change the vertical scale to a logarithmic scale.\nSo let's see these data structures in practice.\n\n\nFill list\n\nThe first test that is performed is how long does it take to fill each data structure. For the std::list, each value is entered directly. For the intrusive list variations, the data are entered into a vector and then pushed back to the intrusive list. \nSo, let's test them: \n\n\nfunction draw_graph_0(){var graph=new google.visualization.LineChart(document.getElementById('graph_0'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['100000',265,261,491,2926],['200000',534,498,773,4717],['300000',1874,1841,1901,7201],['400000',2670,2657,2749,9696],['500000',3410,3447,3486,11608],['600000',4044,4095,4050,14024],['700000',4653,4549,4626,16750],['800000',5406,5320,5414,18568],['900000',5995,5926,6160,20880],['1000000',6806,6785,6784,22795],]);var options={curveType:\"function\",animation:{duration:1200,easing:\"in\"},title:\"fill_back - Normal&lt;8u&gt;\",width:'600px',height:'400px',hAxis:{title:\"Number of elements\",slantedText:true},vAxis:{title:\"us\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_0');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\nWe can see that filling a list is about thrice slower than an intrusive version. This is quite logical because there are much less memory allocations in the case of the intrusive lists. The differences between the different intrusive versions are not very big. The normal version is the fastest, then the auto unlink and finally the safe version is the slowest. \nIf we increase the size of the data type a bit: \n\n\nfunction draw_graph_1(){var graph=new google.visualization.LineChart(document.getElementById('graph_1'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['100000',850,894,967,2685],['200000',1760,1671,1747,5742],['300000',3987,3916,3970,8517],['400000',5257,5191,5238,10919],['500000',6561,6813,6661,13614],['600000',7943,8197,7954,15874],['700000',9251,9523,9049,18625],['800000',10463,10865,10417,21114],['900000',11736,11992,11734,23824],['1000000',13137,13423,13055,26555],]);var options={curveType:\"function\",animation:{duration:1200,easing:\"in\"},title:\"fill_back - Normal&lt;32u&gt;\",width:'600px',height:'400px',hAxis:{title:\"Number of elements\",slantedText:true},vAxis:{title:\"us\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_1');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\nThe results remains more or less the same, but this time there is less difference between list and intrusive list. \n\n\nfunction draw_graph_2(){var graph=new google.visualization.LineChart(document.getElementById('graph_2'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['100000',2131,2109,2923,39337],['200000',3834,3830,5792,90984],['300000',6454,6508,8604,138087],['400000',8499,8926,11614,185607],['500000',11068,10874,14455,230798],['600000',13009,13052,17307,275473],['700000',14965,15008,20593,326638],['800000',17082,17186,23109,372022],['900000',19283,19476,26182,415426],['1000000',21503,21569,29463,463462],]);var options={curveType:\"function\",animation:{duration:1200,easing:\"in\"},title:\"fill_back - Normal&lt;1024u&gt;\",width:'600px',height:'400px',hAxis:{title:\"Number of elements\",slantedText:true},vAxis:{title:\"us\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_2');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\nThis time, the results are really different. The intrusive versions are twenty times faster than a standard list. This comes from dynamic allocations of large blocks that is very expensive. In the case of intrusive list, there are no memory allocations, just modifications of pointers, so it it is normal that for big blocks the difference is higher. \nWe can see that for push_back operations, the intrusive are clearly faster. For small data types, they can be up to three times faster. The difference can be much higher with very big data types. There are no big differences between the different versions of the intrusive lists. The normal mode is about 10% faster than the safe mode. \n\n\nDestruction of list\n\nThe second test is about the time necessary to destruct a collection. For a list, the list is simply allocated on the heap and destructed with delete operator. For an intrusive list, both the vector and the list are allocated on the heap. The time is computed to delete both the vector and the intrusive list. \nLet's take a look at the results: \n\n\nfunction draw_graph_3(){var graph=new google.visualization.LineChart(document.getElementById('graph_3'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['100000',298,283,0,2420],['200000',588,585,0,3132],['300000',1196,1217,1,4487],['400000',2180,2350,1,6478],['500000',3169,3098,1,7259],['600000',3975,3957,1,8609],['700000',4569,4798,1,10018],['800000',5189,5311,1,11501],['900000',5927,6022,1,13004],['1000000',6616,6592,1,14423],]);var options={curveType:\"function\",animation:{duration:1200,easing:\"in\"},title:\"destruction - Normal&lt;8u&gt;\",width:'600px',height:'400px',hAxis:{title:\"Number of elements\",slantedText:true},vAxis:{title:\"us\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_3');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\nThe impressive result is that the normal mode is almost free. It is normal because the destructor of the objects does not do anything. Neither the list does anything about the state of the object after it has been removed. The other two intrusive versions performs the same and twice faster than a list. \nLet's increase a bit the size: \n\n\nfunction draw_graph_4(){var graph=new google.visualization.LineChart(document.getElementById('graph_4'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['100000',515,531,0,1490],['200000',1997,1964,0,3370],['300000',4022,3818,1,5585],['400000',5219,5456,1,7099],['500000',6693,6847,1,9054],['600000',7859,7984,1,11131],['700000',9456,9382,1,12248],['800000',10637,10493,1,14059],['900000',12433,11882,1,15933],['1000000',13646,13098,1,17434],]);var options={curveType:\"function\",animation:{duration:1200,easing:\"in\"},title:\"destruction - Normal&lt;32u&gt;\",width:'600px',height:'400px',hAxis:{title:\"Number of elements\",slantedText:true},vAxis:{title:\"us\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_4');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\nThis time, the std::list version is getting closer to the auto unlink and safe versions. The auto unlink version is a bit slower than the safe version. The normal mode is still free. \nIncreasing it a bit again: \n\n\nfunction draw_graph_5(){var graph=new google.visualization.LineChart(document.getElementById('graph_5'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['100000',4110,4158,1,4388],['200000',8357,8231,1,8949],['300000',12461,11871,1,12417],['400000',16097,16064,1,16249],['500000',19754,19990,1,19181],['600000',23724,24022,1,22019],['700000',28973,28421,2,24928],['800000',32638,32793,1,31896],['900000',37257,36320,1,35455],['1000000',40422,41037,1,39357],]);var options={curveType:\"function\",animation:{duration:1200,easing:\"in\"},title:\"destruction - Normal&lt;128u&gt;\",width:'600px',height:'400px',hAxis:{title:\"Number of elements\",slantedText:true},vAxis:{title:\"us\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_5');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\nWe can see that the list is a small bit faster than the other two versions. \nIf we push the memory to its limit: \n\n\nfunction draw_graph_6(){var graph=new google.visualization.LineChart(document.getElementById('graph_6'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['100000',2582,2689,1,5669],['200000',10506,10450,1,19719],['300000',16490,16429,1,33569],['400000',21521,21702,1,47179],['500000',27188,27217,1,59640],['600000',32507,32470,1,70116],['700000',37288,37344,1,81122],['800000',42825,42611,1,91972],['900000',48004,48315,1,104401],['1000000',53439,53988,1,114482],]);var options={curveType:\"function\",animation:{duration:1200,easing:\"in\"},title:\"destruction - Normal&lt;1024u&gt;\",width:'600px',height:'400px',hAxis:{title:\"Number of elements\",slantedText:true},vAxis:{title:\"us\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_6');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\nThis time, the list is again slower. I'm not sure of why this happens, but it is certainly because of the memory allocator that has two allocate too many big blocks, which tends to be more costly than many small. \nFor the destruction, the normal mode proved its high strength, being totally free to destroy. The safe and auto unlink modes are proving much more expensive during destruction, but still quite a bit faster than a standard list. \nIt is also necessary to keep in mind that the destruction is generally not a common operation and is about 4 times faster than insertion. In practice, neither push_back nor destruction are critical in choosing a data structure. \n\n\nLinear Search in a list\n\nThe next operation that will benchmark is the linear search. The container is filled with all the numbers in [0, n] and shuffled. Then, each number in [0, n] is searched in the container with std::find that performs a simple linear search.\nHow do the different data structures perform: \n\n\nfunction draw_graph_7(){var graph=new google.visualization.LineChart(document.getElementById('graph_7'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['1000',1213,1211,1200,1463],['2000',5715,5561,5931,6992],['3000',12451,11619,11608,14251],['4000',19338,20142,19208,24840],['5000',30147,30889,29863,40523],['6000',42941,44530,43289,59541],['7000',59717,62534,58851,80416],['8000',77519,78889,77188,104198],['9000',99738,99434,100375,135452],['10000',123829,123216,123506,169720],]);var options={curveType:\"function\",animation:{duration:1200,easing:\"in\"},title:\"linear_search - Normal&lt;8u&gt;\",width:'600px',height:'400px',hAxis:{title:\"Number of elements\",slantedText:true},vAxis:{title:\"us\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_7');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\nAs expected, the intrusive list versions are faster than the standard list. The margin is about 40%. The intrusive versions have a better locality than the standard list because there is one less indirection. \nIncreasing the data type size: \n\n\nfunction draw_graph_8(){var graph=new google.visualization.LineChart(document.getElementById('graph_8'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['1000',2901,2862,2940,2757],['2000',14258,14242,14413,18990],['3000',37327,37078,37387,48716],['4000',69310,68935,69152,86224],['5000',109444,110199,108283,134128],['6000',158570,158392,158398,202273],['7000',219949,220489,219070,266387],['8000',285885,289721,283485,342109],['9000',363603,361367,362935,424984],['10000',445068,451009,447940,525289],]);var options={curveType:\"function\",animation:{duration:1200,easing:\"in\"},title:\"linear_search - Normal&lt;128u&gt;\",width:'600px',height:'400px',hAxis:{title:\"Number of elements\",slantedText:true},vAxis:{title:\"us\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_8');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\nThe margin has decreased a bit to about 15%. As the data object does not fit in cache we have higher cache misses rate. \nIf we increase it to the maximum: \n\n\nfunction draw_graph_9(){var graph=new google.visualization.LineChart(document.getElementById('graph_9'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['1000',3517,3818,3487,3570],['2000',19342,18999,18875,22972],['3000',59722,59728,60953,60749],['4000',116755,118256,117172,123127],['5000',194630,195522,192977,204278],['6000',287911,287099,291353,296178],['7000',395506,404527,396043,413398],['8000',519636,527051,527183,549713],['9000',662320,669371,672484,693154],['10000',831052,828032,832995,859092],]);var options={curveType:\"function\",animation:{duration:1200,easing:\"in\"},title:\"linear_search - Normal&lt;1024u&gt;\",width:'600px',height:'400px',hAxis:{title:\"Number of elements\",slantedText:true},vAxis:{title:\"us\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_9');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\nAgain, the margin decreased, to 3%. \nFor linear searching, the intrusive versions are clearly faster, however, not by a high advantage and this advantage tends to get lower with bigger data types. I would really have expected a more interesting result here. We will see with the next results if it gets better. \n\n\nIteration over a list\n\nThis time, we will test the iteration over a whole collection. The iterate is done with the C++11 foreach loop (taking a reference) and the data is used to increment a counter (to make sure the loop is not optimized away. \nLet's start with our small data type: \n\n\nfunction draw_graph_10(){var graph=new google.visualization.LineChart(document.getElementById('graph_10'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['100000',204,202,209,276],['200000',430,404,439,715],['300000',967,956,1086,1969],['400000',1837,1826,1870,2672],['500000',2705,2668,2699,3130],['600000',3176,3110,3217,3815],['700000',3856,3678,3575,4363],['800000',4209,4090,4095,4860],['900000',4778,4334,4433,5511],['1000000',4934,4908,4656,5541],]);var options={curveType:\"function\",animation:{duration:1200,easing:\"in\"},title:\"iterate - Normal&lt;8u&gt;\",width:'600px',height:'400px',hAxis:{title:\"Number of elements\",slantedText:true},vAxis:{title:\"us\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_10');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\nThe standard list is indeed slower than the other versions (by about 20%). Which is expected due to their better data locality. However, the results are not very stable (probably too fast, many things can intervene). I was expecting better results. \nLet's go with a higher data type: \n\n\nfunction draw_graph_11(){var graph=new google.visualization.LineChart(document.getElementById('graph_11'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['100000',3694,3635,3467,3830],['200000',6779,6766,6430,7070],['300000',9472,9819,9291,10270],['400000',12354,12322,12165,13588],['500000',15188,15270,15079,16725],['600000',18447,18246,17797,19875],['700000',20925,20578,20596,23256],['800000',23539,23780,23421,26451],['900000',26492,26237,25975,29785],['1000000',29757,29482,28681,32752],]);var options={curveType:\"function\",animation:{duration:1200,easing:\"in\"},title:\"iterate - Normal&lt;128u&gt;\",width:'600px',height:'400px',hAxis:{title:\"Number of elements\",slantedText:true},vAxis:{title:\"us\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_11');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\nThis time, the results look better, but there are less difference between the standard list and the intrusive versions. The intrusive versions are faster by about 10%. \nIf we take a bigger data type: \n\n\nfunction draw_graph_12(){var graph=new google.visualization.LineChart(document.getElementById('graph_12'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['100000',2797,2649,2496,5211],['200000',10148,10227,10199,10701],['300000',15379,15544,15458,15189],['400000',20181,20599,20213,20135],['500000',25481,25517,25381,25567],['600000',30407,30408,30326,29938],['700000',35187,35343,35498,34985],['800000',40094,39874,40172,40027],['900000',44875,45329,45314,44964],['1000000',49584,50143,50405,49737],]);var options={curveType:\"function\",animation:{duration:1200,easing:\"in\"},title:\"iterate - Normal&lt;1024u&gt;\",width:'600px',height:'400px',hAxis:{title:\"Number of elements\",slantedText:true},vAxis:{title:\"us\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_12');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\nThis time, there is no more difference between the different versions. \nJust like the results for linear search, the intrusive versions are faster but the difference is not huge. For very small data type, there is a gain of about 15 to 20 percent, but on very big data types, there is no more increase in performance. Again, I would have expected better results for the intrusive versions. \n\n\nWrite to elements of the list\n\nThis test is almost the same as the previous one, but this time each element of the collection is modified by incrementing one of its field. \nLet's see if the results are different this time. \n\n\nfunction draw_graph_13(){var graph=new google.visualization.LineChart(document.getElementById('graph_13'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['100000',267,290,263,343],['200000',579,583,548,889],['300000',1111,1142,1114,2151],['400000',2155,2143,2146,3197],['500000',3193,3186,3163,4168],['600000',4016,3991,3978,5179],['700000',4727,4916,4717,6026],['800000',5560,5534,5440,6977],['900000',6125,6157,6064,7693],['1000000',6830,6920,6785,8613],]);var options={curveType:\"function\",animation:{duration:1200,easing:\"in\"},title:\"write - Normal&lt;8u&gt;\",width:'600px',height:'400px',hAxis:{title:\"Number of elements\",slantedText:true},vAxis:{title:\"us\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_0');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\nThe results are more stable than before. We can see that the normal mode is leading the results by a bit less than 30%. Just like for iteration, there no real difference between the different modes. \nLet's increase the data size by a bit: \n\n\nfunction draw_graph_14(){var graph=new google.visualization.LineChart(document.getElementById('graph_14'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['100000',505,513,530,1069],['200000',1957,1991,2023,3222],['300000',4056,4053,4000,4806],['400000',5572,5493,5587,6408],['500000',6763,6798,6714,8578],['600000',8224,8142,8050,10037],['700000',9520,9622,9568,12272],['800000',10982,11451,10947,13818],['900000',12195,12305,12185,15103],['1000000',14043,13657,13775,17187],]);var options={curveType:\"function\",animation:{duration:1200,easing:\"in\"},title:\"write - Normal&lt;32u&gt;\",width:'600px',height:'400px',hAxis:{title:\"Number of elements\",slantedText:true},vAxis:{title:\"us\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_14');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\nThe results are the same, still 30% better for the intrusive version. \nBigger data type again: \n\n\nfunction draw_graph_15(){var graph=new google.visualization.LineChart(document.getElementById('graph_15'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['100000',3263,3415,3172,4444],['200000',9467,9434,9513,8855],['300000',13996,13888,14227,13379],['400000',18181,18458,18255,17684],['500000',22751,23292,22956,22067],['600000',27371,27511,27329,25995],['700000',31236,31389,31404,31164],['800000',35749,35970,36132,35224],['900000',39972,40684,40549,39786],['1000000',45119,45124,44840,43937],]);var options={curveType:\"function\",animation:{duration:1200,easing:\"in\"},title:\"write - Normal&lt;1024u&gt;\",width:'600px',height:'400px',hAxis:{title:\"Number of elements\",slantedText:true},vAxis:{title:\"us\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_15');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\nThis time, the intrusive version is not faster anymore than the standard list. \nWe have seen that when write is made to the data, intrusive list are better than list. The margin is higher than when doing only iteration. \n\n\nReverse the list\n\nLet's test something more useful with a reverse operation. The reverse member function is used to reverse all the containers. \nLet's see how they perform: \n\n\nfunction draw_graph_16(){var graph=new google.visualization.LineChart(document.getElementById('graph_16'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['100000',366,410,390,372],['200000',761,892,758,867],['300000',1278,1354,1308,2062],['400000',2313,2348,2324,3083],['500000',3265,3297,3300,3994],['600000',4036,4171,4063,4890],['700000',4603,4575,4689,6052],['800000',5344,5241,5321,6682],['900000',6107,5912,6251,7623],['1000000',6725,6626,6663,8548],]);var options={curveType:\"function\",animation:{duration:1200,easing:\"in\"},title:\"reverse - Normal&lt;8u&gt;\",width:'600px',height:'400px',hAxis:{title:\"Number of elements\",slantedText:true},vAxis:{title:\"us\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_16');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\nThe intrusive versions are about 25% faster than standard list. Even if reversal does not need to access the values, the pointers of the intrusive lists have a better locality than the one of a list that can be dispersed through memory. \n\n\nfunction draw_graph_17(){var graph=new google.visualization.LineChart(document.getElementById('graph_17'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['100000',585,563,601,1057],['200000',1903,1902,2011,3043],['300000',4121,4041,4049,4671],['400000',5291,5352,5275,6504],['500000',6831,6711,6584,8273],['600000',7980,8113,8105,9900],['700000',9366,9216,9426,11612],['800000',10680,10622,10602,13377],['900000',11917,11908,11915,15140],['1000000',13442,13239,13268,16718],]);var options={curveType:\"function\",animation:{duration:1200,easing:\"in\"},title:\"reverse - Normal&lt;32u&gt;\",width:'600px',height:'400px',hAxis:{title:\"Number of elements\",slantedText:true},vAxis:{title:\"us\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_17');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\nThe performance improved a bit, to 30% improvement for an intrusive list. \nLet's see if this continue: \n\n\nfunction draw_graph_18(){var graph=new google.visualization.LineChart(document.getElementById('graph_18'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['100000',2901,2901,2676,4562],['200000',5889,5942,5613,9059],['300000',8696,8618,8372,13501],['400000',11344,11597,11039,17985],['500000',14431,14123,13954,22546],['600000',17084,16955,16605,27246],['700000',19563,19795,19431,31866],['800000',22806,22428,22092,36645],['900000',25553,25283,25003,41025],['1000000',28049,28174,27590,45780],]);var options={curveType:\"function\",animation:{duration:1200,easing:\"in\"},title:\"reverse - Normal&lt;128u&gt;\",width:'600px',height:'400px',hAxis:{title:\"Number of elements\",slantedText:true},vAxis:{title:\"us\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_18');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\nIt did, the intrusive list is more than 40% faster than the standard list !\nWhat happens a bigger one: \n\n\nfunction draw_graph_19(){var graph=new google.visualization.LineChart(document.getElementById('graph_19'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['100000',4723,4823,4585,4373],['200000',11566,11566,11842,8704],['300000',17471,17377,17587,12985],['400000',22778,22867,22866,17452],['500000',28548,28434,28837,21357],['600000',34005,34089,33913,25907],['700000',39189,39235,39284,30398],['800000',45186,44900,44838,34632],['900000',50337,50529,50677,38540],['1000000',56045,56026,56007,42867],]);var options={curveType:\"function\",animation:{duration:1200,easing:\"in\"},title:\"reverse - Normal&lt;1024u&gt;\",width:'600px',height:'400px',hAxis:{title:\"Number of elements\",slantedText:true},vAxis:{title:\"us\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_19');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\nThe lines have been interchanged! This time the standard list is about 25% faster than the intrusive versions. This time, the better locality of the intrusive versions is not a gain but a loss. \nIt is logical that the margin decrease with very big objects during reversal. Indeed, each element is very close one to another, but the pairs of pointers are separated by the size of the data type. The bigger the data type, the higher distance between the pointers and so the worse spatial locality for the pointers. However, I do not explain why there is this big difference... \nThe performance of intrusive list are clearly interesting for reversing collection of small data types. However, it seems that for high data types, the standard list is faster.\n\n\nSort the list\n\nLet's continue with an even more interesting operation, sorting the list. All the versions are sorted with the sort member function.\n\n\nfunction draw_graph_20(){var graph=new google.visualization.LineChart(document.getElementById('graph_20'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['100000',16314,16503,16364,24992],['200000',38251,37599,38206,62834],['300000',63573,63521,63878,112848],['400000',90236,88561,88996,168037],['500000',114442,114456,116137,236389],['600000',167279,165879,166617,324302],['700000',190762,190586,190292,377142],['800000',223884,223900,224622,477313],['900000',255248,252795,253070,540602],['1000000',287262,286842,288404,614163],]);var options={curveType:\"function\",animation:{duration:1200,easing:\"in\"},title:\"sort - Normal&lt;8u&gt;\",width:'600px',height:'400px',hAxis:{title:\"Number of elements\",slantedText:true},vAxis:{title:\"ms\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_20');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\nThe intrusive versions are really interesting, being twice faster than a standard list. \nLet's see with a see a higher data type: \n\n\nfunction draw_graph_21(){var graph=new google.visualization.LineChart(document.getElementById('graph_21'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['100000',25335,25030,25318,31655],['200000',67224,65937,67185,80637],['300000',118284,116947,119686,139629],['400000',169014,165868,169723,194916],['500000',208261,208245,209291,248475],['600000',294572,287231,294284,339917],['700000',337154,332205,338323,389665],['800000',401654,393743,401249,461721],['900000',440058,434855,440984,506999],['1000000',494861,491360,497710,578176],]);var options={curveType:\"function\",animation:{duration:1200,easing:\"in\"},title:\"sort - Normal&lt;128u&gt;\",width:'600px',height:'400px',hAxis:{title:\"Number of elements\",slantedText:true},vAxis:{title:\"ms\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_21');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\nThe difference is decreasing to about 20%. \nIncreasing it again:\n\n\nfunction draw_graph_22(){var graph=new google.visualization.LineChart(document.getElementById('graph_22'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['100000',31568,33319,32201,40331],['200000',82407,85932,83987,97310],['300000',143651,150155,144553,163818],['400000',202050,209178,203821,232728],['500000',250514,256374,253415,289493],['600000',345760,351034,348564,391229],['700000',397848,402385,402371,454434],['800000',471832,479947,477681,538873],['900000',518542,527961,524002,596696],['1000000',583622,596696,591025,672353],]);var options={curveType:\"function\",animation:{duration:1200,easing:\"in\"},title:\"sort - Normal&lt;1024u&gt;\",width:'600px',height:'400px',hAxis:{title:\"Number of elements\",slantedText:true},vAxis:{title:\"ms\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_22');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\nIt decreased again to 18%. \nFor sort operations, the intrusive versions are clearly interesting, especially for small data types. \n\n\nRandom insert into the list\n\nThe last operation that we will test is the random insert. I have to say that this test is not fair. Indeed, in an intrusive list, from an object we can directly get an iterator and insert at a random position. For a standard list, we have to find the iterator by linear search. I think that it is still important because it is one of the advantages of an intrusive container.\n\n\nfunction draw_graph_23(){var graph=new google.visualization.LineChart(document.getElementById('graph_23'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_ilist','safe_ilist','normal_ilist','list'],['10000',42,46,41,27729],['20000',49,66,45,48736],['30000',64,66,47,62440],['40000',54,53,48,75253],['50000',59,54,49,88493],['60000',67,49,63,104516],['70000',50,53,50,115514],['80000',55,50,50,128950],['90000',51,51,55,144367],['100000',52,52,76,152721],]);var options={curveType:\"function\",animation:{duration:1200,easing:\"in\"},title:\"random_insert - Normal&lt;8u&gt;\",width:'600px',height:'400px',hAxis:{title:\"Number of elements\",slantedText:true},vAxis:{title:\"us\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_23');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\nIt is very clear that the performance are much better but it is logical because we are comparing something in O(1) versus something in O(n). \nConclusion\n\nIn conclusion, intrusive lists are almost always faster than a standard list. However, on my computer and with GCC, the difference is not always very important. It can brings about 20%-30% on some workloads but most likely around 15%. Even if not negligible, it is not a huge improvement. I would have thought that intrusive lists were faster by an higher margin. On some operations like sort, it is clearly more interesting. It has a better data locality than standard list. \nIt is also more interesting to fill the collection, because no memory allocation is involved. But of course, you need to take care of memory allocation by yourself, for example in a vector like here or by dynamically allocating the objects one after one. This has also a cost that is not counted in the benchmark. \nIf you really have to use a linked list and performance is critical, I advice you to use Boost intrusive list. If performance is not really critical, it is not perhaps not interesting because of the increased complexity. \nThere are situations when only intrusive lists can work. If you want the same object to be present in two different list, you can use boost intrusive list with several member hooks, which is not possible with standard list because only a copy is stored, not the object itself. The same is true for objects that are non-copyable, only intrusive list can handle them. And finally, with intrusive lists you can directly get an iterator to an object in O(1) if you have a reference to an object. For a standard list, you have to iterate through the list to find the object. Sometimes, it can be very useful. \nIf you are interested, the Boost documentation provides also a performance benchmark for intrusive list, but it is very old (GCC 4.1.2). It is interesting to see that the results are better for intrusive lists than on my benchmark. I do not know if it comes from the processor, the memory or from the compiler. \nI hope you found this benchmark interesting. If you have questions, comments, ideas or whatever to say about this benchmark, don't hesitate to comment. I would be glad to answer you :) The same if you find errors in this article. If you have different results, don't hesitate to comment as well. \nThe code source of the benchmark is available online: https://github.com/wichtounet/articles/blob/master/src/intrusive_list/bench.cpp\nfunction draw_visualization(){draw_graph_0();draw_graph_1();draw_graph_2();draw_graph_3();draw_graph_4();draw_graph_5();draw_graph_6();draw_graph_7();draw_graph_8();draw_graph_9();draw_graph_10();draw_graph_11();draw_graph_12();draw_graph_13();draw_graph_14();draw_graph_15();draw_graph_16();draw_graph_17();draw_graph_18();draw_graph_19();draw_graph_20();draw_graph_21();draw_graph_22();draw_graph_23();} google.setOnLoadCallback(draw_visualization);", 
      "tags": "Benchmark,Boost,C++,C++11,Performances"
    }, 
    {
      "loc": "/posts/2012/12/wordpress-plugin-google-visualization-charts.html", 
      "title": "New WordPress Plugin - Google Visualization Charts", 
      "text": "google.load('visualization','1',{packages:['corechart']});\n\nAs I started writing some big benchmarks, I discovered that there were no really good plugins to generate graphs in WordPress (at least not free ones). Then, I discovered the Google Visualization API that generates awesome charts. I decided to create a new WordPress plugin to help generates these charts. \nThe Google Visualization API is very powerful. There are a lot of different charts that are available. The charts can be customized easily. The charts are interactive, the user can get the values of any points in the graphs. The charts are rendered using HTML5/SVG technology to provide cross-browser compatibility (including VML for older IE versions) and cross platform portability to iPhones, iPads and Android. No plugins are needed, only the inclusion of the JavaScript library. \nThe plugin supports two different graphs: line charts and bar charts. For each graph, the title of the graph and the titles of the axis can be configured. The height and width of the graph can also be configured. I also added an option to change the scale of the graph to a logarithmic scale. \nExamples\n\nHere is an example of line chart: \n\n\nfunction draw_graph_0(){var graph=new google.visualization.LineChart(document.getElementById('graph_0'));var data=google.visualization.arrayToDataTable([['x','list','vector','deque','vector_pre'],['100000',2545,271,2012,317],['200000',4927,552,998,334],['300000',7310,944,1707,595],['400000',9463,936,2056,1099],['500000',12591,1140,2642,1058],['600000',14351,1894,3125,1237],['700000',16561,1995,3686,1208],['800000',18820,2648,4291,1365],['900000',20832,2777,4962,2268],['1000000',23430,3015,5396,2585],]);var options={curveType:\"function\",animation:{duration:1200,easing:\"in\"},title:\"fill_back - 8 bytes\",width:'600px',height:'400px',hAxis:{title:\"Number of elements\",slantedText:true},vAxis:{title:\"us\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_0');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\nThe chart is generated using the given code: \n[line_chart title=\"fill_back - 8 bytes\" h_title=\"Number of elements\" v_title=\"us\" scale_button=\"true\" width=\"600px\" height=\"400px\"]\n['x', 'list', 'vector', 'deque', 'vector_pre'],\n['100000', 2545, 271, 2012, 317],\n['200000', 4927, 552, 998, 334],\n['300000', 7310, 944, 1707, 595],\n['400000', 9463, 936, 2056, 1099],\n['500000', 12591, 1140, 2642, 1058],\n['600000', 14351, 1894, 3125, 1237],\n['700000', 16561, 1995, 3686, 1208],\n['800000', 18820, 2648, 4291, 1365],\n['900000', 20832, 2777, 4962, 2268],\n['1000000', 23430, 3015, 5396, 2585],\n[line_chart]\n\n\n\nAnd here is an another example of a bar chart: \n\n\nfunction draw_graph_1(){var graph=new google.visualization.ColumnChart(document.getElementById('graph_1'));var data=google.visualization.arrayToDataTable([['Compiler','testsuite','assembly','linked_list'],['GCC -O2',6.58,1.2,0.51],['GCC -O3',6.59,1.2,0.5],['CLang -O2',6.74,1.2,0.49],['CLang -O3',6.58,1.2,0.49],]);var options={title:\"Runtime Performance - Less is better\",animation:{duration:1200,easing:\"in\"},width:'600px',height:'400px',hAxis:{title:\"Options\"},vAxis:{title:\"Seconds\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_1');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\nHere is the code of the chart: \n[bar_chart width=\"600px\" height=\"400px\" title=\"Runtime Performance - Less is better\" h_title=\"Options\" v_title=\"Seconds\" scale_button=\"true\"]\n['Compiler', 'testsuite', 'assembly', 'linked_list'],\n['GCC -O2',  6.58,   1.2, 0.51],\n['GCC -O3',  6.59,   1.2, 0.5],\n['CLang -O2',  6.74,   1.2, 0.49],\n['CLang -O3',  6.58,   1.2, 0.49],\n[/bar_chart]\n\n\n\nFor more examples, you can consult this article or this other one. \nDownloads\n\nThe plugin is available on the WordPress Plugin Directory: Google Visualization Charts\nI hope that this plugin will be useful. I will try to add support for new charts in the future. \nDon't hesitate to comment if you find a bug or if you have an idea of improvement :) As it is my very first WordPress plugin, I'm welcoming all comments.\nfunction draw_visualization(){draw_graph_0();draw_graph_1();}google.setOnLoadCallback(draw_visualization);", 
      "tags": "PHP,Web,WordPress"
    }, 
    {
      "loc": "/stories/donate.html", 
      "title": "Donate", 
      "text": "You probably got to this page because you like my WordPress plugin or a post I wrote here. I'm very happy to hear that!\nI spend a lot of time writing the posts of this site and contributing to different open source projets and I like a lot getting positive feedback. If you want to support me, there are various ways in which you could do this:\n\nBuy me some thing :) from my Amazon Wishlist (from the Europe: Amazon Fr Wishlist.\nMake a donation via PayPal using the button below (credit cards etc. accepted too).", 
      "tags": ""
    }, 
    {
      "loc": "/posts/2012/12/cmake-rerun-last-failed-tests-ctest.html", 
      "title": "CMake Testing - Rerun the last failed tests with CTest", 
      "text": "Some time ago, we saw how to use CMake to run Boost Tests in paralel, now it is time for another tip. \nA feature that I think is lacking in CMake/CTest is a way to launch only the last failed tests. As it is not possible to do that directly, I posted the question on StackOverflow and got a great answer from Fraser. I wanted to share its answer. \nCTest has -I option to select a list of tests to run. The idea here is to convert the log of CTest in format readable by CTest. What I think is great in its answer is that the solution is a CMake script: \nset(FailedFileName FailedTests.log)\nif(EXISTS \"Testing/Temporary/LastTestsFailed.log\")\n  file(STRINGS \"Testing/Temporary/LastTestsFailed.log\" FailedTests)\n  string(REGEX REPLACE \"([0-9]+):[;]*\" \"\\\\1\" FailedTests \"${FailedTests}\")\n  list(SORT FailedTests)\n  list(GET FailedTests 0 FirstTest)\n  set(FailedTests \"${FirstTest};${FirstTest};;${FailedTests};\")\n  string(REPLACE \";\" \",\" FailedTests \"${FailedTests}\")\n  file(WRITE ${FailedFileName} ${FailedTests})\nelse()\n  file(WRITE ${FailedFileName} \"\")\nendif()\n\n\n\nThis test just transforms one file into another. \nYou can then run the last failing tests using: \ncmake -P \nctest -I FailedTests.log\n\nVery easy, isn't it ? \nThere is a limitation to this solution. It won't work when CTest is running in dashboard mode, but it wouldn't take too long to adapt it for that. \nHope you found that tip useful.", 
      "tags": "C++,cmake,Tests,Tools"
    }, 
    {
      "loc": "/posts/2012/12/cpp-benchmark-vector-list-deque.html", 
      "title": "C++ benchmark \u2013 std::vector VS std::list VS std::deque", 
      "text": "google.load('visualization','1',{packages:['corechart']});\n\nLast week, I wrote a benchmark comparing the performance of std::vector and std::list on different workloads. This previous article received a lot of comments and several suggestions to improve it. The present article is an improvement over the previous article. \nIn this article, I will compare the performance of std::vector, std::list and std::deque on several different workloads and with different data types. In this article, when I talk about a list refers to std::list, a vector refers to std::vector and deque to std::deque.\nIt is generally said that a list should be used when random insert and remove will be performed (performed in O(1) versus O(n) for a vector or a deque). If we look only at the complexity, the scale of linear search in both data structures should be equivalent, complexity being in O(n). When random insert/replace operations are performed on a vector or a deque, all the subsequent data needs to be moved and so each element will be copied. That is why the size of the data type is an important factor when comparing those two data structures. Because the size of the data type will play an important role on the cost of copying an element. \nHowever, in practice, there is a huge difference: the usage of the memory caches. All the data in a vector is contiguous where the std::list allocates separately memory for each element. How does that change the results in practice ? The deque is a data structure aiming at having the advantages of both data structures without their drawbacks, we will see how it perform in practice. Complexity analysis does not take the memory hierarchy into level. I believe that in practice, memory hierarchy usage is as important as complexity analysis. \nKeep in mind that all the tests performed are made on vector, list and deque even if other data structures could be better suited to the given workload. \nIn the graphs and in the text, n is used to refer to the number of elements of the collection. \nAll the tests performed have been performed on an Intel Core i7 Q 820 \u00a0@ 1.73GHz. The code has been compiled in 64 bits with GCC 4.7.2 with -02 and -march=native. The code has been compiled with C++11 support (-std=c++11). \nFor each graph, the vertical axis represent the amount of time necessary to perform the operations, so the lower values are the better. The horizontal axis is always the number of elements of the collection. For some graph, the logarithmic scale could be clearer, a button is available after each graph to change the vertical scale to a logarithmic scale. \nThe data types are varying in size, they hold an array of longs and the size of the array varies to change the size of the data type. The non-trivial data type is made of two longs and has very stupid assignment operator and copy constructor that just does some maths (totally meaningless but costly). One may argue that is not a common copy constructor neither a common assignment operator and one will be right, however, the important point here is that it is costly operators which is enough for this benchmark. \nFill\n\nThe first test that is performed is to fill the data structures by adding elements to the back of the container (using push_back). Two variations of vector are used, vector_pre being a std::vector using vector::reserve at the beginning, resulting in only one allocation of memory.\nLets see the results with a very small data type: \n\n\nfunction draw_graph_0(){var graph=new google.visualization.LineChart(document.getElementById('graph_0'));var data=google.visualization.arrayToDataTable([['x','list','vector','deque','vector_pre'],['100000',2545,271,2012,317],['200000',4927,552,998,334],['300000',7310,944,1707,595],['400000',9463,936,2056,1099],['500000',12591,1140,2642,1058],['600000',14351,1894,3125,1237],['700000',16561,1995,3686,1208],['800000',18820,2648,4291,1365],['900000',20832,2777,4962,2268],['1000000',23430,3015,5396,2585],]);var options={curveType:\"function\",animation:{duration:1200,easing:\"in\"},title:\"fill_back - 8 bytes\",width:'600px',height:'400px',hAxis:{title:\"Number of elements\",slantedText:true},vAxis:{title:\"us\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_0');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\nThe pre-allocated vector is the fastest by a small margin and the list is 3 times slower than a vector. deque and vector. \nIf we consider higher data type: \n\n\nfunction draw_graph_1(){var graph=new google.visualization.LineChart(document.getElementById('graph_1'));var data=google.visualization.arrayToDataTable([['x','list','vector','deque','vector_pre'],['100000',104867,55545,66852,21738],['200000',226215,108289,136035,42532],['300000',340910,198343,153446,60317],['400000',445035,217325,269316,80616],['500000',559619,236576,189613,101371],['600000',688422,391354,303729,122447],['700000',799902,405771,426373,138868],['800000',921441,415707,537057,160637],['900000',1006331,439635,263650,177052],['1000000',1113690,464416,372000,199434],]);var options={curveType:\"function\",animation:{duration:1200,easing:\"in\"},title:\"fill_back - 4096 bytes\",width:'600px',height:'400px',hAxis:{title:\"Number of elements\",slantedText:true},vAxis:{title:\"us\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_1');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\nThis time vector and list are performing at about the same speed. The deque is a bit faster than list and vector. The pre-allocated vector is clearly the winner here. The variations in the results of deque and vector are probably coming from my system that doesn't like allocating so much memory back and forth at this speed. \nFinally, if we use a non-trivial data type: \n\n\nfunction draw_graph_2(){var graph=new google.visualization.LineChart(document.getElementById('graph_2'));var data=google.visualization.arrayToDataTable([['x','list','vector','deque','vector_pre'],['100000',8093,8123,10251,8095],['200000',15433,15305,16061,13897],['300000',25964,24643,24450,19954],['400000',33414,30322,32148,27171],['500000',40416,37817,40752,35058],['600000',48991,48594,48785,41049],['700000',55059,55124,55092,47609],['800000',63688,61360,64505,55659],['900000',70550,67636,72329,60952],['1000000',79271,73533,79522,67787],]);var options={curveType:\"function\",animation:{duration:1200,easing:\"in\"},title:\"fill_back - 16 bytes\",width:'600px',height:'400px',hAxis:{title:\"Number of elements\",slantedText:true},vAxis:{title:\"us\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_2');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\nAll data structures are performing more or less the same, with vector_pre being the fastest. \nFor push_back operations, pre-allocated vectors is a very good choice if the size is known in advance. The others performs more of less the same.\nI would have expected a better result for pre-allocated vector. If someone find an explanation for such a small margin, I'm interested. \nLinear Search\n\nThe first operation is that is tested is the search. The container is filled with all the numbers in [0, N] and shuffled. Then, each number in [0,N] is searched in the container with std::find that performs a simple linear search. In theory, all the data structures should perform the same if we consider their complexity. \n\n\nfunction draw_graph_3(){var graph=new google.visualization.LineChart(document.getElementById('graph_3'));var data=google.visualization.arrayToDataTable([['x','deque','list','vector'],['1000',593,1098,318],['2000',2927,5307,1271],['3000',5891,12228,3020],['4000',8663,24415,5081],['5000',12859,36316,8066],['6000',18493,55057,11463],['7000',25057,74344,16022],['8000',38980,99990,21051],['9000',44951,127575,26650],['10000',52281,158216,32557],]);var options={curveType:\"function\",animation:{duration:1200,easing:\"in\"},title:\"linear_search - 8 bytes\",width:'600px',height:'400px',hAxis:{title:\"Number of elements\",slantedText:true},vAxis:{title:\"us\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_3');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\nIt is clear from the graph that the list has very poor performance for searching. The growth is much worse for a list than for a vector or a deque.\nThe only reason is the usage of the cache line. When a data is accessed, the data is fetched from the main memory to the cache. Not only the accessed data is accessed, but a whole cacheline is fetched. As the elements in a vector are contiguous, when you access an element, the next element is automatically in the cache. As the main memory is orders of magnitude slower than the cache, this makes a huge difference. In the list case, the processor spends its whole time waiting for data being fetched from memory to the cache, at each fetch, the processor fetches a lot of unnecessary data that are almost always useless. \nThe deque is a bit slower than the vector, that is logical because here there are more cache misses due to the segmented parts. \nIf we take a bigger data type: \n\n\nfunction draw_graph_4(){var graph=new google.visualization.LineChart(document.getElementById('graph_4'));var data=google.visualization.arrayToDataTable([['x','deque','list','vector'],['1000',1116,2683,776],['2000',4983,16675,3537],['3000',12255,44379,10874],['4000',23212,83026,20189],['5000',37392,133353,33609],['6000',55295,193428,47636],['7000',74877,261314,63911],['8000',100903,340157,84647],['9000',126299,435816,107922],['10000',156386,545160,135680],]);var options={curveType:\"function\",animation:{duration:1200,easing:\"in\"},title:\"linear_search - 128 bytes\",width:'600px',height:'400px',hAxis:{title:\"Number of elements\",slantedText:true},vAxis:{title:\"us\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_4');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\nThe list is still much slower than the others, but what is interesting is that gap between the deque and the array is decreasing. Let's try with a 4KB data type: \n\nfunction draw_graph_5(){var graph=new google.visualization.LineChart(document.getElementById('graph_5'));var data=google.visualization.arrayToDataTable([['x','deque','list','vector'],['1000',4258,7190,4445],['2000',20584,38411,19825],['3000',48236,113189,55341],['4000',87475,223174,118453],['5000',136945,362421,191967],['6000',197856,530943,281252],['7000',273359,726323,387940],['8000',351223,954463,511276],['9000',447525,1211581,652269],['10000',551556,1497916,807161],]);var options={curveType:\"function\",animation:{duration:1200,easing:\"in\"},title:\"linear_search - 4096 bytes\",width:'600px',height:'400px',hAxis:{title:\"Number of elements\",slantedText:true},vAxis:{title:\"us\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_5');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\n\nThe performance of the list are still poor but the gap is decreasing. The interesting point is that deque is now faster than vector. I'm not really sure of the reason of this result. It is possible that it comes only from this special size. One thing is sure, the bigger the data size, the more cache misses the processor will get because elements don't fit in cache lines. \nFor search, list is clearly slow where deque and vector have about the same performance. It seems that deque is faster than a vector for very large data sizes. \nRandom Insert (+Linear Search)\n\nIn the case of random insert, in theory, the list should be much faster, its insert operation being in O(1) versus O(n) for a vector or a deque. \nThe container is filled with all the numbers in [0, N] and shuffled. Then, 1000 random values are inserted at a random position in the container. The random position is found by linear search. In both cases, the complexity of the search is O(n), the only difference comes from the insert that follow the search. We saw before that the performance of the list were poor for searching, so we'll see if the fast insertion can compensate the slow search. \n\n\nfunction draw_graph_6(){var graph=new google.visualization.LineChart(document.getElementById('graph_6'));var data=google.visualization.arrayToDataTable([['x','deque','list','vector'],['10000',8,27,8],['20000',15,45,14],['30000',22,63,21],['40000',29,74,27],['50000',37,87,38],['60000',43,105,44],['70000',50,114,48],['80000',61,130,55],['90000',66,139,61],['100000',70,155,68],]);var options={curveType:\"function\",animation:{duration:1200,easing:\"in\"},title:\"random_insert - 8 bytes\",width:'600px',height:'400px',hAxis:{title:\"Number of elements\",slantedText:true},vAxis:{title:\"ms\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_6');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\nList is clearly slower than the other two data structures that exhibit the same performance. This comes from the very slow linear search. Even if the two other data structures have to move a lot of data, the copy is cheap for small data types. \nLet's increase the size a bit: \n\n\nfunction draw_graph_7(){var graph=new google.visualization.LineChart(document.getElementById('graph_7'));var data=google.visualization.arrayToDataTable([['x','deque','list','vector'],['10000',21,53,25],['20000',39,80,48],['30000',57,103,68],['40000',71,122,90],['50000',88,146,112],['60000',102,165,130],['70000',124,190,152],['80000',140,214,175],['90000',157,238,195],['100000',174,268,213],]);var options={curveType:\"function\",animation:{duration:1200,easing:\"in\"},title:\"random_insert - 32 bytes\",width:'600px',height:'400px',hAxis:{title:\"Number of elements\",slantedText:true},vAxis:{title:\"ms\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_7');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\nThe result are interesting. The list is still the slowest but with a smaller margin. This time deque is faster than the vector by a small margin. \nAgain, increasing the data size: \n\n\nfunction draw_graph_8(){var graph=new google.visualization.LineChart(document.getElementById('graph_8'));var data=google.visualization.arrayToDataTable([['x','deque','list','vector'],['10000',64,80,89],['20000',108,128,154],['30000',158,182,248],['40000',212,248,347],['50000',281,348,469],['60000',402,443,735],['70000',569,643,1034],['80000',767,775,1347],['90000',978,1002,1614],['100000',1190,1202,1962],]);var options={curveType:\"function\",animation:{duration:1200,easing:\"in\"},title:\"random_insert - 128 bytes\",width:'600px',height:'400px',hAxis:{title:\"Number of elements\",slantedText:true},vAxis:{title:\"ms\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_8');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\nThis time, the vector is clearly the looser and deque and list have the same performance. We can say that with a size of 128 bytes, the time to move a lot of the elements is more expensive than searching in the list. \nA huge data type gives us clearer results: \n\n\nfunction draw_graph_9(){var graph=new google.visualization.LineChart(document.getElementById('graph_9'));var data=google.visualization.arrayToDataTable([['x','deque','list','vector'],['10000',4430,178,8074],['20000',7918,311,14121],['30000',11043,444,20014],['40000',13806,555,26783],['50000',17421,694,33519],['60000',20663,904,39175],['70000',23599,1147,45111],['80000',26736,1470,50887],['90000',29524,1940,60139],['100000',32005,2534,65098],]);var options={curveType:\"function\",animation:{duration:1200,easing:\"in\"},title:\"random_insert - 4096 bytes\",width:'600px',height:'400px',hAxis:{title:\"Number of elements\",slantedText:true},vAxis:{title:\"ms\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_9');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\nThe list is more than 20 times faster than the vector and an order of magnitude faster than the deque ! The deque is also twice faster than the vector. \nThe fact than the deque is faster than vector is quite simple. When an insertion is made in a deque, the elements can either moved to the end or the beginning. The closer point will be chosen. An insert in the middle is the most costly operation with O(n/2) complexity. It is always more efficient to insert elements in a deque than in vector because at least twice less elements will be moved. \nIf we look at the non-trivial data type: \n\n\nfunction draw_graph_10(){var graph=new google.visualization.LineChart(document.getElementById('graph_10'));var data=google.visualization.arrayToDataTable([['x','deque','list','vector'],['10000',230,41,425],['20000',376,65,705],['30000',552,84,1054],['40000',692,101,1345],['50000',862,119,1661],['60000',1003,141,1984],['70000',1186,155,2277],['80000',1358,172,2681],['90000',1540,186,2965],['100000',1658,203,3236],]);var options={curveType:\"function\",animation:{duration:1200,easing:\"in\"},title:\"random_insert - 16 bytes\",width:'600px',height:'400px',hAxis:{title:\"Number of elements\",slantedText:true},vAxis:{title:\"ms\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_10');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\nThe results are about the same as for the previous graph, but the data type is only 16B. The cost of the copy constructors and assignment operators is very important for vector and deque. The list doesn't care because no copy neither assignment of the existing elements is made during insertions (only the inserted element is copied). \nRandom Remove\n\nIn theory, random remove is the same case than random insert. Now that we've seen the results with random insert, we could expect the same behavior for random remove. \nThe container is filled with all the numbers in [0, N] and shuffled. Then, 1000 random values are removed from a random position in the container. \nIf we take the same data sizes as the random insert case: \n\n\nfunction draw_graph_11(){var graph=new google.visualization.LineChart(document.getElementById('graph_11'));var data=google.visualization.arrayToDataTable([['x','deque','list','vector'],['10000',6,19,5],['20000',12,41,11],['30000',20,55,18],['40000',27,68,25],['50000',34,81,33],['60000',43,101,40],['70000',49,113,45],['80000',59,126,52],['90000',67,138,61],['100000',72,157,65],]);var options={curveType:\"function\",animation:{duration:1200,easing:\"in\"},title:\"random_remove - 8 bytes\",width:'600px',height:'400px',hAxis:{title:\"Number of elements\",slantedText:true},vAxis:{title:\"ms\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_11');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\n\n\nfunction draw_graph_12(){var graph=new google.visualization.LineChart(document.getElementById('graph_12'));var data=google.visualization.arrayToDataTable([['x','deque','list','vector'],['10000',40,40,63],['20000',85,83,134],['30000',127,132,198],['40000',181,189,282],['50000',245,263,473],['60000',363,376,664],['70000',524,502,960],['80000',743,688,1343],['90000',977,812,1639],['100000',1228,1017,2004],]);var options={curveType:\"function\",animation:{duration:1200,easing:\"in\"},title:\"random_remove - 128 bytes\",width:'600px',height:'400px',hAxis:{title:\"Number of elements\",slantedText:true},vAxis:{title:\"ms\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_12');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\n\n\nfunction draw_graph_13(){var graph=new google.visualization.LineChart(document.getElementById('graph_13'));var data=google.visualization.arrayToDataTable([['x','deque','list','vector'],['10000',2906,109,5649],['20000',6190,233,11760],['30000',9379,359,18218],['40000',12840,490,23634],['50000',16027,585,30046],['60000',18918,773,36100],['70000',22213,999,42453],['80000',25788,1317,48793],['90000',28975,1762,55043],['100000',30860,2128,59791],]);var options={curveType:\"function\",animation:{duration:1200,easing:\"in\"},title:\"random_remove - 4096 bytes\",width:'600px',height:'400px',hAxis:{title:\"Number of elements\",slantedText:true},vAxis:{title:\"ms\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_13');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\n\n\nfunction draw_graph_14(){var graph=new google.visualization.LineChart(document.getElementById('graph_14'));var data=google.visualization.arrayToDataTable([['x','deque','list','vector'],['10000',149,27,294],['20000',319,50,608],['30000',481,68,934],['40000',638,89,1236],['50000',794,108,1547],['60000',954,120,1894],['70000',1101,144,2185],['80000',1253,160,2513],['90000',1399,177,2812],['100000',1595,194,3108],]);var options={curveType:\"function\",animation:{duration:1200,easing:\"in\"},title:\"random_remove - 16 bytes\",width:'600px',height:'400px',hAxis:{title:\"Number of elements\",slantedText:true},vAxis:{title:\"ms\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_14');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\nThe behavior of random remove is the same as the behavior of random insert, for the same reasons. The results are not very interesting, so, let's get to the next workload. \nPush Front\n\nThe next operation that we will compare is inserting elements in front of the collection. This is the worst case for vector, because after each insertion, all the previously inserted will be moved and copied. For a list or a deque, it does not make a difference compared to pushing to the back. \nSo let's see the results: \n\n\nfunction draw_graph_15(){var graph=new google.visualization.LineChart(document.getElementById('graph_15'));var data=google.visualization.arrayToDataTable([['x','deque','list','vector'],['10000',0,0,33],['20000',0,0,135],['30000',0,0,313],['40000',0,0,585],['50000',0,1,913],['60000',0,1,1327],['70000',0,1,1823],['80000',0,1,2405],['90000',0,2,3107],['100000',0,2,4017],]);var options={curveType:\"function\",animation:{duration:1200,easing:\"in\"},title:\"fill_front - 8 bytes\",width:'600px',height:'400px',hAxis:{title:\"Number of elements\",slantedText:true},vAxis:{title:\"ms\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_15');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\nThe results are crystal-clear and as expected, vector is very bad at inserting elements to the front. The list and the deque results are almost invisible in the graph because it is a free operation for the two data structures. This does not need further explanations. There is no need to change the data size, it will only make vector much slower and my processor hotter. \nSort\n\nThe next operation that is tested is the time necessary to sort the data structures. For the vector and the deque std::sort is used and for a list the member function sort is used. \n\n\nfunction draw_graph_16(){var graph=new google.visualization.LineChart(document.getElementById('graph_16'));var data=google.visualization.arrayToDataTable([['x','deque','list','vector'],['100000',9,25,6],['200000',19,61,14],['300000',29,115,22],['400000',40,175,30],['500000',50,233,39],['600000',60,321,48],['700000',71,378,57],['800000',85,457,66],['900000',95,517,74],['1000000',108,593,83],]);var options={curveType:\"function\",animation:{duration:1200,easing:\"in\"},title:\"sort - 8 bytes\",width:'600px',height:'400px',hAxis:{title:\"Number of elements\",slantedText:true},vAxis:{title:\"ms\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_16');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\nFor a small data type, the list is several times slower than the other two data structures. This is again due to the very poor spatial locality of the list during the search. vector is slightly faster than a deque, but the difference is not very significant. \nIf we increase the size: \n\n\nfunction draw_graph_17(){var graph=new google.visualization.LineChart(document.getElementById('graph_17'));var data=google.visualization.arrayToDataTable([['x','deque','list','vector'],['100000',25,32,20],['200000',65,80,48],['300000',103,143,80],['400000',136,197,113],['500000',180,246,149],['600000',223,340,181],['700000',274,396,222],['800000',302,469,266],['900000',358,514,303],['1000000',395,579,337],]);var options={curveType:\"function\",animation:{duration:1200,easing:\"in\"},title:\"sort - 128 bytes\",width:'600px',height:'400px',hAxis:{title:\"Number of elements\",slantedText:true},vAxis:{title:\"ms\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_17');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\nThe order remains the same but the difference between the list and the other is decreasing. \nWith a 1KB data type: \n\n\nfunction draw_graph_18(){var graph=new google.visualization.LineChart(document.getElementById('graph_18'));var data=google.visualization.arrayToDataTable([['x','deque','list','vector'],['100000',176,39,168],['200000',389,94,376],['300000',620,168,595],['400000',859,228,823],['500000',1100,285,1059],['600000',1355,392,1301],['700000',1609,452,1555],['800000',1844,539,1797],['900000',2111,597,2054],['1000000',2397,670,2278],]);var options={curveType:\"function\",animation:{duration:1200,easing:\"in\"},title:\"sort - 1024 bytes\",width:'600px',height:'400px',hAxis:{title:\"Number of elements\",slantedText:true},vAxis:{title:\"ms\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_18');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\nThe list is almost five times faster than the vector and the deque which are both performing the same (with a very slight advantage for vector). \nIf we use the non-trivial data type:\n\n\nfunction draw_graph_19(){var graph=new google.visualization.LineChart(document.getElementById('graph_19'));var data=google.visualization.arrayToDataTable([['x','deque','list','vector'],['100000',92,26,89],['200000',195,70,188],['300000',301,135,296],['400000',410,195,399],['500000',519,255,510],['600000',638,350,623],['700000',763,410,729],['800000',858,492,846],['900000',971,552,954],['1000000',1090,628,1072],]);var options={curveType:\"function\",animation:{duration:1200,easing:\"in\"},title:\"sort - 16 bytes\",width:'600px',height:'400px',hAxis:{title:\"Number of elements\",slantedText:true},vAxis:{title:\"ms\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_19');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\nAgain, the cost of the operators of this type have a strong impact on the vector and deque. \nDestruction\n\nThe next test is to calculate the time necessary to the destruction of a container. The containers are dynamically allocated, are filled with n numbers and then their destruction time (via delete) is computed. \n\n\nfunction draw_graph_20(){var graph=new google.visualization.LineChart(document.getElementById('graph_20'));var data=google.visualization.arrayToDataTable([['x','deque','list','vector'],['100000',34,1489,0],['200000',70,2838,0],['300000',102,4677,0],['400000',142,6072,0],['500000',173,7737,0],['600000',215,8828,0],['700000',353,10599,1],['800000',321,12115,0],['900000',355,13932,1],['1000000',410,15345,0],]);var options={curveType:\"function\",animation:{duration:1200,easing:\"in\"},title:\"destruction - 8 bytes\",width:'600px',height:'400px',hAxis:{title:\"Number of elements\",slantedText:true},vAxis:{title:\"ms\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_20');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\nThe results are already interesting. The vector is almost free to destroy, which is logical because that incurs only freeing one array and the vector itself. The deque is slower due to the freeing of each segments. But the list is much more costly than the other two, more than an order of magnitude slower. This is expected because the list have to free the dynamic memory of each node and also has to iterate through all the elements which we saw was slow. \nIf we increase the data type: \n\n\nfunction draw_graph_21(){var graph=new google.visualization.LineChart(document.getElementById('graph_21'));var data=google.visualization.arrayToDataTable([['x','deque','list','vector'],['100000',898,4403,1],['200000',2488,8499,1],['300000',4091,12499,1430],['400000',5461,16379,1909],['500000',6729,21128,2459],['600000',8164,25719,2729],['700000',9517,31046,3227],['800000',10871,34550,3756],['900000',12392,37176,4163],['1000000',13762,40119,4523],]);var options={curveType:\"function\",animation:{duration:1200,easing:\"in\"},title:\"destruction - 128 bytes\",width:'600px',height:'400px',hAxis:{title:\"Number of elements\",slantedText:true},vAxis:{title:\"ms\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_21');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\nThis time we can see that the deque is three times slower than a vector and that the list is still an order of magnitude slower than a vector ! However, the is less difference than before. \nWith our biggest data type, now: \n\n\nfunction draw_graph_22(){var graph=new google.visualization.LineChart(document.getElementById('graph_22'));var data=google.visualization.arrayToDataTable([['x','deque','list','vector'],['100000',20575,22434,15499],['200000',44234,47254,29848],['300000',67196,69374,39818],['400000',89253,91128,54229],['500000',108689,112557,68090],['600000',131751,135764,75063],['700000',150801,155610,90761],['800000',172365,176957,102830],['900000',192575,193897,112728],['1000000',211507,215274,126348],]);var options={curveType:\"function\",animation:{duration:1200,easing:\"in\"},title:\"destruction - 4096 bytes\",width:'600px',height:'400px',hAxis:{title:\"Number of elements\",slantedText:true},vAxis:{title:\"ms\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_22');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\nThere is no more difference between list and deque. The vector is still twice faster than them. \nEven if the vector is always faster than the list and deque, keep in mind that the graphs for destruction are in microseconds and so the operations are not very costly. It could make a difference is very time-sensitive application but unlikely in most applications. Moreover, destruction is made only once per data structure, generally, it is not a very important operation. \nNumber Crunching\n\nFinally, we can also test a number crunching operation. Here, random elements are inserted into the container that is kept sorted. It means, that the position where the element has to be inserted is first searched by iterating through elements and the inserted. As we talk about number crunching, only 8 bytes elements are tested. \n\n\nfunction draw_graph_23(){var graph=new google.visualization.LineChart(document.getElementById('graph_23'));var data=google.visualization.arrayToDataTable([['x','deque','list','vector'],['10000',39,187,33],['20000',150,1247,134],['30000',339,3380,310],['40000',623,6513,547],['50000',958,10757,864],['60000',1394,16098,1257],['70000',1894,22623,1713],['80000',2479,30656,2249],['90000',3162,39451,2858],['100000',3932,49906,3576],]);var options={curveType:\"function\",animation:{duration:1200,easing:\"in\"},title:\"number_crunching\",width:'600px',height:'400px',hAxis:{title:\"Number of elements\",slantedText:true},vAxis:{title:\"ms\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_23');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\nEven if there is only 100'000 elements, the list is already an order of magnitude slower than the other two data structures. If we look a the curves of the results, it is easy to see that this will be only worse with higher collection sizes. The list is absolutely not adapted for number crunching operations due to its poor spatial locality. \nConclusion\n\nTo conclude, we can get some facts about each data structure:\n\n   std::list is very very slow to iterate through the collection due to its very poor spatial locality.\n   std::vector and std::deque perform always faster than std::list with very small data\n   std::list handles very well large elements\n   std::deque performs better than a std::vector for inserting at random positions (especially at the front, which is constant time)\n   std::deque and std::vector do not support very well data types with high cost of copy/assignment\n\n\nThis draw simple conclusions on usage of each data structure: \n\n   Number crunching: use std::vector or std::deque\n   Linear search: use std::vector or std::deque\n   Random Insert/Remove: use std::list (if data size very small (\n   Big data size: use std::list (not if intended for searching)\n   Non-trivial data type: use std::list unless you need the container especially for searching. But for multiple modifications of the container, it will be very slow. \n   Push to front: use std::deque or std::list\n\n\nI have to say that before writing this new version of the benchmark I did not know std::deque a lot. This is a very good data structure that is very good at inserting at both ends and even in the middle while exposing a very good spatial locality. Even if sometimes slower than a vector, when the operations involves both searching and inserting in the middle, I would say that this structure should be preferred over vectors, especially for data types of medium sizes. \nIf you have the time, in practice, the best way to decide is always to benchmark each version, or even to try another data structures. Two operations with the same Big O complexity can perform quite differently in practice. \nI hope that you found this article interesting. If you have any comment or have an idea about an other workload that you would like to test, don't hesitate to post a comment ;) If you have a question on results, don't hesitate as well. \nThe code source of the benchmark is available online: https://github.com/wichtounet/articles/blob/master/src/vector_list/bench.cpp\nThe older version of the article is still available: C++ benchmark \u2013 std::vector VS std::list\nfunction draw_visualization(){draw_graph_0();draw_graph_1();draw_graph_2();draw_graph_3();draw_graph_4();draw_graph_5();draw_graph_6();draw_graph_7();draw_graph_8();draw_graph_9();draw_graph_10();draw_graph_11();draw_graph_12();draw_graph_13();draw_graph_14();draw_graph_15();draw_graph_16();draw_graph_17();draw_graph_18();draw_graph_19();draw_graph_20();draw_graph_21();draw_graph_22();draw_graph_23();}google.setOnLoadCallback(draw_visualization);", 
      "tags": "Benchmarks,C++,C++11,Performances"
    }, 
    {
      "loc": "/posts/2012/11/cpp-benchmark-vector-vs-list.html", 
      "title": "C++ benchmark - std::vector VS std::list", 
      "text": "google.load('visualization','1',{packages:['corechart']});\n\nA updated version of this article is available: C++ benchmark \u2013 std::vector VS std::list VS std::deque\nIn C++, the two most used data structures are the std::vector and the std::list. In this article, we will compare the performance in practice of these two data structures on several different workloads. In this article, when I talk about a list it is the std::list implementation and vector refers to the std::vector implementation.\nIt is generally said that a list should be used when random insert and remove will be performed (performed in O(1) versus O(n) for a vector). If we look only at the complexity, search in both data structures should be roughly equivalent, complexity being in O(n). When random insert/replace operations are performed on a vector, all the subsequent data needs to be moved and so each element will be copied. That is why the size of the data type is an important factor when comparing those two data structures.\nHowever, in practice, there is a huge difference, the usage of the memory caches. All the data in a vector is contiguous where the std::list allocates separately memory for each element. How does that change the results in practice ?\nKeep in mind that all the tests performed are made on vector and list even if other data structures could be better suited to the given workload.\nIn the graphs and in the text, n is used to refer to the number of elements of the collection.\nAll the tests performed have been performed on an Intel Core i7 Q 820 \u00a0@ 1.73GHz. The code has been compiled in 64 bits with GCC 4.7.2 with -02 and -march=native. The code has been compiled with C++11 support (-std=c++11).\nFill\n\nThe first test that is performed is to fill the data structures by adding elements to the back of the container. Two variations of vector are used, vector_pre being a std::vector with the size passed in parameters to the constructor, resulting in only one allocation of memory.\n\n\nfunction draw_graph_0(){var graph=new google.visualization.LineChart(document.getElementById('graph_0'));var data=google.visualization.arrayToDataTable([['x','vector_pre','vector','list'],['1000',0,0,1],['10000',0,1,10],['100000',4,11,100],['1000000',7,234,1023]]);var options={curveType:\"function\",animation:{duration:1200,easing:\"in\"},title:\"Fill (8 bytes)\",width:'600px',height:'400px',vAxis:{title:\"Milliseconds\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_0');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}function draw_graph_1(){var graph=new google.visualization.LineChart(document.getElementById('graph_1'));var data=google.visualization.arrayToDataTable([['x','vector_pre','vector','list'],['1000',0,9,1],['10000',12,245,18],['100000',949,2635,1153],['1000000',9138,23654,11270]]);var options={curveType:\"function\",animation:{duration:1200,easing:\"in\"},title:\"Fill (1024 bytes)\",width:'600px',height:'400px',vAxis:{title:\"Milliseconds\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_1');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\nAll data structures are impacted the same way when the data size increases, because there will be more memory to allocate. The vector_pre is clearly the winner of this test, being one order of magnitude faster than a list and about twice faster than a vector without pre-allocation. The result are directly linked to the allocations that have to be performed, allocation being slow. Whatever the data size is, push_back to a vector will always be faster than to a list. This is logical becomes vector allocates more memory than necessary and so does not need to allocate memory for each element.\nBut this test is not very interesting, generally building the data structure is not critical. What is critical is the operations that are performed on the data structure. That will be tested in the next sections.\n\n\nRandom Find\n\nThe first operation is that is tested is the search. The container is filled with all the numbers in [0, N] and shuffled. Then, each number in [0,N] is searched in the container with std::find that performs a simple linear search.\n\n\nfunction draw_graph_2(){var graph=new google.visualization.LineChart(document.getElementById('graph_2'));var data=google.visualization.arrayToDataTable([['x','vector','list'],['100',0,11],['1000',0,1545],['5000',0,35886],['10000',0,150865],['20000',0,614496]]);var options={curveType:\"function\",animation:{duration:1200,easing:\"in\"},title:\"Find (8 bytes)\",width:'600px',height:'400px',vAxis:{title:\"Microseconds\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_2');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\nYes, vector is present in the graph, its line is the same as the x line ! Performing a linear search in a vector is several orders of magnitude faster than in a list.\nThe only reason is the usage of the cache line. When a data is accessed, the data is fetched from the main memory to the cache. Not only the accessed data is accessed, but a whole cacheline is fetched. As the elements in a vector are contiguous, when you access an element, the next element is automatically in the cache. As the main memory is orders of magnitude slower than the cache, this makes a huge difference. In the list case, the processor spends its whole time waiting for data being fetched from memory to the cache.\nIf we augment the size of the data type to 1KB, the results remain the same, but slower:\n\n\nfunction draw_graph_3(){var graph=new google.visualization.LineChart(document.getElementById('graph_3'));var data=google.visualization.arrayToDataTable([['x','vector','list'],['100',0,11],['1000',0,3551],['5000',0,195429],['10000',0,829631],['20000',0,3356432]]);var options={curveType:\"function\",animation:{duration:1200,easing:\"in\"},title:\"Find (1024 bytes)\",width:'600px',height:'400px',vAxis:{title:\"Microseconds\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_3');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\n\n\nRandom Insert\n\nIn the case of random insert, in theory, the list should be much faster, its insert operation being in O(1) versus O(n) for a vector.\nThe container is filled with all the numbers in [0, N] and shuffled. Then, 1000 random values are inserted at a random position in the container. The random position is found by linear search. In both cases, the complexity of the search is O(n), the only difference comes from the insert that follow the search.\n\n\nfunction draw_graph_4(){var graph=new google.visualization.LineChart(document.getElementById('graph_4'));var data=google.visualization.arrayToDataTable([['x','vector','list'],['1000',9,85],['2000',9,85],['4000',10,94],['6000',12,98],['8000',13,106],['10000',14,106]]);var options={curveType:\"function\",animation:{duration:1200,easing:\"in\"},title:\"Insert (8 bytes)\",width:'600px',height:'400px',vAxis:{title:\"Milliseconds\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_4');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\nWhen, the vector should be slower than the list, it is almost an order of magnitude faster. Again, this is because finding the position in a list is much slower than copying a lot of small elements.\nIf we increase the size:\n\n\nfunction draw_graph_5(){var graph=new google.visualization.LineChart(document.getElementById('graph_5'));var data=google.visualization.arrayToDataTable([['x','vector','list'],['1000',27,120],['2000',30,113],['4000',34,122],['6000',37,140],['8000',42,145],['10000',47,155]]);var options={curveType:\"function\",animation:{duration:1200,easing:\"in\"},title:\"Insert (32 bytes)\",width:'600px',height:'400px',vAxis:{title:\"Milliseconds\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_5');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\nThe two lines are getting closer, but vector is still faster.\nIncrease it to 1KB:\n\n\nfunction draw_graph_6(){var graph=new google.visualization.LineChart(document.getElementById('graph_6'));var data=google.visualization.arrayToDataTable([['x','vector','list'],['1000',1821,167],['2000',1941,163],['4000',2383,191],['6000',2679,207],['8000',2960,214],['10000',3308,228]]);var options={curveType:\"function\",animation:{duration:1200,easing:\"in\"},title:\"Insert (1024 bytes)\",width:'600px',height:'400px',vAxis:{title:\"Milliseconds\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_6');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\nThis time, list outperforms vector by an order of magnitude ! The performance of random insert in a list are not impacted much by the size of the data type, where vector suffers a lot when big sizes are used. We can also see that list doesn't seem to care about the size of the collection. It is because the size of the collection only impact the search and not the insertion and as few search are performed, it does not change the results a lot.\nIf the iterator was already known (no need for linear search), it would be faster to insert into a list than into the vector.\nRandom Remove\n\nIn theory, random remove is the same case than random insert. Now that we've seen the results with random insert, we could expect the same behavior for random remove.\nThe container is filled with all the numbers in [0, N] and shuffled. Then, 1000 random values are removed from a random position in the container.\n\n\nfunction draw_graph_7(){var graph=new google.visualization.LineChart(document.getElementById('graph_7'));var data=google.visualization.arrayToDataTable([['x','vector','list'],['100',0,0],['1000',0,0],['10000',40,0],['50000',949,2],['100000',3937,4],['200000',16003,9],['300000',42393,12]]);var options={curveType:\"function\",animation:{duration:1200,easing:\"in\"},title:\"Push front (8 bytes)\",width:'600px',height:'400px',vAxis:{title:\"Milliseconds\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_7');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\nAgain, vector is several times faster and looks to scale better. Again, this is because it is very cheap to copy small elements.\nLet's increase it directly to 1KB element.\n\n\nfunction draw_graph_8(){var graph=new google.visualization.LineChart(document.getElementById('graph_8'));var data=google.visualization.arrayToDataTable([['x','vector','list'],['1000',0,0],['10000',2,26],['100000',163,684],['1000000',2147,15950],]);var options={curveType:\"function\",animation:{duration:1200,easing:\"in\"},title:\"Sort (8 bytes)\",width:'600px',height:'400px',vAxis:{title:\"Milliseconds\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_8');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\nThe two lines have been reversed !\nThe behavior of random remove is the same as the behavior of random insert, for the same reasons.\n\n\nPush Front\n\nThe next operation that we will compare is inserting elements in front of the collection. This is the worst case for vector, because after each insertion, all the previously inserted will be moved and copied. For a list, it does not make a difference compared to pushing to the back.\n\n\nfunction draw_graph_9(){var graph=new google.visualization.LineChart(document.getElementById('graph_9'));var data=google.visualization.arrayToDataTable([['x','vector','list'],['100',0,0],['1000',0,0],['10000',40,0],['50000',949,2],['100000',3937,4],['200000',16003,9],['300000',42393,12]]);var options={curveType:\"function\",animation:{duration:1200,easing:\"in\"},title:\"Push front (8 bytes)\",width:'600px',height:'400px',vAxis:{title:\"Milliseconds\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_9');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\nThe results are crystal-clear and as expected. vector is very bad at inserting elements to the front. This does not need further explanations. There is no need to change the data size, it will only make vector much slower.\nSort\n\nThe next operation that is tested is the performance of sorting a vector or a list. For a vector std::sort is used and for a list the member function sort is used.\n\n\nfunction draw_graph_10(){var graph=new google.visualization.LineChart(document.getElementById('graph_10'));var data=google.visualization.arrayToDataTable([['x','vector','list'],['1000',0,0],['10000',2,26],['100000',163,684],['1000000',2147,15950],]);var options={curveType:\"function\",animation:{duration:1200,easing:\"in\"},title:\"Sort (8 bytes)\",width:'600px',height:'400px',vAxis:{title:\"Milliseconds\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_10');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\nWe can see that sorting a list is several times slower. It comes from the poor usage of the cache.\nIf we increase the size of the element to 1KB:\n\n\nfunction draw_graph_11(){var graph=new google.visualization.LineChart(document.getElementById('graph_11'));var data=google.visualization.arrayToDataTable([['x','vector','list'],['1000',2,0],['10000',224,50],['100000',4289,1083],['1000000',50973,17975],]);var options={curveType:\"function\",animation:{duration:1200,easing:\"in\"},title:\"Sort (1024 bytes)\",width:'600px',height:'400px',vAxis:{title:\"Milliseconds\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_11');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\nThis time the list is faster than the vector. It is not very clear on the graph, but the values for the list are almost the same as for the previous results. That is because std::list::sort() does not perform any copy, only pointers to the elements are changed. On the other hand, swapping two elements in a vector involves at least three copies, so the cost of sorting will increase as the cost of copying increases.\n\n\nNumber Crunching\n\nFinally, we can also test a number crunching operation. Here, random elements are inserted into the container that is kept sorted. It means, that the position where the element has to be inserted is first searched by iterating through elements and the inserted. As we talk about number crunching, only 8 bytes elements are tested.\n\n\nfunction draw_graph_12(){var graph=new google.visualization.LineChart(document.getElementById('graph_12'));var data=google.visualization.arrayToDataTable([['x','vector','list'],['1000',0,0],['10000',45,166],['50000',928,10665],['100000',3753,50766],['200000',15185,231480],['300000',34293,715892]]);var options={curveType:\"function\",animation:{duration:1200,easing:\"in\"},title:\"Random Sorted Insert (8 bytes)\",width:'600px',height:'400px',vAxis:{title:\"Milliseconds\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_12');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\nWe can clearly see that vector is more than an order of magnitude faster than list and this will only be more as the size of the collection increase. This is because traversing the list is much more expensive than copying the elements of the vector.\nConclusion\n\nTo conclude, we can get some facts about each data structure:\n\n    std::vector is insanely faster than std::list to find an element\n    std::vector performs always faster than std::list with very small data\n    std::vector is always faster to push elements at the back than std::list\n    std::list handles very well large elements, especially for sorting or inserting in the front\n\n\nThis draw simple conclusions on usage of each data structure:\n\n    Number crunching: use std::vector\n    Linear search: use std::vector\n    Random Insert/Remove: use std::list (if data size very small (< 64B on my computer), use std::vector)\n    Big data size: use std::list (not if intended for searching)\n\n\nIf you have the time, in practice, the best way to decide is always to benchmark both versions, or even to try another data structures.\nI hope that you found this article interesting. If you have any comment or have an idea about an other workload that you would like to test, don't hesitate to post a comment ;) If you have a question on results, don't hesitate as well.\nThe code source of the benchmark is available online: https://github.com/wichtounet/articles/blob/master/src/vector_list/bench.cpp\nfunction draw_visualization(){draw_graph_0();draw_graph_1();draw_graph_2();draw_graph_3();draw_graph_4();draw_graph_5();draw_graph_6();draw_graph_7();draw_graph_8();draw_graph_9();draw_graph_10();draw_graph_11();draw_graph_12();}google.setOnLoadCallback(draw_visualization);", 
      "tags": "Benchmarks,C++,C++11,Performances"
    }, 
    {
      "loc": "/posts/2012/11/gcc-4-7-clang-3-1-eddic.html", 
      "title": "GCC 4.7 vs CLang 3.1 on eddic", 
      "text": "google.load('visualization','1',{packages:['corechart']});\n\nNow that eddic can be compiled with CLang, I wanted to compare the differences in compilation time and in performance of the generated executable between those two compilers. The tests are done using GCC 4.7.2 and CLang 3.1 on Gentoo.\nCompilation Time\nThe first thing that I tested has been the compilation time of the two compilers to compile eddic with different flags. I tested the compilation in debug mode and with -O2 and -O3.\n\n\nfunction draw_graph_0(){var graph=new google.visualization.ColumnChart(document.getElementById('graph_0'));var data=google.visualization.arrayToDataTable([['Options','GCC','CLang'],['-g',234.59,119.59],['-O2',273.02,178.22],['-O3',276.87,183.78],]);var options={title:\"Compilation Time - Less is better\",animation:{duration:1200,easing:\"in\"},width:'400px',height:'300px',hAxis:{title:\"Options\"},vAxis:{title:\"Seconds\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_0');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\nThe most interesting fact in these results is that CLang is much faster than GCC. It takes twice less times to compile eddic with CLang in debug mode than with GCC. The impact on optimizations on CLang's compilation is also more important than on GCC. For both compilers, -O3 does not seems to add a lot of overhead.\nRuntime performance\n\nThen, I tested the performance of the generated executable. I tested it on three things, the whole test suite and two test cases that I know are the slowest for the EDDI Compiler. For each case, I took the slowest value of 5 consecutive executions. \n\n\nfunction draw_graph_1(){var graph=new google.visualization.ColumnChart(document.getElementById('graph_1'));var data=google.visualization.arrayToDataTable([['Compiler','GCC -O2','GCC -O3','CLang -O2','CLang -O3'],['testsuite',6.58,6.59,6.74,6.58],['assembly',1.2,1.2,1.2,1.2],['linked_list',0.51,0.5,0.49,0.49],]);var options={title:\"Runtime Performance - Less is better\",animation:{duration:1200,easing:\"in\"},width:'600px',height:'400px',hAxis:{title:\"Options\"},vAxis:{title:\"Seconds\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_1');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\nThe difference are very small. In -02, GCC performs a bit better, but in -O3, the performance are equivalent. I was a bit disappointed by the results, because I thought that there would be higher differences. It seems that CLang is not as far from GCC that some people would like to say. It also certainly depends on the program being compiled. \nConclusion\n\nIt is clear that CLang is much faster than GCC to compile eddic. Moreover, the performance of the generated executable are almost similar. \nI will continue to use CLang as my development compiler and switches between the two when I'm doing performance benchmarking. I will try to update the benchmark once new versions of GCC / CLang are available.\nfunction draw_visualization(){draw_graph_0();draw_graph_1();}google.setOnLoadCallback(draw_visualization);", 
      "tags": "Benchmarks,CLang,Compilers,EDDI,gcc,Performances"
    }, 
    {
      "loc": "/posts/2012/11/eddic-compiler-1-1-4-graph-coloring-register-allocation.html", 
      "title": "EDDI Compiler 1.1.4 \u2013 Graph Coloring Register Allocation", 
      "text": "I'm proud to announce the release of the version 1.1.4 of the EDDI Compiler (eddic).\nThis version has taken me much more time than I thought but I also added much more features than I thought too. \nThere are few changes of the language itself, the main changes are in the optimization passes or in the compiler. \nFor the language, it is now possible to use dynamically allocated arrays. The this pointer is now implicit in member functions. \nThe standard library has been improved by the addition of a Doubly-Linked List. This list uses the templates so that it is generic. It is possible to add elements to the front and the back of the list. The list is iterable using iterators (bidirectional). \nThe template engine has been almost entirely rewritten. The previous version was too limited and there was code to handle the templates almost in the whole front-end. Now, the templates are handled recursively at each point where they can appear. For not the template instantiation depth is not limited, but this will be done in the next version of eddic. \nThe major change of this version is the use of a Graph Coloring Register Allocator ! This allocator is based on a Chaitin-style allocator. This greatly improves the quality of the generated assembly. The LTAC compilation is now made in two phase. In the first one, only pseudo registers are used. This first pass includes a first cleanup pass. Then, the register allocator replaces all the pseudo registers by actual registers. Finally, the LTAC IR is optimized like before. In the future, it will be improved further. The coalescing and renumbering passes are a bit limited for now and Chaitin-Briggs optimistic coloring will be used in the future. \nThe data-flow framework has been improved to support data-flow analysis of LTAC program. For now, the only analysis that does that is Live Registers Analysis. This analysis is used by the Register Allocator by the Dead Code Elimination that is run in LTAC code. \nThe MTAC optimization engine has been greatly improved by the use of a powerful pass manager that runs the optimization in the correct order and that gives them the necessary information. The Control Flow Graph is now updated by the different passes and never invalidated. The CFG is computed only once before the optimizations. \nThe MTAC optimization engine has also new optimization passes regarding to loops: Loop Invariant Code Motion, Loop Strength Reduction and Complete Loop Peeling. The loops are discovered by a dominance analysis implemented using the Lengauer-Tarjan's algorithm. \nThe inliner has also beeen greatly improved. The inlining decision is now taken at the call site level. It means that only some calls to a function can be inlined and not the whole function. The inliner now supports functions with string parameters. Moreover, the inliner heuristic takes the number of constant parameters at the call site into account to take its decision. \nOn the side of the Compiler, there are several improvements. \n\n    The whole compilation process has been made thread safe.\n    The Test Suite can be run in parallel\n    The Middle-End and Back-Ends have been clearly separated (More information on the Wiki). \n    The LTAC Intermediate Representation now keeps the Basic Blocks of the MTAC representation.\n    eddic can be compiled with CLang\n\nFuture Work\n\nThe next version of the EDDI compiler (eddic) will be the version 1.2.0. This version will add support for inheritance at least in a basic way. It will also add support for returning a structure by value. The structures can contains arrays of defined size. This version will also focus on removing the limitations that exists on some features (Function Call Left Values for instance). It will also contains several necessary cleanups to the files. \nDownload\n\nYou can find the EDDI Compiler sources on the Github repository: https://github.com/wichtounet/eddic\nThe version is available in the v1.1.4 tag available in the GitHub or directly in the master branch.", 
      "tags": "C++,Compilers,EDDI"
    }, 
    {
      "loc": "/posts/2012/11/integer-linear-time-sorting-algorithms.html", 
      "title": "Integer Linear Time Sorting Algorithms", 
      "text": "google.load('visualization','1',{packages:['corechart']});\n\nUpdate: The code is now more C++\nMost of the sorting algorithms that are used are generally comparison sort. It means that each element of the collection being sorted will be compared to see which one is the first one. A comparison must have a lower bound of \u03a9(n log n) comparisons. That is why there are no comparison-based sorting algorithm better than O(n log n).\nOn the other hand, there are also sorting algorithms that are performing better. This is the family of the integer sorting algorithms. These algorithms are using properties of integer to sort them without comparing them. They can be only be used to sort integers. Nevertheless, a hash function can be used to assign a unique integer to any value and so sort any value. All these algorithms are using extra space. There are several of these algorithms. In this article, we will see three of them and I will present an implementation in C++. At the end of the article, I will compare them to std::sort.\nIn the article, I will use n as the size of the array to sort and m as the max number that is permitted in the array.\nBin Sort\n\nBin Sort, or Bucket Sort, is a very simple algorithm that partition all the input numbers into a number of buckets. Then, all the buckets are outputted in order in the array, resulting in a sorting array. I decided to implement the simplest case of Bin Sort where each number goes in its own bucket, so there are m buckets.\nThe implementation is pretty straightforward:\nvoid binsort(std::vector<std::size_t>&& A){\n    std::vector<std::vector<std::size_t>> B(MAX + 1);\n\n    for(std::size_t i = 0; i < SIZE; ++i){\n        B[A[i]].push_back(A[i]);\n    }\n\n    std::size_t current = 0;\n    for(std::size_t i = 0; i < MAX; ++i){\n        for(auto item : B[i]){\n            A[current++] = item;\n        }\n    }\n}\n\n\n\nB is the array of buckets. Each bucket is implemented as a std::vector. The algorithm starts by filling each buckets with the numbers from the input array. Then, it outputs them in order in the array.\nThis algorithm works in O(n + m) and requires O(m) extra memory. With these properties, it makes a very limited algorithm, because if you don't know the maximum number and you have to use the maximum number of the array type, you will have to allocate for instance 232 buckets. That won't be possible.\nCouting Sort\n\nAn interesting fact about binsort is that each bucket contains only the same numbers. The size of the bucket would be enough. That is exactly what Counting Sort. It counts the number of times an element is present instead of the elements themselves. I will present two versions. The first one is a version using a secondary array and then copying again into the input array and the second one is an in-place sort.\nvoid counting_sort(std::vector<std::size_t>&& A){\n    std::vector<std::size_t> B(SIZE);\n    std::vector<std::size_t> C(MAX);\n\n    for (std::size_t i = 0; i < SIZE; ++i){\n        ++C[A[i]];\n    }\n\n    for (std::size_t i = 1; i <= MAX; ++i){\n        C[i] += C[i - 1];\n    }\n\n    for (long i = SIZE - 1; i >= 0; --i) {\n        B[C[A[i]] - 1] = A[i];\n        --C[A[i]];\n    }\n\n    for (std::size_t i = 0; i < SIZE; ++i){\n        A[i] = B[i];\n    }\n}\n\n\n\nThe algorithm is also simple. It starts by counting the number of elements in each bucket. Then, it aggregates the number by summing them to obtain the position of the element in the final sorted array. Then, all the elements are copied in the temporary array. Finally, the temporary array is copied in the final array. This algorithms works in O(m + n) and requires O(m + n). This version is presented only because it is present in the literature. We can do much better by avoiding the temporary array and optimizing it a bit:\nvoid in_place_counting_sort(std::vector<std::size_t>&& A){\n    std::vector<std::size_t> C(MAX + 1);\n\n    for (std::size_t i = 0; i < SIZE; ++i){\n        ++C[A[i]];\n    }\n\n    int current = 0;\n    for (std::size_t i = 0; i < MAX; ++i){\n        for(std::size_t j =0; j < C[i]; ++j){\n            A[current++] = i;\n        }\n    }\n}\n\n\n\nThe temporary array is removed and the elements are directly written in the sorted array. The counts are not used directly as position, so there is no need to sum them. This version still works in O(m + n) but requires only O(m) extra memory. It is much faster than the previous version.\nRadix Sort\n\nThe last version that I will discuss here is a Radix Sort. This algorithm sorts the number digit after digit in a specific radix. It is a form of bucket sort, where there is a bucket by digit. Like Counting Sort, only the counts are necessary. For example, if you use radix sort in base 10. It will first sort all the numbers by their first digit, then the second, .... It can work in any base and that is its force. With a well chosen base, it can be very powerful. Here, we will focus on radix that are in the form 2r. These radix have good properties, we can use shifts and mask to perform division and modulo, making the algorithm much faster.\nThe implementation is a bit more complex than the other implementations:\nstatic const std::size_t digits = 2;             //Digits\nstatic const std::size_t r = 16;                 //Bits\nstatic const std::size_t radix = 1 << r;         //Bins\nstatic const std::size_t mask = radix - 1;\n\nvoid radix_sort(std::vector<std::size_t>&& A){\n    std::vector<std::size_t> B(SIZE);\n    std::vector<std::size_t> cnt(radix);\n\n    for(std::size_t i = 0, shift = 0; i < digits; i++, shift += r){\n        for(std::size_t j = 0; j < radix; ++j){\n            cnt[j] = 0;\n        }\n\n        for(std::size_t j = 0; j < SIZE; ++j){\n            ++cnt[(A[j] >> shift) && mask];\n        }\n\n        for(std::size_t j = 1; j < radix; ++j){\n            cnt[j] += cnt[j - 1];\n        }\n\n        for(long j = SIZE - 1; j >= 0; --j){\n            B[--cnt[(A[j] >> shift) && mask]] = A[j];\n        }\n\n        for(std::size_t j = 0; j < SIZE; ++j){\n           A[j] = B[j];\n        }\n    }\n}\n\n\n\nr indicates the power of two used as the radix (2r). The mask is used to compute modulo faster. The algorithm repeats the steps for each digit. Here digits equals 2. It means that we support 232 values. A 32 bits value is sorted in two pass. The steps are very similar to counting sort. Each value of the digit is counted and then the counts are summed to give the position of the number. Finally, the numbers are put in order in the temporary array and copied into A.\nThis algorithm works in O(digits (m + radix)) and requires O(n + radix) extra memory. A very good thing is that the algorithm does not require space based on the maximum value, only based on the radix.\nResults\n\nIt's time to compare the different implementations in terms of runtime. For each size, each version is tested 25 times on different random arrays. The arrays are the same for each algorithm. The number is the time necessary to sort the 25 arrays. The benchmark has been compiler with GCC 4.7.\nThe first test is made with very few duplicates (m = 10n).\n\n\nfunction draw_graph_0(){var graph=new google.visualization.ColumnChart(document.getElementById('graph_0'));var data=google.visualization.arrayToDataTable([['x','std::sort','counting_sort','in_place_counting_sort','bin_sort','radix_sort'],['100000',171,182,105,945,89],['500000',993,2229,970,6435,461],['1000000',2175,4812,2046,14096,1068],['5000000',11791,27050,10202,81255,6148],]);var options={title:\"m = 10n\",animation:{duration:1200,easing:\"in\"},width:'600px',height:'400px',hAxis:{title:\"n\"},vAxis:{title:\"ms\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_0');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\nRadix Sort comes to be the fastest in this case, twice faster as std::sort. In place counting sort has almost the same performance as std::sort. The other are performing worse.\nThe second test is made with few duplicates (m ~= n).\n\n\nfunction draw_graph_1(){var graph=new google.visualization.ColumnChart(document.getElementById('graph_1'));var data=google.visualization.arrayToDataTable([['x','std::sort','counting_sort','in_place_counting_sort','bin_sort','radix_sort'],['100000',186,73,37,309,90],['500000',991,611,189,3126,455],['1000000',2235,2171,547,7978,1038],['5000000',12184,18470,4516,49056,5791],]);var options={title:\"m ~= n\",animation:{duration:1200,easing:\"in\"},width:'600px',height:'400px',hAxis:{title:\"n\"},vAxis:{title:\"ms\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_1');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\nThe numbers are impressive. In place counting sort is between 3-4 times faster than std::sort and radix sort is twice faster than std::sort ! Bin Sort does not performs very well and counting sort even if generally faster than std::sort does not scale very well.\nLet's test with more duplicates (m = n / 2).\n\n\nfunction draw_graph_2(){var graph=new google.visualization.ColumnChart(document.getElementById('graph_2'));var data=google.visualization.arrayToDataTable([['x','std::sort','counting_sort','in_place_counting_sort','bin_sort','radix_sort'],['100000',178,65,25,262,90],['500000',979,450,143,2332,461],['1000000',2171,1480,321,6240,1041],['5000000',11978,16205,3453,41709,5890],]);var options={title:\"m = n / 2\",animation:{duration:1200,easing:\"in\"},width:'600px',height:'400px',hAxis:{title:\"n\"},vAxis:{title:\"ms\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_2');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\nstd::sort and radix sort performance does not change a lot but the other sort are performing better. In-place counting sort is still the leader with a higher margin.\nFinally, with a lot of duplicates (m = n / 10).\n\n\nfunction draw_graph_3(){var graph=new google.visualization.ColumnChart(document.getElementById('graph_3'));var data=google.visualization.arrayToDataTable([['x','std::sort','counting_sort','in_place_counting_sort','bin_sort','radix_sort'],['100000',161,46,12,144,74],['500000',918,322,76,1023,449],['1000000',2062,824,167,2721,1041],['5000000',10789,8534,1030,24026,5686],]);var options={title:\"m = n / 10n\",animation:{duration:1200,easing:\"in\"},width:'600px',height:'400px',hAxis:{title:\"n\"},vAxis:{title:\"ms\",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_3');button.onclick=function(){if(options.vAxis.logScale){button.value=\"Logarithmic Scale\";}else{button.value=\"Normal scale\";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}\nAgain, std::sort and radix sort performance are stable, but in-place counting is now ten times faster than std::sort !\nConclusion\n\nTo conclude, we have seen that these algorithms can outperforms std::sort by a high factor (10 times for In place Counting Sort when there m << n). If you have to sort integers, you should consider these two cases:\n\n    m > n or m is unknown : Use radix sort that is about twice faster than std::sort.\n    m << n : Use in place counting sort that can be much faster than std::sort.\n\n\nI hope you found this article interesting. The implementation can be found on Github: https://github.com/wichtounet/articles/tree/master/src/linear_sorting\nfunction draw_visualization(){draw_graph_0();draw_graph_1();draw_graph_2();draw_graph_3();}google.setOnLoadCallback(draw_visualization);", 
      "tags": "Algorithm,Benchmarks,C++,Performances"
    }, 
    {
      "loc": "/posts/2012/11/cmakelatex-1-0-2-nomenclature-filters.html", 
      "title": "CMakeLatex 1.0.2 - Support for nomenclature and better filters", 
      "text": "I released a new version of CMakeLatex, the version 1.0.2. \nFirst of all, this version restore the support for nomenclature. Then, it also adds filters for makeindex (including makeglossaries and makenomenclature). The filters will hides all the information of the output stream but the errors. The filters for pdflatex are also improved. \nCMakeLatex is a CMake script to build Latex documents using CMake / Make. It supports glossary, indexes, bibliographies and nomenclature. It can automatically converts your images to the right format using imagemagick or cairosvg (for SVG to PDF conversion). \nYou can download it on Github: CMakeLatex Github repository\nIf you have any idea for improvement, don't hesitate to contact me or to create a Feature Request on Github.", 
      "tags": "cmake,Latex,Linux"
    }, 
    {
      "loc": "/posts/2012/11/eddic-compiles-with-clang-3-1.html", 
      "title": "eddic compiles with CLang 3.1", 
      "text": "I finally added support for compiling eddic with LLVM CLang 3.1 !\nThe current development version can be completely compiled with CLang. Starting with the version 1.1.4, all versions of eddic will be support GCC and CLang. \nThe changes have not been as painful as I first thought. \n\n    The main problem that I has was about a static const variable of a class that had no user-constructor. GCC allows that, but it is not standard compliant and CLang was complaining. \n    Another problem that I encountered was about the used of bit flags and Template Meta Programming. I simplified that by the use of a simple type traits and it worked. I don't really know why this does not worked at first. \n    The remaining effort was to fix the several warnings that CLang had. \n\n\nCLang also fixed a bug in my code with a warning on a assignment that was not supposed to be an assignment, thanks CLang. \nThe most interesting fact about CLang is that is it twice faster to build eddic than GCC. I think I'm gonna use it during development to fasten the compile time. Moreover, even if I only worked two days with it, it seems that the error messages are indeed better than the GCC's ones. \nI haven't tried to compare the performances of eddic in both cases, but I will do that in the future, soon after the 1.1.4 version is released. \nI tried the CLang static analyzer on eddic but it didn't found any bugs. Moreover, it crashed on several of my files. I didn't found why for now, but I will continue to investigate, perhaps I'm not using it correctly. \nI expect to publish the next version of eddic in the next two weeks. This version has much more improvements that I thought at first and I have less time to work now that I'm working on my Master thesis. \nMore informations on CLang: The official site.", 
      "tags": "CLang,Compilers,EDDI,gcc,Linux"
    }, 
    {
      "loc": "/posts/2012/10/run-boost-test-parallel-cmake.html", 
      "title": "Run your Boost Tests in parallel with CMake", 
      "text": "I was looking for a Test Library to run eddic tests in parallel to replace Boost Test Library. I posted my question on StackOverflow and an awesome solution has been posted. With CMake and a little CMake additional file, it is possible to run the tests written with Boost Test Library in parallel without changing anything in the tests code !\nCTest is the test runner that is shipped with CMake. This runner can run tests in parallel using the -j X option (X is the numbers of threads). However, it can only run the tests that are declared in the CMakeLists.txt file. In my case, this means only one (the executable with Boost Test Library). If you have T tests, a solution would be create T executable files. Then, they can be run in parallel by ctest. However, this is not very practical. The solution proposed in this article is better. \nIntegrate Boost Test Library in CMake\n\nRyan Pavlik provides a series of CMake modules in its Github repository. One of this module is named BoostTestTargets. It automatically generates the CTest commands to run all the tests that you have. The small drawback is that you to list all the tests. \nTo start, you have to download these files: \n\n    BoostTestTargets.cmake\n    GetForceIncludeDefinitions.cmake\n    CopyResourcesToBuildTree.cmake\n    BoostTestTargetsStatic.h\n    BoostTestTargetsDynamic.h\n    BoostTestTargetsIncluded.h\n\n\nThese files must be placed next to your CMakeLists.txt file. Then, you have to modify your CMakeLists.txt file to enable testing and enable the new module. For example, if you have two test suites and five tests in each:  \nINCLUDE(CTest)\n\nENABLE_TESTING()\n\nfile(\n    GLOB_RECURSE\n    test_files\n    test/*\n)\n\ninclude(BoostTestTargets.cmake)\n\nadd_boost_test(eddic_boost_test\n    SOURCES ${test_files}\n    TESTS \n    TestSuiteA/test_1\n    TestSuiteA/test_2\n    TestSuiteA/test_3\n    TestSuiteA/test_4\n    TestSuiteA/test_5\n    TestSuiteB/test_1\n    TestSuiteB/test_2\n    TestSuiteB/test_3\n    TestSuiteB/test_4\n    TestSuiteB/test_5\n    )\n\n\n\nAll the test files are searched in the test directory and used in the SOURCES variable. Then all the tests are declared. \nThe main test file has to include a specific header file:\n#define BOOST_TEST_MODULE eddic_test_suite\n#include <BoostTestTargetConfig.h>\n\n\n\nThis file will be automatically detected by BoostTestTargets and configured correctly. And that's it !\nYou can run CMake again in your build directory to use the new test system: \n[bash]cmake .[/bash]\nIf the configuration has been successful, you will see a message indicating that. For example, I see that: \n-- Test 'eddic_boost_test' uses the CMake-configurable form of the boost test framework - congrats! (Including File: /home/wichtounet/dev/eddi/eddic/test/IntegrationTests.cpp)\n-- Configuring done\n-- Generating done\n-- Build files have been written to: /tmp/ramdrive/dev/eddic\n\nRun tests in parallel\n\nYou can then run your tests in parallel with ctest. For instance, with 9 threads: \nctest -j 8\n\nIn my case, my tests are completed 6x faster ! This is very valuable when you often run your tests. \nFor more information on how to integrate your Boost Test Library tests with CMake, you can consult the The cmake-modules repository", 
      "tags": "Boost,C++,cmake,Concurrency,EDDI,Performances,Tests"
    }, 
    {
      "loc": "/posts/2012/09/cmake-compile-latex-documents.html", 
      "title": "Use CMake to easily compiles Latex documents into PDF", 
      "text": "Everyone who compiles Latex documents by hand knows that it is not a panacea. You have to compile the file several times to handle the references. Moreover, if you have a glossary or an index, you have to run others commands between Latex commands so that everything is correctly resolved. The better way to handle Latex compilation is to write a MakeFile compiling each part. However, writing a Latex MakeFile by hand is not easy and especially not interesting. \nUsing CMake for most of my development projects, I tried to find a CMake script to generates a MakeFile easily. I did found a good script for that, but I wanted to add some features and change some things, so I forked it to Github: The CMakeLatex repository. \nUsage\n\nHere is an example using all the features of the script for one of my Latex documents. \nPROJECT(master_project NONE)\ncmake_minimum_required(VERSION 2.8)\nSET(LATEX_OUTPUT_PATH build)\nINCLUDE(UseLATEX.cmake)\n\nfile(GLOB_RECURSE contents_files RELATIVE ${CMAKE_SOURCE_DIR} contents/*.tex)\n\nADD_LATEX_DOCUMENT(\n    master.tex\n    INPUTS ${contents_files}\n    IMAGE_DIRS images\n    BIBFILES bibliography.bib\n    USE_INDEX\n    USE_GLOSSARY\n    FILTER_OUTPUT\n    )\n\n\n\nTo use it, you have to download the files of the repository and put them aside your Latex files (or just make symlinks to the files in a clone of the repository for easy update). Then, the UseLATEX.cmake file has to be included in your CMakeLists.txt file. \nI think that it is a good practice to generates the Latex files in another directory. This directory can be set using the LATEX_OUTPUT_PATH variable. \nThen, to add a latex document, you can use the ADD_LATEX_DOCUMENT function. The first parameter is the name of the main Latex file. After that, you have to give several parameters: \n\n    INPUTS: It needs the list of Latex files that are included in master file. I use the GLOB_RECURSE function to find all of them in a contents subfolder. \n    IMAGE_DIRS: The directory where the image are stored. They will be copied to the build folder and automatically converted if necessary. \n    BIBFILES: If you have a bibliography, you just have to list all the .bib files of your project. \n    USE_INDEX: Necessary only if your document use an index. \n    USE_GLOSSARY: Necessary only if your document use a glossary. \n    FILTER_OUTPUT: This option activates the filtering of pdflatex output to the console. For now, the option is quite limited, but it allows you to have a smoother output. It has to be taken into account that this option hides the overflow and underflow warnings. \n    CONFIGURE: You can use the CMake configuration feature on some of your files if you want CMake variables to be replaced in the documents. \n\n\nOnce your Latex document is configured, you can just run cmake on your project. After that, you can use targets to generate pdf: \n\n    make pdf: This will generate the Latex file using several passes and running all the necessary commands. \n    make fast: This will generate a pdf in only one pass. This can be useful if you want to see a rough draft of your document quickly.\n\n\nI already use this script for several of my documents. I hope that it will be useful for some of you. If you want any problem in the script or in the generate make file or if you have an idea for improvement, don't hesitate to let a command or to publish an Issue or a Pull Request in the CMakeLatex repository. \nThis script only support pdflatex and can only generates pdf directly. If you want latex support with dvi/ps/pdf generation, you should take a look at the original project:  CMakeUserUseLATEX", 
      "tags": "cmake,Latex,Others,Tools"
    }, 
    {
      "loc": "/posts/2012/09/linux-symbolic-links-hard-links.html", 
      "title": "Linux symbolic links (soft) and hard links", 
      "text": "On Linux, it is possible to create links to existing file. These links can be either symbolic links or hard links. Each of them having advantages and drawbacks. In this small post, we will see the differences between the two kinds of links and how to use them.\nHard Link\n\nAn hard link refers directly to the physical location of another file (an inode to be precise).\nA hard link has some limitations: it cannot refer to a directory and cannot cross file system boundaries. It means that you can only create hard links to the same file system where the hard link is located.\nWhen the source of the link is moved or removed, the hard link still refer to the source.\nSymbolic link are created with the\u00a0ln\u00a0command. For instance, to create a link to source_file: \nln source_file link\n\nSymbolic Link\n\nA symbolic link refers to a symbolic path indicating the location of the source file. You can see it as a link to a path (itself refering to an inode).\nA symbolic link is less limited. It can refer to a directory and can cross file system boundaries.\nHowever, when the source of the link is moved or removed, the symbolic link is not updated.\nSymbolic link are created with the ln command. For instance, to create a symbolic link to source_file:\nln -s source_file link\n\nDeletion\n\nThe deletion of a link (hard or symbolic) can be achieved with the rm or unlink commands: \nrm link\nunlink link\n\nConclusion\n\nAnd that's it!\nSymbolic and hard links are very useful tools and are very easy to use. \nI hope that this blog post helped you understand a little better the differences between the two types of links and how to use them.", 
      "tags": "Linux"
    }, 
    {
      "loc": "/posts/2012/09/packt-publishing-thousandth-book-celebration.html", 
      "title": "Packt Publishing celebrates its 1000th IT Book !", 
      "text": "Packt Publishing is about to publish its 1000th title, on the 30th of September, 2012.\nPackt published their first book in April 2004. They now have a lot of books on about every subject from web development to IT architecture, games to e-commerce. Their books are known for their high quality.\nFor this occasion, they are offering a surprise gift to all their members. If you want to be part of it, you just have to sign up for a free Packt Publishing account. If you're already registered, you don't have anything to do! You need to be registered before the 30th of September in order to get involved.\nPackt is also known for their support to Open Source. They support Open Source projects through a project royalty donation. They already have contributed over \u00a3300,000. For this special occasion, they will allocate 30,000 to share between projects and authors in their own way that will be disclosed on the website soon.\nFor more information about Packt Publishing, their books or how to sign-up for a free account for this offer, you can view the official website: http://www.packtpub.com/", 
      "tags": "Books,Programming,Promotion,Releases"
    }, 
    {
      "loc": "/posts/2012/09/back-in-berkeley-california.html", 
      "title": "Back in Berkeley, California", 
      "text": "I arrived yesterday to Berkeley, California.\nJust like I did my Bachelor thesis in Lawrence Berkeley National Laboratory (LBNL), I will do my Master Thesis there too. The thesis will last a bit less than a semester.\nDuring my Master Thesis I will try to use profiling samples from the Linux perf tools in GCC or Clang to optimize processor cache usage (avoid cache and page faults).\nI will try to publish some posts about that during the semester if I have time.", 
      "tags": "Compilers,gcc,Others,Personal,The site"
    }, 
    {
      "loc": "/posts/2012/09/eddi-compiler-1-1-3-templates.html", 
      "title": "EDDI Compiler 1.1.3 - Templates", 
      "text": "I finished the version 1.1.3 of the EDDI Compiler (eddic).\nThe main improvement to the language is the support of templates. The syntax is more or less the same as the syntax of C++ templates, but the features are much more limited. In EDDI, you can declare class templates and function templates. Class templates can also includes member function templates.\nHere is an example of the use of templates in EDDI:\ntemplate<type T>\nstruct node {\n    T value;\n\n    this(T init){\n        print(\"C1|\");\n        this.value = init;\n    }\n\n    T get_value(){\n        return this.value;\n    }\n\n    template<type U>\n    void print_value(U v){\n        print(v);\n        print(\"|\");\n    }\n}\n\ntemplate<type T>\nvoid debug(T t){\n    print(t);\n    print(\"|\");\n}\n\ntemplate<type T>\nvoid test(node<T>* node){\n    debug<T>(node.value);\n    debug<T>(node.get_value());\n}\n\nvoid main(){\n    node<int> first_node(100);\n    node<float> second_node(13.3);\n\n    test<int>(first_node);\n    test<float>(second_node);\n\n    first_node.print_value<float>(1.0);\n    second_node.print_value<int>(10);\n}\n\n\n\nThis new feature adds generic programming capabilities to the language.\nThis version also adds other language improvements. The first one is the support of the ! operator for a bool, to test if a bool is false. This version also includes support for iterating through all the chars of a string with a foreach loop. And finally, the this pointer is now implicit to access member fields of a struct from member functions.\nThe optimization engine has been greatly improved. The pointers are much better handled and some regression due to new features have been fixed. The Constant Propagation optimization can take default values of struct and arrays into account. Finally, the functions with char parameters can now be inlined.\nFinally, the compiler use a new logging system, that can be completely removed at compile-time for release versions.\nFuture Work\n\nThe next version of the EDDI compiler (eddic) will be the version 1.1.4. This version will add support for some basic pointer manipulation. It will also add support for dynamically allocated arrays. Finally, the version will includes several new optimization techniques regarding to loops: Loop Invariant Code Motion, Loop Strength Reduction and perhaps some basic Loop Unrolling.\nDownload\n\nYou can find the EDDI Compiler sources on the Github repository: https://github.com/wichtounet/eddic\nThe exact version I refer to is the v1.1.3 available in the GitHub tags or directly as the release branch.", 
      "tags": "C++,Compilers,EDDI"
    }, 
    {
      "loc": "/stories/publications.html", 
      "title": "Publications", 
      "text": "2013\nCache-Friendly Profile Guided Optimization (Master Thesis)\nBaptiste Wicht, February 8, 2013\nURL (PDF)\n2012\nBinary Trees Implementations Comparison for Multicore Programming\nBaptiste Wicht, June 7, 2012\nURL (PDF)\nCojac, A Numerical Problem Sniffer\nFrederic Bapst and Baptiste Wicht\u2028, Dr Dobbs, February 27, 2012\nURL\n2011\nInlining Assistance for Large-Scale Object-Oriented Software (Bachelor Thesis)\nBaptiste Wicht, August 11, 2011\nURL (PDF)", 
      "tags": ""
    }, 
    {
      "loc": "/posts/2012/08/jelastic-java-host-recommended-james-gosling.html", 
      "title": "Jelastic Java Host - Recommended by James Gosling !", 
      "text": "I recently came across an interesting tool. Jelastic is a Platform as a Service (PaaS) provider for Java. Basically, it's a cloud for Java applications.\nThe most interesting point about Jelastic (in my opinion) is the fact that it can run any Java application. There are no API to use or special change that have to be made: you can take any Java app that you have and run it on Jelastic. Jelastic runs Glassfish, Tomcat and Jetty application servers. It's up to the developer to choose the application server. Because it's only made for Java, you have directly access to the application server where you can deploy to, you don't have access to the machine itself.\nAnother great advantage of Jelastic is that it automatically scales vertically. At the beginning, you application is only allowed a very small amount of CPU and memory and when the system detects that it needs more, it automatically gives more resources to the application. And when the application has too much resources, there are released. That has the advantage that you don't need to worry about the resources of your application and that the costs are to the minimum when the application doesn't need a lot of resources. Of course, you can also put limits on the scalability. An application can also be run in several different application servers (horizontal scaling). It supports automatic load balancing for the different instances.\nA Jelastic environment provides also access to a database server of your choice\u00a0(MySQL, MariaDB, PostgreSQL, MongoDB, CouchDB). It also has several other good features. You can look at the official list if you want a complete list of features.\nThe official Jelastic\u00a0site provides several very good guides about how to deploy a specific type of application to Jelastic. For example, there are guides for Play! Framework, Clojure or Alfresco.\nThe interesting point about Jelastic is that it has been recommended by James Gosling itself (the father of Java):\nI really like Jelastic. It\u2019s actually software package that a number of ISPs are using. It\u2019s a Java hosting system and so you don\u2019t get a bare Linux machine. What you get is a JavaEE container, and you can drop WAR files on them and they have this really nice control panel where you get a slider that says how many clones of Glassfish do you want and check boxes for [databases]. You don\u2019t have to go into Linux \u2013 Oh my God, what it takes to install anything: it\u2019s like which version of Linux is compatible with which app server and what time\u2026 they actually take care of that and it works lovely. I actually built these clusters and they can span multiple ISPs, multiple countries, multiple datacenters, and that\u2019s how I deal with my personal extreme paranoia of the survivability of these things.\nJames is working in a small startup, Liquid Robotics that handles a set of automatic robots in the ocean.\nI think that all these information\u00a0are making of Jelastic a very good choice for a Java host !\nMore information\n\n    Source :\u00a0James Gosling (Father of Java) Loves\u00a0Jelastic\n    Official Site : http://www.jelastic.com", 
      "tags": "Java,Web"
    }, 
    {
      "loc": "/posts/2012/08/eddi-compiler-1-1-2-read-command-line.html", 
      "title": "EDDI Compiler 1.1.2 \u2013 Read command line", 
      "text": "I finished the\u00a0eddi compiler (eddic) version 1.1.2. It took me a long time because of a lot of other things I had to do this month.\nThis version includes two major changes. First, this version adds a new type for characters (char). A char can be declared using a char literal ('b' for instance) or from an int ( (char) 77). This version introduces the [] operator for string to have access to a specific char.\nAnother major improvement is the support for reading the command line. For now, only characters can be read, one by one with the read_char function.\nThe standard library includes a new function to compare two strings (str_equals):\nbool str_equals(string a, string b){\n    if(length(a) != length(b)){\n        return false;\n    }\n\n    for(int i = 0; i &lt; length(a); ++i){\n        if(a[i] != b[i]){\n            return false;\n        }\n    }\n\n    return true;\n}\n\n\n\nThe other improvements are not relative to the language. The inlining engine can now inline functions that takes arrays as parameters. The symbol table is now represented by the global context. There is no global symbol table. This new version includes several improvements of the code and a cleanup of the AST to remove redundancy.\nFuture Work\n\nThe next version of the eddi compiler (eddic) will be the version 1.1.3. This version will introduce support for a very basic version of template engine. It will also add support for foreach on string. This version will also add new features and cleanup in the different optimizations passes.\nDownload\n\nYou can find the EDDI Compiler sources on the Github repository: https://github.com/wichtounet/eddic\nThe exact version I refer to is the v1.1.2 available in the GitHub tags or directly as the release branch.", 
      "tags": "C++,Compilers,EDDI"
    }, 
    {
      "loc": "/posts/2012/08/algorithms-books-reviews.html", 
      "title": "Algorithms books Reviews", 
      "text": "To be sure to be well prepared for an interview, I decided to read several Algorithms book. I also chosen books in order to have information about data structures. I chose these books to read:\n\n    Data Structures & Algorithm Analysis in C++, Third Edition, by Clifford A. Shaffer\n    Algorithms in a Nutshell, by George T. Heineman, Gary Pollice and Stanley Selkow\n    Algorithms, Fourth Edition, by Robert Sedgewick and Kevin Wayne\n    Introduction to Algorithms, by\u00a0Thomas H. Cormen,\u00a0Charles E. Leiserson,\u00a0Ronald L. Rivest\u00a0and\u00a0Clifford Stein. I have to say that I have only read most of it, not completely, because some chapters were not interesting for me at the current time, but I will certainly read them later.\n\n\nAs some of my comments are about the presentation of the books, it has to be noted that I have read the three first books on my Kindle.\nIn this post, you will find my point of view about all these books.\nData Structures & Algorithm Analysis in C++\n\nThis book is really great. It contains a lot of data structures and algorithms. Each of them is very clearly presented. It is not hard to understand the data structures and the algorithms.\nEach data structure is first presented as an ADT (Abstract Data Structure) and then several possible implementations are presented. Each implementation is precisely defined and analyzed to find its sweet pots and worst cases. \u00a0Other implementations are also presented with enough references to know where to start with them.\nI have found that some other books about algorithms are writing too much stuff for a single thing. This is not the case with this book. Indeed, each interesting thing is clearly and succinctly explained.\nAbout the presentation, the code is well presented and the content of the book is very well written. A good think would have been to add a summary of the most important facts about each algorithm and data structure. If you want to know these facts, you have to read several pages (but the facts are always here).\nThe book contains very good explanation about the complexity analysis of algorihtms. It also contains a very interesting chapter about limits to computation where it treats P, NP, NP-Complete and NP-Hard complexity classes.\nThis book contains a large number of exercises and projects that can be used to improve even more your algorithmic skills. Moreover, there are very good references at the end of each chapters if you want more documentation about a specific subject.\nI had some difficulty reading it on my Kindle. Indeed, it's impossible to switch chapters directly with the Kindle button. If you want quick access to the next chapter, you have to use the table of contents.\nAlgorithms in a Nutshell\n\nThis book is much shorter than the previous one. Even if it could be a good book for beginners, I didn't liked this book a lot. The explanations are a bit messy sometimes and it could contain more data structures (even if I know that this is not the subject of the book). The analysis of the different algorithms are a bit short too. Even if it looks normal for a book that short, it has to be known that this book has no exercise.\nHowever, this book has also several good points. Each algorithm is very well presented in a single panel. The complexity of each algorithm is directly given alongside its code. It helps finding quickly an algorithm and its main properties.\nAnother thing that I found good is that the author included empiric benchmarks as well as complexity analysis. The chapters about Path Finding in AI and computational geometry were very interesting, especially because it is not widely dealt with in other books.\nIt also has very good references for each chapter.\nThis book was perfect to read with Kindle, the navigation was very easy.\nAlgorithms\n\nThis book is a good book, but suffers from several drawbacks regarding to other books. First, the book covers a lot of data structures and algorithms. Then, it also has very good explanations about complexity classes. It also has a lot of exercises. I also liked a lot the chapter about string algorithms that was lacking in previous books.\nMost of the time, the explanations are good, but sometimes, I found them quite hard to understand. Moreover, some parts of code are also hard to follow. The author included Java runs of some of programs. In my opinion, this is quite useless, empiric benchmarks could have been useful, but not single runs of the program. Some of the diagrams were also hard to read, but that's perhaps a consequence of the Kindle.\nA think that disappointed me a bit is that the author doesn't use big Oh notation. Even, if we have enough information to easily get the Big Oh equivalent, I don't understand why a book about algorithms doesn't use this notation.\nJust like the first book, there is no simple view of a given algorithm that contains all the information about an algorithm. Another think that disturbed me is that the author takes time to describe an API around the algorithms and data structures and about the Java API. Again, in my opinion only, it takes a too large portion of the book.\nAgain, this book was perfect to read with Kindle, the navigation was very easy.\nIntroduction to Algorithms\n\nThis book is the most complete I read about algorithms and data structures by a large factor. It has very complete explanations about complexity analysis: big Oh, Big Theta, Small O. For each data structure and algorithm, the complexity analysis is very detailed and very well explained. The pieces of code are written in a very good\u00a0pseudo code\u00a0manner.\nAs I said before, the complexity analysis are very complete and sometimes very complex. This can be either an advantage or a disadvantage, depending of what you awaits from the book. For example, the analysis is made using several notations Big Oh, Big Theta or even small Oh. Sometimes, it is a bit hard to follow, but it provides very good basis for complexity analysis in general.\nThe book \u00a0was also the one with the best explanations about linear time sorting algorithms. In the other books, I found difficult to understand sorts like counting sort or bucket sort, but in this book, the explanations are very clear. It also includes\u00a0multithreaded algorithm analysis, number theoretic algorithms, polynomials and a very complete chapter about linear programming.\nThe book contains a huge number of exercises for each chapters and sub chapters.\nThis book will not only help you find the best suited algorithm for a given problem, it will also help you understand how to write your own algorithm for a problem or how to analyze deeply an existing solution.\nAlgorithms Book\u00a0Wrap-up\n\nAs I read all these Algorithms books in order, it's possible that my review is a bit subjective regarding to comparisons to other books.\nIf you plan to work in C++ and need more knowledge in algorithms and C++, I advice you to read Data Structures & Algorithm Analysis in C++, that is really awesome.\u00a0If you want a very deep knowledge about algorithm analysis and algorithms in general and have good mathematical basis, you should really take a deep look at\u00a0Introduction to Algorithms. If you want short introduction about algorithms and don't care about the implementation language, you can read Algorithms in a Nutshell. Algorithms is like a master key, it will gives you good starting knowledge about algorithm analysis and a broad range of algorithms and data structures.", 
      "tags": "Algorithm,Books,C++,Conception,Java,Performances,Programming"
    }, 
    {
      "loc": "/posts/2012/08/architexa-free-understand-code-base.html", 
      "title": "Architexa is available for free - Understand your code base", 
      "text": "Architexa is a tool suite that helps a team to document collaboratively a large Java code base. The tool is made for a whole team to understand a code base. The tool is available as an Eclipse plugin.\nWhen several developers are working on a large application, it is not always simple to have a whole view of the application. Even with some documentation of the application code. It is even harder for a new developer that joins the project to know what the code base is about. In all these cases, Architexa will help your team. It can also be useful when you inherit an application.\nStarting from today, Architexa is available for free\u00a0for individuals and for teams of up to three developers. You can read the official announce at the end of the article.\nMy Review of Architexa\n\nI tried Architexa on several of my current Java Projects, but never in team. So perhaps my point of view is not very accurate regarding to general users of the tool. I made my tests using Eclipse Juno.\nHowever, even when working alone on a project, I think that this tool is very useful.\nThe installation is very straightforward, you just have to use the update site directly in Eclipse. Then, you have several new options in the EDI to use Architexa features.\nThree diagrams are available in the Architexa tool suite:\n\n    Class Diagram : This diagram can be automatically generated for a package, or several packages.\n    Sequence Diagram : You can create Sequence Diagrams for some of your program actions.\n    Layered Diagram : This diagram allows you to represent the architecture of your application. The system allows you to represent several levels of details.\n\n\nYou can easily have several diagrams of each type in your project. You can store them as local files, in a server or in the community server to make them available for everyone.\nYou can add comment in each diagram. In each diagram you can also access the Javadoc of each class. Of course, you can also access any piece of code from your diagrams.\nAdvantages\n\n\n    Architexa is very simple to use. The tool have access to very good guides directly inside the IDE.\n    The Real-Time Code analysis is awesome. Once something is in a diagram, it is always kept up to date.\n    The sharing features are also great.\n    Even if there are fews diagrams, I think that there are largely enough to have a very good understanding of a code base.\n    All the graphs looks very nice, there are very readable\n\n\nDrawbacks\n\n\n    No support for generics and enums.\n    The tool is only available as an Eclipse plugin. I'm especially using IntelliJ Idea and NetBeans.\n    The tool is only available for Java. There is a prototype for C/C++ that is available on demand, but I didn't tried it at the current time.\n    Sometimes, the creation of a very simple diagram takes a bit long time for my feeling. Creating a diagram with three elements can take several seconds. Perhaps, it is better with larger diagrams. I haven't had the occasion to test it with large code .\n\n\nConclusion\n\nTo conclude, Architexa is a great tool suite. It is useful for any Java developers that works in a large application. It allows them to have better understanding of its code base.\nThe official announce: Architexa Tool suite is Now Available for Free\nMore information on the official site:\u00a0http://www.architexa.com/", 
      "tags": "Conception,Java,Tools"
    }, 
    {
      "loc": "/posts/2012/08/memory-manager-intel-assembly-64-linux.html", 
      "title": "Memory Manager in 64bits Intel Assembly on Linux", 
      "text": "For the last version of the EDDI Compiler, it has been necessary to extend the dynamic memory allocator, to support free memory. In this post, we will see how to write a simple Memory Manager in Intel Assembly for Linux.\nIn the past, we've seen how to write a basic memory allocator, this time, we will write a more complete version.\nThe implementation is made in 64bits Intel Assembly.\nMemory Manager specification\n\nThe memory will be allocated by blocks. Each block will contain a header with two information:\n\n    A boolean flag indicating if the block is free or not\n    The size of the block (including the header)\n\n\nEach time some memory is asked, the blocks are tested one by one until an available one is found. If no available block is found, a new block is allocated after the last one and this block is returned.\nThe memory manager consists of three functions:\n\n    memory_init: Init the memory manager\n    memory_alloc: Allocate\u00a0the given number of bytes of memory\n    memory_free: Release the given block\n\n\nThe parameter is passed in the r14 register. The return value is returned in the rax register.\nGlobal State\n\nThis implementation needs two global variables. One for the start address of memory and the other one for the last:\nsection .data\nmem_last dq 0\nmem_start dq 0\n\n\n\nInit memory Manager\n\nThe init function is very simple to implement:\ninit:\npush rbp\nmov rbp, rsp\nmov rax, 12\nxor rdi, rdi\nsyscall\nmov [mem_start], rax\nmov [mem_last], rax\nleave\nret\n\n\n\nWe just have to call sys_brk in order to get the location of program break. Then, the start and the last addresses are the same.\nFree memory\n\nThe free function is the simplest one:\nfree:\npush rbp\nmov rbp, rsp\nmov qword [r14 - 16], 1\nleave\nret\n\n\n\nThe address to free is passed in the r14 register. We have to go back 16 bytes (size of the control block) to go to the start of the block. The availability flag is set to 1 (the block is free).\nThe alloc function\n\nThe alloc function is the most complex:\nalloc:\npush rbp\nmov rbp, rsp\npush rdi\npush r10\npush r11\npush r12\npush r13\npush r14\nadd r14, 16\nmov r12, [mem_start]\nmov r13, [mem_last]\n.start:\ncmp r12, r13\nje .alloc\nmov r10, [r12]\nmov r11, [r12 + 8]\ncmp r10, 1\njne .move\ncmp r11, r14\njl .move\nmov qword [r12], 0\nlea rax, [r12 + 16]\npop r14\npop r13\npop r12\npop r11\npop r10\npop rdi\nleave\nret\n\n.move:\nadd r12, r11\njmp .start\n\n.alloc:\nlea rdi, [r12 + r14]\nmov rax, 12\nsyscall\nmov [mem_last], rdi\nmov qword [r12], 0\nmov qword [r12 + 8], r14\nlea rax, [r12 + 16]\npop r14\npop r13\npop r12\npop r11\npop r10\npop rdi\nleave\nret\n\n\n\nAs the function is a bit complex, I will detail it in part:\nadd r14, 16\nmov r12, [mem_start]\nmov r13, [mem_last]\n.start:\ncmp r12, r13\nje .alloc\nmov r10, [r12]\nmov r11, [r12 + 8]\ncmp r10, 1\njne .move\ncmp r11, r14\njl .move\nmov qword [r12], 0\nlea rax, [r12 + 16]\n\n\n\nThe necessary number of bytes is passed in the r14 register. We add 16 bytes (size of the control group) to the size as we also need some place for the header. Then, we load the start and last addresses. If both addresses are equal, we need to allocate more memory (detailed later). Then, we check the size and the availability of the current block. If the size is enough to fit the needs and the block is available, we set it to unavailable. We return the address past the control block (16 bytes).\n.move:\nadd r12, r11\njmp .start\n\n\n\nTo move to the next block, we just have to add the size of the current block to the current block address.\n.alloc:\nlea rdi, [r12 + r14]\nmov rax, 12\nsyscall\nmov [V_mem_last], rdi\nmov qword [r12], 0\nmov qword [r12 + 8], r14\nlea rax, [r12 + 16]\n\n\n\nTo allocate memory, we compute the new program break and call sys_brk again to set the new program break. The block is then set to not available and the size is set. We return the address past the control block (16 bytes).\nThe rest of the program is just here to save and restore the registers and compute the stack frames.\nWrap-Up\n\nIn this article, we saw how to implement a very simple memory manager in 64bits Intel Assembly on Linux. This memory manager is very simple, but has several drawbacks:\n\n    The overhead for small blocks is important. For example, allocating an 8 bytes integer needs a 24 bytes block, thrice the size of the int.\n    In the worst-case scenario, all of the process memory need to be walked across to find a new free block\n    The functions are not thread-safe\n    This algorithm can lead to a lot of memory fragmentation\n\n\nIn the future I will try to make a more powerful version of this memory manager.\nDownload\n\nAll the functions are available online on the Github Repository:\n\n    alloc\n    free\n    init\n\n\nThey are also available in 32bits Intel Assembly:\n\n    alloc\n    free\n    init", 
      "tags": "Assembly,Intel,Linux"
    }, 
    {
      "loc": "/posts/2012/07/eddi-compiler-1-1-1-dynamic-memory-allocation-constructors-destructors.html", 
      "title": "EDDI Compiler 1.1.1 \u2013 Dynamic Memory Allocation and Constructors/Destructors", 
      "text": "As I'm in holiday, the work is going pretty fast.\u00a0The\u00a0version 1.1.1\u00a0of the\u00a0EDDI Compiler\u00a0(eddic) is available.\nThis version introduces two major changes. The first is the support of dynamic memory allocation. You can allocate a struct or a standard type in help using the new operator. The memory can be released using the delete operator. Another related improved is the addition of constructors and destructors to the language. The following sample shows what can be done with the new features:\nstruct A {\n    int a;\n\n    this(int a){\n        this.a = a;\n\n        print(\"Constructed\");\n    }\n\n    ~this(){\n        println(\"Destructed\");\n    }\n}\n\nvoid main(){\n    A* b = new A(55);\n    delete b;\n}\n\n\n\nThe constructor is called once the memory is allocated. The delete operator calls the destructor and then free the memory. \nWhen a structure is allocated on the stack, the constructor is called at the declaration point and the destructor is called when the variable gets out of scope. \nThe memory manager is quite simple for now. Memory is allocated in blocks. Each block has a header indicating the size of the block and its availability. The size of the header is 8 bytes in 32 bits and 16 bytes in 64 bits. The free operation can be done in constant time by just setting the availability flag to false. The disadvantage of this technique is that all the blocks needs to be tested to find a free block. This can be slow in some situations. I will try to make a better version in the future. \nFor that, the memory model has been improved. All the offsets are now increasing and the stack addresses are set at the end of the block. \nAnother interesting improvement of the language is the support of switch. For now, only switch on int is supported. Here is an example of a switch in EDDI:\nswitch(a){\n    case 3:\n        print(\"3\");\n    case 4:\n        print(\"4\");\n    case 5:\n        print(\"5\");\n    case 6:\n        print(\"6\");\n    default:\n        print(\"default\");\n}\n\n\n\nThe performances of the optimizer have been improved, by doing live-variable analysis less often. Pointers can now be passed in registers. Some of the variables used as temporary copies are removed \nThe peephole optimizer has been improved to use conditional move when possible. Moreover, the peephole optimizer is now able to perform some local copy propagation. \nFuture work\nThe next version of the EDDI Compiler will be the version 1.1.2. This version will add features to read the command-line. Moreover, it will also add support for char type and string comparisons. With that, I think that the language will start to be usable for toy applications. \nThere  will be some improvements to the code that have been left aside for a too long time. \nDownload\n\nYou can find the EDDI Compiler sources on the Github repository: https://github.com/wichtounet/eddic\nThe exact version I refer to is the v1.1.1 available in the GitHub tags or directly as the release branch.", 
      "tags": "C++,Compilers,EDDI,Releases"
    }, 
    {
      "loc": "/posts/2012/07/c11-synchronization-benchmark.html", 
      "title": "C++11 Synchronization Benchmark", 
      "text": "In the previous parts of this serie, we saw some C++11 Synchronization techniques: locks, lock guards and atomic references.\nIn this small post, I will present the results of a little benchmark I did run to compare the different techniques. In this benchmark, the critical section is a single increment to an integer. The critical section is protected using three techniques:\n\n    A single std::mutex with calls to lock() and unlock()\n    A single std::mutex locked with std::lock_guard\n    An atomic reference on the integer\n\n\nThe tests have been made with 1, 2, 4, 8, 16, 32, 64 and 128 threads. Each test is repeated 5 times.\nThe results are presented in the following figure:\n\nAs expected, the mutex versions are much slower than the atomic one. An interesting point is that the the atomic version has not a very good scalability. I would have expected that the impact of adding one thread would not be that high.\nI'm also surprised that the lock guard version has a non-negligible\u00a0overhead when there are few threads.\nIn conclusion, do not locks when all you need is modifying integral types. For that, std::atomic is much faster. Good Lock-Free algorithms are almost always faster than the algorithms with lock.\nThe sources of the benchmark are available on Github:\u00a0https://github.com/wichtounet/articles/tree/master/src/threads/benchmark", 
      "tags": "Benchmarks,C++,C++11 Concurrency Tutorial,Concurrency,Performances"
    }, 
    {
      "loc": "/posts/2012/07/eddi-compiler-1-1-0-member-functions.html", 
      "title": "EDDI Compiler 1.1.0 - Member functions", 
      "text": "The\u00a0version 1.1.0\u00a0of the\u00a0EDDI Compiler\u00a0(eddic) is available. It took much less time to implement that version than I thought. \nThe main change to the language is the support of member functions. Each structure can now declare some functions. Functions can be called in each structure object. Here is an example of what can be done with that feature in EDDI:\nstruct Counter {\n    int value;\n\n    void increment(){\n        this.value = this.value + 1;\n    }\n\n    void add(int number){\n        this.value = this.value + number;\n    }\n\n    void add(int n1, int n2){\n        this.value = this.value + n1;\n        this.value = this.value + n2;\n    }\n}\n\nvoid main(){\n    Counter counter;\n    counter.increment();\n    println(counter.value);\n\n    counter.add(99);\n    println(counter.value);\n\n    counter.add(11, 69);\n    println(counter.value);\n}\n\n\n\nThe this pointer is available in each member function. The pointer is passed on the stack just like any other parameter. \nAnother improvement is the support of the ternary operator:\nvoid main(){\n    int a = 5 &gt; 2 ? 44 : 66;\n    println(a);\n}\n\n\n\nThe inliner has been improved to support inlining member functions and functions with pointer parameters. The parameter allocation in register is only done starting at O1. \nThe peephole optimizer has also been improved. Some stacks operations optimization are performed and some unnecessary copies of parameter register are removed.  \nFinally, the assembly generation has been improved to not use stack frames starting at O2. When this optimization is enabled, the local variables are addressed using stack pointers instead of the base pointer that is not used anymore. This optimization reduces the overhead of function calls. \nFuture work\n\nThe next version of the EDDI Compiler will be the\u00a0version 1.1.1.\nDownload\n\nYou can find the compiler sources on the Github repository:\u00a0https://github.com/wichtounet/eddic\nThe exact version I refer to is the v1.1 available in the GitHub tags or directly as the release branch.", 
      "tags": "C++,Compilers,EDDI,Optimization"
    }, 
    {
      "loc": "/posts/2012/07/manage-command-line-boost-program-options.html", 
      "title": "Manage command-line options with Boost Program Options", 
      "text": "In command-line program, we often faces problems with the management of command-line options. When you have a few options, it's not a problem. But when writing complex programs with tens of options (or hundreds), it starts to be too complicated to manage by hand. That's where Boost Program Options enters the game!\nBoost Program Options is one of the Boost C++ Libraries. It is a very powerful library to handle command-line options. You define all the options of the program and then Boost Program Options takes care of all. It parses the command line, handles errors, gets values and even displays help. It is not a perfect library. But it is very complete that will answer most of the common needs. \nThis library is not header-only. You will need to build the library and link your program with the library. \nGetting started\n\nIn this article, I will use po as an abbreviation of boost::program_options and all source will contains this namespace alias:\nnamespace po = boost::program_options;\n\n\n\nFirst of all, it is necessary to create an instance of po::option_description:\npo::options_description description(\"MyTool Usage\");\n\ndescription.add_options()\n    (\"help\", \"Display this help message\")\n    (\"version\", \"Display the version number\");\n\n\n\nThe parameter to the constructor is the title of the options. To add options, you use the add_options() function and append all your options, each one surrounded with parenthesis. Here, we declared two options (help and version). They can be set with --help and --version. \nThen, you can parse the command line by declaring a po::variables_map to store the variables and parse the command line into that storage: \npo::variables_map vm;\npo::store(po::command_line_parser(argc, argv).options(description).run(), vm);\npo::notify(vm);\n\n\n\nThen, you can easily verify if an option has been set by using the count(const std::string& name) function on the vm object: \nif(vm.count(\"help\")){\n    std::cout &lt;&lt; description;\n}\n\n\n\nYou can use operator on the description to output all the options of program. \nShort options\n\nBy default, all the options are accessed by using -- in front of them. You can also specify a short version for each option: \ndescription.add_options()\n    (\"help,h\", \"Display this help message\")\n    (\"version,v\", \"Display the version number\");\n\n\n\nWith that, you can display with either --help or -h. Even if you select help with -h, you can still verify if help has been set with count(\"help\"). \nOption with value\n\nBoost Program Options can also handle option that need a specific value. Lets add a compression option:\ndescription.add_options()\n    (\"help,h\", \"Display this help message\")\n    (\"compression,c\", po::value&lt;int&gt;(), \"Compression level\")\n    (\"version,v\", \"Display the version number\");\n\n\n\nYou can then get the value of option easily: \nif(vm.count(\"compression\")){\n    std::cout &lt;&lt; \"Compression level \" &lt;&lt; vm[\"compression\"].as&lt;int&gt;() &lt;&lt; std::endl;\n}\n\n\n\nFor the story, the option value are stored as boost::any. You can get the value of the option by using operator[] on the po::variables_map. You can get the value type with the as function with the type you need. \nOn the command line, the value can be set with --compression 10, -c 10 or -c10. \nYou can also configure a default value for an option:\ndescription.add_options()\n    (\"help,h\", \"Display this help message\")\n    (\"compression,c\", po::value&lt;int&gt;()-&gt;default_value(5), \"Compression level\")\n    (\"version,v\", \"Display the version number\");\n\n\n\nWith that, if the option is not set on the command line, the option has the specified value. With that, the option is always defined. \nFinally, you can also set an implicit value. This is the value of the option is the option is set to the command line without a value (--compression or -c): \ndescription.add_options()\n    (\"help,h\", \"Display this help message\")\n    (\"compression,c\", po::value&lt;int&gt;()-&gt;default_value(5)-&gt;implicit_value(10), \"Compression level\")\n    (\"version,v\", \"Display the version number\");\n\n\n\nPositional options\n\nIt is often convenient to have a list of files on the command line. These options does not have a name. In Boost Program Options, these options are called positional options. You have to declare them in the describe as any other action. For example, for a list of files: \ndescription.add_options()\n    (\"help,h\", \"Display this help message\")\n    (\"compression,c\", po::value&lt;int&gt;()-&gt;default_value(5)-&gt;implicit_value(10),\"Compression level\")\n    (\"input-files\", po::value&lt;std::vector&lt;std::string&gt;&gt;(), \"Input files\")\n    (\"version,v\", \"Display the version number\");\n\n\n\nThen, you have to declare it as positional and then finally specify it when parsing the command-line: \npo::positional_options_description p;\np.add(\"input-files\", -1);\npo::variables_map vm;\npo::store(po::command_line_parser(argc, argv).options(description).positional(p).run(), vm);\npo::notify(vm);\n\n\n\nThe positional options values are retrieved the exact same way as other options: \nif(vm.count(\"input-files\")){\n    std::vector&lt;std::string&gt; files = vm[\"input-files\"].as&lt;std::vector&lt;std::string&gt;&gt;();\n    for(std::string file : files){\n        std::cout &lt;&lt; \"Input file \" &lt;&lt; file &lt;&lt; std::endl;\n    }\n}\n\n\n\nWrap-Up\n\nIn this article, we saw the most important aspects of Boost Program Options. With these notions, you can start using this great library. If you need more information about the library, you can read the official documentation that is very well made. \nYou can download the final sources of this article on Github: v1.cpp", 
      "tags": "Boost,C++"
    }, 
    {
      "loc": "/posts/2012/07/c11-concurrency-tutorial-part-4-atomic-type.html", 
      "title": "C++11 Concurrency Tutorial - Part 4: Atomic Types", 
      "text": "In the previous article, we saw advanced techniques about mutexes. In this post, we will continue to work on mutexes with more advanced techniques. We will also study another concurrency technique of the C++11 Concurrency Library: Atomic Types\nAtomic Types\n\nWe will take, the example of a Counter:\nstruct Counter {\n    int value;\n\u00a0 \u00a0\u00a0\n    void increment(){\n        ++value;\n    }\n\u00a0 \u00a0\u00a0\n    void decrement(){\n        --value;\n    }\n\u00a0 \u00a0\u00a0\n    int get(){\n        return value\n    }\n};\n\n\n\nWe already saw that this class was not safe at all to use in multithreaded environment. We also saw how to make if safe using mutexes. This time, we will see how to make it safe using atomic types. The main advantage of this technique is its performance. Indeed, in most cases, the std::atomic operations are implemented with lock-free operations that are much faster than locks. \nThe C++11 Concurrency Library introduces Atomic Types as a template class: std::atomic. You can use any Type you want with that template and the operations on that variable will be atomic and so thread-safe. It has to be taken into account that it is up to the library implementation to choose which syncronization mechanism is used to make the operations on that type atomic. On standard platforms for integral types like int, long, float, ... it will be some lock-free technique. If you want to make a big type (let's saw 2MB storage), you can use std::atomic as well, but mutexes will be used. In this case, there will be no performance advantage. \nThe main functions that std::atomic provide are the store and load functions that atomically set and get the contents of the std::atomic. Another interesting function is exchange, that sets the atomic to a new value and returns the value held previously. Finally, there are also two functions compare_exchange_weak and compare_exchance_strong that performs atomic exchange only if the value is equal to the provided expected value. These two last functions can be used to implement lock-free algorithms. \nstd::atomic is specialized for all integral types to provide member functions specific to integral (like operators ++, --, fetch_add, fetch_sub, ...). \nIt is fairly easy to make  the counter safe with std::atomic: \n#include <atomic>\n\nstruct AtomicCounter {\n    std::atomic<int> value;\n\n    void increment(){\n        ++value;\n    }\n\n    void decrement(){\n        --value;\n    }\n\n    int get(){\n        return value.load();\n    }\n};\n\n\n\nIf you test this counter, you will see that the value is always the expected one. \nWrap-Up\n\nIn this article we saw a very elegant technique to perform atomic operations on any type. I advice you to use std::atomic any time you need to make atomic operations on a type, especially integral types. \nThe source code for this article can be found on Github.\nNext\n\nIn the next post of this series, we will see how to use the Futures facility to perform asynchronous task.", 
      "tags": "C++,C++11 Concurrency Tutorial,Concurrency,Performances"
    }, 
    {
      "loc": "/posts/2012/07/eddi-compiler-1-0-3-inlining-register-allocation.html", 
      "title": "EDDI Compiler 1.0.3 - Inlining and register allocation", 
      "text": "The\u00a0version 1.0.3\u00a0of the\u00a0EDDI Compiler\u00a0(eddic) is available.\nThe only improvement to the language is that the size of a global array can now be defined using a constant global variable.\nThe main improvement of this version is the addition of inlining in the optimization engine. This optimization replace a call to a function by the body of the function. For now, the inlining optimizer is quite basic. For now, it doesn't inline only a specific call site but all the call sites of a given function. Moreover, the heuristics used for inlining are quite simple (only the size of the function is taken into account). Only functions that takes int and float parameters can be inlined. This optimization will be improved in the future.\nThe second main change is the arrival of a basic register allocation. In each function, one or more variables can be assigned to registers. Only the most used variables are allocated into registers. Another optimization is that variables that are not used after all optimization techniques have been applied are removed from the function storage. The unused functions are also removed from the program after the optimization passes.\nMoreover, the performances of optimization engine have been improved by about 20%.\nThe MTAC representation has been improved. The ARRAY operators have been removed because they can be replaced with the DOT operators. The preamble and prologue generations for LTAC has also been refactored. When it is possible, the stack frames are not generated.\nFinally, the configuration of the compiler has been improved with several new optimization option and the options being separated into several option groups.\nFuture work\n\nThe next version of the EDDI Compiler will be the\u00a0version 1.1.0.\nThe main change will be member functions inside of structures. For now, there will be no kind of virtual functions and inheritance but that will certainly come in its time.\nAnd as ever, I will be more than pleased to hear any idea you could have about this project :)\nDownload\n\nYou can find the compiler sources on the Github repository:\u00a0https://github.com/wichtounet/eddic\nThe exact version I refer to is the v1.0.3 available in the GitHub tags or directly as the release branch.", 
      "tags": "C++,Compilers,EDDI,Optimization,Releases"
    }, 
    {
      "loc": "/posts/2012/07/taskwarrior-php-frontend-0-1.html", 
      "title": "taskwarrior-php 0.1 : A simple PHP Frontend for Taskwarrior", 
      "text": "I released the version 0.1 of taskwarrior-php.\nThis project is a simple PHP Frontend for Taskwarrior. For now, the frontend is quite basic. All the tasks are displayed and sorted by projects. The completion of each project is also computed.\n\nYou can also insert a new task. For now, only the project and the description of the task can be modified.\nDownload\n\nThe application is available on the Git repository :\u00a0https://github.com/wichtounet/taskwarrior-php\nThe installation is simple, you just have to put all the files in a folder of a PHP server. Then, you have to edit the config.php to set the location of your Taskwarrior files.\nIt is necessary that the Taskwarrior files are on the PHP server as well. For that, you can use the FTP pull and push commands of Taskwarrior.\nDon't hesitate to contact me if you have some ideas for this project or if you find some bugs.", 
      "tags": "Linux,Releases,Tools,Web"
    }, 
    {
      "loc": "/posts/2012/07/eddi-compiler-1-0-2-better-pointer-support-new-optimizations.html", 
      "title": "EDDI Compiler 1.0.2 \u2013 Better pointer support and Dead-Code Elimination", 
      "text": "The version 1.0.2 of the EDDI Compiler (eddic) is available.\nThe language itself does not features something new, but the support of pointers has been greatly improved. You can now declare arrays of pointers and return pointers from functions. Structures can hold pointers as well. Moreover, arrays of structures are now supported. These new features have increased the number of operators of the MTAC Level.\nThe more important part of this new version resides in the Optimization Engine. A new optimization technique has been implemented: Dead-Code Elimination. This technique removes all code that calculates values for variables that are not used anymore after this statement. Another change is that empty functions are removed after optimization (as well as every call to the removed functions). The liveness analyzer has been replaced by a global Live-Variable Analysis routine. This information is used in the optimization engine and in the LTAC Compiler. Finally, the Peephole Optimizer has been improved to support some local optimization techniques like constant propagation and basic dead-code elimination.\nThe code generators have also been improved by outputting only native functions that are called. It means that if the program does not print a float, the _F5printF function will not be generated. Moreover, the native functions have been moved in external assembly files.\nFuture work\nThe next version of the EDDI Compiler will be the version 1.0.3.\nThis version will see a first basic version of Inlining optimization and certainly register-allocation of the most used variables. There will certainly be no change of the language itself.\nA cleanup of the two compilers (MTAC and LTAC) will be performed as well as simplification of the MTAC Language if possible.\nThe other changes will mainly be minor changes to the compiler.\nAnd as ever, I will be more than pleased to hear any idea you could have about this project :)\nDownload\n\nYou can find the compiler sources on the Github repository:\u00a0https://github.com/wichtounet/eddic\nThe exact version I refer to is the v1.0.2 available in the GitHub tags or directly as the release branch.", 
      "tags": "C++,Compilers,EDDI,Optimization"
    }, 
    {
      "loc": "/posts/2012/06/eddi-compiler-1-0-1-pointers-better-struct-support.html", 
      "title": "EDDI Compiler 1.0.1 - Pointers and better struct support", 
      "text": "The version 1.0.1 of the EDDI Compiler (eddic) is now available. \nThe language itself has been updated to support pointers. For now, this support is quite basic, but it allows to pass any type of the language by pointer to a function. No arithmetic is permitted on pointers, only dereferencing is allowed. The following sample shows how pointers are used in the language: \nstruct A {\n    int a;\n    string b;\n    float c;\n}\n\nvoid main(){\n    A a;\n\n    a.a = 44;\n    a.b = \"44\";\n    a.c = 44f;\n\n    test(a); \n    print(a.a);\n    print(\"|\");\n}\n\nvoid test(A* a){\n    A* b = a;\n\n    a.a = 55;\n\n    print(a.a);\n    print(\"|\");\n\n    b.a = 66;\n    b.b = \"66\";\n    b.c = 66f;\n\n    print(a.a);\n    print(\"|\");\n    print(b.a);\n    print(\"|\");\n}\n\n\n\nThis sample is not very useful, but it shows the usage of pointers well enough. \nAnother improvement to the language is that it supports now nested struct. It means that a member of a struct can be a struct itself. \nThat's it for the language improvements. On the side of the compiler itself, I've improved the error reporting for structs. For example, the compiler display a clear error when a struct is recursively nested. The peephole optimizer has been improved a bit with new optimization, but it still rather simple. The optimization engine is now able to optimize functions in parallel. The improvement is not quite large, but that can be useful if there are a lot of functions. I've also improved a lot the Abstract Syntax Tree representation of assignments to unify variable, array and struct assignments in one Node with the notion of LeftValue. \nFinally, the tests have also been improved. New tests have been added and helped me find new bugs. Moreover, the tests are now made on each optimization levels for each test case. There was some issue with smallest optimization level. \nFuture work\n\nThe next version of the EDDI Compiler will be the version 1.0.2. \nThis version will adds support for returning a pointer from a function. Moreover, it will also adds support for pointers inside of struct. The last change to the language will be that you will be able to declare array of pointers and array of structure. \nThe peephole optimizer will perform more powerful optimization. At least, I will add an optimization to remove assignments to registers that are not used and use less registers. That will perhaps imply to add support for basic blocks in the LTAC Language. \nI will also add a powerful dead-code optimization to the Optimization Engine. This will replace the RemoveAssign and RemoveMultipleAssign pass of the engine, being more powerful. \nAs ever, I'm open to any idea you could have about this project :)\nDownload\n\nYou can find the compiler sources on the Github repository:\u00a0https://github.com/wichtounet/eddic\nThe exact version I refer to is the v1.0.1 available in the GitHub tags or directly as the release branch.", 
      "tags": "C++,Compilers,EDDI,Optimization"
    }, 
    {
      "loc": "/posts/2012/06/the-site-now-running-wordpress-3-4.html", 
      "title": "The site is now running WordPress 3.4", 
      "text": "I just updated the site to run WordPress 3.4\nNormally, you should not see any differences as most of the new features of this version are in the admin side, but if you see something that doesn't work, don't hesitate to contact me.", 
      "tags": "Others,Releases,The site,WordPress"
    }, 
    {
      "loc": "/posts/2012/06/eddic-1-0-structures-global-optimizations.html", 
      "title": "EDDI Compiler 1.0 - Structures and Global Optimizations", 
      "text": "I've the pleasure to announce the availability of version 1.0 of the EDDI Compiler (eddic). \nThis release adds one big enhancement to the language: Structures\nStructures are used like in the C programming language: \nstruct Complex {\n    int imag;\n    int real;\n}\n\nvoid main(){\n    Complex c;\n    c.imag = 222;\n    c.real = 666;\n\n    println(c.imag);\n    println(c.real);\n\n    c.imag += 111;\n    c.real += 222;\n\n    println(c.imag);\n    println(c.real);\n\n    test(c);\n\n    if(c.b){\n        println(c.imag);\n    } else {\n        println(c.real);\n    }\n}\n\nvoid test(Complex a){\n    println(a.imag);\n    println(a.real);\n}\n\n\n\nFor now on, you can declare structures, use local variables of the struct type and pass them as parameter. But the usage of structure is still limited, there are no way to return a structure from a function and no way to pass a structure by reference. Another limitation is that a member of struct cannot be of a struct type. At least, the last limitation will be addressed in the next version of eddic. \nAnother main change is the use of a new low-level Intermediate Representation (LTAC). This change is describe more in details in this article. \nThe main other change is the use of a data-flow framework for global optimization in the optimization engine. An optimization is global if it takes into account all the basic blocks of the function being optimized. For that, it takes a Control-Flow graph of the function and follow the logical flow of the function to determine what can be optimized. Two old optimization have been transformed from local to global: Constant Propagation and Copy Propagation. They have also been merged for being more efficient, so they are done both in one pass of the flow. I also implemented a new technique: Common Subexpression Elimination. This optimization make sure that no computation is made when the result is still available. The control flow graph is handled with the Boost Graph Library. \nI also fixed a performance issue on the Optimization Engine. Before, the optimization were done for the whole program and if one optimization was successful, all the optimization techniques were tried again on the whole program. Now, there are made one function at a time and restarted only for this function. It should prove faster on problem with a lot of functions. \nIn the side of the assembly generation, I changed the way the floats constants are handled. Before, a general purpose register was used to load the constant and then load it in the SSE register. To avoid having to use a GP Register, I used a constant float pool and loaded the float directly from memory to the SSE Register. \nOn the compiler side, I added several new unit test and fixed the old tests. They were lots of bugs in the tests itself that made that they were not working at all. The test suite is now much more robust and showed me lots of other bugs. \nI removed the dependency to Boost Chrono by relying on the new std::chrono library. \nFuture work\n\nThe next version will be the 1.0.1 version. There will be several changes with this version. \nI will improve the support of structures. I will add the support for struct inside structs and perhaps passing struct by reference (which would also means adding supports for references for other types as well). \nI will also make more improvements to the optimization engine. I will add at least one new data-flow optimization and I will try to make the optimization pass faster. \nFinally, as ever, I will certainly make some refactorings on some parts of the Compiler, but it starts looking good. \nDownload\n\nYou can find the compiler sources on the Github repository:\u00a0https://github.com/wichtounet/eddic\nThe exact version I refer to is the v1.0 available in the GitHub tags or directly as the release branch.", 
      "tags": "C++,Compilers,EDDI,Optimization"
    }, 
    {
      "loc": "/posts/2012/05/advanced-compiler-design-and-implementation-book-review.html", 
      "title": "Advanced Compiler Design and Implementation - Book Review", 
      "text": "After having read my first book about compilers, I decided to try another one more focused on optimizations. For that, I chose \"Advanced Compiler Design and Implementation\", by Steven S. Muchnick.\nThis book covers several subjects about compilers, but more than 60% of the text is about compiler optimizations.\nThe first chapter introduces the main concepts of compiler design. It also explains why optimization is so important in a compiler.\nThe algorithms of this book are presented in ICAN (Informal Compiler Algorithm Notation) notation. The chapter two provides both a brief and a full description of this notation. In my case, the brief description has been enough to understand the algorithms presented in the following chapters, but it can be useful for a deep understanding of the notation to read the full description.\nThe next chapter covers Symbol Table. It also includes a way to generate load and store instructions directly based on the information contained in the Symbol Table. Then, the fourth chapter presents the intermediate representations used in that book. This book uses three different intermediate languages: A high-level one, a medium-level one and a low-level. This chapter covers each of them in details. The importance of the design of an intermediate representation is also discussed here. There will be two more intermediate forms used in the book, static single-assignment (SSA) and program dependence graphs that are discussed later in the book.\nThe chapter five gives some information about the different runtime support of some architectures. It is very useful to know how to handle high-level languages at runtime. The next one is about producing code generators automatically from machine descriptions. Three approaches are covered in this chapter.\nWith the seventh chapter, the optimization techniques start. This chapter covers control-flow analysis. It will introduce several techniques that can be used to perform this kind of analysis, namely depth first search and dominators, interval analysis and structural analysis. These analysis can be used to identify structures like loops and branches in the intermediate representations. The chapter eight covers data-flow analysis. This chapter introduces a lot of mathematical concepts like lattices or flow functions. It takes some time to understand completely the concepts of this chapter, but the explanations are very good. Again, three methods of doing this analysis are studied. It covers iterative data-flow analysis, control-tree techniques and slotwise analysis. Another techniques are also introduced, but not covered in details. The chapter 9 covers dependence analysis. This analysis will be vital for optimizations on arrays and loops and to instruction scheduling techniques that will be studied later. Finally, the chapter ten introduces alias-analysis techniques.\nOnce the analysis techniques have been covered, the other chapters are about optimization themselves. The chapter 11 introduces optimizations. It explains which optimizations should be performed at which level and in which order. It also describes briefly the optimizations that are covered in the next chapters. You will see that the following chapters are very rich, each of them containing a lot of optimizations that can be performed.\nThe first optimizations that are covered (in chapter 12) are the so-called early optimizations. It includes scalar replacement of aggregates, value numbering, copy propagation and sparse conditional constant propagation. It also covers constant folding and algebraic simplifications. After that, the optimizations that reduce redundancy are covered. Again, several techniques are covered, common subexpression elimination, forward substitution, loop invariant code motion, partial redundancy elimination and code hoisting. Then, the loop optimizations are introduced. This chapter first introduces a way to identify induction variables in a loop and then covers some optimization that can be used. For example, strength reduction and unnecessary bounds checking optimizations are covered.\nThe next two chapters are more related to low-level problematic. The chapter 15 covers optimizations that can be applied to reduce the cost of procedures. It discusses tail-call optimization, procedure integration, in-line expansion, leaf-routine optimization and shrink wrapping. The, the chapter 16 covers a very important subject that is Register Allocation. It covers several techniques like cost based methods and global graph coloring.\nThe chapter 17 deals with code scheduling. It is a technique that reorder instructions to take best advantage of the pipelines built into ,modern processors. First, local approaches (within a basic block) are discussed and then optimization for scheduling across basic-block boundaries are covered. For the two subjects, several techniques are discussed. The chapter 18 covers low-level optimizations like unreachable-code elimination, loop inversion, dead-code elimination, etc... This chapter is very broad and very interesting too.\nThe chapter 19 covers more complex optimization: the inteprocedural optimizations. Several techniques for doing inteprocedural analysis are covered in details as well as several optimizations depending on these analysis, like constant propagation. This chapter is not very simple to understand and even less to apply, but it is very interesting. The chapter 20 is the last about optimizations. It covers techniques to improve the memory hierarchy usage. The first optimizations are about instruction-cache: instruction prefetching, procedure sorting and procedure splitting for example. Then, data-cache optimizations are covered. It includes data prefetching and scalar replacement of array elements in details and gives an outline for some other optimizations.\nFinally, the chapter 21 studies four different compilers to see what optimizations are applied and in which order. Their intermediate forms are also studied. It is very interesting how this is done in real-world compiler.\nTo conclude, I think that this book is really great. It covers a lot of optimizations that can be implemented in a compiler. All the optimizations are covered in details with code samples and examples of applying the optimization on some code. However, it has to be said that this book is not easy to read and sometimes it is hard to understand exactly what means a specific optimization and in what it differs from some close technique. If you want to write an aggressive optimizer compiler or just write some optimizations for an existing one, you should consider to take a look at this book.\nIf you know another good book on Compilers, I will be glad to hear about it.", 
      "tags": "Books,Compilers,Optimization"
    }, 
    {
      "loc": "/posts/2012/05/compiler-architecture-refinements-eddic.html", 
      "title": "Compiler Architecture refinements for eddic", 
      "text": "The next version of eddic will see an\u00a0improved compiler architecture. There are two new main changes in this version:\n\n    A better separation between the front end and the back end\n    A new intermediate representation to improve and ease code generation\n\n\nFront end and Back End\n\nFirst, the front and back ends have been clearly separated. The general compiler architecture is currently something like that:\n\nThe first part didn't change, but the Compiler was part was clearly separated between front and back ends:\n\nThe backend has no information about the source language. It only sees the intermediate representation provided by the front-end, named: Medium-Level Three Address Code (MTAC).\nThere are several advantages to this model. The main one is that it is easy to add support for a new programming language to the compiler. Only the front end needs to be changed. The same can be achieved if a new output is necessary, for example output ARM assembly instead of Intel assembly.\nNew intermediate representation\n\nIn the previous versions of the compiler, the code generators were fairly complex. Indeed, they had to transform the MTAC intermediate representation directly into assembly. This process involves several things:\n\n    instruction selection\n    register allocation\n    low-level optimization (replace a \u00a0mov rax, 0 with xor rax, rax for example)\n    handle basic blocks management\n\n\nIn this version, I decided to change it to a better architecture. This architecture uses a new intermediate representation: Low-Level Three Address Code (LTAC). As its name states, it is a low-level representation, close to assembly. In this \u00a0representation there are addresses, registers and abstracted instructions. This representation is platform independent (the differences between 32 and 64 bits are moved to the code generators). There are no more basic blocks here, only functions containing statements.\nThe next figure presents the structure of the backend:\n\nThe compiler is responsible for transforming the MTAC Representation in LTAC Representation. It does not do any low-level optimization. The instruction selection is easier as it is platform independent. The peephole optimizer is responsible for the low-levels optimizations. In the 1.0 release, there would be only few things done at this level. In the future, I will try to invest some time to complete it to generate better assembly code. The optimizations are far simpler than the one done in the MTAC optimization engine. Indeed, a peephole optimizer is generally working only in a small window of instructions, like three or four instructions at a time. And finally, the code generators performs the instruction selection process and address resolving. It also has to translate symbolic registers into physical ones.\nConclusion\n\nI hope that these refinements in the compiler architecture will allow the compiler to produce better code.\nThe 1.0 version of the compiler will include another new features:\n\n    Basic support for custom structures\n    Global optimizations\n    Some bug fixes found with the new set of unit tests\n\n\nAs always, feel free to comment on the new architecture, the compiler itself, the project or whatever", 
      "tags": "Assembly,Compilers,EDDI,Intel,Linux"
    }, 
    {
      "loc": "/posts/2012/04/install-valgrind-on-gentoo-linux.html", 
      "title": "Install Valgrind on Gentoo Linux", 
      "text": "Valgrind is very powerful suite of software for dynamic analysis of binary programs. Valgrind is available in an ebuild on the Gentoo portage tree, but if you want to install valgrind on your Gentoo distribution, there is a problem with the build with the standard library. On Gentoo, the standard C library (glibc) is stripped and Valgrind needs the debug symbols to work. If you try to launch valgrind without the debug symbols, you will get the following error: \nvalgrind:  Fatal error at startup: a function redirection\nvalgrind:  which is mandatory for this platform-tool combination\nvalgrind:  cannot be set up.  Details of the redirection are:\nvalgrind:  \nvalgrind:  A must-be-redirected function\nvalgrind:  whose name matches the pattern:      strlen\nvalgrind:  in an object with soname matching:   ld-linux-x86-64.so.2\nvalgrind:  was not found whilst processing\nvalgrind:  symbols from the object with soname: ld-linux-x86-64.so.2\nvalgrind:  \nvalgrind:  Possible fixes: (1, short term): install glibc's debuginfo\nvalgrind:  package on this machine.  (2, longer term): ask the packagers\nvalgrind:  for your Linux distribution to please in future ship a non-\nvalgrind:  stripped ld.so (or whatever the dynamic linker .so is called)\nvalgrind:  that exports the above-named function using the standard\nvalgrind:  calling conventions for this platform.\nvalgrind:  \nvalgrind:  Cannot continue -- exiting now.  Sorry.\n\nSo first, you have to activate the debug symbols for the libraries in your /etc/make.conf:\nFEATURES=\"splitdebug\"\n\nThen, you can emerge again the glibc: \nsudo emerge glibc\n\nIf you already had emerged valgrind, there is no need to emerge it again, it should work now. \nAnd finally, you can emerge valgrind: \nsudo emerge valgrind\n\nAnd everything will work fine.", 
      "tags": "Gentoo,Linux,Tools"
    }, 
    {
      "loc": "/posts/2012/04/switching-gentoo-linux.html", 
      "title": "Switching to Gentoo Linux", 
      "text": "After having switched to Mint from Ubuntu, I'm on the verge of switching to Gentoo Linux.\nGentoo is a powerful operating system base on Linux. This operating system provides extreme configurability and performance. Gentoo is very lightweight on its own, by default, there is not even a window manager installed. A big advantage of this system is that you can customize your system to your exact needs. You can use it as a server, a desktop distribution or whatever you needs. You install only the program you needs. This advantage leads to an inconvenient: you will need an advanced knowledge on Linux to install your system. Indeed, you will have to configure your kernel, choose compilation flags, choose your packages carefully and know your hardware as well.\nGentoo is based on a very powerful software distribution system, Portage. Portage is used to install new packages, get the latest software for Gentoo or upgrade your system. Except for some proprietary software, all the packages are built from the sources. This allow to a deep customization of your software. The installation of some package can take a big amount of time to compile. Count at least several hours to install a system based on Gnome Shell for example.\nIf you plan to install a full installation of Gentoo, reserve some days for that. I've spent several days working on my installation before getting to something fully working.\nHere is my current configuration:\n\n    Gentoo operating system\n    Linux Kernel 3.3\n    Gnome Shell 3.2.1\n    Google Chrome 18\n    NVidia Drivers 295.33\n    ...\n\n\nAs I've stripped my kernel and my init scripts to the maximum, my boot time is much faster and my installation takes much less space than my Mint installation.\nI said that I'm on the verge of switching because I still have some applications that are not installed on my new Gentoo distribution. For example, I have no multimedia support for now, but I already spent most of my time on my new distribution.\nI will try to write some posts on Gentoo in the future.", 
      "tags": "Gentoo,Linux,Mint"
    }, 
    {
      "loc": "/posts/2012/04/c11-concurrency-tutorial-advanced-locking-and-condition-variables.html", 
      "title": "C++11 Concurrency Tutorial - Part 3: Advanced locking and condition variables", 
      "text": "In the previous article, we saw how to use mutexes to fix concurrency problems. In this post, we will continue to work on mutexes with more advanced techniques. We will also study another concurrency technique of the C++11 Concurrency Library: condition variables.\nRecursive locking\n\nLet's imagine that you have a simple class like this one:\nstruct Complex {\n    std::mutex mutex;\n    int i;\n\n    Complex() : i(0) {}\n\n    void mul(int x){\n        std::lock_guard&lt;std::mutex&gt; lock(mutex);\n        i *= x;\n    }\n\n    void div(int x){\n        std::lock_guard&lt;std::mutex&gt; lock(mutex);\n        i /= x;\n    }\n};\n\n\n\nAnd you want to add an operation doing both operations with no problems, so you add a new function:\nvoid both(int x, int y){\n    std::lock_guard&lt;std::mutex&gt; lock(mutex);\n    mul(x);\n    div(y);\n}\n\n\n\nNow, it's time to test this function:\nint main(){\n    Complex complex;\n    complex.both(32, 23);\n\n    return 0;\n}\n\n\n\nIf you launch this application, you'll see that the program will never terminates. The problem is very simple. In the both() function, the thread acquires the lock and then calls the mul() function. In this function, the threads tries to acquire the lock again, but the lock is already locked. This is a case of deadlock. By default, a thread cannot acquire the same mutex twice.\nThere is a simple solution to this problem: std::recursive_mutex. This mutex can be acquired several times by the same thread. Here is the correct version of the Complex struct:\nstruct Complex {\n    std::recursive_mutex mutex;\n    int i;\n\n    Complex() : i(0) {}\n\n    void mul(int x){\n        std::lock_guard&lt;std::recursive_mutex&gt; lock(mutex);\n        i *= x;\n    }\n\n    void div(int x){\n        std::lock_guard&lt;std::recursive_mutex&gt; lock(mutex);\n        i /= x;\n    }\n\n    void both(int x, int y){\n        std::lock_guard&lt;std::recursive_mutex&gt; lock(mutex);\n        mul(x);\n        div(y);\n    }\n};\n\n\n\nThis time, the application works correctly.\nTimed locking\n\nSometimes, you doesn't want a thread to wait ad infinitum for a mutex. For example, if your thread can do something else when waiting for the thread. For this purpose, the standard library has a solution: std::timed_mutex and std::recursive_timed_mutex (if you need the recursivity properties of the mutex). You have access to the same functions as a std::mutex: lock() and unlock(), but you have also two new functions: try_lock_for() and try_lock_until().\nThe first one is also the most useful. It allows you to set a timeout after when the function automatically returns even if the lock was not acquired. The function returns true if the lock has been acquired, false otherwise. Let's try it with a simple example:\nstd::timed_mutex mutex;\n\nvoid work(){\n    std::chrono::milliseconds timeout(100);\n\n    while(true){\n        if(mutex.try_lock_for(timeout)){\n            std::cout &lt;&lt; std::this_thread::get_id() &lt;&lt; \": do work with the mutex\" &lt;&lt; std::endl;\n\n            std::chrono::milliseconds sleepDuration(250);\n            std::this_thread::sleep_for(sleepDuration);\n\n            mutex.unlock();\n\n            std::this_thread::sleep_for(sleepDuration);\n        } else {\n            std::cout &lt;&lt; std::this_thread::get_id() &lt;&lt; \": do work without mutex\" &lt;&lt; std::endl;\n\n            std::chrono::milliseconds sleepDuration(100);\n            std::this_thread::sleep_for(sleepDuration);\n        }\n    }\n}\n\nint main(){\n    std::thread t1(work);\n    std::thread t2(work);\n\n    t1.join();\n    t2.join();\n\n    return 0;\n}\n\n\n\n(The example is completely useless in practice)\nThe first interesting thing in this example is the declaration of the duration with std::chrono::milliseconds. This is also a new feature of the C++11 standard. You have access to several time unit: nanoseconds, microseconds, milliseconds, seconds, minutes and hours. We use a variable of this kind to set the timeout of the try_lock_for function. We also use this to make a thread sleeps with std::this_thread::sleep_for(duration). The rest of the example has nothing exciting in it, just some prints to see the results visually. Note that the program never stops, you have to kill it.\nCall once\n\nSometimes you want a function to be called only once no matter the number of threads that are used. Imagine a function that has two parts. The first part has to be called only once and the second has to be executed every time the function gets called. We can use the std::call_once function to fix this problem very easily. Here is an example using this mechanism:\nstd::once_flag flag;\n\nvoid do_something(){\n    std::call_once(flag, [](){std::cout &lt;&lt; \"Called once\" &lt;&lt; std::endl;});\n\n    std::cout &lt;&lt; \"Called each time\" &lt;&lt; std::endl;\n}\n\nint main(){\n    std::thread t1(do_something);\n    std::thread t2(do_something);\n    std::thread t3(do_something);\n    std::thread t4(do_something);\n\n    t1.join();\n    t2.join();\n    t3.join();\n    t4.join();\n\n    return 0;\n}\n\n\n\nEach std::call_once is matched to a std::once_flag variable. Here I put a closure to be executed only once, but a function pointer or a std::function will make the trick.\nCondition variables\n\nA condition variable manages a list of threads waiting until another thread notify them. Each thread that wants to wait on the condition variable has to acquire a lock first. The lock is then released when the thread starts to wait on the condition and the lock is acquired again when the thread is awakened.\nA very good example is a concurrent Bounded Buffer. It\u2019s a cyclic buffer with a certain capacity with a start and an end. Here is our implementation of a Bounded Buffer using condition variables:\nstruct BoundedBuffer {\n    int* buffer;\n    int capacity;\n\n    int front;\n    int rear;\n    int count;\n\n    std::mutex lock;\n\n    std::condition_variable not_full;\n    std::condition_variable not_empty;\n\n    BoundedBuffer(int capacity) : capacity(capacity), front(0), rear(0), count(0) {\n        buffer = new int[capacity];\n    }\n\n    ~BoundedBuffer(){\n        delete[] buffer;\n    }\n\n    void deposit(int data){\n        std::unique_lock&lt;std::mutex&gt; l(lock);\n\n        not_full.wait(l, [this](){return count != capacity; });\n\n        buffer[rear] = data;\n        rear = (rear + 1) % capacity;\n        ++count;\n\n        not_empty.notify_one();\n    }\n\n    int fetch(){\n        std::unique_lock&lt;std::mutex&gt; l(lock);\n\n        not_empty.wait(l, [this](){return count != 0; });\n\n        int result = buffer[front];\n        front = (front + 1) % capacity;\n        --count;\n\n        not_full.notify_one();\n\n        return result;\n    }\n};\n\n\n\nThe mutexes are managed by a std::unique_lock. It is a wrapper to manage a lock. This is necessary to be used with the condition variables. To wake up a thread that is waiting on a condition variable, the notify_one() function is used. The wait function is a bit special. It takes as the first argument the unique lock and a the second one a predicate. The predicate must return false when the waiting must be continued (it is equivalent to while(!pred()){cv.wait(l);}). The rest of the example has nothing special.\nWe can use this structure to fix multiple consumers / multiple producers problem. This problem is very common in concurrent programming. Several threads (consumers) are waiting from data produced by another several threads (producers). Here is an example with several threads using the structure:\nvoid consumer(int id, BoundedBuffer&amp; buffer){\n    for(int i = 0; i &lt; 50; ++i){\n        int value = buffer.fetch();\n        std::cout &lt;&lt; \"Consumer \" &lt;&lt; id &lt;&lt; \" fetched \" &lt;&lt; value &lt;&lt; std::endl;\n        std::this_thread::sleep_for(std::chrono::milliseconds(250));\n    }\n}\n\nvoid producer(int id, BoundedBuffer&amp; buffer){\n    for(int i = 0; i &lt; 75; ++i){\n        buffer.deposit(i);\n        std::cout &lt;&lt; \"Produced \" &lt;&lt; id &lt;&lt; \" produced \" &lt;&lt; i &lt;&lt; std::endl;\n        std::this_thread::sleep_for(std::chrono::milliseconds(100));\n    }\n}\n\nint main(){\n    BoundedBuffer buffer(200);\n\n    std::thread c1(consumer, 0, std::ref(buffer));\n    std::thread c2(consumer, 1, std::ref(buffer));\n    std::thread c3(consumer, 2, std::ref(buffer));\n    std::thread p1(producer, 0, std::ref(buffer));\n    std::thread p2(producer, 1, std::ref(buffer));\n\n    c1.join();\n    c2.join();\n    c3.join();\n    p1.join();\n    p2.join();\n\n    return 0;\n}\n\n\n\nThree consumer threads and two producer threads are created and query the structure constantly. An interesting thing about this example is the use of std::ref to pass the buffer by reference, it is necessary to avoid a copy of the buffer.\nWrap-Up\n\nIn this article we saw several things. First, we saw how to use a recursive_mutex to allow a thread to acquire a thread more than once. Then, we saw how to acquire a mutex with a timeout. After that, a method to call a function only once has been studied. And finally, condition variables were used to solve the multiple consumers / multiple producers problem.\nThe source code for this article can be found on Github.\nNext\n\nIn the next post of this series, we will another technique of this new C++11 Concurrency Library, the Atomics.", 
      "tags": "C++,C++11 Concurrency Tutorial,Concurrency"
    }, 
    {
      "loc": "/posts/2012/04/linux-kernel-tip-do-not-disable-system-v-ipc-for-x-org-and-chrome.html", 
      "title": "Linux Kernel Tip : Do not disable System V IPC for X.Org and Chrome", 
      "text": "Yesterday I recompiled my Linux Kernel stripping it again and I found out that X.org was not working very anymore. Some windows were frozen and there was some troubles with the mouse. Another problem was that Google Chrome wouldn't display anything but blank pages. \nThe solution was easy: Do not disable the System V IPC option on the kernel.", 
      "tags": "Gentoo,Linux"
    }, 
    {
      "loc": "/posts/2012/03/enhanced-code-snippets-syntaxhighlighter-evolved.html", 
      "title": "Enhanced Code Snippets with SyntaxHighlighter Evolved", 
      "text": "After a long time of service, I decided to replace the old WP-Syntax plugin with a more modern one: SyntaxHighlighter Evolved. \nI thought that the style of the code snippets of WP-Syntax started looking a bit old. The new plugin has several advantages:\n\n    The code snippets look better\n    A useful toolbar is available on each snippet allowing you to copy the code, to print it or to view the source only\n    The configuration is more complete\n\n\nThis plugin use the SyntaxHighlighter JavaScript package by Alex Gorbatchev.\nHere is an example using this new plugin: \nExecutorService threadPool = Executors.newFixedThreadPool(4);\n\nCompletionService&lt;String&gt; pool = new ExecutorCompletionService&lt;String&gt;(threadPool);\n\nfor(int i = 0; i &lt; 10; i++){\n   pool.submit(new StringTask());\n}\n\nfor(int i = 0; i &lt; 10; i++){\n   String result = pool.take().get();\n\n   //Compute the result\n}\n\nthreadPool.shutdown();\n\n\n\nFor now, only two posts are using this new plugin:\n\n    C++11 Concurrency \u2013 Part 1 : Start Threads\n    C++11 Concurrency Tutorial \u2013 Part 2 : Protect shared data\n\n\nThe other ones are still using the old plugin. I will convert the other posts when I will find some time. \nI hope that this change will makes the site better for you.", 
      "tags": "The site,Web,WordPress"
    }, 
    {
      "loc": "/posts/2012/03/cp11-concurrency-tutorial-part-2-protect-shared-data.html", 
      "title": "C++11 Concurrency Tutorial - Part 2 : Protect shared data", 
      "text": "In the previous article, we saw how to start threads to execute some code in parallel. All the code executed in the threads were independant. In the general case, you often use shared objects between the threads. And when you do it, you will face another problem: synchronization. \nWe will see what is this problem in a simple code. \nSynchronization issues\n\nAs an example, we will take a simple Counter structure. This structure has a value and methods to increment or decrement the value. Here is the structure:\nstruct Counter {\n    int value;\n\n    void increment(){\n        ++value;\n    }\n};\n\n\n\nThere is nothing new here. Now, let's start some threads and make some increments: \nint main(){\n    Counter counter;\n\n    std::vector<std::thread> threads;\n    for(int i = 0; i < 5; ++i){\n        threads.push_back(std::thread([&amp;counter](){\n            for(int i = 0; i < 100; ++i){\n                counter.increment();\n            }\n        }));\n    }\n\n    for(auto&amp; thread : threads){\n        thread.join();\n    }\n\n    std::cout << counter.value << std::endl;\n\n    return 0;\n}\n\n\n\nAgain, nothing new there. We launch 5 threads and each one increment the counter hundred times. After all thread have finished their work, we print the value of the counter. \nIf we launch this program, we should expect that it will print 500. But this is not the case. No one can say what this program will print. Here are some results I obtained on my computer: \n442\n500\n477\n400\n422\n487\n\nThe problem is that the incrementation is not an atomic operation. As a matter of fact, an incrementation is made of three operations: \n\n    Read the current value of value\n    Add one to the current value\n    Write that new value to value\n\n\nWhen you run that code using a single thread, there are no problems. It will execute each part of the  operation one after another. But when you have several threads, you can start having troubles. Imagine this situation:\n\n    Thread 1 : read the value, get 0, add 1, so value = 1\n    Thread 2 : read the value, get 0, add 1, so value = 1\n    Thread 1 : write 1 to the field value and return 1\n    Thread 2 : write 1 to the field value and return 1\n\n\nThese situations come from what we call interleaving. Interleaving describe the possible situations of several threads executing some statements. Even for three operations and two threads, there is a lot of possible interleavings. When you have more threads and more operations, it is almost impossible to enumerate the possibles interleavings. The problem can also occurs when a thread gets preempted between instructions of the operation. \nThere are several solutions to fix this problem: \n\n    Semaphores\n    Atomic references\n    Monitors\n    Condition codes\n    Compare and swap\n    etc.\n\n\nIn this blog post we will learn how to use semaphores to fix this problem. As a matter of fact, we will a special kind of semaphores called mutexes. A mutex is a very object. Only one thread can obtain the lock on a mutex at the same time. This simple (and powerful) property of a mutex allow us to use it to fix synchronization problems. \nUse a mutex to make our Counter thread-safe\n\nIn the C++11 threading library, the mutexes are in the mutex header and the class representing a mutex is the std::mutex class. There are two important methods on a mutex: lock() and unlock(). As their names indicate, the first one enable a thread to obtain the lock and the second releases the lock. The lock() method is blocking. The thread will only return from the lock() method when the lock has been obtained. \nTo make our Counter struct thread-safe, we have to add a set::mutex member to it and then to lock()/unlock() the mutex in every function of the object: \nstruct Counter {\n    std::mutex mutex;\n    int value;\n\n    Counter() : value(0) {}\n\n    void increment(){\n        mutex.lock();\n        ++value;\n        mutex.unlock();\n    }\n};\n\n\n\nIf we test now this implementation with the same code as before for starting the threads, the program will always displays 500. \nExceptions and locks\n\nNow, let's see what happens in another case. Imagine that the Counter has a decrement operation that throws an exception if the value is 0: \nstruct Counter {\n    int value;\n\n    Counter() : value(0) {}\n\n    void increment(){\n        ++value;\n    }\n\n    void decrement(){\n        if(value == 0){\n            throw \"Value cannot be less than 0\";\n        }\n\n        --value;\n    }\n};\n\n\n\nYou want to access this structure concurrently without modifying the class. So you create a wrapper with locks for this class: \nstruct ConcurrentCounter {\n    std::mutex mutex;\n    Counter counter;\n\n    void increment(){\n        mutex.lock();\n        counter.increment();\n        mutex.unlock();\n    }\n\n    void decrement(){\n        mutex.lock();\n        counter.decrement();        \n        mutex.unlock();\n    }\n};\n\n\n\nThis wrapper works well in most of the cases, but when an exception occurs in the decrement method, you have a big problem. Indeed, if an exception occurs, the unlock() function is not called and so the lock is not released. As a consequence, you program is completely blocked. To fix this problem, you have to use a try/catch structure to unlock the lock before throwing again the exception:\nvoid decrement(){\n    mutex.lock();\n    try {\n        counter.decrement();\n    } catch (std::string e){\n        mutex.unlock();\n        throw e;\n    } \n    mutex.unlock();\n}\n\n\n\nThe code is not difficult but starts looking ugly. Now imagine you are in a function with 10 different exit points. You will have to call unlock() from each of these points and the probability that you will forget one is big. Even bigger is the risk that you won't add a call to unlock when you add a new exit point to a function. \nThe next section gives a very nice solution to this problem.\nAutomatic management of locks\n\nWhen you want to protect a whole block of code (a function in our case, but can be inside a loop or another control structure), it exists a good solution to avoid forgetting to release the lock: std::lock_guard. \nThis class is a simple smart manager for a lock. When the std::lock_guard is created, it automatically calls lock() on the mutex. When the guard gets destructed, it also releases the lock. You can use it like this: \nstruct ConcurrentSafeCounter {\n    std::mutex mutex;\n    Counter counter;\n\n    void increment(){\n        std::lock_guard<std::mutex> guard(mutex);\n        counter.increment();\n    }\n\n    void decrement(){\n        std::lock_guard<std::mutex> guard(mutex);\n        counter.decrement();\n    }\n};\n\n\n\nMuch nicer, isn't it :)\nWith that solution, you do not have to handle all the cases of exit of the function, they are all handled by the destructor of the std::lock_guard instance. \nConclusion\n\nWe are now done with semaphores. In this article, you learned how to protect shared data using mutexes from the C++ Threads Library. \nKeep in mind that locks are slow. Indeed, when you use locks you make sections of the code sequential. If you want an highly parallel application, there are other solutions than locks that are performing much better but this is out of the scope of this article. \nNext\n\nIn the next blog post of this serie, I will talk about advanced concepts for mutexes and how to use condition variables to fix little concurrent programming problem. \nThe source code for each sample is available on Github.", 
      "tags": "C++,C++11 Concurrency Tutorial,Concurrency,Performances"
    }, 
    {
      "loc": "/posts/2012/03/eddic-0-9-1-enhanced-floating-point-support.html", 
      "title": "EDDIC 0.9.1 - Enhanced floating point support", 
      "text": "I just released the version 0.9.1 of the EDDI Compiler (eddic).\nThis release is a minor one, there are no huge changes to the language nor in the compiler itself. But that version was necessary before the 1.0 version. \nThe floating point support of the language have been enhanced with casts. You can now cast float values to int and vice-versa. The syntax is the same as in C:\nvoid main(){\n   float a = 1.5;\n   float b = a + (float) 100;\n   println((int)b);\n}\n\n\n\nAnother improvement is the support for integer suffixes for float: \nvoid main(){\n   float a = 100f;\n}\n\n\n\nFinally, the optimizer has been adapted to support float as well. The optimization techniques are the same as the one for integers. \nLast but not least, the compiler can now pass some parameters in registers. In 32 bits platform, the first integer parameter is passed in a register and on 64 bits platform, the first two parameters are passed in registers. In both architectures, the first float parameter is passed in a SSE register. \nFuture work\n\nThe next version will be the 1.0 version. There will be several major changes with this new version. \nFirst, the optimization engine will be almost entirely rewritten. Global optimization will be added to the engine. \nThere will also be some improvements in the intermediate representation. I will probably a second level of intermediate representation: a low-level Three Address Code representation. This new intermediate representation will be generated by an IntelCompiler to handle stuff common to both 32 and 64bits code generator. This will also includes a pass for global register allocation. \nAs these changes will not be simple to implement, this version can takes some time before being released. \nDownload\n\nYou can find the compiler sources on the Github repository:\u00a0https://github.com/wichtounet/eddic\nThe exact version I refer to is the v0.9.1 available in the GitHub tags or directly as the release branch.", 
      "tags": "Assembly,C++,Compilers,EDDI,Intel"
    }, 
    {
      "loc": "/posts/2012/03/cpp11-concurrency-part1-start-threads.html", 
      "title": "C++11 Concurrency - Part 1 : Start Threads", 
      "text": "C++11 introduced a new thread library. This library includes utilities for starting and managing threads. It also contains utilities for synchronization like mutexes and other locks, atomic variables and other utilities. In this serie of posts, I will try to explain most of the features provided by this new library.\nTo compile the samples of this article, you will need a compiler with C++11 support. In my case, I used GCC 4.6.1 (you need to pass the \"-std=c++0x\" or \"-std=c++11\" option to get the C++11 support activated).\nStarting threads\n\nStarting a new thread is very easy. When you create an instance of a std::thread, it will automatically be started. When you create a thread you have to give it the code it will execute. The first choice for that, is to pass it a function pointer. Let's start with the very common Hello World:\n#include <thread>\n#include <iostream>\n\nvoid hello(){\n    std::cout << \"Hello from thread \" << std::endl;\n}\n\nint main(){\n    std::thread t1(hello);\n    t1.join();\n\n    return 0;\n}\n\n\n\nAll the threads utilities are located in the thread header. An interesting thing in this first example is the call to the join() function. Calling this function forces the current thread to wait for the other one (in this case, the main thread has to wait for the thread t1 to finish). If you omit this call, the result is undefined. The program can print Hello from thread and a new line, can print just Hello from thread without new line or can print nothing. That's because the main thread can return from the main function before the t1 thread finishes its execution.\nDistinguishing threads\n\nEach thread has a single id allowing us to distinguish each of them. The std::thread class has a get_id() function returning an unique id for this thread. You can get a reference to the current thread with the std::this_thread variable. The next example starts with threads and each of them prints its id:\n#include <thread>\n#include <iostream>\n#include <vector>\n\nvoid hello(){\n    std::cout << \"Hello from thread \" << std::this_thread::get_id() << std::endl;\n}\n\nint main(){\n    std::vector<std::thread> threads;\n\n    for(int i = 0; i < 5; ++i){\n        threads.push_back(std::thread(hello));\n    }\n\n    for(auto& thread : threads){\n        thread.join();\n    }\n\n    return 0;\n}\n\n\n\nStarting each thread one after one and then storing them into a vector is a common way to handle several threads. With that, you can easily change the number of threads. Even with a very little sample like this one, the results is not predictable. The theoretic case:\nHello from thread 140276650997504\nHello from thread 140276667782912\nHello from thread 140276659390208\nHello from thread 140276642604800\nHello from thread 140276676175616\n\nIs, in my case, also the less common. You can also get results like this one:\nHello from thread Hello from thread Hello from thread 139810974787328Hello from thread 139810983180032Hello from thread\n139810966394624\n139810991572736\n139810958001920\n\nOr a lot of another results. This is because of interleaving. You have no way to control the order of execution of threads. A thread can be preempted at any moment and the appends to the out stream are made one after one (first the append of the string, then append the id and finally the new line), so a thread can print its first part and then be interrupted to print its second part after all the others threads.\nStart a thread with a lambda\n\nWhen the code that has to be executed by each thread is very small, you don't necessary want to create a function for that. In that case, you can use a lambda to define the executed by a thread. We can rewrite the code of the last sample using lambda easily:\n#include <thread>\n#include <iostream>\n#include <vector>\n\nint main(){\n    std::vector<std::thread> threads;\n\n    for(int i = 0; i < 5; ++i){\n        threads.push_back(std::thread([](){\n            std::cout << \"Hello from thread \" << std::this_thread::get_id() << std::endl;\n        }));\n    }\n\n    for(auto& thread : threads){\n        thread.join();\n    }\n\n    return 0;\n}\n\n\n\nHere we just used a lambda expression instead of the function pointer. Of course, this produces the exact same result as the previous sample.\nNext\n\nIn the next post of this series, we will see how to protect code using locks.\nThe source code for each sample is available on Github.", 
      "tags": "C++,C++11 Concurrency Tutorial,Concurrency"
    }, 
    {
      "loc": "/posts/2012/03/introduction-64-bit-intel-assembly-language-programming-linux-book-review.html", 
      "title": "Introduction to 64 Bit Intel Assembly Language Programming for Linux - Book Review", 
      "text": "The first book I read about Intel Assembly was lacking information about 64 bits programming. So I ordered and read Introduction to 64 Bit Intel Assembly Language Programming for Linux, by Ray Seyfarth. \nThis book covers a lot of subjects in assembly. It is adapted to people starting assembly, but it also contains advanced assembly programming techniques. I think that this book is adapted to a lot of people wanting to improve their skills in Intel Assembly. This book covers only 64 bit Intel Assembly in details. It does not cover old memory models, only the memory mode used now. \nThis book uses yasm to assemble the programs. It uses gdb to debug the assembly programs. \nThe first chapters are very general. They are covering numbers (octal, decimal and hexadecimal notions), computer memory and memory mapping mode. \nThe first technical chapter covers Registers in details. It defines all the registers available in Intel Assembly. You will see how to move constants to registers. You will also learn how to move values between memory and registers. Then, the next chapter covers all the mathematical operations (negate, addition, subtraction, division and multiplication). It also covers the use of conditional move instructions. The next one is about bit manipulations (not, and, or and shift). It also covers bit testing and filling. \nAfter that, the chapter eight covers a very important subject: branching and looping. All the jumps are covered in details. You will see how to convert each control structure (if, for, while, do-while) of programming language to assembly. After that, the string instructions are also explained. Once you know how to create control structures, it's time to create your own functions. In that chapter, you will learn the stack and the function call conventions. The stack frames and the recursion are also covered. \nThe arrays are covered in the next chapter. You will see how to allocate arrays on the stack or on the heap using malloc. The command line parameters are also covered (that was a very interesting part). \nThen, floating point math is covered. For that, the Streaming SIMD Extensions (SSE) are used. All the math operations are covered. As is the way to transfer data between XMM registers and memory. The conversion and comparison instructions are also explained here. Some complete samples like dot product of 3D vectors help us understand the SSE instructions. \nThe system calls are covered in details in chapter twelve. The C system library wrapper functions for system calls are also covered. After that, a whole chapter addresses structures. The allocation of structs is also addressed. Then, the way to use I/O streams from assembly is taught. \nA whole chapter is devoted to the implementation of data structures in Intel Assembly. The covered data structures are the linked lists, doubly linked lists, the hash tables and the binary trees. Each common operation on these data structures is implemented. \nAfter that, the last chapters are about optimization and performances. The chapter 16 covers High Performance Assembly Programming in details. In that chapter, you will learn a set of optimization that can be applied to improve the performances of a given code. For example, you will see how to make efficient use of cache or how to make better performing loops. These optimization can also be applied to other programming languages. The following chapters are all covering a single problem and a way to optimize it the most using Intel Assembly. For each of these problems, the C version is compared to the assembly version. Three problems are presented: counting bits in an array of integers, the Sobel filter and computing the correlation of two variables given some sample values. \nTo conclude, I found this book very book. It covers a lot of subjects in a very good manner. I liked a lot the performance techniques covered in the book. The deep coverage of SSE instructions was also very interesting.", 
      "tags": "Assembly,Books,Intel"
    }, 
    {
      "loc": "/posts/2012/03/a-new-theme-for-the-site.html", 
      "title": "A new theme for the site", 
      "text": "I changed the theme on the site. I used the Sleek theme from Studiopress. \nThe main reason to change to this theme was that I replaced some of my addons. For example, the breadcrumbs are already included in the theme. There is also an included widgets for Twitter. \nAnother reason is that I find this theme more good looking than the hold one. And finally, this new theme is more up-to-date.\nI hope that you will find this theme adapted. \nI've still some work to do adapting this theme for the site. If you encounter any kind of problems with the new design, don't hesitate to let a comment or to contact me.", 
      "tags": "The site,Web,WordPress"
    }, 
    {
      "loc": "/posts/2012/03/eddic-0-9-floating-point-support.html", 
      "title": "EDDIC 0.9 - Floating point support", 
      "text": "I just finished working on the 0.9 version of the EDDIC Compiler.\nThe language does now support floating point variables. Here is an example of what can be done in EDDI now:\nvoid main(){\n   float a = 1.5;\n   float b = 3.0;\n   float c = a + b;\n   println(c);\n   c = b + 2.75;\n   println(c);\n\n   println(test(2.0888, 1.00222));\n\n   float array[7];\n\u00a0 \u00a0array[0] = 21.999;\n}\n\n\n\nFor now, there is no interoperability between integers and floating, so you can't add an integer to a floating point or cast a floating point to an integer. Those features will be added in the 0.9.1 version. The floating point support has been implemented using the Streaming SIMD Extension\u00a0(SSE) of Intel processors. This won't work on processor that doesn't include support for SSE.\nAnother big improvement is that the position of the tokens in the source file are now collected through the parser. When an error or a warning arises during the compilation, the precise position of the error or the warning is printed to the console.\nNew options are available for eddic:\n\n    --ast : Print the Abstract Syntax Tree representation of the source\n    --tac : Print the Three Address Code representation of the source\n    --ast-only : Only print the Abstract Syntax Tree representation of the source (do not continue compilation after printing)\n    --tac-only : Only print the Three Address Code representation of the source (do not continue compilation after printing)\n\n\nAnd, finally, some improvements have been made to the sources of the project.\nDownload\n\nYou can find the compiler sources on the Github repository:\u00a0https://github.com/wichtounet/eddic\nThe exact version I refer to is the v0.9 available in the github tags or directly as the release branch.", 
      "tags": "Assembly,Compilers,EDDI,Intel"
    }, 
    {
      "loc": "/posts/2012/02/cojac-a-numerical-problem-sniffer.html", 
      "title": "COJAC, A Numerical Problem Sniffer", 
      "text": "During my bachelor at the HES-SO University of applied sciences in Fribourg, I worked on a Java project, COJAC.\nCOJAC is a tool performing On-the-fly code instrumentation to help uncover numerical problems with integer (overflows) and floating point (smearing, cancellation, infinity, NaN) arithmetic.\nYesterday, Dr Dobbs published an article by one of my professor Fr\u00e9d\u00e9ric Bapst and myself.\nThis article discusses the question of numerical problems in programming, and focuses on the approach of using on-the-fly code instrumentation to uncover them at runtime. Two realizations are presented: a complete and stable solution for Java applications, and a proof-of-concept Valgrind add-on for Linux executables. Both tools require no intervention on the source code and no recompilation, and should be helpful as a diagnostic tool for developers, as well as for education purposes for undergraduate programmers.\nIf you are interested by this project, I invite you to read the article on Dr Dobbs : Project of the Month: Cojac, A Numerical Problem Sniffer\nYou can also test the tool or browse the source code by downloading it on the COJAC website.", 
      "tags": "Compilers,Java,Performances"
    }, 
    {
      "loc": "/posts/2012/02/eddic-0-8-1-do-while-loop-and-better-optimization.html", 
      "title": "EDDIC 0.8.1 : do while loop and better optimization", 
      "text": "Only three days after the 0.8 version, I finished the 0.8.1 version.\nIt's a minor version, so there is no big changes to the language. However, I added support for the do while loop in the source code.\nAnother change is that assignment is now returning a value. That allows you to make some code like this one:\nint a = b = 5;\nb = (a = 4) + 1;\n\n\n\nThis new version includes also some new changes for the optimization engine. I implemented constant propagation and copy propagation for offset assignment. For example:\na(8) = 4;\nb = a(8);\n\n\n\nbecomes:\na(8) = 4;\nb = 4;\n\n\n\nAnd the last change is that the concatenations that are detected to be constant after some optimization are made at compile-time by the optimization engine. This simplify a lot the generated code for source file with a lot of concatenations.\nThe next version (the 0.9) will introduce floating point operations and parameter passing with registers (probably only in 64 bit). It's also possible that I will try to implement a first version of global optimization.\nDownload\n\nYou can find the compiler sources on the Github repository:\u00a0https://github.com/wichtounet/eddic\nThe exact version I refer to is the v0.8.1 available in the github tags or directly as the release branch.", 
      "tags": "EDDI,Optimization"
    }, 
    {
      "loc": "/posts/2012/02/assembly-language-step-by-step-book-review.html", 
      "title": "Assembly Language Step By Step, Programming with Linux - Book Review", 
      "text": "To improve my skills in Intel Assembly, I ordered and read Assembly Language Step by Step, Programming with Linux, by Jeff Duntemann. Just for the record, I read it on my Amazon Kindle. \nThis book is really made for very beginners. The author uses a lot of metaphor to explain some concepts, comparing assembly to a game he explains in several pages... I didn't liked the writing style of this book. In my opinion, the author uses way too much metaphor and some things takes too many pages to be explained. Another problem of this book is the examples, there are covering tens of pages each. It is a good thing to have complete examples in a book, but having examples of more than 100 lines of code (not counting the comments) in a book is not really convenient (again, only in my opinion). \nAnother lack of this book is that it covers only 32 bit programming. For a book written in 2009, it is quite limited. And finally, I found it bad to not cover floating point. I think that this is an important subject. \nEven if I'm not a fan of this book, most of the content is still interesting and you can learn the basis of assembler with it if you're patient with the writing style, the metaphors and the long examples. \nIf you are a real beginner in assembly and in programming in general, this book can still be valuable for you. \nThe first chapters are covering computer programming, processors, arithmetic in different bases and memory locations. Then, the following chapters are covering the tools (assembler, linker and visual tools for editing and debugging). After that, we are jumping in the heart of the subject by learning arithmetic computations, system calls and stack control. The bits instructions are covered in details in a whole chapter. Then, you will be introduced to the writing of functions and how to use string instructions to simplify your programs. The last (and very big) chapter is about using the functions of the C library to performs work like I/O operations, time calculations, print formatted text and generate random numbers. For this last I would have preferred to learn how to do all that operations using only assembly, but it is important to know how to call C functions. \nTo conclude, I will advice this book only to people who learn assembly as their first programming language. For the others, there is a high risk of be deceived. \nNote that, if you want to follow the examples of this book, you'll certainly need the Insight Debugger. You can install this debugger by following the procedure described here.", 
      "tags": "Assembly,Intel,Linux"
    }, 
    {
      "loc": "/posts/2012/02/eddic-0-8-64bit-generation.html", 
      "title": "EDDIC 0.8 : 64bit generation", 
      "text": "I just released the version 0.8.\nThe main change of this version is the addition of a 64bit generation. If you compiles eddic in 64bit, the default output of the compiler will be 64 bit, otherwise it will be 32 bit. You can also select the output by setting command line switch (-32 and -64).\nThe biggest change at the side of the language is the support of command line arguments. If the main function is declared as main(string[] args), the args passed from the command line will be accessible.\nI've also added two operators to the language : size() and length(). These operators allows the programmer to get the size of an array, respectively the length of a string. If the information is present at compile-time, the operator is replaced by the constant otherwise it is equivalent to a single memory access.\nI've also made some improvements to the generated x86 code. For example, I'm using string instructions to simplify the generated code and lea and shl to perform fast multiplications. I also changed the syntax used in the generated assembly replacing AT&T syntax by the Intel syntax.\nI've added a new optimization technique, copy propagation. This technique keeps track of the assignment of variables to a variables to simplify the generated three-address-code.\nDownload\n\nYou can find the compiler sources on the Github repository :\u00a0https://github.com/wichtounet/eddic\nThe exact version I refer to is the v0.8 available in the github tags or directly as the release branch.", 
      "tags": "Assembly,EDDI,Intel"
    }, 
    {
      "loc": "/posts/2012/02/local-optimization-on-three-address-code.html", 
      "title": "Local optimization of Three-Address-Code", 
      "text": "Some compilers are using Three-Address-Code (TAC) as an intermediate representation. This representation is very simple to understand and write. Moreover, it's easy to run some optimization on this representation.\nEach TAC statement has this general form : result = operand1 operator operand2\nFor example, here are some TAC statements:\na = 1\nx = a * 3\nif x > a goto test\nparam \"dddd\"\ncall print\ntest:\nparam \"asdf\"\ncall print\n\n\n\nIn this post, we will see some of the local optimizations that can be applied on TAC. A local optimization is an optimization that is applied locally to a basic block. A basic block is a set of TAC statements that has only one entry point and one exit point. Once the first instruction of the basic block is executed, the rest of the instructions are necessarily executed exactly once. These optimizations are easy to design and implement. If you want to run global optimizations (through all the basic blocks of a function) or even Interprocedural Optimization (IPO), you will need a far more complex framework to run optimizations. I will try to write something on global optimization when I will have implemented some of them in EDDI.\nThe goal of optimization is of course to replace some statements with more efficient statements. \n\n\nThe list presented in this post is not exhaustive, this is only the optimizations that I've implemented in EDDIC, but this represent most of the local optimizations.\nThe first three optimization techniques can be applied independently on each statement of the program. \n1. Arithmetic Identities\n\nThe first optimization is about arithmetic identities. There are some properties in math that we can use to simplify simple TAC statement.\nHere are all the identities that are simplified in EDDIC:\n\n    x = a + 0 or x = 0 + a => x = a\n    x = a - 0 => x = a\n    x = 0 - a => x = -a\n    x = a - a => x = 0\n    x = a * 1 or x = 1 * a => x = a\n    x = a * 0 or x = 0 * a => x = 0\n    x = a * -1 or x = -1 * a => x = -a\n    x = a / 1 => x = a\n    x = a / -1 => x = -a\n    x = 0 / a => x = 0\n    x = a / a => x = 1\n\n\nAll the expressions on the right are more efficient to compute than the one on the left. \n2. Reduce in strength\n\nAnother easy optimization is the reduction of strength of some math operations. For example, an addition is cheaper than multiplication and multiplication is cheaper than division. If your language does not have floating point math, the only reduction that can be done is this one: \nHere are all the identities that are simplified in EDDIC:\n\n    x = 2 * a or x = a * 2 => x = a + a\n\n\nWith floating point math, we can do a little better: \n\n    x = a / 2 => x = a * 0.5\n    x = a / 4 => x = a * 0.25\n    etc...\n\n\n3. Constant folding\n\nWhen both operands on the right side of the TAC statement are integers, we can replace the math operation directly by the result of the computation. \nWith a and b being any integer, we can transform these TAC statements: \n\n    x = 1 + 2 => x = 3\n    x = 3 - 1 => x = 2\n    x = 3 * 2 => x = 6\n    x = 5 / 2 => x = 2\n    x = 5 % 2 => x = 1\n\n\nWe can also use this optimization to simplify conditional jumps. For example, if 3 > 2 goto B2 can be replaced by goto B2. \nMore than being way more efficient statements, it also enables other optimization to be performed on the TAC program. \nThe next two optimizations cannot be made on each statement independently. They have to be made on each basic blocks. They are replacing some variables by other variables or values.  \n4. Constant propagation\n\nThis optimization consists in replacing a variable by its constant value at each place we know it's constant. For example, this basic block: \na = 2\nb = c * a \na = 5\na = a + b\nc = a + 2\n\n\n\ncan be optimized into:\na = 2\nb = c * 2\na = 5\na = 5 + b\nc = a + 2\n\n\n\nTwo use of a variable have been replaced by its value. In this case, we cannot replace the last use of a because we do not know its value there. \nThis optimization can be made using a simple algorithm on each statement of a basic block: \n\n    If the statement is of the form x = constant, c[x] = constant\n    If the statement is of the form x = a + b, c[x] = null\n    For each variable appearing in an operand of a statement, if c[x] is not null, replace the variable by c[x]\n\n\n5. Copy propagation\n\nCopy propagation is almost the same as constant propagation. We replace a variable by the variable it refers to. For example, we can optimize: \nb = a\nc = b + 2\n\n\n\ninto:\nb = a\nc = a + 2\n\n\n\nThe algorithm is the same as the one for constant propagation but we keep track of the variables that are assigned to a variable. \nThese two optimizations does not create a more efficient code, but the optimized code can be optimized again. \n6. Remove assign\n\nWe can often find some assigns that are useless in a basic blocks. There are three types of assigns that can be removed: \n\n    x = x is never useful\n    An assignment to a temporary variable that is not used after this assignment is not useful. A temporary is a variable created by the compiler to perform some complex expressions. They are not stored and are used only within one basic block, so its value is not useful after the basic block. \n    An assignment to x following another assignment to x, with no use of x between the two assignments, is not useful. \n\n\n7. Remove temporaries\n\nWhen compiling some expression, we often generate this kind of code: \nt1 = a + b\nx = t1\n\n\n\nWe can simplify this code into: \nx = a + b\n\n\n\nFor that optimization, we can apply a more complex propagation. For each assignment to a temporary, we store the right side of the assignment. Then, for each assignment of a temporary to another variable (x = t1) if this use of the temporary is the only one, we replace the right side by the right side of the assignment to the temporary. \n8. Remove needless jumps\n\nWe can also find some jumps from basic blocks to basic that are not useful. A jump (conditional or not) to the next basic blocks is not useful. If we have two basic blocks: \nB1:\na = 2\ngoto B2\nB2: \nb = a\n\n\n\nwe can optimize into: \nB1:\na = 2\nB2: \nb = a\n\n\n\nFor that optimization, we have to test each jump for the distance of the target block. If the distance is only one, we can remove the jump. This works also for conditional jumps. A conditional has two exit points. If the condition is true, we jump to the specified block, otherwise we jump to the next block. If the target block is the next one, the effect is the same has a non-conditional jump and then can be removed. \nThe last two optimizations are not really local, but are simple versions of global optimizations. There are not as powerful as they are not following a data-flow, but they can be greatly improve the efficiency of some function, even if they don't have the power of the equivalent global optimization.  \n9. Remove dead basic blocks\n\nSometimes after having simplified some conditional jumps into simple jumps or even removed some of them, some basic blocks are not reachable. For example, this set of basic block:\nB1:\na = 2\ngoto B3\nB2: \nb = a\nB3:\nb = 33\n\n\n\ncan be optimized into:\nB1:\na = 2\ngoto B3\nB3:\nb = 33\n\n\n\nThere are no general algorithm for applying that. It depends on the instruction set that you TAC language has. \n10. Merge basic blocks\n\nFinally, another optimization, not really local again, is to merge some basic blocks. After the basic blocks have been optimized, we often have some blocks that are redundant. For example: \nB1:\na = 2\nB2: \nb = a\n\n\n\ncan be optimized into:\nB1:\na = 2\nb = a\n\n\n\nOf course, the second basic block that is merged with the first one must not be referred by a jump. \nOptimization passes\n\nWhen you have ten optimization techniques, you will have to find a way to make them interact correctly. As you certainly saw on the examples, some of the optimized sample can be optimized again with another optimization. \nThere are no general algorithm to make all optimization techniques work together in an optimal way. I chose a simple technique in EDDI. All the techniques are run on the complete code one after another. Then, if one or more techniques have had an effect on the program, we run again all the optimization techniques. So the optimizations run until there are no more changes to the program. \nConclusion\n\nBy using all the techniques described in this post, you will be able to have an efficient code. It won't be as good as with local optimization coupled to global optimization, but it's a good start for a simple compiler. \nI hope I will have the time to implement some global optimization techniques into eddic and then write about it on this blog.", 
      "tags": "Compilers,EDDI,Optimization"
    }, 
    {
      "loc": "/posts/2012/02/eddic-0-7-1-boolean-operators.html", 
      "title": "EDDIC 0.7.1 : Boolean conditions and new operators", 
      "text": "I just finished working on the 0.7.1 version of eddic.\nEven it it's a minor version, there are several new features in the language itself.\nFirst of all, the boolean conditions have been greatly improved. You can now use && (short circuit and operator) and || (short circuit or operator) operators to make complex conditions for if and while structure. Moreover, you can now declare variables of bool type. You can also print bool variables. That will simplify the code that can be written with EDDI.\nAnother big improvement to the language is the addition of increment and decrement operators. Both postfix and prefix forms are available. You can use an increment or decrement as a single statement or inside another expressions.\nIncrement and decrement operators are not the only operators added to the language. You can now use compound operators (+=, -=, *=, /= and %=) to make direct modifications to variables.\nIn the next version, there will certainly be some improvements of the generated assembly. I don't know what improvement will be done on the language. \nIf some of you have an idea of improvement for the language or the compiler itself, don't hesitate to make me know :)\nDownload\n\nYou can find the compiler sources on the Github repository : https://github.com/wichtounet/eddic\nThe exact version I refer to is the v0.7.1 available in the github tags or directly as the release branch.", 
      "tags": "C++11,Compilers,EDDI"
    }, 
    {
      "loc": "/posts/2012/01/install-insight-debugger-linux-mint-ubuntu.html", 
      "title": "Install the Insight Debugger on Linux Mint (works for Ubuntu too)", 
      "text": "Insight is a very good debugger based on gdb. I prefer it over ddd or kdbg as I find it clearer and easier to use. Moreover, this debugger is also the one used in the book Assembly language Step by Step, for Linux. However, Insight has been removed from Debian packages already more than a year ago. \nBut, thanks to SevenMachines, a PPA repository is available to install it on Linux Mint (works also on Ubuntu and Ubuntu-based Linux distributions). \nTo add the repository to your apt sources, add the following lines to the /etc/apt/sources.list file:\ndeb http://ppa.launchpad.net/sevenmachines/dev/ubuntu natty main \ndeb-src http://ppa.launchpad.net/sevenmachines/dev/ubuntu natty main \n\nand update your apt sources: \nsudo apt-get update\n\nThen you can install insight: \nsudo apt-get install insight\n\nAnd now you are ready to use Insight as your debugger. \nIf you don't trust this PPA repository, you can also try it to install it from the sources (http://sources.redhat.com/insight/), but doesn't seem to very simple to install it. I wasn't able to build it on my Linux Mint 12.", 
      "tags": "Assembly,C++,gcc,Linux,Mint,Tools"
    }, 
    {
      "loc": "/posts/2012/01/boost-enable_if-handle-ambiguous-function-overload-void.html", 
      "title": "Use Boost enable_if to handle ambiguous function overload return types", 
      "text": "The title is not really clear but I didn't found a better one. The example will be clearer (I hope). In EDDI, I had this little function : \ntemplate<typename Visitor, typename Visitable>\nvoid visit(Visitor&amp; visitor, Visitable&amp; visitable){\n    visitor(visitable);\n}\n\n\n\nFor the record, this function is only invoking a specific operator of a visitor. The problem was that I wanted this function to handle also non-void visitors. The visitor in question has a result_type typedef indicating the return type of the visit. The naive version cannot work : \ntemplate<typename Visitor, typename Visitable>\ntypename Visitor::result_type visit(Visitor&amp; visitor, Visitable&amp; visitable){\n    return visitor(visitable);\n}\n\ntemplate<typename Visitor, typename Visitable>\nvoid visit(Visitor&amp; visitor, Visitable&amp; visitable){\n    visitor(visitable);\n}\n\n\n\nThe problem here is that there are ambiguities for overload resolution because the return type is not considered in this resolution. What we want is that the overload resolution does not consider the function returning something (the first one). And that's here that Boost can help, specifically the Boost enable_if library. This function allows to enable of disable some function template of function class based on a boolean condition. In our case, we want to disable the function is the return type is void. So, we will use the boost::disable_if template to disable it. This template has to parameter B and T. When B is true, the template is evaluated to T, otherwise there is an error used for SFINAE (Substitution failure is not an error) To test if the return type is void, we will use Boost type_traits, specifically the boost::is_void template. \nHere is the version using disable_if : \ntemplate<typename Visitor, typename Visitable>\ntypename boost::disable_if<boost::is_void<typename Visitor::result_type>, typename Visitor::result_type>::type\nvisit(Visitor&amp; visitor, Visitable&amp; visitable){\n    return visitor(visitable);\n}\n\ntemplate<typename Visitor, typename Visitable>\nvoid visit(Visitor&amp; visitor, Visitable&amp; visitable){\n    visitor(visitable);\n}\n\n\n\nWith that, you can call the visitor with a void return type. However, it's not enough. Indeed, the call is still ambiguous when the return type is not void. So we have to enable the second function only if the return type is void : \ntemplate<typename Visitor, typename Visitable>\ntypename boost::disable_if<boost::is_void<typename Visitor::result_type>, typename Visitor::result_type>::type\nvisit(Visitor&amp; visitor, Visitable&amp; visitable){\n    return visitor(visitable);\n}\n\ntemplate<typename Visitor, typename Visitable>\ntypename boost::enable_if<boost::is_void<typename Visitor::result_type>, typename Visitor::result_type>::type\nvisit(Visitor&amp; visitor, Visitable&amp; visitable){\n    visitor(visitable);\n}\n\n\n\nWith that, you can call the function with both visitors and the good function will be chosen depending on the result type of the visitor. \nI hope this example of using Boost enable_if will help you when you face similar problems.", 
      "tags": "Boost,C++,templates"
    }, 
    {
      "loc": "/posts/2012/01/compilers-principles-techniques-tools.html", 
      "title": "Compilers : Principles, Techniques & Tools - Book Review", 
      "text": "Some weeks ago, I finished\u00a0reading Compilers : Principles, Techniques & Tools, by Afred V. Aho, Monica S. Lam, Ravi Sethi and Jeffrey D. Ullman. This book is also called the Dragon Book due to the cover.\nThis book is a reference about compiler construction and design. If you are interested in this subject, this book is for you, it's a must-have. However, I have to warn you that this book is very technical and hard. Honestly, some of the chapters are beyond my comprehension. Before this book, I had no real comprehension of the subject. I will certainly read again some of the chapters when I will have more practice into the subject.\nIf you want, the book is full of exercises about each subject covered in the book. If you plan to do all the\u00a0exercises, you'll need a lot of time as there are a lot of them and some of them are quite hard. I've done some of them but only a little part.\nThe first chapter introduces the construction of compilers. You will see the common structure of compilers, the evolution of programming languages and the science behind building a compiler and its applications. The second chapter is still quite general. It will teach you how to develop a simple syntax-directed translator. This chapter is very important as it will give you the basics for understanding the following chapters. You will learn how to define a grammar, what are the main parsing techniques and what is lexical analysis. It will also covers symbol tables and intermediate language generation.\nWith the third chapter (Lexical Analysis), we are entering the hearth of the matter. You will learn the vocabulary behind lexical analysis (tokens, lexemes, attributes, ...). Then, after you've learned how to define and recognize tokens, you will see the different techniques to build an efficient lexical analyzer. The first technique that will be covered is the use of a lexer generator (Lex). Then you will see in details how to construct a lexer using regular expressions or finite automata especially\u00a0Nondeterministic\u00a0Finite Automata and Deterministic Finite Automata.\nThe next one (Syntax Analysis) is about parsing. After learning how to define and write a grammar you will see how to parse it. You will see in details the most commons types of parsing (Top-Down, Bottom-Up) and the most common parsers (LL(K) and LR(K) parsers). The construction of these kinds of parsers is covered in details and the way to optimize them is also teached. Finally, you will see how to automatically generate a parser using Lex and Yacc. This chapter is sometimes very hard to understand (in my own opinion) but very interesting especially if you plan to build parser without generating it with some advanced tools (for example Yacc or Boost Spirit for C++).\nThe fourth chapter (Syntax Directed Translation) explains you how to translate some source code (parse it) into a coherent structure (an abstract tree) using a Syntax Directed Scheme. The translation is made based on a syntax using semantic actions and rules to translate the source into something else. You'll see different ways of doing that translations.\nThen, the next one (Intermediate Code Generation) teaches you how to generate Intermediate Code from the source. Two different representations are covered : syntax trees and three-address-code. Another subject covered in this chapter is type checking. You'll see in details how to translate expressions, control flow instructions and switch statements into three-address-code statements.\nThe seventh chapter (Run-Time Environment) gives a lot of information about the different\u00a0run-time\u00a0targets that you can compile for. A lot of subjects are covered here: stack and heap allocation, locality exploitation, garbage collectors... This chapter is in my opinion a very good instruction to computer architecture. You cannot imagine develop a compiler without having a deep understanding of the target machine.\nThe next chapter (Code Generation) is also a very important one. In this chapter, you will see how to generate assembly code from the three-address-code. You will learn how to select the good instructions. A very important subject covered in this chapter is register allocation. You'll learn how to choose wisely the registers to produce efficient code. The basic blocks are also covered there with flow graphs. More than just generating code from Three-Address-Code statements, you'll also see how to optimize them. Only local (to a basic block) optimization techniques \u00a0will be covered in this chapter. Several techniques that aims at testing if code is optimal are also taught there.\nThe global optimizations are covered in the next chapter (Machine-Independent Optimizations). You will discover several optimizations that you can do globally (inside a function but among different basic blocks). A data-flow analysis framework is explained here in details. After that, for each of the optimization, the parameters of the data flow analysis are explained. The optimization of loops is treated too.\nThe three next chapters (Instruction-Level Parallelism, Optimizing for Parallelism and Locality and Interprocedural Analysis) are the most complex of the book. They are covering in details the optimizations that can be made when a compiler supports instruction-level parallelism (executes several instructions in one clock cycle). It also covers interprocedural analysis of a program to allow even better optimization than global optimization inside a function. Honestly, I didn't understand some of the concepts described here. I will read them again one by one, chapter by chapter and try to implement some of the techniques in EDDI in the future.\nTo conclude, I will say that\u00a0Compilers : Principles, Techniques & Tools is a very good book that every compiler designer and developer should read before starting constructing a \u00a0compiler. Although very technical, it's quite clear and contains a huge amount of information. If \u00a0you plan to develop a compiler, it is a very good idea to read this book first.\nI've implement some of the techniques explained in this book in my own compiler. I implemented most of the local optimizations presented and Intermediate Code generation. You can find some information here.", 
      "tags": "Books,C++,Compilers,EDDI,Java,Optimization,Programming"
    }, 
    {
      "loc": "/posts/2012/01/eddic-0-7-compiler-model-optimizations.html", 
      "title": "EDDIC 0.7 : New compilation model and optimizations", 
      "text": "I'm proud to announce a new release of EDDIC, the version 0.7.\nMost of the changes are internal to the compiler. I read a new book : Compilers: Principles, Techniques, and Tools\u00a0and applied some of the advices of the author. The biggest change is the use of a new intermediate representation : Three-Address-Code statements. This representation is easy, all the statements are basically of the form a = b + c with + being any operator of the language. The big advantage of this representation is that we can easily run optimization on it. Another advantage is that this representation is complete enough to represent most of the programming languages, so, we can imagine compiling several different source languages into the TAC language and then compiling them the same way.\nOnce the Three-Address-Code representation is generated and separated into basic blocks, it is compiled into X86 assembly using a code generator. I've made a lot of improvements on the generated assembly. For example, I'm using several new instructions (neg, inc, dec, xor, ...) to generate more efficient code. Moreover, I'm doing a better use of registers with keeping variables into registers as long as possible.\nBetter optimization engine\n\nHere is the list of what the optimizer do at the TAC level:\n\n    Simplify arithmetic identities : a = b + 0 => a = b\n    Reduce in strength : a = b * 2 => a = b + b\n    Constant folding : a = 2 + 2 => a = 4\n    Constant propagation : when a constant is assigned to a, reuse the constant as long as no other\u00a0assignment\u00a0is made to a\n    Remove overridden assign\n    Remove dead basic blocks : when a condition is known at compile time we can know the path it will take and remove basic blocks that will never be taken\n    Remove needless jumps : After the other optimization have been done it is possible that a goto is directly targeting the next basic block so we can remove it\n    Merge basic blocks : After some statements have been replaced or removed it is possible that we can merge some basic blocks together\n\n\nThe optimizer is running the different optimization technique as long as one of them as an effect on the code. At the present time, the optimization techniques are used locally (within a basic block) so the generated assembly is not perfect, but for what I tested so far, it's a good start.\nOther changes\n\nMoreover, the language itself also had some improvements:\n\n    The minus and plus unary operators have been added to the grammar\n    The local and global variables can be const\n    A source file can now includes another source or a file from the standard library (very little for now, but a little start)\n\nThe project itself has also been improved\n\n    Most of the classes and files are now documented using Doxygen\n    The unit tests are now testing compilation and execution of some samples, that helped me finding some bugs in the code base and in the new changes\n\nDownload\n\nYou can find the compiler sources on the Github repository : https://github.com/wichtounet/eddic.\nThe exact version I refer to is the v0.7 available in the github tags or directly as the release branch.", 
      "tags": "Books,C++,Compilers,EDDI,Optimization"
    }, 
    {
      "loc": "/posts/2012/01/install-cinnamon-linux-mint.html", 
      "title": "Install Cinnamon in Linux Mint - A forked Gnome Shell", 
      "text": "In the last Linux Mint version (12), the developers have introduced a set of extensions to the Gnome Shell, Mint Gnome Shell Extensions (MGSE).\nBut, plugins can't do everything the developers want. So they forked Gnome Shell and started building their own shell : Cinnamon.\nAt the time of writing, the appearance of this new shell is similar to MGSE in Linux Mint 12, but with some differences : only one status bar, the left bottom menu was changed, notification bar in the bottom bar, ...\nYou can try it on your Linux Mint right now :\nsudo apt-get update\nsudo apt-get install cinnamon-session\n\nThen, you have to logout and select Cinnamon in the Logon screen as the desktop environment. \nPersonally, I still prefer MGSE, because I like having two bars, but that will perhaps change with some more tests on Cinnamon. And you, what do you think about Cinnamon ? Or about MGSE ? \nIf you want more informations about this new shell, you can read the official site.", 
      "tags": "Linux,Mint,Releases"
    }, 
    {
      "loc": "/posts/2011/12/merry-christmas.html", 
      "title": "Merry Christmas", 
      "text": "A bit late, but better late than never : Merry Christmas to all the readers of this blog :)", 
      "tags": "Others,Personal,The site"
    }, 
    {
      "loc": "/posts/2011/12/moodle-promotion-on-packt-publishing-books.html", 
      "title": "Moodle promotion on Packt Publishing Books", 
      "text": "In their December promotion, Pack Publishing are offering heavy discounts on all their Moodle books during all the month.\nYou can find all books available on offer on this page :\u00a0http://www.packtpub.com/news/moodle-festive-month\nThere are great offers:\n\n    Buy any\u00a0Moodle\u00a0print book and get\u00a020% off\n    Buy any\u00a0Moodle\u00a0eBook and get\u00a030% off\n\n\nFor those who don't know Moodle,\u00a0Moodle is currently the world's most popular E-learning platform. Moodle is a free, open-source PHP web application for producing modular internet-based courses that support a modern social constructionist pedagogy.", 
      "tags": "Books,Others,Promotion"
    }, 
    {
      "loc": "/posts/2011/12/wordpress-3-3-sonny-released.html", 
      "title": "WordPress 3.3 \u201cSonny\u201d released!", 
      "text": "WordPress 3.3 introduces some very interesting features, specially for the blogger itself.\u00a0It includes a new drag-and-drop uploader, hover menus for the navigation, a new toolbar, improved co-editing support, and a new Tumblr importer.\nThe admin interface has add a great cleanup too.\nMore information on the official release notes :\u00a0http://wordpress.org/news/2011/12/sonny/\nI already updated the blog to Wordpress 3.3 and it looks great for now. For the first time, I didn't have to disable all the addons prior to updating. This time it worked directly :)", 
      "tags": "Releases,The site,Web,WordPress"
    }, 
    {
      "loc": "/posts/2011/11/cpp-templates-complete-guide-book.html", 
      "title": "C++ Templates : The Complete Guide - Book Review", 
      "text": "After the Effective C++ Serie, I read C++ Templates: The Complete Guide, from David Vandevoorde and Nicolai M. Josuttis\nThe templates are one of the most powerful feature of C++. However, this is a complex technique that is often misused or misunderstood. This book will help you learning what exactly are templates and how they can be used to improve your software development in C++.\nThis book is sometimes very technical and is not the easiest to read. Nevertheless, the quality of the information it contains is great. This book covers all the aspects of template programming, from generic programming to template meta programming passing by traits and policy classes.\nThe first two chapters are introducing function templates and class templates. Then, the third chapter is about the nontype template parameters. Indeed, template parameters can be values and not types. For example, you can pass int constants as template parameters. Then, the two following chapters are more about templates in practice. You will learn the different way to include template code in your common C++ base code. You will also see some tricks useful when developing templates. The last chapter of this first part is fixing a terminology for templates.\nThe second part of the book (Templates in-Depth) starts with the fundamentals \u00a0of templates in-depth. Then, the names in templates are covered in details. After that, we have three very technical and complex chapters. The first covers the instantiations of templates in-depth, the second covers the template argument detection and the next one is about specializations and overloading. The last chapter of this part is about the future directions of the C++ templates. This chapter covers some extensions that have been added to library and compilers, \u00a0but were not in C++ standard at the time the book was written. Some of these futures directions are now part of the new C++11 standard.\nThe next part (Templates and Design) is about the techniques that can be used to improve your software design using templates. The first chapter covers the most common use of templates: compile-time polymorphism. Then, the traits and policy classes are covered. The traits classes are a way to add more information to a template parameter and policy classes represent a configurable behavior for templates. The 16th is talking about some optimization that can be made about templates and inheritance. The next chapter focuses on template metaprogramming. A metaprogram is a program that is not computed at runtime, but at compile-time resulting in performance sometimes very important. Then, the last chapter introduces the expression templates. This technique is a way to encapsulate expressions into templates in order to optimize some computations. The example is about matrix computations.\nThe final part (Advanced Applications) present four examples in which the templates brings a lot of power. The first example is about type classification. How to know at compile-time of what kind is a given type and makes something depending on the characteristics of the type. The second example is about developing Smart Pointers. The next one presents an implementation of tuples with templates and the last one implements function objects and callbacks. These four examples are not made to be used instead of the standard library, but there are good examples to prove the power of templates.\nTo conclude, I'll say that this book is a very good guide about templates. It covers most of the details that you can face when developing with templates or when working with very templatized libraries like Boost.", 
      "tags": "Books,C++,templates"
    }, 
    {
      "loc": "/posts/2011/11/dynamic-memory-allocation-intel-assembly-linux.html", 
      "title": "Dynamic memory allocation in Intel Assembly on Linux", 
      "text": "For the version 0.6.0 of the EDDI Compiler, I have written a simple dynamic memory allocation function in assembly. I did that to avoid using malloc in my assembly code. As this is not an easy subject, this article will explain the main parts of writing this function.\nAs the EDDI Compiler creates program for Linux platform, this article will focus on writing a little memory allocator for Linux in Intel Assembly.\nIn this article I will follow the AT&T notation.\nSpecifications\n\nThe function works like malloc but is simpler. The specifications are the following ones:\n\n    We call the function with one argument: the dynamic memory size we need\n    The function returns the start address of the allocated memory in the %eax register\n    There is no need to deallocate the allocated memory\n    The size that we ask will generally small and always less than 16384 octets\n    Having some gaps in the memory is not a problem for now\n\n\nSo as you can see there are several limitations to this memory allocator. These limitations are the one I had for EDDI, so I'll follow them in this article.\nDynamic memory allocation\n\nIn Linux, there are two ways for performing dynamic memory allocation:\n\n    brk: Increment the size of the data segment after the end of the program. This memory is directly after the program and is always contiguous. It's the easiest way for allocating memory. This technique is not perfect for large blocks of data.\n    mmap: Creates a new memory mapping in the virtual address space. The kernel gives you memory in virtually every place of the memory.\n\n\nIn our case, as we need only small blocks, we will use brk to dynamically allocate memory.\nWe can call these procedures using system calls. In assembly, you can use system calls with interruptions (0x80).\nImplementation\n\nWe need two variables for this function. One to keep track of the remaining size and another one to keep track of the current address of the allocated memory.\n.data\n.size VIeddi_remaining, 4\n\nVIeddi_remaining:\n.long 0\n.size VIeddi_current, 4\n\nVIeddi_current:\n.long 0\n\n\n\nBoth variables are initialized to 0.\nAnd here is the function I've developed :\neddi_alloc:\npushl %ebp\nmovl %esp, %ebp\nmovl 8(%ebp), %ecx\nmovl VIeddi_remaining, %ebx\ncmpl %ebx, %ecx\njle alloc_normal\nmovl $45, %eax\nxorl %ebx, %ebx\nint  $0x80\nmovl %eax, %esi\nmovl %eax, %ebx\naddl $16384, %ebx\nmovl $45, %eax\nint  $0x80\nmovl %esi, %eax\nmovl $16384, VIeddi_remaining\nmovl %esi, VIeddi_current\n\nalloc_normal:\nmovl VIeddi_current, %eax\nmovl VIeddi_current, %ebx\naddl %ecx, %ebx\nmovl %ebx, VIeddi_current\nmovl VIeddi_remaining, %ebx\nsubl %ecx, %ebx\nmovl %ebx, VIeddi_remaining\nleave\nret\n\n\n\nI will describe now each part of the alloc function.\nmovl 8(%ebp), %ecx\nmovl VIeddi_remaining, %ebx\ncmpl %ebx, %ecx\njle alloc_normal\n\n\n\nIn this part we test if there is enough remaining size for the dynamic memory allocation request. It's equivalent to if(remaining >= size). If there is enough size, we jump to the normal allocation part :\nalloc_normal:\nmovl VIeddi_current, %eax\nmovl VIeddi_current, %ebx\naddl %ecx, %ebx\nmovl %ebx, VIeddi_current\nmovl VIeddi_remaining, %ebx\nsubl %ecx, %ebx\nmovl %ebx, VIeddi_remaining\n\n\n\nFirst, we move the current address of memory into the %eax register for the return value. Then we add the size of the new allocated block to the current address. Finally we remove the size of the new allocated block from the remaining size. After that, we can leave the function.\nThe most interesting part is what we do when we have to allocate more memory :\nmovl $45, %eax\nxorl %ebx, %ebx\nint  $0x80\nmovl %eax, %esi\nmovl %eax, %ebx\naddl $16384, %ebx\nmovl $45, %eax\nint  $0x80\nmovl $16384, VIeddi_remaining\nmovl %esi, VIeddi_current\n\n\n\nWe start by doing an interruption to execute a system call. The 45 in the %eax register indicates a sys_brk call. The 0 in the %ebx register, indicates that we want the current position of brk space. We save this current position into the %esi register. Then we add 16384 bits (4K octets) to this address. We call again the sys_brk routine to set the address of the brk space to the calculated address. This is the way to dynamically allocates 4K of memory. Finally, we add 4K to the remaining size in octets and we put the current address (before the add) as the current address.\nPossible improvements\n\nWe should make some optimization if this function has to be invoked frequently. The first interruption (call to sys_brk) has only to be done once. The very first time we need to get the start address. Then, we can use the current address as the base address when we do the new allocation.\nAnother improvement is to avoid having gaps between the used blocks. For that, we can avoid setting the current address directly to the newly allocated address but just add 4K to the remaining size. The blocks will overlap 2 allocated blocks.\nWe could also check that the value returned by the sys_brk is valid. On error, the procedure can return -1.\nConclusion\n\nIn this post, we developed a basic dynamic memory allocation function in Intel assembly on the Linux platform. I hope that this information can helps some of you.\nDon't hesitate if you have a question or a comment on my implementation.", 
      "tags": "Assembly,EDDI,Intel,Linux"
    }, 
    {
      "loc": "/posts/2011/11/eddi-compiler-0-6-1.html", 
      "title": "EDDI Compiler 0.6.1 : Function return types", 
      "text": "I just released a new version of the EDDI Compiler : eddic 0.6.1\nThis is a minor update with only one change on the language: the functions can now return something. The return values are returned in registers (%eax for int and %eax:%ebx for strings). At this time, it is not possible to return an array from a function.\nThe other changes of this version are on the code base side. All the headers have been cleaned. There are less useless imports and the code is cleaner. Moreover, I also have rewritten the Readme in order to include more useful information in it. The parsing phase should be a little faster now and the assembly has been improved by using the POP instruction. The phases of checking have also been reordered. In the future, it's possible that several phases will be merged together for performance purposes, but for now, it's quite fast on my sample even the 2MB stress file.\nYou can now generate the Doxygen generation using make doc. The target is generated with CMake. At this time, the documentation is almost empty, but I will work on it on the next releases.\nThe next version will be a major release. I don't know what will be the changes for the language itself, but the compiler will use a new intermediate representation. It will use Three-Address-Code representation. This representation is simple and can be easily optimized. This will make easier the transformation from the AST to the assembly. At this time, the code of the intermediate compiler is very hard to maintain and contains a lot of logic. The switch to a new, simpler, intermediate representation will simplify the intermediate compiler.\nYou can find the EDDI compiler sources on the Github repository :\u00a0https://github.com/wichtounet/eddic.\nThe exact version I refer to is the v0.6.1 available in the github tags or directly as the release branch.", 
      "tags": "C++,Compilers,EDDI,Releases"
    }, 
    {
      "loc": "/posts/2011/11/linux-mint-12-lisa-released.html", 
      "title": "Linux Mint 12 (Lisa) released!", 
      "text": "Linux Mint 12 has just been released!\nThis new version includes a Gnome 3 using a specific extension MGSE (Mint Gnome Sheel Extensions) and a Gnome 2 UI (MATE). You will find also a lot of other improvements. \nFrom several months, Linux Mint is the most used Linux distribution. \nFor more informations, you can read the official announcement", 
      "tags": "Linux,Releases"
    }, 
    {
      "loc": "/posts/2011/11/print-strings-integers-intel-assembly.html", 
      "title": "How to print strings and integers in Intel Assembly on Linux ?", 
      "text": "In this post, we'll learn how to print strings and integers to the console on Linux using Intel Assembly. In this post, I'll use the AT&T notation, because it's the notation used in EDDI. \nIn EDDI, I have to print strings and numbers to the console, as this is not an easy exercise, I wanted to share my experience here. \nOn Linux, the only way to print something on the console is to use a system call. For that, we have to use the 0x08 interrupt code. \nDeclare strings\n\nFirst, we'll see how to declare strings in an Intel Assembly file. You can use the .string instruction to achieve that : \nStringToPrint:\n.string \"Hello\"\n\n\n\nPrint strings\n\nThen, to print, we will call the sys_write system call : \nmovl $4, %eax\nmovl $1, %ebx\nmovl $StringToPrint, %ecx\nmovl $5, %edx\nint $0x80\n\n\n\nThe value in %eax (4) indicates the system call we need (sys_write). The 1 in %ebx indicates that we want to write in the console. Finally the two last parameters indicates the string to print and the size of the string. In Intel assembly, the int instruction launch an interrupt and the 0x80 in the interrupt table is set to the system call in the Linux Kernel. \nAs you can see, this code does use 4 registers and does not save any of them. Ideally, you will save the registers before and restore them. It depends on when you use this routine. \nPrint integers\n\nWriting an integer is a bit more complicated. If you have the integer in the string, there is no problem, but if you have only a long on your assembly, you'll have to convert the int into a string to print it. We will convert the integer char after char and use the stack as storage for our string. Then every char will be printed to the console using the same system as before. \nSo let's say we have our number in the %eax register : \nmovl $9234, %eax\n\n\n\nSo let's take a look at the code : \nxorl %esi, %esi\n\nloop:\nmovl $0, %edx\nmovl $10, %ebx\ndivl %ebx\naddl $48, %edx\npushl %edx\nincl %esi\ncmpl $0, %eax\njz   next\njmp loop\n\nnext:\ncmpl $0, %esi\njz   exit\ndecl %esi\nmovl $4, %eax\nmovl %esp, %ecx\nmovl $1, %ebx\nmovl $1, %edx\nint  $0x80\naddl $4, %esp\njmp  next\n\nexit:\n\n\n\nThe first part of the code consists in dividing the value by 10 until we reach zero. The remainder of the division is pushed onto the stack. For example, for our number, after this part, we'll have 4-3-2-9 on the stack. The order is reversed, which is logic because we stack the remainders from the right. During this phase, we count the number of elements using the %esi register. \nOnce this is done, we print each characters one by one starting with the last that has been pushed. Here we decrement the counter for each char and we use the sys_write call with %esp as the address of the string of one character. After each character, we incremetn the %esp to cancel the push that we used. \nWe have to do this in two phases in order to get the characters in the good order and not in reverse order. \nHandle negative numbers\n\nAs you may have noticed, we do not manage negative numbers in our code. They will be printed, but it will be positive number. Indeed, in Intel Assembly (and in processors in general), negative numbers are handled with two's complement. Handling negative numbers in our code is not a big deal. We can add this code at the beginning : \ncmpl $0, %eax\njge loop\nneg %eax\npushl %eax\n; Print \"-\" \npopl %eax\n\n\n\nFirst of all, we check if the number is smaller than 0, if it's not the case, we directly jump to the code we used before. If it's smaller, we negate the number and print a - before printing the real number. We have to save the %eax register before printing the - character because %eax is used for printing. \nYou'll now have a complete procedure to print an integer on the console in assembly. \nI hope that this could be of some help for somebody.", 
      "tags": "Assembly,EDDI,Intel,Linux"
    }, 
    {
      "loc": "/posts/2011/11/eddi-compiler-0-6-0-arrays.html", 
      "title": "EDDI Compiler 0.6.0 : Arrays", 
      "text": "This new version of the EDDI Compiler was faster to finalize than the previous.\nThe main feature of this release is the use of arrays. You can now use arrays in the EDDI code. You can declare global or local arrays and pass them as parameters to the function. In the assembly, there is certainly still some optimization to perform, but the code works well for now. A new loop is also available the foreach loop for arrays. The loop iterates through each element of the array. \nI also performed some new improvements in the compiler speed. \nThe local and global variables now have default values (0 for int and the empty string for strings). So you can omit the value in the declaration. \nI removed the dependency to the C library with replacing malloc with a little memory allocation function I wrote myself. This function is very simple and only use sys_brk to allocate memory directly after the program. You cannot release the memory for now, but that was the same before. \nThe compiler is now able to warn you if you declare something and you don't use it (parameter, variable, function). Moreover, if you enable the optimization, the functions and variables that are not used will not be compiled. \nI made a little fix to the print_integer function to handle negative numbers. Before that, they were printed but in two's complement, now they are printed in the negative form (-344 for example). \nI don't know exactly yet what will be included in the next release of the EDDI Compiler. Probably this will be minor release with the inclusion of function return types, but I'm not sure yet. In the future, I also want to add some kind of structure to the program. \nYou can find the compiler sources on the Github repository : https://github.com/wichtounet/eddic. \nThe exact version I refer to is the v0.6 available in the github tags or directly as the release branch.", 
      "tags": "C++,Compilers,EDDI,Releases"
    }, 
    {
      "loc": "/posts/2011/11/new-theme-site.html", 
      "title": "New Wordpress theme for the site", 
      "text": "After a long time with the old F2 theme, I decided to choose a more modern design. I chose the WP Plus design which is based on the Google Plus Design. \nI think that this design is more practical and cleaner for the users and more comfortable. \nMoreover, I also took some time to change some of my addons. I replaced All In One SEO with Wordpress SEO plugin from Joost de Valk. I think that this plugin is better than the first one, but more of that, it also replaced one addon generating the XML sitemap and helped me adding a breadcrumb to the site. \nI hope that these changes will improve the user experience on my website. \nIf you encounter any kind of problems with the new design, don't hesitate to let a comment or to contact me.", 
      "tags": "Personal,The site,Web,WordPress"
    }, 
    {
      "loc": "/posts/2011/11/boost-1-48-0-has-been-released.html", 
      "title": "Boost 1.48.0 has been released", 
      "text": "A new version of Boost is available : Boost 1.48.0\nThis release includes three new libraries : Locale, Container and Move. \nA lot of bug have been fixed and there are also some changes in the existing libraries.", 
      "tags": "Boost,C++,Libraries,templates"
    }, 
    {
      "loc": "/posts/2011/11/boost-intrusive_ptr.html", 
      "title": "Boost intrusive_ptr : faster shared pointer", 
      "text": "This post will present the Boost intrusive_ptr and its usage in C++ programming. \nRecently, I took some time to optimize the parsing performances of the EDDI Compiler. The parsing phase creates a lot of nodes to fill the Abstract Syntax Tree. \nOne of the way I found was to replace some shared_ptr by some intrusive_ptr of the Boost library. \nIt's a faster alternative of shared_ptr. Like its name indicates, it's intrusive. The reference counter is included directely in the managed class, in the contrary of the shared_ptr where the reference counter has to be dynamically allocated to live aside the object. This leads to some performances improvement. Considering memory, the footprint of an intrusive_ptr is the same as the footprint of a raw pointer. This is not the case for the shared_ptr that have a pointer to the object, a pointer to the counter and the counter itself. \nFor example, if you have a class X:\nclass X {\n    std::string name;\n    int age;\n};\n\n\n\nAnd you use it in your code using a shared_ptr : \nvoid test(){\n    std::shared_ptr<X> x(new X);\n\n    std::cout << x->name << std::endl;\n}\n\n\n\nand you want to use an intrusive_ptr, you have first to add a reference counter inside the X class : \nclass X {\n    std::string name;\n    int age;\n\n    long references;\n    X() : references(0) {}\n};\n\n\n\nAnd you have to indicate to the intrusive_ptr where the reference counter can be found for this class : \ninline void intrusive_ptr_add_ref(X* x){\n    ++x->references;\n}\n\ninline void intrusive_ptr_release(X* x){\n    if(--x->references == 0) \n        delete x;\n}\n\n\n\nAnd finally you can use the intrusive_ptr to replace your shared_ptr : \nvoid test(){\n    boost::intrusive_ptr<X> x(new X);\n\n    std::cout << x->name << std::endl;\n}\n\n\n\nThe smart pointer itself can be used exactly the same way as a shared_ptr. If you have several classes that are managed using an intrusive_ptr, you can use a function template to tell Boost that all the reference counter are at the same place : \ntemplate<typename T>\ninline void intrusive_ptr_add_ref(T* expr){\n    ++expr->references;\n}\n\ntemplate<typename T>\ninline void intrusive_ptr_release(T* expr){\n    if(--expr->references == 0)\n        delete expr;\n}\n\n\n\nAs you can see, the pointer is very intrusive and needs some boilerplate code added to your application, but it can leads to some interesting improvements for classes very often dynamically allocated. \nThere is another advantage in using intrusive_ptr. As the reference counter is stored into the object itself, you can create several intrusive_ptr to the same object without any problem. This is not the case when you use a shared_ptr. Indeed, if you create two shared_ptr to the same dynamically allocated object, they will both have a different references counter and at the end, you will end up with an object being deleted twice. \nOf course, there are not only advantages. First of all, you have to declare a field in every classes that you want to manage using an intrusive_ptr and you have to declare functions to manage the reference. Then there are some disadvantages when using this pointer type compared to a shared_ptr : \n\n    It's impossible to create a weak_ptr from a intrusive_ptr\n    Code redundancy, you have to copy the reference counter in every class that you want to use an intrusive_ptr with\n    You have to provide a function for every types that has to be used with intrusive_ptr (only two functions if you use the template versions of the two functions)\n\n\nTo conclude, the boost::intrusive_ptr can be a good replacement of std::shared_ptr in a performance critical application, but if you have no performances problem, do not use it because it makes your code less clear. If you are concerned by performances when using std::shared_ptr, consider also using std::make_shared to create your pointers, so that the reference counter and the object itself will be allocated at the same place and at the same time, resulting in better performances. Another case where it's interesting to use an intrusive_ptr is when dealing with libraries using a lot of raw pointers, because you can create several intrusive_ptr to the same raw pointer without any problem.\nFor more information, you can consult the official documentation.", 
      "tags": "Boost,C++,Performances"
    }, 
    {
      "loc": "/posts/2011/11/eddic-0-5-1-better-assembly-generation-and-faster-parsing.html", 
      "title": "eddic 0.5.1 : Better assembly generation and faster parsing", 
      "text": "I'm very pleased to release the version 0.5.1 of the EDDI Compiler.\nIt makes now a long time since the last version of eddic, but I started again working frequently on it. This version doesn't add any new feature to the language, but there are a lot of improvements in the compiler itself. \nFirst of all, the generated assembly has been improved a lot. I use now a intermediate representation of assembly and then the compiler is able to make more optimizations in its choice. This optimization is especially visible for integer computations. Before this, all the computations used stack operations and then we use almost only registers when it's possible. It's still not perfect, but it uses way less instructions. Moreover, this can enable me to write a 64 assembly code instead of 32 and provide both versions in the compiler. \nAnother improvement is the speed of the parser. I now use Boost Spirit to parse the source file and construct an Abstract Syntax Tree. This parsing is very fast now (with some optimizations). Moreover, it will be easier to add new constructs later. \nI also improved the general performances at some places. I also use Boost Program Options to parse the command line options. \nIn the next version (0.6.0), I will introduce arrays of int and strings and the foreach construct for array. I will also remove the dependency to malloc writing a memory allocation manager in assembly. I will also introduce warnings in the compiler. \nYou can find the compiler sources on the Github repository : https://github.com/wichtounet/eddic. \nThe compiler now needs Boost 1.47.0 to build. \nThe exact version I refer to is the v0.5.1 available in the github tags or directly as the release branch.", 
      "tags": "Assembly,Boost,C++,EDDI,Performances,Releases,templates"
    }, 
    {
      "loc": "/posts/2011/10/effective-stl-book-review.html", 
      "title": "Effective STL Book Review", 
      "text": "I finished reading the last Effective C++ volume : Effective STL, Scott Meyers.\nAgain, this book follows the same model as the two others, providing several rules aiming at making you a better (more effective) STL programmer. All the items of this book are centered on the usage of the Standard Template Library (STL).\nThe first chapters (Containers) gives you several advices for using STL Containers. The main point of this chapter is about how to choose carefully a container for a specific use case. It also contains several advices on how to use them well regarding to performances and thread safety.\nIn the next chapter (vector and string), the author focuses on two specific containers : vector and string. There are some specificities on these two containers that can improve the efficiency of the program.\nThe third chapter (Associative Containers) is about the associative containers of the STL : set, map, multimap and multiset. It also contains some important informations about which methods to use for each usage in order to preserve the efficiency of each container. It will also explain you the very important difference between equality and equivalence.\nThe next one (Iterators) explains which iterators to use and how to convert iterators of one type to another.\nThe chapter five (Algorithms) describes the most important algorithms of the STL. There are tons of algorithms in the STL and using them can save you from writing a lot of boilerplate code. For example, you will learn the different sorting algorithms and for_each. I found that this chapter was especially interesting.\nThe sixth chapter (Functors) explains you how to create functors and predicates for using with STL classes. It also treats of the special functions to convert functions to functors.\nThe last chapter (Programming with the STL) gives you advices on how to use the STL to make easier the programming of concrete programs. It will teach you what functions to use, what headers to include and how to decipher STL-related errors.\nI found that this book was really good, as good as the first one. The advices are very useful and easy to understand. Using this advices enabled me to improve my code and the efficiency of it. I will recommend this book to every C++ developers using the STL.", 
      "tags": "Books,C++,templates"
    }, 
    {
      "loc": "/posts/2011/10/eddic-0-5-functions-foreach.html", 
      "title": "EDDIC 0.5 : Functions and foreach", 
      "text": "I'm pleased to release the version 0.5. of the EDDI Compiler.\nThis new version introduced the first version of function calls. The function can take several parameters but cannot return anything at this moment. A version of foreach loop is now available in the language.\nYou can also declare variables globally in the source code. The global variables are stored in the .data section of the ELF file and the local variables are stored on the stack.\nThe error reporting of the compiler has been improved. Indeed, now the syntactical errors are reported with the exact location of the source.\nThere are also a lot of improvements in the source code. The big header files have been splitted into several files. I replaced all the pointers by smart pointers that allowed me to remove all the memory leaks of the applications and to simplify the memory management. Finally, I started using some new features of C++11 to improve the source code of the application.\nThe next version will certainly see return types for functions and perhaps a first version of switch case. Moreover, I have a lot of improvements to do at the assembly level. Indeed, the generated assembly is not efficient at all. Perhaps, I will consider adding arrays too to this version.\nYou can find the compiler on the Github repository : https://github.com/wichtounet/eddic. If you watch the repository, you'll see that I followed a new branching model, the one proposed and enforced by the git-flow tool.\nThe exact version I refer to is the v0.5 available in the github tags.", 
      "tags": "C++,C++11,EDDI,Git,Releases"
    }, 
    {
      "loc": "/posts/2011/10/install-git-flow-linux.html", 
      "title": "How to install git-flow on Linux", 
      "text": "One week ago, I started using git-flow on eddic. This is a collection of Git extensions to easily follow a branching-model convention for a Git project. I will try to describe this project later on this blog.\nYou can install git-flow using this simple command:\nwget --no-check-certificate -q -O - https://github.com/nvie/gitflow/raw/develop/contrib/gitflow-installer.sh | sudo sh\n\nI recommend you to install a script to autocomplete the git-flow commands and params: \nmkdir -p ~/src/external && cd ~/src/external\ngit clone https://github.com/bobthecow/git-flow-completion.git git-flow-completion\nmkdir -p ~/bin/ && cd ~/bin\nln -s ~/src/external/git-flow-completion/git-flow-completion.bash ./git-flow-completion.sh\n\nThen add a simple command in your .bashrc file:\nsource ~/bin/git-flow-completion.sh\n\nIf you want an introduction of git-flow, I recommend you this blog post : Why aren't you using git-flow ?", 
      "tags": "EDDI,Git,Linux"
    }, 
    {
      "loc": "/posts/2011/10/diploma-thesis-inlining-assistance-for-large-scale-object-oriented-applications.html", 
      "title": "Diploma Thesis : Inlining Assistance for large-scale object-oriented applications", 
      "text": "One month ago, my diploma thesis has been accepted and I got my Bachelor of Science in Computer Science.\nI made my diploma thesis at Lawrence Berkeley National Laboratory, Berkeley, California. I was in the team responsible of the developmenet of the ATLAS Software for the LHC in Cern. The title of my thesis is Inlining Assistance for large-scale object-oriented applications\nThe goal of this project was to create a C++ analyzer to find the best functions and call sites to inline. The input of the analyzer is a call graph generated by CallGrind of the Valgrind project.\nThe functions and call sites to inline are computed using a heuristic, called the temperature. This heuristic is based on the cost of calling the given function, the frequency of calls and the size of the function. The cost of calling a function is based on the number of parameters, the virtuality of the function and the shared object the function is located in.\nThe analyzer is also able to find clusters of call sites. A cluster is a set of hot call sites related to each other. It can also finds the functions that should be moved from one library to the other or the function that should not be virtual by testing the use of each function in a class hierarchy.\nTo achieve this project, it has been necessary to study in details how a function is called on the Linux platform. The inlining optimization has also been studied to know what were the advantages and the problems of this technique.\nTo retrieve the information about the sizes and the virtuality of the function, it has been necessary to read the shared libraries and executables files. For that, we used\u00a0libelf. The virtuality of a function is calculated by reading each virtual table and searching for the function in the virtual tables content.\nThe graph manipulation is made by the Boost Graph Library. As it was an advanced library, it has helped me improving my skills in specific topics like templates, traits or Template Metaprogramming.\nThe analyzer is able to run on the Linux platform on any program that has been compiled using gcc.\n\n\nWe have tested the analyzer on the CLang compiler and have been able to obtain these results :\n\nCluster 1 and 2 indicates that we have inlined the first, respectively the second, cluster. Callsites_5 indicates that the first five call sites have been inlined and Functions_3 indicates that we inlined the first three functions. As we can see, the results are not really impressive, but we have only done inlining. Moreover, in some large applications, even little savings are really interesting. For example, in the ATLAS software, 1% of saving represents 100K$/year.\nHere is the base outline of my work:\n\n    Introduction\n    Analysis : Function Call, Inlining, Compiler Inlining\n    Information Extraction : Graph manipulation, parsing object files\n    Information analysis : Heuristc, library issues, clustering, virtual hierarchy issues\n    Design\n    Tests : Tests on CLang, Tests on ATLAS\n    Performance analysis : Performance of the analyzer\n    Refactorings\n    Problems\n    Tools : Application used during the project\n    Conclusion\n\n\nYou can download a PDF version of my thesis here :\u00a0Inlining Assistance for large-scale object-oriented applications", 
      "tags": "Boost,C++,Compilers,gcc,Linux,Optimization,Performances,Personal"
    }, 
    {
      "loc": "/posts/2011/09/book-review-more-effective-c.html", 
      "title": "Book Review : More Effective C++", 
      "text": "Once I finished reading Effective C++, I decided to read the next one in the Effective C++ series: More Effective C++ from the same author (Scott Meyers). \nThat book follows the same model as the preceding. It seems that the entire book is made of several (35) ways to improve your C++ programs and designs. Again, the guidelines are separated into several chapters that I'll describe in the following paragraphs. \n\n\nThe first chapter (Basics) talks about the references and pointers, the C++ style casts and the arrays and polymorphism together. \nThe second one (Operators) will teach you how to be wary of the user-defined conversion functions and how to distinguish between postfix and prefix version of the increment operator. You'll also learn that some operators must not be overloaden. \nThe next chapter (Exceptions) will give you a lot of advices when working with exceptions. The chapter starts by telling the reader how to avoid resource leaks when working with exception-code. It also talks about how an exception is thrown and how to catch an exception in the right way. The point of the exception specifications is also addressed here. \nThe fourth chapter (Efficiency) will give you several guidelines to improve your program's performance. You'll learn how to avoid implicit conversions or facilitate the return value optimization. Another important guideline of this chapter is about the cost of several techniques that are used in C++ like multiple inheritance of virtual functions. \nThe next chapter (Techniques) is certainly the most advanced chapter of this book. I found this chapter less interesting and more dificult to read than the others. All the guidelines are very specific like limiting the number of objects of one class, reference counting or prohibiting heap-based object. These guidelines can be interesting if you really need one of the specific presented points. \nThe last chapter (Miscellany) talks about different things to improve the way you code. For example, you'll learn how to program in the future tense and how to combine C and C++ in the same program. You'll also familiarize yourself with the language standard. \nI liked the previous book a lot, it was very instructive and very interesting to read, almost as easy as a roman to read. For this one, I'm less convinced. Indeed, some of the guidelines are very long and hard to read. I have to say that I didn't read all of the guidelines completely. Especially in the Techniques chapter, some of the guidelines are very very long and IMHO not very interesting. Perhaps, it's just me. In fact, I'm still a beginner in C++ and perhaps some of the guidelines are just too advanced for me and that makes them boring or hard to read, I don't know, but I won't recommend this book to everyone. Before buying this book, I recommend you to read the table of contents and to see if you're interested in every guidelines that the author proposes.", 
      "tags": "Books,C++"
    }, 
    {
      "loc": "/posts/2011/09/packt-open-source-awards-2011.html", 
      "title": "Packt Open Source Awards 2011", 
      "text": "Packt launched the Open Source Awards 2011 contest. This is a contest that aims to encourage, support, recognize and reward Open Source projects.\nThis contest has been running since 2006.\nThe nominations started the first of August and finished on the 9th of September. The finalists of each category are available on the website. \nYou can vote for your favorite open source project in each of these categories:\n\n    Open Source CMS\n    Open Source Mobile Toolkits and Libraries\n    Most Promising Open Source project\n    Open Source Business Applications\n    Open Source JavaScript Libraries\n    Open Source Multimedia Software\n\n\nThe winner of each category will win 2500$ !\nMorevoer, if you vote for your favorite project, you will be entered into a prize draw to win a Kindle!\nThe votes are open, you can vote now on this page. \nYou can have more information about the awards here.", 
      "tags": "Others,Promotion,Web"
    }, 
    {
      "loc": "/posts/2011/09/google-is-open-to-all.html", 
      "title": "Google+ is now open to all", 
      "text": "After about 90 days of trial on invitation-only mode, Google+ is now open to everybody. \nFor those who don't know, Google+ is the social network platform of Google, with several interesting features like Circles, Hangouts, ...\nFor example, you can see my page on Google+. \nPersonally, I find this social network very interesting, but there are not enough people on it to concurrence really Facebook and the others networks. Don't hesitate to give it a try, it's worth it!", 
      "tags": "Google,Tools,Web"
    }, 
    {
      "loc": "/posts/2011/09/book-review-effective-c.html", 
      "title": "Book Review : Effective C++", 
      "text": "Some time ago, I have read Accelerated C++. After this introductory book, I have chosen to read a book focused on the good practices of C++ development. On that purpose, I bought Effective C++ Third Edition from Scott Meyers. I already finished this book months ago, but I didn't found the time and the movitation to review it until now. \nFirst of all, this book is aimed for people who already know C++ development and want to improve their skills in this language and especially to produce better programs and designs. This book can also be used by C developer that just switched to C++. The book is organized around 55 specific guidelines. Each guideline describe a way to write better C++. \n\n\nThe guidelines are grouped into nine chapters, each of which focus a specific part of program development and design. The guidelines and the chapters are not specially made to be read in a specific order, but some of the guidelines are referring to other ones. However, I recommend that you read the guidelines in the given order, but you can also choose the guidelines or chapters that interest you the most. \nThe first chapter is an introduction of the C++ language. You will learn that C++ is not only a single language, but a multiparadigm programming language. The book will also show some errors that should be avoided when we are used to the C programming language. \nThe second chapter focuses on the constructors, the destructors and the assignment operators. Indeed, there are several rules that should be followed when declaring those things for a class, especially when talking about inheritance. For example, this chapter will teach you how and why to prevent exceptions from leaving destructors. This chapter will also talk about the copy constructors. \nIn the next chapter, you'll learn how to manage resources in the right way. You'll be introduced to the use of objects to manage a resource, to the RAII (Resource Acquisition Is Initialization) principle and the different forms of the new and delete operators. The point of storing newed (dynamically allocated) objects is also addressed. \nThe fourth chapter is about designs and declarations. Basically, you'll learn how to declare interfaces that are easy to use in the right way (and hard to use incorrectly, as the author says). More than just interfaces, you'll see how to treat class design as type design, so that your classes can be used like any other type in your C++ code (overlading operators is a way to achieve this goal). You'll also learn how to declare a good function signature that can be used without any problem. \nNow that you know how to declare a good interface or a type, it's time to implement it. In the Implementation chapter, you'll see how to declare variables in the right way and how to avoid excessive casting. An important part of this chapter is the management of exceptions in your functions. Namely, you'll learn what are the different exception-safety levels for the functions and how to provide the best levels for your functions. \nThe next chapter is focused on inheritance and object-oriented design. You'll learn when and how to use inhenritance in your classes and how to avoid virtual functions when it is possible by several ways and patterns that are proposed by the author. The chapter shows also that some things are not meant to be inherited and that multiple inheritance should be used judiciously. \nThe seventh chapter talks about templates and generic programming. Compile-time polymorphisme will be addressed. After the reading of this chapter, you'll knwo how to declare and define a good function template. You'll also know how to use traits classes to get information about types at runtime. Last but not least, this chapter contains also an introduction about Template Metaprogramming (TMP). \nThe eighth chapter will teach you how customize the new and delete operators to reach your needs in memory management. This is the most specific chapters of the book and it won't be useful to everyone, but that's interesting to read it once to know what happens in the background. \nFinally, the last chapter contains miscelleanous items, especially what libraries you should try to familiarize you with to improve your code even more or to avoid reinventing the wheel. \nIn my opinion, this book is a must-have for every beginner and medium C++ developers. All the guidelines will help you produce a better code and to avoid the most common traps that this language contains. I'm sure that after the reading of this book, your code will improve greatly.", 
      "tags": "Books,C++"
    }, 
    {
      "loc": "/posts/2011/09/profile-c-application-with-callgrind-kcachegrind.html", 
      "title": "How to profile C++ application with Callgrind / KCacheGrind", 
      "text": "I have shown before how to profile a C++ application using the Linux perf tools. \u00a0In this post, we will see how to profile the same kind of\u00a0application\u00a0using Callgrind. Callgrind is a tool in part of the Valgrind toolchain. It is running in Valgrind framework. The principle is not the same. When you use Callgrind to profile an application, your application is transformed in an intermediate language and then ran in a virtual processor emulated by valgrind. This has a huge run-time overhead, but the precision is really good and your profiling data is complete. An application running in Callgrind can be 10 to 50 times slower than normally.\nThe output of Callgrind is flat cal graph that is not really usable directly. In this post, we will use KCachegrind to display the informations about the profiling of the analyzed application.\n\n\nInstallation\n\nFirst of all, you need to install Callgrind and KCachegrind. You also need to install graphviz in order to view the call graph in KCachegrind. The applications are already packaged for the most important Linux distributions. You can just use apt-get to install them:\nsudo apt-get install valgrind kcachegrind graphviz\n\nor aptitude:\nsudo aptitude install valgrind kcachegrind graphviz\n\nor whatever your favourite package manager is.\nUsage\n\nWe have to start by profiling the application with Callgrind. To profile an application with Callgrind, you just have to prepend the Callgrind invocation in front of your normal program invocation:\nvalgrind --tool=callgrind program [program_options]\n\nThe result will be stored in a callgrind.out.XXX file where XXX will be the process identifier. \nYou can read this file using a text editor, but it won't be very useful because it's very cryptic. That's here that KCacheGrind will be useful. You can launch KCacheGrind using command line or in the program menu if your system installed it here. Then, you have to open your profile file. \nThe first view present a list of all the profiled functions. You can see the inclusive and the self cost of each function and the location of each one. \n\nOnce you click on a function, the other views are filled with information. The view in uppper right part of the window gives some information about the selected function. \n\nThe view have several tabs presenting different information: \n\n    Types : Present the types of events that have been recorded. In our case, it's not really interesting, it's just the number of instructions fetch\n    Callers : List of the direct callers\n    All Callers : List of all the callers, it seems the callers and the callers of the callers\n    Callee Map : A map of the callee, personally, I do not really understand this view, but it's a kind of call graph representing the cost of the functions\n    Source code : The source code of the function if the application has been compiled with the debug symbol\n\n\nAnd finally, you have another view with data about the selected function. \n\nAgain, several tabs: \n\n    Callees : The direct callees of the function\n    Call Graph : The call graph from the function to the end\n    All Callees : All the callees and the callees of the callees\n    Caller Map : The map of the caller, again not really understandable for me\n    Machine Code : The machine code of the function if the application has been profiled with --dump-instr=yes option\n\n\nYou have also several display options and filter features to find exactly what you want and display it the way you want. \nThe information provided by KCacheGrind can be very useful to find which functions takes too much time or which functions are called too much. \nI hope this article will be useful.", 
      "tags": "C++,Linux,Performances,Tools"
    }, 
    {
      "loc": "/posts/2011/08/compute-metrics-of-c-project-using-cccc.html", 
      "title": "How to compute metrics of C++ project using CCCC", 
      "text": "CCCC (C and C++ Code Counter) is a little command-line tool that generates metrics from the source code of a C or C++ project. The output of the tool is a simple HTML website with information about all your sources.\nCCCC generates not only information about the number of lines of codes for each of your modules, but also complexity metrics like the McCabe Cyclomatic Complexity level of your modules and functions, design metrics like the coupling between the modules or object oriented metrics like the depth of inheritance tree for each of your classes, ...\n\n\nInstallation\nOn some Linux systems, cccc is already packaged, so you just have to use your favourite package manager to install it. On Ubuntu, I used :\nsudo apt-get install cccc\n\n\n\nto install it. If the tool is not packaged for your system, you can download it here. Then, you have run the build script :\nsh build_posixgcc.sh\n\n\n\nand you will find a cccc executable in the cccc folder. You can just put the executable in your path or use it using the absolute path. \nUsage\n\nThe usage of the tool is really easy. You just have to invoke it passing all the sources files you want to parse as arguments. For example: \ncccc src/*.cpp include/*.hpp\n\n\n\nAnd the site will be generated in a .cccc folder in the current folder. You can also specify the output directory using the --outdir=folder option. \nThe main entry of the HTML generated website is the cccc.html file. You can find plenty of information in this generated website about the verified project. \nYou can find more information about the tool on the official website : http://cccc.sourceforge.net/", 
      "tags": "C++,Linux,Tools"
    }, 
    {
      "loc": "/stories/eddi-compiler-eddic.html", 
      "title": "The EDDI compiler : eddic", 
      "text": "eddic is a compiler I'm writing in C++. This compiler is made for EDDI. It is a programming language I invented especially for this compiler. The language is still basic, but it's close to C in its syntax.\nThe language\nEDDI was first an interpreted language, but I decided to switch to a compiled language in order to learn Linux assembly code. For now, the generated assembly is not really optimized, but I will try to improve it in the same time as my assembly skills.\nAt this time, the EDDI language supports:\n\nseveral types: int, char, bool, strings and structures\ntemplates\nvariables\nMathematical expressions with +-*/% operators\nstring concatenations\nconditional branches if, else, else if\nboolean expressions for branches and loops\nloops: for, foreach and while\narrays, both global and local\nfunction calls\nfunction overloading\narrays\n...\n\nFor now, the generated code is 32 bits or 64 bits.\nBuilding\nA compiler supporting the new standard, C++11, is necessary to build the compiler. The compilation has been tested on GCC 4.7 and CLang 3.1 and greater versions. You need Boost 1.47.0 installed on your computer to build this project.\nYou have to use CMake to build the compiler:\n$ git clone git://github.com/wichtounet/eddic.git\n$ cd eddic\n$ cmake .\n$ make\n\n\n\nUsage\nYou can compile an EDDI source file using the compiler easily. For example, with one of the provided sample:\n$ cd eddic\n$ ./bin/eddic samples/asm.eddi\n\n\n\nThat will create a \"a.out\" file in the current folder. You can then run this file as any other executable on your computer:\n./a.out\n\n\n\nCompilation model\nThe compilation of EDDI Source file to assembly code is made in several phases. You can have a description of the architecture on the wiki.\nMore information about the EDDI compiler\nThe EDDI compiler is available on GitHub under the Boost Software License 1.0:\u00a0eddic.\nThe ChangeLog of each version of eddic is available on Github.\nAll the posts about the EDDI compiler", 
      "tags": ""
    }, 
    {
      "loc": "/posts/2011/07/java-7-has-been-released.html", 
      "title": "Java 7 has been released!", 
      "text": "Five years after Java 6, Oracle has just released Java 7!\nThis is the first release of Java since Oracle bought Sun Microsystems.\nThis new version of Java introduces a lot of new features, but some of the languages new features will be introduced in Java 8 as stated by the \"Plan B\".\nIn this version, there some great new language features, as stated by the JSR 334 :\n\n    Strings in switch\n    Binary integral literals and underscores in numeric literals\n    Multi-catch and more precise rethrow\n    Improved Type Inference for Generic Instance Creation (diamond)\n    try-with-resources statement\n    Simplified Varargs Method Invocation\n\n\nWe will also see the new NIO.2 API (specified by the JSR 203).\nA new bytecode instruction has been added to the virtual machine, InvokeDynamic.\nYou can\u00a0download Java SE 7\u00a0on the Oracle website.\nI think it was time now for Java to have a new version with some refreshing, and it's IMO a good new version that we have now. I just hope that the next version, \u00a0Java 8, will be here in less than five years to give us the closures.", 
      "tags": "Java,Java 7"
    }, 
    {
      "loc": "/posts/2011/07/eddi-0-4-1-loops-and-better-assembly-generation.html", 
      "title": "EDDI 0.4.1 : Loops and better assembly generation", 
      "text": "I just released the 0.4.1 version of the EDDI compiler.\nThis version introduce two kind of loops :\n\nthe while loop\nthe for loop, in its general form with three expressions\n\nMoreover, you can now use parenth in mathematical expressions.\nThat's it for the new features, but the compiler has been greatly improved. Now the scope of variables is managed, so you can have twice the same variables as long as they are not visible at the same time.\nFor the assembly, there have been many improvements. The variables are not stored in a more efficient way, the concatenation of strings has been improved to take less space and other little changes have been made. The Lexer has been rewritten using a Scanner to manage the source file directly so that the error do now give the line and the column of the error source. The Parser and the Compiler itself have had some refactorings, but nothing really big.\nYou can find the compiler on the Github repository :\u00a0https://github.com/wichtounet/eddic\nThe exact version I refer to is the v0.4.1 available in the github tags.\nThe next version will certainly see more loops versions, some assembly refinements and perhaps first kind of function calls. I will also try to escalate the Token information in order to have better reporting when there are\u00a0semantic\u00a0errors. I will also some refactorings in the parse node to have a better integration of the Condition and the StringPool.", 
      "tags": "Assembly,C++,EDDI,Releases"
    }, 
    {
      "loc": "/posts/2011/07/eddi-0-4-native-compilation-swap.html", 
      "title": "EDDI 0.4 : Native compilation and swap operator", 
      "text": "The version 0.4 of EDDI is released. \nThere is only one new feature, the swap operator () to swap two variables together, but the biggest news is that now EDDI is not anymore an interpreted language, but is a compiled language. \nIn fact, I rewritten the compiler in order to output Linux assembly code. For now the code is only 32 bits, but I plan to support 64 as well. I made that change in order to not having to write a virtual machine and in order to learn assembly as well. The current outputted assembly code is not really optimized and there will certainly be a lot of changes. Indeed, in order to simplify the switch to native compiler, I continued using stack operations, so that the numeric computations have a lot have a lot of stack operations in it. Moreover, I'm far from being a professional in assembly, so that, they can beginner's errors in the generated code. \nI use as to compile the assembly and then gcc to link. I will try to not depend on gcc, but it seems to be difficult if I want to use malloc (used for the string concatenation). \nYou can download the sources and find some information on the GitHub repository : https://github.com/wichtounet/eddic/ (check the tag v0.4 if you want the exact version I refer in this post). \nDo not hesitate to send me your comments about the C++ code, the design or the outputted assembly. \nThe first version will see loops integrated, certainly some assembly optimizations and some code refactorings I planned.", 
      "tags": "Assembly,C++,EDDI,Intel,Releases"
    }, 
    {
      "loc": "/posts/2011/07/profile-applications-linux-perf-tools.html", 
      "title": "How to profile your applications using the Linux perf tools", 
      "text": "When an application encounters some performance issues, we have to find the code that causes the problem to optimize only what really matters. \nTo find the code we have to optimize, the profilers are really useful. In this post, we'll use the Linux perf tools to profile a simple C++ application. \nThe perf tools are integrated in the Linux kernel since the 2.6 version. The perf tools are based on the perf events subsystem. The perf profiler uses hardware counters to profile the application. The result of this profiler are really precise and because it is not doing instrumentation  of the code, it is really fast. \n\n\nInstallation\n\nFirst of all, if it is not already done, you have to install the perf tools on your computer. On Ubuntu, you can just use apt-get to install it : \nsudo apt-get install linux-tools\n\nOn the other systems, just use your favorite package manager to install the perf tools. \nUsage\n\nTo profile an application, you have to record information about an executation, for that, you just have to use perf record : \nperf record program [program_options]\n\nFor example : \nperf record eddic assembly.eddi\n\nOnce the execution is over, perf will gives you some information about the record, like: \n[ perf record: Woken up 44 times to write data ]\n\n[ perf record: Captured and wrote 11.483 MB perf.data (~501721 samples) ]\n\nIf you see that the size of the perf.data is really small, generally for small execution time, you can configure the event period in order to have more information with the --count=period option using a small period. I usually uses 1000, but it can be useful to use a smaller number when the application has a short execution time. \nThen, to see the list of the most costly functions, you just have to use perf report : \nperf report\n\nIt will display a list of the most costly functions ordered by cost. Here is an example taken from one of my C++ applications (the length of the function names is reduced to fit the screen) here : \n# Events: 374K cycles\n#\n# Overhead         Command             Shared Object                                                                                                                               \n# ........  ..............  ........................  ...............................................................\n#\n    87.58%        inlining  [vesafb]                  [k] 0xffffffff81100700\n    83.27%         readelf  [vesafb]                  [k] 0xffffffff815c3930\n    41.40%              sh  [vesafb]                  [k] 0xffffffff815c3930\n    37.74%        inlining  libstdc++.so.6.0.14       [.] 0x653e0         \n    12.49%         readelf  libc-2.13.so              [.] vfprintf\n     5.37%        inlining  inlining                  [.] parseFunction(std::string, std::string, std::map\n     5.20%         readelf  libc-2.13.so              [.] _IO_new_file_xsputn\n     4.50%         readelf  readelf                   [.] 0x150e          \n     4.10%        inlining  libc-2.13.so              [.] _int_malloc\n     4.01%        inlining  libc-2.13.so              [.] memcpy\n     3.80%         readelf  libc-2.13.so              [.] ___printf_chk\n     2.58%        inlining  libc-2.13.so              [.] __malloc\n     1.86%        inlining  libc-2.13.so              [.] _IO_fgets\n     1.84%        inlining  inlining                  [.] parseExecutable(std::string, std::set\n     1.83%         readelf  libc-2.13.so              [.] __strchrnul\n     1.83%        inlining  libc-2.13.so              [.] _int_free\n     1.77%        inlining  libc-2.13.so              [.] __strlen_sse42\n     1.50%        inlining  libc-2.13.so              [.] cfree\n     1.48%        inlining  libc-2.13.so              [.] __memchr\n     1.23%        inlining  inlining                  [.] parseLibrary(std::string, std::se\n     1.19%        inlining  libboost_graph.so.1.46.1  [.] char* std::string::_S_construct(char const*)\n     1.17%         readelf  libc-2.13.so              [.] __dcigettext\n     1.15%        inlining  libc-2.13.so              [.] _IO_getline_info_internal\n\nFor every functions, you have the information about the cost of the function, the command used to launch it and the shared object in which the function is located. You can navigate through the list like in more utility. \nThis tool can be really useful to see which functions is interesting to optimize in order to increase the overall performance of the application. \nFor more information about the perf tools, you can read the perf wiki\nIn a future article, I will talk about another profiler, Callgrind.", 
      "tags": "C++,Linux,Performances,Tools"
    }, 
    {
      "loc": "/posts/2011/07/eddi-0-3-branches-conditions.html", 
      "title": "EDDI 0.3 - Branches and conditions if, else if, else", 
      "text": "I just pushed a new version of EDDI on the Git repository : EDDI 0.3\nThis new version adds a new big features : Branches and condition. You can now use else / else if / else statements in EDDI code. So that a code like that will be executed :\nif(3 > 2){\n    Print(\"That's true. \");\n}\n\nif(2 < 1){\n    Print(\"Try again\");\n} else {\n    Print(\"Good job\");\n}\n\nif(2 > 3){\n    Print(\"Not correct...\");\n} else if(6 > 3){ \n    Print(\"Right\");\n}\n\n\n\nand will give an output like this one : \n\nThat's true. \nGood job\nRight\n\n\nNow, there is no optimization made on the branches or the condition. I'm planning to make optimization when the condition doesn't depend on a variable so that I can automatically chose the good branch to execute. \nTo implement that branches, I use a common system with jumps and labels. The labels are special bytecode instructions read by the virtual machine and indicating the address of the next instruction. The condition are putting a 1 or a 0 on the stack and the JUMP_IF_NOT bytecode jump if there is a zero on the stack. \nFor the next feature of the language, I plan to add a for loop. But I'm currently thinking of stopping the development of the virtual machine and output directly assembly code instead of bytecode. Because I want to concentrate on the compiler and I don't care about portability in this particular case. Moreover, this will force me to learn deeply assembly code and enable me to make more optimization. But nothing is sure at this moment. \nThe sources are available on Github : \n\n    The compiler, eddic : https://github.com/wichtounet/eddic/\n    The virtual machine, eddivm : https://github.com/wichtounet/eddivm/\n    A commons library used by the two projects : https://github.com/wichtounet/eddi-commons/\n\n\nIf you want to see the exact version reffered to in this subject, you can select the tag v0.3", 
      "tags": "C++,EDDI,Releases"
    }, 
    {
      "loc": "/posts/2011/06/book-review-accelerated-cpp.html", 
      "title": "Book Review : Accelerated C++", 
      "text": "Because I started a project in C++ and had not a lot of knowledges about this language, I bought some books and just finished the first : Accelerated C++, written by Andrew Koenig and Barbara E. Moo\nThis book, as its name indicates, will not tell you anything about C++. It will teach you everything you need to know when starting developing applications in C++. As the authors said : \nyou need to know everything in this book - even tough this book doesn't tell you everything you need to know\n\nThis book is a really good book for people wanting to learn C++ quickly having knowledge in another language. It's not a good book if it's you first programming language, it will not tell you how to write a if/else statement. \nThis book takes a practical approach. For every notion you'll learn in the book, you practice it using some examples, improved chapter after chapter. Each chapter is also finished with a set of exercises that you can solve if you want to practice directly. In every chapter, you'll learn how to use the standard library utilities to makes coding easier, it's a really good point. \nYou'll start working with strings in a simple example project, then improve the project using the STL containers and algorithms. The sequential and the associative containers are studied. After using the generic functions from the STL, you'll write your own generic functions using templates. Once you got the basis, the authors teach you how to define your own types. You will then learn how to manage memory, More than defining types, you also will be able to write abstract types and use inheritance to solve problems. The authors will also show you a way to manage memory (almost) automatically using handles (smart pointers). And finally, you will revisit the first example improving it by using everything you learned so far. \nTo conclude, I have to say that this book is really a good one and I recommend it for every developer that want to switch from another language to C++", 
      "tags": "Books,C++"
    }, 
    {
      "loc": "/posts/2011/06/no-more-ads-on-the-site.html", 
      "title": "No more ads on the site !", 
      "text": "Hi,\nAs you have perhaps noticed, there is no more Google Adsense on the site. I removed them for several reasons :\n\n    They were not really visually good\n    They slowed down the site by a factor of two\n    That gave a bad image of the site\n    This is not the main goal of the website to make money\n    They didn't made enough money to counter the previous disadvantages\n\nSo you will now have a faster and a bit nicer website to look at :)\nThe only page that contains ads on the site is the search because of the use of Google Custom Search that includes Google Ads, but this is not my ads. I will perhaps consider to add another search system in the future.\nI hope this will make the site more enjoyable\nP.S. Is there is still a page with ads that I have forgotten to update, just let a comment with the URL of the page and I will remove the ads", 
      "tags": "Google,Personal,The site,Web"
    }, 
    {
      "loc": "/posts/2011/06/eddi-0-2-1-integer-operations-and-optimizations.html", 
      "title": "EDDI 0.2.1 : Integer operations and optimizations", 
      "text": "I've introduced a new feature in EDDI. You can now make computations on integers and string concatenations. \nSo you can now write this kind of thing with EDDI : \nint i = 4 + 2 * 2;\nint j = i + 5 % 6 / 3 * 4;\nPrint(i + 2);\nPrint(j % i);\n\n\n\nAdding computations has not been very difficult. The difficult thing has been to find a way to mange operators priorities. For now, I'm not really satisfied with the result, but it works. I will try to think of another way to make that in the future. \nI've also introduced the first compile-time optimizations. When a computation is known to be constant a compile time, the computation is directly replaced with its result. \nThe next step will be to introduce branches and loops. \nThe sources are available on Github : \n\n    The compiler, eddic : https://github.com/wichtounet/eddic/\n    The virtual machine, eddivm : https://github.com/wichtounet/eddivm/\n    A commons library used by the two projects : https://github.com/wichtounet/eddi-commons/\n\n\nIf you want to see the exact version reffered to in this subject, you can select the tag v0.2.1", 
      "tags": "C++,EDDI,Releases"
    }, 
    {
      "loc": "/posts/2011/06/eddi-0-2-types-and-variables.html", 
      "title": "EDDI 0.2 : Integers and variables", 
      "text": "I just pushed the last commits of Eddi 0.2. \nThis new version allows the use of integers. You can declare int variables and pass int values or variables to the Print operation. \nI've also refactored the compiled to use a kind of parse tree and several phases. But now, I'm not really satisfied with the design. The classes are too strongly coupled and the parse tree is too specific I think, too many assumptions are made during the semantical analysis. But now, I don't know how to improve that. I also think that the design and the operations will not support some more advanced adds later, I don't know... Don't hesitate if you have any idea or comment on the design :)\nI've also made some changes to the Lexer in order to improve the performances, but nothing spectacular. \nYou can now compile this kind of code with Eddi : \nint a = 1;\nstring b = \"asdf\";\nPrint(1);\nPrint(\"Test\");\nPrint(a);\nPrint(b);\nb = \"new b\";\nPrinb(b);\n\n\n\nThe next changes will be to add operations on int and perhaps also the concat on two stirngs. I will see. I will also try to improve the design of the compiler if I found some ideas. \nThe sources are available on Github : \n\n    The compiler, eddic : https://github.com/wichtounet/eddic/\n    The virtual machine, eddivm : https://github.com/wichtounet/eddivm/\n    A commons library used by the two projects : https://github.com/wichtounet/eddi-commons/\n\nIf you want to see the exact version reffered to in this subject, you can select the tag v0.2", 
      "tags": "C++,EDDI,Releases"
    }, 
    {
      "loc": "/posts/2011/06/install-specific-version-gcc-ubuntu.html", 
      "title": "How to install a specific version of GCC on Ubuntu 11.04 (natty)", 
      "text": "Sometimes you need to install a specific version of gcc for some reasons, for example when you need to have the same compiler version as the one used by your team. \nIn that, the package manager doesn't help because not every version of gcc is packaged in every version of Ubuntu. So you must install it by hand and it can take a little time and there is some things that has to be done in order to work. \nI'm talking here of Ubuntu 11.04 (natty), because this is the version I installed Ubuntu on. This procedure will certainly work but you could have a problem with some dependencies that are installed in natty and not in your version or in the contrary have a dependency already installed. \nSo this article will detail every step to install a specific version of gcc \n\n\nPersonally, I've made the whole installation from the folder ~/dev/ . You can use this folder or use another one, but I recommend to you use an empty folder for that. When I will talk about the installation, I will refer to this folder.  \nNote 1 : Because I wanted this new gcc to be my main compiler, I've directly installed everything in /usr/local/. If you want to install it in a specific folder, you can use the --prefix=FOLDER option fo the ./configure command. If you make so, you don't have to use the sudo before the make install unless you choose another directory where you don't have the right to write in. \nNote 2 : If you have a multicore processor, you should use the -jX option with make where X is your number of core (you can make it +1). \nBuilding gcc requires several libraries that are not installed by default. Let's start with GNU Multiple Precision Library (GMP). You can download the latest version (5.0.2 now) here : http://gmplib.org/ . Decompress the library in your installation folder and then use the followings commands : \ncd gmp_dir\n./configure\nmake\nmake check\nsudo make install\n\nYou should have a message indicating that the libraries have been installed in your folder. \nAfter that, you can install the GNU MPFR library (version 3.0.1 now), available here : http://www.mpfr.org/mpfr-current/#download . Unzip the file in your installation folder and type the following commands : \ncd mpfr_dir\n./configure\nmake\nmake check\nsudo make install\n\nYou should see the same confirmation message than for the last installation. Then, you can install the last library, MPC (version 0.9 now), that you can download here : http://www.multiprecision.org/index.php?prog=mpc&page=download . Once again, unzip the file and your installation folder and launch the same commands : \ncd mpfr_dir\n./configure\nmake\nmake check\nsudo make install\n\nSame confirmation message. \nTo prepare the installation of gcc, you have to type the given two commands : \nexport C_INCLUDE_PATH=/usr/include/x86_64-linux-gnu \nexport CPLUS_INCLUDE_PATH=/usr/include/x86_64-linux-gnu \n\nHere we are, you are ready to install gcc. Download the version you want to install here : http://gcc.gnu.org/releases.html and extract it on your installation folder. \nNote : for those who have installed the first three libraries in different folder you have to indicate to ./configure where they are using the given command line options : --with-gmp=FOLDER, --with-mpfr=FOLDER and --with-mpg=FOLDER\nNote : I installed gcc for C and C++, if you want to select other languages just tune the --enable-languages option and if you want every language, just remove this option. \nThen create a directory on the same level as gcc sources dir : \ncd installation_folder\nmkdir build\ncd build\n\nand now from this folder, we can install everything : \n../gcc_dir/configure --enable-languages=c,c++\nmake\nsudo make install\n\nNow it's time to take a coffee (or even two), because the full compilation can take a lot of time. \nWhen the compilation is finished, you can try it with this command \ngcc --version\n\nthat should give you the version you just installed. If it is not the case, verify that you did every step and if it's the case, take a look at the official installation guide", 
      "tags": "C++,gcc,Linux"
    }, 
    {
      "loc": "/posts/2011/06/introduce-variables-on-eddi.html", 
      "title": "EDDI 0.1.1 : Variables", 
      "text": "The version 0.1.1 of EDDI is now available. \nThis new version introduce the feature to put variable on the code. You can now write things like that : \na = \"Variable a\";\nb = \"Variable b\";\nPrint(a);\nPrint(b);\n\n\n\nAnd you can also reassign value to a variable and assign the value of a variable to another : \na = b;\nb = \"New variable b\";\n\n\n\nNothing extraordinary, but it's a start. The variable name are compiled into integers and a table of variable has been made on the virtual machine. \nThe last step will be to introduce a new type : the integers. But for this integration, I'm not exactly sure on how to do that. I will certainly create a string pool and put only references to the strings on the stack, but it's not clearly defined. Don't hesitate if you have any comment :)\nThe project is available on Github : \n\n    The compiler, eddic : https://github.com/wichtounet/eddic/\n    The virtual machine, eddivm : https://github.com/wichtounet/eddivm/\n    A commons library used by the two projects : https://github.com/wichtounet/eddi-commons/\n\nIf you want to see the exact version reffered to in this subject, you can select the tag v0.1.1.", 
      "tags": "C++,EDDI,Releases"
    }, 
    {
      "loc": "/posts/2011/06/git-tip-restore-a-deleted-tag.html", 
      "title": "Git Tip : Restore a deleted tag", 
      "text": "A little tip that can be very useful, how to restore a deleted Git tag. \nIf you juste deleted a tag by error, you can easily restore it following these steps. First, use\ngit fsck --unreachable | grep tag\n\nthen, you will see the unreachable tag. If you have several tags on the list, use \ngit show KEY\n\nto found the good tag and finally, when you know which tag to restore, use\ngit update-ref refs/tags/NAME KEY\n\nand the previously deleted tag with restore with NAME. \nThanks to Shawn Pearce for the tip.", 
      "tags": "Git,Others,Tips"
    }, 
    {
      "loc": "/posts/2011/06/write-and-read-binary-files-in-c.html", 
      "title": "Write and read binary files in C++", 
      "text": "To write the EDDI compiler, I had to write and read binary files. Writing text files is really easy in C++, directly using the << operator on the stream, but writing binary is a little harder and, I must say, a lot less elegant.\nFirst, to write to a binary file, we have to use the binary flag when we create the file :\nstd::ofstream stream(\"yourFile\", std::ios::binary);\n\n\n\nand then, we have to use the write method to write to the file. But this function is really basic and takes only a char and the size of the data we wan't to write, so we have to convert our data to char. A good way to do that is using the reinterpret_cast function and the sizeof operator. For example, to write an int, you can make that :\nint test = 22;\noutStream.write(reinterpret_cast<const char*>(&test), sizeof(int));\n\n\n\nBut your code is quickly polluted if you have of write operations to do.\n\n\nWe can simplify that, using a function template like this one :\ntemplate<typename T>\nstd::ostream& binary_write(std::ostream& stream, const T& value){\n    return stream.write(reinterpret_cast<const char*>(&value), sizeof(T));\n}\n\n\n\nAnd you use it directly like that :\nint test = 22;\nbinary_write(stream, test);\n\n\n\nA little less verbose, isn't it ? You can also pass a class or struct instance directly tot his method. If you have complex objects, it's perhaps not the more proper way to do it, in that case, consider using some serialization API. If you have object with variable length, it will not work because the size cannot be computed with the sizeof operator. For example, this function doesn't work with a std::string because the sizeof operator doesn't represent the real size of the string. We can make another function to write string :\ntemplate<>\nstd::ostream& binary_write_string(std::ofstream& stream, const std::string& value){\n    return stream->write(value.c_str(), value.length());\n}\n\n\n\nThen, to read a binary, you have also to open it with the binary tag :\nstd::ifstream inStream(\"yourFile\", std::ios::binary);\n\n\n\nAnd then, you have to use the read method to read your values :\nint test;\ninStream.read(reinterpret_cast<char*>(&test), sizeof(int));\n\n\n\nOnce again, we can create a function template to have a little better code :\ntemplate<typename T>\nstd::istream & binary_read(std::istream& stream, T& value){\n    return stream.read(reinterpret_cast<char*>(&value), sizeof(T));\n}\n\n\n\nand you can use it the same way :\nint test;\nbinary_read(stream, test);\n\n\n\nOnce again, this function will not work with the class or struct with variable size. Even with strings, there is no way to read them easily. If you want to read them, you'll have to write the size of the string directly in the file and then read the size before and you can read a char using the read method passing the size of the string and create a new string using the char.\nWith that, you are able to read and write to and from binary files.", 
      "tags": "C++,I/O,templates"
    }, 
    {
      "loc": "/posts/2011/06/eddi-new-programming-language.html", 
      "title": "EDDI : A new programming language project", 
      "text": "The project I'm working on for my Bachelor thesis is a C++ project. I've never worked on a big C++ project, so I decided to start a personal project in C++. \nI wanted to develop my own language for a long time now. So I chose to develop a new language : EDDI\nBecause I didn't want to write assembly code, EDDI follows the same model as the Java language. The EDDI source files are first compiled into intermediate byteode file and then this compiled file is executed by a virtual machine. \nI didn't use a generator for the lexer and the structural analysis, because I wanted to write these parts by myself, but perhaps in the future I will consider using it, like lex & yacc. \nOf course, I don't write this language to compete with the other programming languages, it's only a way for me to learn C++ better and to improve my skills in general. \nNow, EDDI is only in version 0.1 and you can almost do nothing with this programming language. The only thing you can do with this language is to print strings to the console, but I will continue to work on the compiler and the virtual machine to add new instructions and to improve the compiler and the vm. \nHere is an example of an EDDI program: \nPrint(\"Hello World\");\n\n\n\nAnd this program is compiled like this: \nHEADER\nPUSH S13Hello World\nPRINT\nEXIT\n\nThe result doesn't appear like that in the compiled file because the output is made in binary files but this correspond to the EDDI bytecode instructions. \nAs you can see, I used a stack system. The PUSH instruction add something on the stack and the PRINT instruction pop the head of the stack and print it. \nThis project is distributed under the Boost Software License 1.0. The sources of the project are available on Github : \n\n    The compiler, eddic : https://github.com/wichtounet/eddic/\n    The virtual machine, eddivm : https://github.com/wichtounet/eddivm/\n    A commons library used by the two projects : https://github.com/wichtounet/eddi-commons/\n\n\nIf you want to see the exact version reffered to in this subject, you can select the tag v0.1. \nI'm open to any kind of comments regarding the project, the source code or anything else related to EDDI. \nI'll try to post some informations about my work on this project on this blog, the decisions made, the technical challenges, ...\nFor those who are interested on the origins of the name, it comes from EDsger Wybe DIjkstra, the famous computer scientist.", 
      "tags": "C++,EDDI,Releases"
    }, 
    {
      "loc": "/posts/2011/06/upload-files-to-ftp-using-bash.html", 
      "title": "Upload files to FTP using Bash", 
      "text": "This morning, I wanted to automatically update a little website from my computer without using Filezilla. So I searched a little bit and found that there is a very useful tool called nftp. To install it, you only have to use apt-get : \nsudo apt-get install ncftp\n\nThis tool can be used directly from bash to upload files to FTP (and also to get files of course). \nIn my case, I just have to put a complete hierarchy of files into a specific folder of my website. So I wrote a little script that put everything on the FTP server : \nread -s -p \"Enter Password: \" mypassword\nncftp <<EOF\nopen -u username -p $mypassword yoursitehost\ncd \"folder on the website\"\nlcd \"folder on the computer\"\nput -R *\nbye\nEOF\n\nThis script asks you your password. With that, you don't have to put it in clear inside your program. The most important command here is the put -R * that make a recursive upload of the current folder in the current remote folder. \nIf I launch it from my computer (using the good values of course), it gives me that : \n$ bash website.sh\nNcFTP 3.2.4 (Apr 07, 2010) by Mike Gleason (http://www.NcFTP.com/contact/).\nCopyright (c) 1992-2009 by Mike Gleason.\nAll rights reserved.\nConnecting to 74.208.211.161...                                                 \nFTP Server ready.\nLogging in...                                                                   \nUser username logged in\nLogged in to baptiste-wicht.com.                                                \ndocs/report.pdf:                                        39.92 kB   79.26 kB/s  \ndocs/requirements.pdf:                                  40.60 kB   80.91 kB/s  \ndocs/logbook.pdf:                                       32.39 kB   64.34 kB/s  \ndocs/week1.pdf:                                         32.13 kB   64.05 kB/s  \ndocs/01.06.2011.pdf:                                    34.77 kB   69.26 kB/s  \ndocuments.php:                                         869.00 B    6.72 kB/s  \nfooter.php:                                             99.00 B   45.00 B/s   \nheader.php:                                            851.00 B  151.56 B/s   \nindex.php:                                             230.00 B   37.11 B/s   \nlinks.php:                                             188.00 B   37.73 B/s   \nminutes.php:                                           254.00 B    1.96 kB/s  \nstyles/default.css:                                      1.00 kB    8.01 kB/s  \nweeks.php:                                             237.00 B   65.24 B/s\n\nYou will see the current status of all the files during the upload. The tool is enough smart to detect if a file must be sent or not (so it upload only newer files). \nI hope this can help some of you.", 
      "tags": "Linux,Web"
    }, 
    {
      "loc": "/posts/2011/06/this-website-is-now-running-wordpress-3-1-3.html", 
      "title": "This website is now running WordPress 3.1.3", 
      "text": "I just made the update of this website to WordPress 3.1.3. \nI've had no problems with the update. But at the start the automatic updater throws me an Out Of Memory Error. But after disabling all my plugins, the automatic update had no problem to update my entire website without any errors :)\nDon't hesitate to contact me (in the comments or via the contact form) if you found any problem on the website.", 
      "tags": "The site,Web,WordPress"
    }, 
    {
      "loc": "/posts/2011/06/solve-file-param-is-missing-problem-of-w3-total-cache.html", 
      "title": "Solve \"File param is missing\" problem of W3 Total Cache", 
      "text": "As you may have seen, my website had not CSS these last days. \nThis was due to a bug in the W3 Total Cache plugin of Wordpress. The minified CSS file wasn't accessible. When we tried to access it from the site, there was an error : \"File param is missing\"\nThere is an easy solution to solve this problem. You just have to disable the \"Rewrite URL structure\" option on the Minify tab in the W3 Total Cache options. This will solve the problems. The only issue with this solution, is that you will not have fancy links for your CSS and JS minified files, but I think it's a really little problem comparing to the lack of CSS :)\nHope this will be helpful to some of you.", 
      "tags": "Performances,The site,Web,WordPress"
    }, 
    {
      "loc": "/posts/2011/05/avoid-scrolling-problems-in-kile-when-using-gnome.html", 
      "title": "How to solve scrolling problems in Kile when using Gnome", 
      "text": "From this morning, I was encoutering problems when scrolling in Kile editor using Gnome. When I scrolled, not all the lines were moving and the text was only correct when I clicked on them... \nAfter some researches, I found that the solution was to use a different graphics system. You can do that in any Qt applicaitions using the graphics-system command line option. You can choose between raster and opengl. opengl is supposed to be the fastest one, but it is still experimental. In my case, I use raster that solve the scrolling problems and it doesn't change anything, which is fine. \nSo you can use this command-line to start Kile : \nkile --graphicssystem raster\n\nAnd that will solve your scrolling problems if you encounter some. You can also use this tip to improve performances of Kile if you need. If you do, test with opengl and if it's not stable on your system, choose raster, that will improve the performance compared to the default graphics system.", 
      "tags": "Latex,Tips,Linux"
    }, 
    {
      "loc": "/posts/2011/05/now-writing-from-berkeley-california.html", 
      "title": "Now writing from Berkeley, California", 
      "text": "Hi, \nThis message has been written from California, where I'm for 3 months. I'm making my bachelor final project in Berkeley Labs. \nI'll certainly give some informations about the project and my researches during the next months. \nI hope that I'll have the time to write more articles this next months as I've made the last months... I had a lot of work at school and no motivation to write.", 
      "tags": "Others,Personal,The site"
    }, 
    {
      "loc": "/posts/2011/01/using-linq-to-query-sharepoint-lists.html", 
      "title": "Using LINQ to query Sharepoint lists", 
      "text": "When I started using Sharepoint 2010 with .NET, I used the Sharepoint 2010 API to query the Sharepoint Lists, but when I come with lookup column with multiple values, it started to be really difficult to use.\nSo I found that I can use LINQ to query Sharepoint lists and for what I saw on the internet, it was really simple to use. LINQ provide a complete API to query data and to update them. More than that, LINQ is also able to do mapping object-relational, what is really helpful in code lisibility.\nIn this code, I will take as example a Sharepoint site with two lists :\n\n    departments : only a Title column\n    projects : Title, year, nbstudents and department, a lookup column to departments with multiple values\n\n\nSo first of all, you need to create the entities and the data context, but you don't have to do it by hand. There is a tool that make all that for you, SPMetal.\n\n\nOpen a command line and cd to \"C:\\Program Files\\Common Files\\Microsoft Shared\\Web Server Extensions\\14\\bin\", and then you can use the following command :\nSPMetal.exe /web:http://localhost/ /code:C:\\Projects.cs\n\nYou can use the URL of your Sharepoint site and you can change the name of the C# file. This will generate a long file containing the DataContext and the mapping objects. Here is a part of the code I get in this file :\npublic partial class ProjectsDataContext : Microsoft.SharePoint.Linq.DataContext {\n\n    #region Extensibility Method Definitions\n    partial void OnCreated();\n    #endregion\n\n    public ProjectsDataContext(string requestUrl) : this(requestUrl, true) {\n\n    }\n\n    public ProjectsDataContext(string requestUrl, Boolean tracking) : base(requestUrl)\n    {\n        this.OnCreated();\n        ObjectTrackingEnabled = tracking;\n    }\n\n    [Microsoft.SharePoint.Linq.ListAttribute(Name=\"departments\")]\n    public Microsoft.SharePoint.Linq.EntityList<item> Departments {\n        get {\n            return this.GetList<item>(\"departments\");\n        }\n    }\n\n        //...\n\n\n\nAdd this file to your Visual Studio Project. You will have some errors because, you must include the reference to LINQ for Sharepoint. Right click the preferences of your project, choose \"Add reference\" and add the Microsoft.SharePoint.Linq.dll and now you're ready to use LINQ for Sharepoint in your project. \nQuery Data\n\nFirst, you can query data using LINQ, by example, getting all the projects : \nusing (ProjectsDataContext context = new ProjectsDataContext(SPContext.Current.Web.Url))\n{\n    var query = from c in context.Projects select c;\n\n    foreach (var project in query)\n    {\n        console.writeLine(\"Title : \" + project.Title.ToString());\n        console.writeLine(\"Year: \" + project.Year.ToString());\n        console.writeLine(\"Nb of students : \" + project.Nbstudents.ToString());\n\n        string str = \"\";\n\n        int index = 0;\n        foreach (Item item in project.Department)\n        {\n            str += index++ &gt; 0 ? \", \" + item.Title : item.Title;\n        }\n\n        console.WriteLine(str);\n    }\n}\n\n\n\nYou can see that it's really simple and a lot easier than the way with Sharepoint API. More than that, the mapping to Object is just great :)\nUpdate Data\n\nYou can also insert data, really easily with LINQ : \nusing (ProjectsDataContext context = new ProjectsDataContext(SPContext.Current.Web.Url))\n{\n    Item department = new Item();\n    department.Title = \"New department\";\n\n    context.Departments.InsertOnSubmit(department);\n\n    context.SubmitChanges();\n}\n\n\n\nTo delete a Data, you can query it and then use DeleteOnSubmit to delete it. To update a data, it's even more simple, you just have to edit the item and then use SubmitChanges() to commit them. \nAs you can see, using LINQ allows you to write code simple, readable and all that faster than if you use Sharepoint API. \nI hope this can be useful to someone.", 
      "tags": "Sharepoint,Visual Studio"
    }, 
    {
      "loc": "/posts/2011/01/export-a-sharepoint-2010-site-as-solution-package.html", 
      "title": "Export a Sharepoint 2010 site as Solution Package", 
      "text": "Hi,\nFrom several days, I started developing with Sharepoint 2010 for a School project. It's not as easy as I thought in my first opinion. So I will try to share some solutions I found with you\nIn Sharepoint 2007, we used Solution Generator to create a wsp file of the site and then we can use this wsp file in Visual Studio for example.\nBut in Sharepoint 2010, you can do it directly in the site administration. Go in Site Settings -> Site action and then choose \"Save site as template\". Then, you just have to provide a name and description and you can save \u00a0the template.\nIn the next view, you have a link to the Solution gallery. Go in this view and then click on your template and you can download the .wsp file.\nIn some cases, we can have some problems during export... Try to create a blank site et add only the things you want to export and then retry.\nWhen you've the wsp file, you can import it in Visual Studio 2010 using New Project -> Import Sharepoint Solution Package. This can take a lot of time to import all the content of the package.\nWith that, you can create things in Sharepoint and then use and edit them in Visual Studio.\nI hope this can be useful to someone.", 
      "tags": "Sharepoint,Visual Studio"
    }, 
    {
      "loc": "/posts/2010/10/jtheque-core-2-1-0-released.html", 
      "title": "JTheque Core 2.1.0 released !", 
      "text": "It's my pleasure to announce that I've finally released JTheque Core 2.1.0 !\nThe different services of the core are now separated using\u00a0OSGi.\u00a0With this separation, I've improved a lot the design of the core and the orthogonality of the different services. Each service is now an OSGi bundle. I've also refactored the implementation of all services. Several services have been completely rewritten. The majority of the bundles are now thread-safe.\nNow, to create modules for a JTheque application, you have to write an OSGi bundle representing the module. Then, you only have to use Spring to launch the module. This is done using Spring Dynamic Modules. The used OSGi container is Felix.\nNow that this version of the core is finalized, I'll updates the applications. First of all, JTheque Movies with the new version of the core.\nFore more informations and to download JTheque Core, you can go on\u00a0the description page. If you want to try developing a module (or see how it is done), you can consult\u00a0this starter guide.", 
      "tags": "Java,JTheque,Modular,OSGi,Releases,Spring"
    }, 
    {
      "loc": "/posts/2010/10/compute-command-line-arguments-with-apache-commons-cli.html", 
      "title": "Compute command-line arguments with Apache Commons CLI", 
      "text": "For a project at school, I needed to refactor an old code parsing almost 30 command line arguments. I needed to add some more arguments and change some old args, but the old code was not maintainable at all. So I decided to use a library to make the parsing. of the args. \nI chose Apache Commons CLI. This is a really simple library to make that parsing. It's not perfect, but it makes the work I needed and is powerful to do that job. \nWith this API, you have to declare an Options instance. This class is used to describe the command line arguments of the program. Options constructor don't take any arguments. \nOptions options = new Options();\n\n\n\n\n\nThen you have to use the addOption methods to add some arguments to the application. There is three versions of the methods : \n\n    addOption(Option opt) : Add an option of the class Option. \n    addOption(String opt, boolean hasArg, String description) : Add a new option to the arguments. This option has only a short name. \n    addOption(String opt, String longOpt, boolean hasArg, String description) : Add a new option to the arguments.  The option has a short name and a long name. \n\n\nWe need some explanations here. The short opt is used to define an arg with a simple dash (-shortopt) and the long opt is defined with double dash (--longopt). The hasArg indicate if the parameter accepts an argument. The description is, like its name indicates, the description of the option. It's used to print the help of the program.\nUsing Option instances you can configure all the properties of an option using the setters and the constructor. Here is all the setters that can be used to configure the option : \n\n     void   setArgName(String argName) : The name of the args\n     void   setArgs(int num) : The number of args the option takes\n    void    setDescription(String description) : The description of the option\n     void   setLongOpt(String longOpt) : The long option name\n     void   setOptionalArg(boolean optionalArg) : Indicate if the argument of this option is optional\n     void   setRequired(boolean required) : Indicate if the option is required or not\n    void    setType(Object type) : Set the type of the Option. Here are the supported type : File.class, Number.class, Class.class, Object.class, Url.class\n     void   setValueSeparator(char sep) : Set the value separator, it's used to make a system like the property of Java like -Dmaven.test.skip=true, the separator is = \n\n\nThere is also an other way to create Option instance, using the OptionBuilder class. It's a little weird because all the methods are static and the method returns a reference to the builder. And then you make a call to the builder instance using the static method. The method are equivalent with the methods of the Option class with different names (withXXX, hasXXX, ...). When you have configured the option, you have to call one of the create methods to create the instance and reset the OptionBuilder. \nOnce you filled the Options instance with the arguments of the program, you can use it. You have to use a CommandLineParser to parse the Options. There is three implementation of this interface : \n\n    BasicParser : A very simple parser\n    PosixParser : A parser to parse short options\n    GnuParser : A parser to parse both long and short options\n\n\nA simple example using the GnuParser : \nCommandLineParser parser = new GnuParser();\n\nCommandLine cmd = parser.parse(options, args);\n\n\n\nYou receive a CommandLine object representing all the arguments. The parse() method can throw a ParseException if the given arguments are not valid. With that object, you can get the options that have been passed to the application. For that, you can use the given methods : \n\n    Object  getOptionObject : Return the option value parsed to the specified type\n     Properties getOptionProperties(String opt) \n     String getOptionValue : Return the value of the option\n     String[]   getOptionValues : Return the values of the option\n     Object getParsedOptionValue(String opt)  : Return the option value parsed to the specified type\n     boolean    hasOption : Indicate if the option has been specified or not\n     List   getArgList()  : Return all the args that are not specified args\n     String[]   getArgs() : Return all the args that are not specified args\n\nWith this API, you can also generate the help of the program : \nHelpFormatter formatter = new HelpFormatter();\n\nformatter.printHelp( \"program\", options);\n\n\n\nWith that, you display the list of arguments taken by the program. \nWith that example, we've seen the main features of this library. \nFor more information, you consult the Apache Commons CLI website.", 
      "tags": "Apache,Java,Libraries"
    }, 
    {
      "loc": "/posts/2010/09/the-pragmatic-programmer-book-review.html", 
      "title": "The Pragmatic Programmer - Book Review", 
      "text": "This week, I finished a new book : The Pragmatic Programmer, from journeyman to master, written by Andrew Hunt and David Thomas.\nAccording to the author, reading this book will make you a better programmer, a pragmatic programmer. A pragmatic programmer is a person who loves its work and who always want to improve it. He wants to improve its skills and to learn new technologies. He doesn't only code, he wants to provide better and better code.\nThis book don't focus on any language, it can be useful to programmer of every language.\nI don't advice this book to complete beginners because this book contains a lot of different ideas that can discourage neophyte because of the lot of works they must provide to become a real pragmatic programmer.\nYou will learn several very important things in these books :\n\n    Have a pragmatic philosophy : Assume your responsibilities, don't let broken windows appears, fix issues as they come, make quality software, improve your knowledges, communicate with other persons, ...\n    Adopt a pragmatic approach : Duplication is Hell, Orthogonality is Heaven, use tracer bullets and prototype when starting projects to achieve your objectives\n    Use the good tools : Use good editors, automate all that you can, construct a set of tools for your usage\n    Be paranoiac : design by contract, use exceptions, ...\n    Don't go to deep in your errors\n    Make your code better and better while you're coding, consider the speed of algorithms\n    Before the project, get the good requirements, specify as good as you can\n    Create a pragmatic team\n\n\nLike you can see this book provide a long list of advices, that is not always easy to read and to understand. I've made a lot of pauses, re-reading a passage to have a good understanding of the whole lot.\nI''ve found all the advices very good and interesting and I\u00a0think\u00a0that applying these advices will help me to make better work.\nBut, I must say that some chapters have not aged well. Especially, on tools. The authors advice to use only tools like plain text editor and shell commands. I think that with the power of modern IDE we can save a lot of time.\nBut this little default expected, this book is a great book, a must read book, that every programmer should read once in its life.\nMore informations on the website of the book : http://www.pragprog.com/titles/tpp/the-pragmatic-programmer", 
      "tags": "Books,Others"
    }, 
    {
      "loc": "/posts/2010/09/a-better-swingworker.html", 
      "title": "Swing tip : A better SwingWorker without exception swallowing", 
      "text": "When we develop Swing applications, SwingWorker are very helpful. But there is a big disadvantage using this class. if you don't call get() in the done method, you will lose all the exceptions that the computation in the doInBackground() has thrown. And you action can stop and you will never see why. In 95% of my actions using SwingWorker, the doInBackground() return nothing.\nJonathan Giles has presented on his blog a good solution to solve this exception swallowing. In my side, I've often something to do in the EDT before the doInBackground() run, so I've made the changes on the code presented by Jonathan and it gave me that simple class that I found better than the SwingWorker :\npublic abstract class BetterSwingWorker {\n    private final SwingWorker<Void, Void> worker = new SimpleSwingWorker();\n\n    public void execute() {\n        SwingUtilities.invokeLater(new Runnable() {\n            @Override\n            public void run() {\n                before();\n            }\n        });\n\n        worker.execute();\n    }\n\n    protected void before() {\n        //Nothing by default\n    }\n\n    protected abstract void doInBackground() throws Exception;\n\n    protected abstract void done();\n\n    private class SimpleSwingWorker extends SwingWorker<Void, Void> {\n        @Override\n        protected Void doInBackground() throws Exception {\n            BetterSwingWorker.this.doInBackground();\n\n            return null;\n        }\n\n        @Override\n        protected void done() {\n            try {\n                get();\n            } catch (final InterruptedException ex) {\n                throw new RuntimeException(ex);\n            } catch (final ExecutionException ex) {\n                throw new RuntimeException(ex.getCause());\n            }\n\n            BetterSwingWorker.this.done();\n        }\n    }\n}\n\n\n\nYou can use it as the default SwingWorker. You must implement the doInBackground() and done() methods and you can, only if you want, override the before() method that is invoked in the EDT at the start of the process. And then, you can execute your SwingWorker using execute(). \nI hope this little class can be useful to somebody. \nSource for the non-swallowing swingworker.", 
      "tags": "Java,Swing,Tips"
    }, 
    {
      "loc": "/posts/2010/09/solve-einsteins-riddle-using-prolog.html", 
      "title": "Solve Einstein\u2019s Riddle using Prolog", 
      "text": "This week, we started learning Prolog at school. So to exercise, I choose the Einstein's Riddle. Einstein wrote this riddle in the 19th century. He stated that only 2% of the population can solve it by mind. Personnally, I'm not of this two %, I needed paper and pens to solve it. But this is not the them of the post, so let's use Prolog to solve it. I will present my solution, there is certainly other solutions, and certainly better, but it makes only some days that I started learning this language and this new kind of developing, logical programming. \nHere is the riddle as stated by Einstein :\n\n    In a street there are five houses, painted five different colours.\n    In each house lives a person of different nationality\n    These five homeowners each drink a different kind of beverage, smoke different brand of cigar and keep a different pet.\n\n\nThe question is : Who owns the fish ?\nAnd there are 15 hints :\n\n    The Brit lives in a red house.\n    The Swede keeps dogs as pets.\n    The Dane drinks tea.\n    The Green house is next to, and on the left of the White house.\n    The owner of the Green house drinks coffee.\n    The person who smokes Pall Mall rears birds.\n    The owner of the Yellow house smokes Dunhill.\n    The man living in the centre house drinks milk.\n    The Norwegian lives in the first house.\n    The man who smokes Blends lives next to the one who keeps cats.\n    The man who keeps horses lives next to the man who smokes Dunhill.\n    The man who smokes Blue Master drinks beer.\n    The German smokes Prince.\n    The Norwegian lives next to the blue house.\n    The man who smokes Blends has a neighbour who drinks water.\n\n\nSo let's start with the code !\n\n\nFirst of all, we'll create a list of tuple containing all the informations about a men . The position in the list represent the position of the house in the street. So we'll create a predicate to create the list :\npersons(0, []) :- !.\npersons(N, [(_Men,_Color,_Drink,_Smoke,_Animal)|T]) :- N1 is N-1, persons(N1,T).\n\n\n\nThe first predicate, is to end when the index is 0 and the list is empty. And the second one create a recursive list with N element. Then, I needed a predicate to get the Nth element if corresponding to some informations of the recursive list : \nperson(1, [H|_], H) :- !.\nperson(N, [_|T], R) :- N1 is N-1, person(N1, T, R).\n\n\n\nAgain, the first one is used to stop when we are at the good element. And the second predicate iterate until the good element is found. \nThen, I have translated the hints into predicate : \n% The Brit lives in a red house\nhint1([(brit,red,_, _, _)|_]).\nhint1([_|T]) :- hint1(T).\n% The Swede keeps dogs as pets\nhint2([(swede,_,_,_,dog)|_]).\nhint2([_|T]) :- hint2(T).\n% The Dane drinks tea\nhint3([(dane,_,tea,_,_)|_]).\nhint3([_|T]) :- hint3(T).\n% The Green house is on the left of the White house\nhint4([(_,green,_,_,_),(_,white,_,_,_)|_]).\nhint4([_|T]) :- hint4(T).\n% The owner of the Green house drinks coffee. \nhint5([(_,green,coffee,_,_)|_]).\nhint5([_|T]) :- hint5(T).\n% The person who smokes Pall Mall rears birds\nhint6([(_,_,_,pallmall,bird)|_]).\nhint6([_|T]) :- hint6(T).\n% The owner of the Yellow house smokes Dunhill\nhint7([(_,yellow,_,dunhill,_)|_]).\nhint7([_|T]) :- hint7(T).\n% The man living in the centre house drinks milk\nhint8(Persons) :- person(3, Persons, (_,_,milk,_,_)).\n% The Norwegian lives in the first house\nhint9(Persons) :- person(1, Persons, (norwegian,_,_,_,_)).\n% The man who smokes Blends lives next to the one who keeps cats\nhint10([(_,_,_,blend,_),(_,_,_,_,cat)|_]).\nhint10([(_,_,_,_,cat),(_,_,_,blend,_)|_]).\nhint10([_|T]) :- hint10(T).\n% The man who keeps horses lives next to the man who smokes Dunhill\nhint11([(_,_,_,dunhill,_),(_,_,_,_,horse)|_]).\nhint11([(_,_,_,_,horse),(_,_,_,dunhill,_)|_]).\nhint11([_|T]) :- hint11(T).\n% The man who smokes Blue Master drinks beer\nhint12([(_,_,beer,bluemaster,_)|_]).\nhint12([_|T]) :- hint12(T).\n% The German smokes Prince\nhint13([(german,_,_,prince,_)|_]).\nhint13([_|T]) :- hint13(T).\n% The Norwegian lives next to the blue house\nhint14([(norwegian,_,_,_,_),(_,blue,_,_,_)|_]).\nhint14([(_,blue,_,_,_),(norwegian,_,_,_,_)|_]).\nhint14([_|T]) :- hint14(T).\n% The man who smokes Blends has a neighbour who drinks water\nhint15([(_,_,_,blend,_),(_,_,water,_,_)|_]).\nhint15([(_,_,water,_,_),(_,_,_,blend,_)|_]).\nhint15([_|T]) :- hint15(T).\n% The question : Who owns the fish ?\nquestion([(_,_,_,_,fish)|_]).\nquestion([_|T]) :- question(T).\n\n\n\nI've used one main way to do the predicates. The first predicate type used for every predicates except 8 and 9 is really  simple. I expressed the valid values and then, I used iteration to iterate over the arrays. With that, the predicate is true when the the list contains the good value (or values when testing for an house next to another). \nThe other predicate is that we specify that the Nth contains some values. \nAfter that, we must specify the question : \nquestion([(_,_,_,_,fish)|_]).\nquestion([_|T]) :- question(T).\n\n\n\nWe just iterate the list, specifying that there is a man with a fish. Without the question, we can solve the problem, but we don't know that the last animal is a fish. \nAnd after all, we can try to solve the riddle : \nsolution(Persons) :-\n  persons(5, Persons),\n  hint1(Persons),\n  hint2(Persons),\n  hint3(Persons),\n  hint4(Persons),\n  hint5(Persons),\n  hint6(Persons),\n  hint7(Persons),\n  hint8(Persons),\n  hint9(Persons),\n  hint10(Persons),\n  hint11(Persons),\n  hint12(Persons),\n  hint13(Persons),\n  hint14(Persons),\n  hint15(Persons),\n  question(Persons).\n\n\n\nWe just say that the solution is the combinaison of all the hints and the question, so that the solution must validate all predicates. \nSo let's try our program : \nwichtounet@wichtounet-laptop:~/Desktop$ gprolog\nGNU Prolog 1.3.0\nBy Daniel Diaz\nCopyright (C) 1999-2007 Daniel Diaz\n| ?- [einstein.pl].      \nuncaught exception: error(syntax_error('user_input:1 (char:10) , | ] or operator expected in list'),read_term/3)\n| ?- \nProlog interruption (h for help) ? e\nwichtounet@wichtounet-laptop:~/Desktop$ gprolog\nGNU Prolog 1.3.0\nBy Daniel Diaz\nCopyright (C) 1999-2007 Daniel Diaz\n| ?- consult('einstein.pl').\ncompiling /home/wichtounet/Desktop/einstein.pl for byte code...\n/home/wichtounet/Desktop/einstein.pl compiled, 100 lines read - 14891 bytes written, 17 ms\nyes\n| ?- solution(Persons).\nPersons = [(norwegian,yellow,water,dunhill,cat),(dane,blue,tea,blend,horse),(brit,red,milk,pallmall,bird),\n(german,green,coffee,prince,fish),(swede,white,beer,bluemaster,dog)] ? a\n(20 ms) no\n| ?- \nProlog interruption (h for help) ? e\n\n\nWith that, we found not only the man who have fish but also all the other informations. The answer is the german. \nThat's all we need :)\nI hope you found that post interesting. \nHere is the complete source code : Einstein's Riddle in Prolog", 
      "tags": "Others,Prolog"
    }, 
    {
      "loc": "/posts/2010/09/jdk-7-features-updated-plan-b-is-apparently-here.html", 
      "title": "JDK 7 Features updated ! Plan B has apparently been approved", 
      "text": "I was presenting the Plan B of JDK 7 the last week and apparently, this plan has been approved.\nThe JDK 7 Features page has been updated on the site of Oracle.\nSo here are the (definitive ?) list of features for JDK 7 :\n\n    JSR 292: Support for dynamically-typed languages (InvokeDynamic)\n    Languages update of the project Coin\n    Concurrency and collections updates (jsr166y)\n    ionet   JSR 203: More new I/O APIs for the Java platform (NIO.2)\n    SCTP (Stream Control Transmission Protocol)\n    SDP (Sockets Direct Protocol)\n    Elliptic-curve cryptography (ECC)\n    client  XRender pipeline for Java 2D\n    Create new platform APIs for 6u10 graphics features\n    Nimbus look-and-feel for Swing\n    Swing JLayer component\n\n\nAnd we can also see that there is some new features that we doesn't have seen before:\n\n    TLS 1.2\n    JDBC 4.1\n    Unicode 6.0\n    Locale enhancement\n    Separate user locale and user-interface locale\n    NIO.2 filesystem provider for zip/jar archives\n    Use the Windows Vista IPv6 stack when available\n\n\nAnd after all that informations, we can see the features delayed to JDK 8 :\n\n    JSR 294: Language and VM support for modular programming\n    JSR 308: Annotations on Java types\n    JSR TBD: Language support for collections [NEW]\n    JSR TBD: Project Lambda\n    Modularization (Project Jigsaw)\n    JSR 296: Swing application framework\n    Swing JDatePicker component\n\n\nFor more informations and the complete list of features for the two versions of JDK, you can consult the JDK 7 Features page. There will certainly be some additional informations at JavaOne this week.", 
      "tags": "Java,Java 7,Releases"
    }, 
    {
      "loc": "/posts/2010/09/jtheque-utils-1-1-5.html", 
      "title": "JTheque Utils 1.1.5", 
      "text": "It's my pleasure to announce the release of a new version of JTheque Utils, the 1.1.5.\nThere is a lot of changes in this version. First of all, the library is now OSGi Ready, you can use it with no problem in an OSGi application. Here are the main changes of this version :\n\n    The main classes have been made thread safe and all the classes are now documented to indicate if they are thread safe, not thread safe or immutable.\n    The library has now some annotations to document thread safety, thanks to Brian Goetz for the idea\n    SwingUtils support now headless environment\n    Version has a better version comparison\n    A new simple way to manage system properties with the SystemProperty class\n    CollectionUtils has a new set of methods to create collections and concurrent collections\n    A simple thread safe weak event listener list, WeakEventListenerList\n    HashCodeUtils has been improved to manage arrays\n    Some classes have been made Immutable\n    The utility class have new methods\n    And a lot of other little changes and bug fixes\n\nMore informations on the JTheque website. \u00a0You can download it from here.\nI hope that this library will be useful to someone.", 
      "tags": "Java,JTheque,Libraries,OSGi,Releases"
    }, 
    {
      "loc": "/posts/2010/09/java-concurrency-part-7-executors-and-thread-pools.html", 
      "title": "Java Concurrency - Part 7 : Executors and thread pools", 
      "text": "Let's start with a new post in the Java concurrency series.\nThis time we'll learn how to start cleanly new threads and to manage thread pools. In Java, if you have a Runnable like this :\nRunnable runnable = new Runnable(){\n   public void run(){\n      System.out.println(\"Run\");\n   }\n}\n\n\n\nYou can easily run it in a new thread :\nnew Thread(runnable).start();\n\n\n\nThis is very simple and clean, but what if you've several long running tasks that you want to load in parralel and then wait for the completion of all the tasks, it's a little bit harder to code and if you want to get the return value of all the tasks it becomes really difficult to keep a good code. But like for almost any problems, Java has a solution for you, the Executors. This simple class allows you to create thread pools and thread factories.\n\n\nA thread pool is represented by an instance of the class ExecutorService. With an ExecutorService, you can submit task that will be completed in the future. Here are the type of thread pools you can create with the Executors class :\n\n    Single Thread Executor : A thread pool with only one thread. So all the submitted task will be executed sequentially. Method : Executors.newSingleThreadExecutor()\n    Cached Thread Pool : A thread pool that create as many threads it needs to execute the task in parralel. The old available threads will be reused for the new tasks. If a thread is not used during 60 seconds, it will be terminated and removed from the pool. Method : Executors.newCachedThreadPool()\n    Fixed Thread Pool : A thread pool with a fixed number of threads. If a thread is not available for the task, the task is put in queue waiting for an other task to ends. Method : Executors.newFixedThreadPool()\n    Scheduled Thread Pool : A thread pool made to schedule future task. Method : Executors.newScheduledThreadPool()\n    Single Thread Scheduled Pool : A thread pool with only one thread to schedule future task. Method : Executors.newSingleThreadScheduledExecutor()\n\n\nOnce you have a thread pool, you can submit task to it using the different submit methods. You can submit a Runnable or a Callableto the thread pool. The method return a Future representing the future state of the task. If you submitted a Runnable, the Future object return null once the task finished.\nBy example, if you have this Callable :\nprivate final class StringTask implements Callable<String> {\n   public String call(){\n      //Long operations\n\n      return \"Run\";\n   }\n}\n\n\n\nIf you want to execute that task 10 times using 4 threads, you can use that code :\nExecutorService pool = Executors.newFixedThreadPool(4);\n\nfor(int i = 0; i < 10; i++){\n   pool.submit(new StringTask());\n}\n\n\n\nBut you must shutdown the thread pool in order to terminate all the threads of the pool :\npool.shutdown();\n\n\n\nIf you don't do that, the JVM risk to not shutdown because there is still threads not terminated. You can also force the shutdown of the pool using shutdownNow, with that the currently running tasks will be interrupted and the tasks not started will not be started at all.\nBut with that example, you cannot get the result of the task. So let's get the Future objects of the tasks :\nExecutorService pool = Executors.newFixedThreadPool(4);\n\nList<Future<String>> futures = new ArrayList<Future<String>>(10);\n\nfor(int i = 0; i < 10; i++){\n   futures.add(pool.submit(new StringTask()));\n}\n\nfor(Future<String> future : futures){\n   String result = future.get();\n\n   //Compute the result\n}\n\npool.shutdown();\n\n\n\nBut this code is a bit complicated. And there is a disadvantage. If the first task takes a long time to compute and all the other tasks ends before the first, the current thread cannot compute the result before the first task ends. Once again, Java has the solution for you, CompletionService.\nA CompletionService is a service that make easier to wait for result of submitted task to an executor. The implementation is ExecutorCompletionService who's based on an ExecutorService to work. So let's try :\nExecutorService threadPool = Executors.newFixedThreadPool(4);\n\nCompletionService<String> pool = new ExecutorCompletionService<String>(threadPool);\n\nfor(int i = 0; i < 10; i++){\n   pool.submit(new StringTask());\n}\n\nfor(int i = 0; i < 10; i++){\n   String result = pool.take().get();\n\n   //Compute the result\n}\n\nthreadPool.shutdown();\n\n\n\nWith that, you have the result in the order they are completed and you don't have to keep a collection of Future.\nHere we are, you have the tools in hand to launch tasks in parralel using performing thread pools. Using Executors, ExecutorService and CompletionService you can create complex algorithm using several taks. With that tools, it's really easy to change the number of threads performing in parralel or adding more tasks without changing a lot of code.\nI hope that this post will help you to write better concurrent code.", 
      "tags": "Concurrency,Java"
    }, 
    {
      "loc": "/posts/2010/09/hardware-guide-the-power-supply.html", 
      "title": "Hardware Guide : The power supply", 
      "text": "After writing a lot about Java concurrency, I wanted to write about something else, I chosen Hardware, so I wrote a new guide about power supplies.\nIntroduction\n\nThe power supply provide electrical power to the computer and to the several components. Without power supply, a computer cannot start. The power supply is connected to the power distribution system of your home and convert this power into the good number of watts needed by the components of your PC. All the power is redistributed using several different connectors.\nWhen we buy a power supply, you need to keep in mind several elements, the available connectors and the power generated by the power supply.\n\n\nConnectors\n\nFrom your power supply, several connectors go out. All of these connectors have a specific use. Here are the existing types of connectors that you can find on a power supply :\n\n    ATX Connectors : This connector is used to power the motherboard. Generally, there is 20 pins, but new motherboards need 24. So new power supplies provide a 24 pins connectors with 4 pins detachable. Pay attention that some motherboard also needs an additional 4 pins connector, so verify that your power supply has this \u00a0connector before buying it.\n    Molex Connectors for \u00a05 \u00bc et 3 \u00bd peripheral : This connector power an IDE component (hard disk, CD/DVD reader/writer).\n    Molex Connectors for \u00a0floppy : this connector is less and less used so not all power supply provide this connector.\n    12V 6 pins Connector : This connector enable to connect a PCI-Express graphics card. Not all cards need that connector, only the last generation graphics card need a power addition. Most of the graphics card have a connector of this type, but for big configuration with two graphics card (SLI or CrossFire), you'll need two connectors. The power supply with two connectors of this type are named SLI-Ready.\n    SATA Connectors : To power SATA peripheral.\n\n\nGenerally each type of connector have keyed to avoid branch the cable in the wrong direction. There is also adapters to switch from one type to an other one or to double a connector (but pay attention to not overhead your power supply).\nPay also attention to the length of the cables if you have a big case (Big Tower).\nThe power\n\nThe power of your power supply is the number of Watts that it can deliver. Pay attention that a basic power supply will often have brownouts if there is a lot of load. This is why it's more interesting to choose a known power supply with a lower tension than a noname one with a bigger tension.\nPay attention to the tension on each connector. Some alimentations don't provide the indicated tension. It's why, it's always good to find tests of clients on Internet before buying something.\nOf course, you need enough power for your components. The components needing the more power is the processor and the graphics cards. The other components needs less power. For a basic computer a power supply of 300W is enough. When we use last generation graphics card or dual/quadri core processor, you need to have more power, almost 400W-450W. When you have several processors or graphics card, there is a lot more. There is power supply with 1000W but this is an exception only needed (not always...) by big gamers or scientists.\nTo compute the number of Watt that a component need, you can almost use this list :\nPour calculer le besoin en Watts d'un composant vous pouvez plus ou moins vous fier \u00e0 cette liste :\n\n    Motherboard : 40-50 W\n    Simple core processor : 40-50 W\n    Dual Core processor : 90-100 W\n    Server Processor (Xeon by example) : ~150W\n    Graphics card PCI/AGP : 50 W\n    Graphics card PCI Express : 125W\n    Additional PCI Card : 15-55 W\n    Hard Disk : 15-40 W depending on the use\n    CD/DVD Readers/Writers : 10-20 W\n\n\nOf course, these datas can change from one peripheral to an other, but this is a good mean.\nYou can use this online calculator to compute the power you need.\nStandards\n\nYou need to choose the power supply in terms of the standard of your computer case. An ATX power supply doesn't fit an case of type Micro-ATX.\nNoise\n\nThe power supply is an element who heats a lot, so you need a cooling system. Generally a power supply have a fan, but some power supply use a passive cooling system. The better is to have a big fan (120mm), it makes less noise.\nWe can also use a power supply with two fans for a better air extraction.\nPay attention that the fans are the most silent.\nModularity\n\nSome power supply are modular. This power supplies don't have the connectors directly connected to the box, but you can connect them yourself. So we only connect the connectors we need. This improve the air flow. But these models are more expensive.\nSize\n\nSome power supplies are bigger than the other, so pay attention that it fits in your case. This the case for the most powerful models and some modular models. It can also be hard to put some power supplies in some cases due to their concept. To be sure that the two are compatibles, you can directly contact your vendor or make a search on the internet to have returns on the mount of this power supply on your case. But generally you will not have compatibility problems.\nPower Consumption\n\nMore and more vendors put the power consumption on the front of the stage. So it's interesting to choose a power supply with less power consumption if you have the choice between several power supplies that are in your needs. There is some standards like the Certification 80 plus that guarantee that the efficiency of the power supply is at least of 80%.\nConclusion\n\nTo conclude, the choice of a power supply is not really serious, but it's a serious point in a configuration. Pay attention to have a power supply with enough connectors and enough power to power all your components.\nTips\n\nHere are some rules to choose a good power supply :\n\n    Don't use too much connectors splitters, you risk to overload your power supply\n    Clean regularly your power supply. Don't let the dust win. The fan can block and don't correctly evacuate the heating and the components can be broken. Of course, this is also a good thing to do for the computer in general.\n    Don't use a power supply in a configuration where the components needs more power than the power supply provide. If you make it you can stress the power supply and the different connectors will not provide enough tension and some of your components may not appreciate this situation.", 
      "tags": "Hardware,Others"
    }, 
    {
      "loc": "/posts/2010/09/java-7-delays-and-plan-b.html", 
      "title": "Java 7 Delays and Plan B", 
      "text": "Mark Reinhold has posted a message about the planning of Java 7. In this message, he explains that the current schedule of the JDK 7 is completely unrealistic. This delay is due to the add of new projects (lambda, Coin, Jigsaw) and the acquisition of Sun by Oracle. \nThe current estimate by the team is that the JDK7 can be complete for a release around the middle of 2012. \nBut, Mark indicates a new option, the \"Plan B\". With this plan, the JDK7 will be available at mid 2011 without Jigsaw and Lambda and with only a portion of the Coin Project. And JDK8 will be released in late 2012 with the complete set of features scheduled actually for JDK7. \nPersonnally, I think it's a good idea to separate the two releases and have a first release soon. Like Mark says, it makes a very long time that we don't have had a new Java release, so it will be interesting to have a light JDK7 before 2012. \nAnd you, what do you think ? \nSource : Re-thinking JDK7, by Mark Reinhold", 
      "tags": "Java,Java 7,Releases"
    }, 
    {
      "loc": "/posts/2010/09/tip-batch-resize-images-on-ubuntu-linux.html", 
      "title": "Tip : Batch resize images on Ubuntu Linux", 
      "text": "After needing to optimize a lot of images at once, this weekend I needed to resize a lot of images to the same size because they were too big.\nLike every other thing in Linux, there is a really simple tool to automate that. I used imagemagick to do that. Of course, there is certainly a lot of other things to make that work, but this is the first I've found and it works well.\nSo first, you need to install it if you don't have the tool :\nsudo apt-get install imagemagick\n\nAnd then, you can resize all the JPG images to a width of 640px of the current folder using the single command :\nmogrify -resize 640 *.jpg\n\nIf you want the height, just add a x :\nmogrify -resize x640 *.jpg\n\nYou can also specify maximum width and height, that can be useful if you have big images and you don't want a width larger than x and a height larger than y but you don't want to resize little images in the same folder. Here is an example resizing images if the width is larger than 1280 or height larger than 1024 :\nmogrify -resize '1280x1024>' *.jpg\n\nWith all that commands, the ratio is preserved. If you want more informations on the possible resize options, you can consult the documentation of ImageMagick.\nHope that will help someone.", 
      "tags": "Linux,Tips"
    }, 
    {
      "loc": "/posts/2010/09/java-concurrency-atomic-variables.html", 
      "title": "Java Concurrency - Part 6 : Atomic Variables", 
      "text": "When a data (typically a variable) can be accessed by several threads, you must synchronize the access to the data to ensure visibility and correctness. \nBy example, if you have a simple counter (yes, once again) : \npublic class Counter {\n    private int value;\n\n    public int getValue(){\n        return value;\n    }\n\n    public int getNextValue(){\n        return value++;\n    }\n\n    public int getPreviousValue(){\n        return value--;\n    }\n}\n\n\n\nThis class works really well in single-threaded environment, but don't work at all when several threads access the same Counter instance. If you don't know why, read this post about synchronization. You can solve the problem using synchronized at method level : \npublic class SynchronizedCounter {\n    private int value;\n\n    public synchronized int getValue(){\n        return value;\n    }\n\n    public synchronized int getNextValue(){\n        return value++;\n    }\n\n    public synchronized int getPreviousValue(){\n        return value--;\n    }\n}\n\n\n\nThis class now works well. But locking is not a lightweight mechanism and have several disadvantages. When several threads try to acquire the same lock, one or more threads will be suspended and they will be resumed later. When the critical section is little, the overhead is really heavy especially when the lock is often acquired and there is a lot of contention. Another disadvantage is that the other threads waiting of the lock cannot do something else during waiting and if the thread who has the lock is delayed (due to a page fault or the end of the time quanta by example), the others threads cannot take their turn. \nSo how to do to avoid this disadvantages ? We must use non-blocking algorithms. This algorithms don't use blocking mechanisms and by that fact are more scalable and performing. These algorithms use low-level machine instructions which are atomic to ensure the atomicity of higher-level operations. While locking is a pessimistic approach, we can also use optimistic technique to develop algorithms. This time, we'll detect collisions between threads in which case, the operation fails and we do something else (often retrying the same operation).\nThe actual processors provide several instructions that simplify greatly the implementation of these non-blocking algorithms, the most-used operation today is the compare-and-swap operation (CAS). This operation takes three parameters, the memory address, the expected current value and the new value. It atomically update the value at the given memory address if the current value is the expected, otherwise it do nothing. In both cases, the operation return the value at the address after the operation execution. So when several threads try to execute the CAS operation, one thread wins and the others do nothing. So the caller can choose to retry or to do something else. We often use this operation to implement another operation, the compare-and-set. This method makes exactly the same things as CAS but return a boolean indicating if the operation succeeded or not. \nBefore Java 5.0, this operation was not available directly to developer, but in Java 5.0 several atomic variables (for int, long, boolean and reference values) were added. The int and long versions also supports numeric operations. The JVM compiles these classes with the better operations provided by the hardware machine, CAS or a Java implementation of the operation using a lock. Here are the classes : \n\nAtomicInteger\nAtomicLong\nAtomicBoolean\nAtomicReference\n\n\nAll these classes supports compare-and-set (via the compareAndSet() method) and other operations (get(), set() and getAndSet()). The setters operations are implemented using compareAndSet. These classes supports multi-threaded access and have a better scalability than synchronizing all the operations. \nHere is how we can rewrite our counter using an AtomicInteger : \npublic class AtomicCounter {\n    private final AtomicInteger value = new AtomicInteger(0);\n\n    public int getValue(){\n        return value.get();\n    }\n\n    public int getNextValue(){\n        return value.incrementAndGet();\n    }\n\n    public int getPreviousValue(){\n        return value.decrementAndGet();\n    }\n}\n\n\n\nThe incrementAndGet() and decrementAndGet() methods are two of the numeric operations provided by the AtomicLong and AtomicInteger classes. You also have getAndDecrement(), getAndIncrement(), getAndAdd(int i) and addAndGet(). \nThis version is faster than the synchronized one and is also thread safe. \nIf you only have the compareAndSet(), here is how we can implement increment() method using it : \npublic void increment(AtomicInteger integer){\n    while(true){\n        int current = integer.get();\n        int next = current + 1;\n\n        if(integer.compareAndSet(current, next)){\n            return;\n        }\n    }\n}\n\n\n\nThis seems to be complicated, but this is the cost of non-blocking algorithms. When we detect collision, we retry until the operation succeeded. This is the common schema for non-blocking algorithms. \nHere is a thread-safe Stack implemented using AtomicReference : \npublic class Stack {\n    private final AtomicReference<Element> head = new AtomicReference<Element>(null);\n\n    public void push(String value){\n        Element newElement = new Element(value);\n\n        while(true){\n            Element oldHead = head.get();\n            newElement.next = oldHead;\n\n            //Trying to set the new element as the head\n            if(head.compareAndSet(oldHead, newElement)){\n                return;\n            }\n        }\n    }\n\n    public String pop(){\n        while(true){\n            Element oldHead = head.get();\n\n            //The stack is empty\n            if(oldHead == null){\n                return null;\n            }\n\n            Element newHead = oldHead.next;\n\n            //Trying to set the new element as the head\n            if(head.compareAndSet(oldHead, newHead)){\n                return oldHead.value;\n            }\n        }\n    }\n\n    private static final class Element {\n        private final String value;\n        private Element next;\n\n        private Element(String value) {\n            this.value = value;\n        }\n    }\n}\n\n\n\nIt's really more complicated than using synchronized on the two methods but also more performing if there is contention (and often even if there is no contention). \nSo this ends this post. To conclude, atomic variables classes are a really good way to implement non-blocking algorithms and moreover are also a very good alternative to volatile variables, because they can provide atomicity and visibility.", 
      "tags": "Concurrency,Java"
    }, 
    {
      "loc": "/posts/2010/09/java-concurrency-part-5-monitors-locks-and-conditions.html", 
      "title": "Java Concurrency - Part 5 : Monitors (Locks and Conditions)", 
      "text": "After seeing how to synchronize code using semaphores, we'll see how to do that using monitors.\nMonitors are an other mechanism of concurrent programming. It's a higher level mechanism than semaphores and also more powerful. A monitor is an instance of a class that can be used safely by several threads. All the methods of a monitor are executed with mutual exclusion. So at most one thread can execute a method of the monitor at the same time. This mutual exclusion policy makes easier to work with monitor and to develop the method content of the monitor.\nMonitors have an other feature, the possibility to make a thread waiting for a condition. During the wait time, the thread temporarily gives up its exclusive access and must reacquire it after the condition has been met. You can also signal one or more threads that a condition has been met.\nThere is several advantages on using monitors instead of a lower-level mechanisms :\n\n    All the synchronization code is centralized in one location and the users of this code don\u2019t need to know how it\u2019s implemented.\n    The code doesn't depend on the number of processes, it works for as many processes as you want\n    You don\u2019t need to release something like a mutex, so you cannot forget to do it\n\n\nWhen we must describe a monitor, we simple use the monitor keyword and describe the methods as common methods :\nmonitor SimpleMonitor {\n    public method void testA(){\n        //Some code\n    }\n\n    public method int testB(){\n        return 1;\n    }\n}\n\n\n\nTo describe a condition variable, we use the cond keyword. A condition variable is a kind of queue of process who are waiting on the same condition. You have several operations available on a condition, the most important is to signal a process waiting to be awaken and to wait on a condition. There are some similarities between signal/wait operations and P and V of semaphores, but this is a little different. The signal operation does nothing if the queue is empty and the wait operation put always the thread in the waiting queue. The process queue is served in a first come, first served mode.   When a thread wakes up after waiting on a condition, it must reacquire the lock before continuing in the code.\nBefore going further, we must have more information about the signal operations. When writing monitors, you normally have the choice between several philosophies for the signaling operation :\n\n    Signal & Continue (SC) : The process who signal keep the mutual exclusion and the signaled will be awaken but need to acquire the mutual exclusion before going.\n    Signal & Wait (SW) : The signaler is blocked and must wait for mutual exclusion to continue and the signaled thread is directly awaken and can start continue its operations.\n    Signal & Urgent Wait (SU) : Like SW but the signaler thread has the guarantee than it would go just after the signaled thread\n    Signal & Exit (SX) : The signaler exits from the method directly after the signal and the signaled thread can start directly. This philosophy is not often used.\n\n\nThe available policies depends on the programming language, in Java, there is only one policy available, the SC one.\nIn Java there is no keyword to directly create a monitor. To implement a monitor, you must create a new class and use Lock and Condition classes. Lock is the interface is ReentrantLock is the main used implementation, this is the one that we'll learn to use in the current post. To create a ReentrantLock, you have two constructors, a default constructor and a constructor with a boolean argument indicating if the lock is fair or not. A fair lock indicates that the threads will acquire the locks in the order they ask for. Fairness is a little heavier than default locking strategies, so use it only if you need it. To acquire the lock, you just have to use the method lock and unlock to release it.\nThe explicit locks have the same memory semantics than the synchronized blocks. So the visibility of the changes is guarantee when you use lock()/unlock() blocks.\nSo to implement, the monitor example we've seen before, we just need to create a class and use the lock to make the mutual exclusion :\npublic class SimpleMonitor {\n    private final Lock lock = new ReentrantLock();\n\n    public void testA() {\n        lock.lock();\n\n        try {\n            //Some code\n        } finally {\n            lock.unlock();\n        }\n    }\n\n    public int testB() {\n        lock.lock();\n\n        try {\n            return 1;\n        } finally {\n            lock.unlock();\n        }\n    }\n}\n\n\n\nThe person who've already read the other parts of this post set will say that it will be easier to use the synchronized keyword on the two methods. But with synchronized, we will not have the condition variables. If you don't need condition variables but only locking, it will be easier to use the synchronized blocks instead of Locks.\nYou can create conditions using the newCondition method on the lock. A condition is a variable of type Condition. You can make the current thread wait on the condition using the await method (and its variant with timeout) and you can signal threads using signal and signalAll methods. The signalAll methods wakes up all the threads waiting on the condition variable.\nLet's try with a simple common example : A bounded buffer. It's a cyclic buffer with a certain capacity with a start and an end.\nimport java.util.concurrent.locks.Condition;\nimport java.util.concurrent.locks.Lock;\nimport java.util.concurrent.locks.ReentrantLock;\n\npublic class BoundedBuffer {\n    private final String[] buffer;\n    private final int capacity;\n\n    private int front;\n    private int rear;\n    private int count;\n\n    private final Lock lock = new ReentrantLock();\n\n    private final Condition notFull = lock.newCondition();\n    private final Condition notEmpty = lock.newCondition();\n\n    public BoundedBuffer(int capacity) {\n        super();\n\n        this.capacity = capacity;\n\n        buffer = new String[capacity];\n    }\n\n    public void deposit(String data) throws InterruptedException {\n        lock.lock();\n\n        try {\n            while (count == capacity) {\n                notFull.await();\n            }\n\n            buffer[rear] = data;\n            rear = (rear + 1) % capacity;\n            count++;\n\n            notEmpty.signal();\n        } finally {\n            lock.unlock();\n        }\n    }\n\n    public String fetch() throws InterruptedException {\n        lock.lock();\n\n        try {\n            while (count == 0) {\n                notEmpty.await();\n            }\n\n            String result = buffer[front];\n            front = (front + 1) % capacity;\n            count--;\n\n            notFull.signal();\n\n            return result;\n        } finally {\n            lock.unlock();\n        }\n    }\n}\n\n\n\nSo some explications :\n\n    The two methods are protected with the lock to ensure mutual exclusion\n    Then we use two conditions variables. One to wait for the buffer to be not empty and an other one to wait for the buffer to be not full.\n    You can see that I have wrapped the await operation on a while loop. This is to avoid signal stealers problem that can occurs when using Signal & Continue\n\n\nAnd that BoundedBuffer can be easily used with several threads with no problems.\nAs you can see, you can use monitors to solve a lot of concurrent programming problems and this mechanism is really powerful and performing.\nI hope you found that article interesting and that this set of posts about Java concurrency brings you some stuff about Java.", 
      "tags": "Concurrency,Java"
    }, 
    {
      "loc": "/posts/2010/09/save-time-with-the-gmail-priority-inbox.html", 
      "title": "Save time with the Gmail Priority Inbox", 
      "text": "Some days ago, Gmail released a new feature, the Priority Inbox. Actually, the feature is not released on all accounts, but if it is released on yours, you can see a message \"Try Gmail Priority Inbox\", in top right high corner, just after your user name.\nOnce you activated this new inbox, you will see two inbox, the new Priority Inbox on top and the old Inbox. The Inbox has not changed, but now you can use the Priority Inbox. In this view, you will see your messages sorted in two categories, the first one contains the important unread messages and the second one contains all the other messages.\nIf you found an error, namely a non-important message tagged as important or the contrary, you have two new buttons :\n\nWith these buttons, you can move a message from the priority messages to the others and vice versa. When you do that, the algorithm between the sorting will save your action and try to improve the efficiency of the Priority Inbox to not make the same error again.\nAt this time, I'm completely happy with this new feature, I've had only one message marked as important that was not, but it's all. I think it's a great tool that Google has offerred to us.\nIf you want more informations, let's watch this video from Google :", 
      "tags": "Google,Personal,Web"
    }, 
    {
      "loc": "/posts/2010/09/my-java-benchmarks-on-github.html", 
      "title": "My Java Benchmarks on GitHub", 
      "text": "I've created a new github repository for my Java Benchmarks : java-benchmarks\nFrom now all my benchmarks will be pushed to this repository. This is more simple for me to manage and more secure also.\nAt this time, there is seven benchmarks on the repository :\n\n    Closest Pair Search Benchmark : A benchmark to test two closest pair point search algorithms : the naive one and the sweeping plane one. Results.\n    File Copy Benchmark : A benchmark on the different ways to make file copy in Java. Results.\n    Iteration Remove Benchmark :\u00a0A simple benchmark to test if it's interesting to remove the read elements from a list when we make several\u00a0iterations over the list.\n    Reflection Benchmark : A little benchmark to test the performances of reflection versus switch cases and direct invocations.\n    Short Indexes Loop Benchmark : A benchmark to test which primitive type is the most performing using as iteration index.\u00a0Results.\n    Synchronization Benchmark : A benchmark to test the performances of the different synchronization mechanisms available in Java to provide mutual exclusion. Results.\n    Unmodifiable Benchmark : A benchmark to test the performances of unmodifiable collection versus creating a copy of the list.\n\n\nI hope you'll find these sources interesting. If you found errors or improvements, don't hesitate to comment to tell me what.", 
      "tags": "Benchmarks,Git,Java,Performances"
    }, 
    {
      "loc": "/posts/2010/09/java-synchronization-mutual-exclusion-benchmark.html", 
      "title": "Java Synchronization (Mutual Exclusion) Benchmark", 
      "text": "I've created another benchmark. This time, I've benchmarked the different ways of synchronizing a little code using mutual exclusion on this code.\nThe code to protect will be very simple. It's a simple counter :\n//Init\nint counter = 0; \n//Critical section\ncounter++;\n\n\n\nThe critical section, if not protected with synchronization system, will not function properly due to possible interleavings (read the article on synchronization if you don't know what is interleaving).\n\n\nI've used 3 different synchronizers to synchronize this increment :\n\n    synchronized block\n    Semaphores (fair and unfair)\n    Explicit locks (fair and unfair)\n\n\nI've also used a third way to solve the problem with AtomicInteger. This is not the same as the other ways because it does not provide mutual exclusion but this is a good way to synchronize simple values, like integers or boolean, but also references. The atomicity of the operations of the AtomicInteger is made using the compare-and-swap operation of the operating system. So there is no waiting operations. So there is less context switches and result in more performing code normally.\nHere is the code of these 4 ways to solve the problems :\nprivate class SynchronizedRunnable implements Runnable {\n    private int counter = 0;\n\n    @Override\n    public synchronized void run() {\n        counter++;\n    }\n}\n\nprivate class ReentrantLockRunnable implements Runnable {\n    private int counter = 0;\n\n    private Lock lock;\n\n    private ReentrantLockRunnable(boolean fair) {\n        super();\n\n        lock = new ReentrantLock(fair);\n    }\n\n    @Override\n    public void run() {\n        lock.lock();\n\n        try {\n            counter++;\n        } finally {\n            lock.unlock();\n        }\n    }\n}\n\nprivate class SemaphoreRunnable implements Runnable {\n    private int counter = 0;\n\n    private final Semaphore semaphore;\n\n    private SemaphoreRunnable(boolean fair) {\n        super();\n\n        semaphore = new Semaphore(1, fair);\n    }\n\n    @Override\n    public void run() {\n        try {\n            semaphore.acquire();\n        } catch (InterruptedException e) {\n            throw new RuntimeException(e);\n        }\n\n        try {\n            counter++;\n        } finally {\n            semaphore.release();\n        }\n    }\n}\n\nprivate class AtomicIntegerRunnable implements Runnable {\n    private AtomicInteger counter = new AtomicInteger(0);\n\n    @Override\n    public void run() {\n        counter.incrementAndGet();\n    }\n}\n\n\n\nI used Runnable to facilitate the testing and timing of the different mechanisms.\nThe test is made in two phases :\n\n    Test with only one thread with a sophisticated benchmark framework. This act also as warmup for the different code.\n    Test with several threads (several test with increasing number of threads). The test is made using a little code I wrote for the occasion. Each method is executed 2\u00b2\u00b3 times (8388608 times exactly).\n\n\nThe source code is available at the end of the post.\nThe test has been launched on a Ubuntu 10.04 with a Java 6 virtual machine. The computer has a 64 bit Core 2 Duo 3.16 Ghz processor and 6Go of DDR2.\nSo let's see the results. First with one thread :\n\nThe first thing we see is that the AtomicInteger is the fastest version. This is because AtomicInteger do not use waiting operation, so this result in less context switches and more performances. But this is not exactly the case of the benchmark, so let's concentrate on the 5 others methods. We see that the synchronized method is the fastest and that fair methods are a little slower than unfair, but not a lot.\nNow, we'll test the scalability of all these methods using several threads.\n\nThis method we can see that the fair methods are awfully slow compared to the the unfair versions. Indeed adding fairness to a synchronizer is really heavy. When fair, the threads acquire the locks in the order they ask for. With nonfair locks, barging is allowed. So when a thread try to acquire the lock and its available, it can acquire it even if there is threads waiing for the lock. It's heavier to provide fairness because there is a lot more context switches. The problem was not here with only one thread because it's always fair.\nThe results for the other versions are the same as with one thread.\nLet's add two more threads :\n\nThe fair versions are more and more slows when we add threads. The scalability of these methods is really bad. Let's see the graph without the fair versions :\n\nThis time we can see some differences. The synchronized method is the slower this time and semaphore has a little advantage. Let's see with 8 threads :\n\nHere the synchronized method is really slower than the other methods. It appears that the algorithm of the synchronized block is less scalable than the explicit locks and semaphore versions. Let's watch what happens with other number of threads :\n\n\nI've also made the test with other number of threads (16, 64 and 256), but the results are the same as the other.\nWe can made several conclusions based on the results :\n\n    Fair versions are slow. If you don't absolutely need fairness, don't use fair locks or semaphores\n    Semaphores and explicit locks have the same performances. This is because the 2 classes (Semaphore and ReentrantLock) are based on the same class AbstractQueueSynchronizer that is used by almost all synchronization mechanisms of Java\n    Explicit locks and semaphores are more scalable than synchronized blocks. But that depend on the virtual machine, I've seen other results indicating that the difference is a lot smaller\n    The AtomicInteger is the most performing method. This class doesn't provide mutual exclusion, but provide thread safe methods to works on simple values (there is version for Long, Double, Boolean and even Reference)\n\n\nSo that's all for this benchmark. I hope you found it interesting.\nThe sources of the benchmark :\u00a0Synchronization Benchmark Sources", 
      "tags": "Benchmarks,Concurrency,Java,Performances"
    }, 
    {
      "loc": "/posts/2010/08/java-concurrency-part-4-semaphores.html", 
      "title": "Java Concurrency - Part 4 : Semaphores", 
      "text": "We continue in Java Concurrency with the semaphores. Semaphores is also a way to synchronize threads.\nSemaphores are a really simple concept, invented by the famous Dutch computer scientist Edsger Dijkstra. Basically a semaphore is a counter (integer) that allows a thread to get into a critical region if the value of the counter is greater than 0. If it's the case, the counter is decremented by one otherwise, the thread is waiting until it can go. And when the thread go away from the critical region, the counter is incremented by one to allow one more thread to pass the critical region. A semaphore is created with a certain value for its counter.\u00a0So, you can execute two actions on a semaphore P and V.\nBy example, if you have a critical that cannot be executed concurrently, you can use a semaphore :\nsem mutex = new sem(1)\nP(mutex)\n//Critical region\nV(mutex)\n\n\n\nSo you must always call by yourself the P operation before the critical region and V after it. We call a mutex (mutual exclusion) a semaphore with a value of one. So only one thread can enter the region guarded by the semaphore. This is the most used semaphore. The other use of semaphore is to guard a set of resources like database connections or a data pool.\nIn Java, a semaphore is created using the java.util.concurrent.Semaphore class. You can create easily :\nSemaphore mutex = new Semaphore(1);\nSemaphore available = new Semaphore(100);\n\n\n\nThe P and V operations are represented using the acquire and release methods. The method acquire can be interrupted if the thread is interrupted. There is an uninterruptible version with the method acquireUninterruptibly(). There is also a third version with the tryAcquire method. This method acquire a permit only if there is one permit available, otherwise, this method return false directly. All the waiting methods have also an overloaded version with a timeout. You can also acquire several permits at once using the permits argument to the different versions of acquire methods.\nA little example with a mutex using the same example as the previous post on Java concurrency :\npublic class Example {\n    private int value = 0;\n\n    private final Semaphore mutex = new Semaphore(1)\n\n    public int getNextValue() throws InterruptedException {\n        try {\n            mutex.acquire();\n            return value++;\n        } finally {\n            mutex.release();\n        }\n    }\n}\n\n\n\nFor more informations about Semaphore in Java, the best is to consult the Javadoc of the Semaphore class.\nTo conclude, semaphores are a powerful ways to solve concurrency problems, but this is not adapted to all problems. If you need only mutual exclusion, synchronized blocks are a better solutions. The problems with semaphores is that you can forget to call the release method and that can cause deadlock sometimes difficult to find.", 
      "tags": "Concurrency,Java"
    }, 
    {
      "loc": "/posts/2010/08/java-concurrrency-synchronization-locks.html", 
      "title": "Java Concurrency \u2013 Part 3 : Synchronization with intrinsic locks", 
      "text": "create threads and manipulate them, it's time to go to most important things : synchronization.\nSynchronization is a way to make some code thread safe. A code that can be accessed by multiple threads must be made thread safe. Thread Safe describe some code that can be called from multiple threads without corrupting the state of the object or simply doing the thing the code must do in right order.\nFor example, we can take this little class :\npublic class Example {\n    private int value = 0;    \n\n    public int getNextValue(){\n        return value++;\n    }\n}\n\n\n\nIt's really simple and works well with one thread, but absolutely not with multiple threads. An increment like this is not a simple action, but three actions :\n\n    Read the current value of \"value\"\n    Add one to the current value\n    Write that new value to \"value\"\n\nNormally, if you have two threads invoking the getNextValue(), you can think that the first will get 1 and the next will get 2, but it is possible that the two threads get the value 1. Imagine this situation :\n\nThread 1 : read the value, get 0, add 1, so value = 1\nThread 2 : read the value, get 0, add 1, so value = 1\nThread 1 : write 1 to the field value and return 1\nThread 2 : write 1 to the field value and return 1\n\nThese situations come from what we call interleaving. Interleaving describe the possible situations of several threads executing some statements. Only for three operations and two threads, there is a lot of possible interleavings.\nSo we must made the operations atomic to works with multiple threads. In Java, the first way to make that is to use a lock. All Java objects contains an intrinsic locks, we'll use that lock to make methods or statement atomic. When a thread has a lock, no other thread can acquire it and must wait for the first thread to release the lock. To acquire the lock, you have to use the synchronized keyword to automatically acquire and release a lock for a code. You can add the synchronized keyword to a method to acquire the lock before invoking the method and release it after the method execution. You can refactor the getNextValue() method using the synchronized keyword :\npublic class Example {\n    private int value = 0;    \n\n    public synchronized int getNextValue(){\n        return value++;\n    }\n}\n\n\n\nWith that, you have the guarantee that only thread can execute the method at the same time. The used lock is the intrinsic lock of the instance. If the method is static, the used lock is the Class object of Example. If you have two methods with the synchronized keyword, only one method of the two will be executed at the same time because the same lock is used for the two methods. You can also write it using a synchronized block :\npublic class Example {\n    private int value = 0;\n\n    public int getNextValue() {\n        synchronized (this) {\n            return value++;\n        }\n    }\n}\n\n\n\nThis is exactly the same as using the synchronized keyword on the method signature. Using synchronized blocks, you can choose the lock to block on. By example, if you don't want to use the intrinsic lock of the current object but an other object, you can use an other object just as a lock :\npublic class Example {\n    private int value = 0;\n\n    private final Object lock = new Object();\n\n    public int getNextValue() {\n        synchronized (lock) {\n            return value++;\n        }\n    }\n}\n\n\n\nThe result is the same but has one difference, the lock is internal to the object so no other code can use the lock. With complex classes, it not rare to use several locks to provide thread safety on the class.\nThere is an other issue with multiple threads : the visibility of the variables. This seems when a change made by a thread is visible by an other thread. For performance improvements, the Java compiler and virtual machines can made some improvements using registers and cache. By default, you have no guarantee that a change made by a thread is visible to an other thread. To make a change visible to an other thread, you must use synchronized blocks to ensure visibility of the change. You must use synchronized blocks for the read and for the write of the shared values. You must make that for every read/write of a value shared between multiple threads.\nYou can also use the volatile keyword on the field to ensure the visibility of read/write between multiple threads. The volatile keyword ensure only visibility, not atomicity. The synchronized blocks ensure visibility and atomicity. So you can use the volatile keyword on fields that doesn't need atomicity (if you make only read and write to the field without depending on the current value of the field by example).\nYou can also note that this simple example can be solved using AtomicInteger, but that will be covered later in an other part of the posts.\nPay attention that trying to solve thread safety on a problem can add new issues of deadlock. By example, if thread A owns the lock 1 and are waiting for the lock 2 and if lock 2 is acquired by thread B who waits on lock 1, there is a deadlock. Your program is dead. So you have to pay great attention to the locks.\nThere is several rules that we must keep in mind when using locks :\n\n    Every mutable fields shared between multiple threads must be guarded with a lock or made volatile, if you only need visibility\n    Synchronize only the operations that must synchronized, this improve the performances. But don't synchronize too few operations. Try to keep the lock only for short operations.\n    Always know which locks are acquired and when there are acquired and by which thread\n    An immutable object is always thread safe\n\n\nHere we are, I hope that this post helps you to understand thread safety and how to achieve it using intrinsic locks. In the next posts, we'll see another synchronization methods.", 
      "tags": "Concurrency,Java"
    }, 
    {
      "loc": "/posts/2010/08/file-copy-benchmark-updates-once-again.html", 
      "title": "Java File Copy Benchmark Updates (once again)", 
      "text": "I've made another updates to my file copy benchmark.\nFirst of all, I used my little utility class to automatically create the graphs. The graph are a little less clean, but I spare a lot of time not creating them myself.\nThen, I've also made some corrections on the code :\n\n    I''ve used a buffer size of 8192 instead of 4096\n    I've made some corrections using the channels because the old code can forgot to write some portions of the file\n    I used allocateDirect() instead of allocate() for the ByteBuffer.\n\n\nAnd I've added a new method using Java 7 : Path.copyTo(Path path).\nSo the new results are all based on a Java 7 Virtual Machine.\nYou'll find all the new informations and result, on the original post : File Copy in Java - Benchmark\nI hope this new informations will interest you.", 
      "tags": "Benchmarks,I/O,Java,Java 7,Performances"
    }, 
    {
      "loc": "/posts/2010/08/java-7-try-with-resources-statement.html", 
      "title": "Java 7 : The new try-with-resources statement", 
      "text": "From the build 105, the compiler and runtime of Java 7 Releases have support for the new form of try : try-with-resources, also called ARM (Automatic Resource Management) blocks. \nThis new statement make working with streams and all kind of closeable resources easier. By example, in Java, you can have this kind of code : \nprivate static void customBufferStreamCopy(File source, File target) {\n    InputStream fis = null;\n    OutputStream fos = null;\n    try {\n        fis = new FileInputStream(source);\n        fos = new FileOutputStream(target);\n\n        byte[] buf = new byte[8192];\n\n        int i;\n        while ((i = fis.read(buf)) != -1) {\n            fos.write(buf, 0, i);\n        }\n    }\n    catch (Exception e) {\n        e.printStackTrace();\n    } finally {\n        close(fis);\n        close(fos);\n    }\n}\n\nprivate static void close(Closeable closable) {\n    if (closable != null) {\n        try {\n            closable.close();\n        } catch (IOException e) {\n            e.printStackTrace();\n        }\n    }\n}\n\n\n\nA little bit heavy, isn't it ? This is only an example, here the management of exceptions is not good. \nSo let's use try-with-resources statement to simplify this code, who becomes : \nprivate static void customBufferStreamCopy(File source, File target) {\n    try (InputStream fis = new FileInputStream(source);\n        OutputStream fos = new FileOutputStream(target)){\n\n        byte[] buf = new byte[8192];\n\n        int i;\n        while ((i = fis.read(buf)) != -1) {\n            fos.write(buf, 0, i);\n        }\n    }\n    catch (Exception e) {\n        e.printStackTrace();\n    }\n}\n\n\n\nA lot cleaner, no ? With that code, the resources are automatically closed after the try. In the try resources list, you can declare several resources, but all these resources must implement the java.lang.AutoCloseable interface. \nIf you want more informations, about this new statement read try-with-resources specifications.", 
      "tags": "Java,Java 7,Others,Releases"
    }, 
    {
      "loc": "/posts/2010/08/java-concurrency-in-practice-book-review.html", 
      "title": "Java Concurrency in Practice - Book Review", 
      "text": "I used my holidays to concentrate myself on the reading of my last book : Java Concurrency in Practice of Brian Goetz (with Tim Peierls, Joshua Bloch, Joseph Bowbeer, David Holmes and Doug Lea).\nThis book is, in my point of view, the reference for the development of concurrency programs in Java.\nReading this book, you will learn that concurrency is everywhere when programming in Java (all the examples are in Java, but the theory \u00a0is valid for almost all programming languages). You will also learn why the GUI Frameworks are single-threaded. You will also understand that a lot of Java programs aren't correct because of the lack of thread safety.\nThe first chapter, the introduction, explains what's are the threads and why we use\u00a0parallel\u00a0processing. It contains also the first interleaving example (really simple) and how to solve it. In the third chapter, the author explains what is Thread Safety and how to achieve it using locks (intrinsic locks with synchronized). In the next chapter, you learn how to share objects between several threads. This include the notions of visibility, immutability, thread confinement and safe publication. With the fourth chapter, you learn how to design a thread safe class, delegate the thread safety to an other class and learn why it's really important to document the synchronization policies. In the last chapter of this first part, we see how to build blocks of statements. We use concurrent collections, blocking queues, synchronizers, blocking and interruptible methods.\nThe second part is about structuring concurrent applications. It contains information about the executor framework, finding\u00a0parallelism, the cancellation and the shutdown of tasks, the thread pools and the GUI applications.\nThe third part is about liveness hazards, performance and scalability and also about testing concurrent programs.\nThe last part describe advanced topics. It contains explicit locks using ReentrantLock. It explains also how to build custom synchronizers. A chapter is about building concurrent programs using non-blocking algorithms. This algorithms are better performing but a lot more difficult to build. And the last chapter is about the Java Memory Model. This chapter is very technical but really interesting if you are interested to understand deeply the Java language.\nTo conclude, this book is a reference for every person who want to write concurrent applications.\nPost Scriptum : This is the hundredth post of this blog. I'm proud to see that there is a lot of regular readers and I hope that this blog will live long.", 
      "tags": "Books,Concurrency,Java"
    }, 
    {
      "loc": "/posts/2010/08/holidays.html", 
      "title": "Holidays", 
      "text": "Monday, I will go on holidays for one week. I'll not have internet except on my smartphone, so I'll not post on this blog during one week.\nI will just approve comments and perhaps answer to comments if this is necessary, but this is all.\nSo, to next week.", 
      "tags": "Others,Personal,The site"
    }, 
    {
      "loc": "/stories/jtheque-project.html", 
      "title": "JTheque", 
      "text": "JTheque is a personal project I've developed for several years now.\nIt a parent project for several projects I've made:\n\nJTheque Core : A framework to create modular Java Desktop applications\nJTheque Utils: A collection of utility classes to facilitate the development of Java applications\nJTheque XML Utils: A simple library to write and read XML files using JDOM or the javax.xml package\nSeveral applications including an application to manage movies, another to manage films or an application to generate metrics for a Java project.\n\nThe repositories are available on my Github repositories.", 
      "tags": ""
    }, 
    {
      "loc": "/posts/2010/08/a-website-for-jtheque.html", 
      "title": "A website for JTheque", 
      "text": "I've the pleasure to inform you that I've created a new website in English for JTheque : http://www.jtheque.com\nThe old websites of JTheque (a French website and a French forge) were completely out of date and were too complicated too manage. This time I created an english, really simple, website to add the more useful informations about my JTheque projects. I always wanted to have a real website for JTheque. Before that, I had the Maven auto generated websites, but this is not a real website and it's not really good-looking. I used Google Sites to create this website.\nAt this time, I've included three projects in the website : JTheque Core, JTheque Utils and JTheque XML Utils. There is not a lot of informations for the moment, \u00a0but from this time I'll include all the future informations in this new website and I will of course inform you via this blog of all the informations about my projects.\nI hope that this website will interest you and that it will help to promote a little my JTheque Project.\nIf you found any error on the website, don't hesitate to contact me, via comment or email or whatever you want. If you need more informations on one or more project, don't hesitate to request them and I will include them in the website as soon as possible.", 
      "tags": "Java,JTheque"
    }, 
    {
      "loc": "/posts/2010/08/do-not-use-relative-path-with-logback.html", 
      "title": "Do not use relative path with LogBack", 
      "text": "A little tip that can be useful and save a lot of time : Do not use relative path with LogBack.\nI wondered why this little LogBack configuration didn't work :\n<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n\n<configuration>\n    <contextName>JTheque</contextName>\n\n    <appender name=\"FILE\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\">\n        <file>logs/jtheque.log</file>\n\n        <rollingPolicy class=\"ch.qos.logback.core.rolling.FixedWindowRollingPolicy\">\n            <FileNamePattern>logs/jtheque.%i.log.zip</FileNamePattern>\n            <MinIndex>1</MinIndex>\n            <MaxIndex>5</MaxIndex>\n        </rollingPolicy>\n\n        <triggeringPolicy class=\"ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy\">\n            <MaxFileSize>5MB</MaxFileSize>\n        </triggeringPolicy>\n\n        <layout class=\"ch.qos.logback.classic.PatternLayout\">\n            <Pattern>%d{HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n</Pattern>\n        </layout>\n    </appender>\n\n    <root level=\"DEBUG\">\n        <appender-ref ref=\"FILE\"/>\n    </root>\n</configuration>\n\n\n\nNo file were written. I searched during a long time and after that tested with an absolute path and it worked really well. But absolute path is not very good. But, you can use system properties in the configuration, so I used user.dir to make the think works : \n        ...\n        <file>${user.dir}/logs/jtheque.log</file>\n\n        <rollingPolicy class=\"ch.qos.logback.core.rolling.FixedWindowRollingPolicy\">\n            <FileNamePattern>${user.dir}/logs/jtheque.%i.log.zip</FileNamePattern>\n            <MinIndex>1</MinIndex>\n            <MaxIndex>5</MaxIndex>\n        </rollingPolicy>\n        ...\n\n\n\nAnd this time, it works well !\nHope this will be useful to somebody.", 
      "tags": "Java,Tips"
    }, 
    {
      "loc": "/posts/2010/08/generate-graphs-benchmarks-easily.html", 
      "title": "Generate graphs benchmarks easily", 
      "text": "After launching a lot of benchmarks for file copy benchmark and always generating the graphs from the results in Excel, I realized that I was loosing a lot of time to do that. So like any Java developer, I decided to create a little tool that do the work automatically for me.\nFor creating benchmarks, I'm using a little micro-benchmarking framework, described here. After the results are generated, I automatically generate a bar chart of the result using JFreeChart.\nHere is an example of graph generated by the tool :\n\n\n\nUsage of the library\n\nThe usage is quite simple. By example, if you want to benchmark two methods :\npublic void method1(){\n    //Code...\n}\n\npublic void method2(){\n    //Code...\n}\n\n\n\nStart creating a Benchs :\nBenchs benchs = new Benchs(\"Title of the benchmark\");\n\nbenchs.setFolder(\"folder_path\");\n\n\n\nfolder_path indicates the folder were the graphs will be generated.\nAnd let\u2019s start the benchs :\nbenchs.bench(\"First method\", new Runnable(){\n    public void run() {\n        method1();\n    }\n});\n\nbenchs.bench(\"Second method\", new Runnable(){\n    public void run() {\n        method2();\n    }\n});\n\nbenchs.generateCharts();\n\n\n\nThe charts will be generated in the specified folder.\nSub chart\n\nIf in the first graph, there is some methods that takes a lot more time than the others methods, a sub chart will be generated including only the best methods. The methods to be removed from the graph to create the sub graph are selected using an exclusion factor. All the benchmarks with a mean exclusionFactor times higher than an other benchmark mean will be excluded. You can configure the exclusion factor using the setExclusionFactor setter. The default is 50.\nYou can donwload it here :\u00a0benchmark-utils.tar.gz\nYou can consult the GitHub website for more informations and to get the sources.", 
      "tags": "Benchmarks,Java,Performances"
    }, 
    {
      "loc": "/posts/2010/08/tip-launch-java-applications-from-java-applications-with-ant.html", 
      "title": "Quick Tip : Launch Java Applications From Java applications with Ant", 
      "text": "One week ago, I searched a way to launch a Java application from an other Java application without loosing portability. And I found a post on StackOverflow explaining how achieve that goal using Apache Ant.\nIt's really easy. It use the Ant classes and simulate a project launching and a build task. In this post, we'll see a simple method to launch an application from Java.\n\n\nHere is a simple method that launch an application using Ant :\npackage org.jtheque.osgi;\n\nimport org.apache.tools.ant.BuildException;\nimport org.apache.tools.ant.BuildLogger;\nimport org.apache.tools.ant.DefaultLogger;\nimport org.apache.tools.ant.DemuxOutputStream;\nimport org.apache.tools.ant.Project;\nimport org.apache.tools.ant.taskdefs.Java;\nimport java.io.PrintStream;\n\npublic class Launcher {\n    private static int launchApplication(Class mainClass, String args) {\n        int returnCode;\n\n        Project project = new Project();\n\n        project.setBasedir(System.getProperty(\"user.dir\"));\n        project.init();\n\n        PrintStream out = System.out;\n        PrintStream err = System.err;\n\n        BuildLogger logger = new DefaultLogger();\n        logger.setOutputPrintStream(out);\n        logger.setErrorPrintStream(err);\n        logger.setMessageOutputLevel(Project.MSG_INFO);\n\n        project.addBuildListener(logger);\n\n        System.setOut(new PrintStream(new DemuxOutputStream(project, false)));\n        System.setErr(new PrintStream(new DemuxOutputStream(project, true)));\n\n        project.fireBuildStarted();\n\n        Throwable caught = null;\n        try {\n            project.log(\"Launch Application\");\n\n            Java javaTask = new Java();\n            javaTask.setTaskName(\"Application Launcher\");\n            javaTask.setProject(project);\n            javaTask.setFork(true);\n            javaTask.setFailonerror(true);\n            javaTask.setCloneVm(true);\n            javaTask.setClassname(mainClass.getName());\n            javaTask.setArgs(args);\n            javaTask.init();\n\n            returnCode = javaTask.executeJava();\n        } catch (BuildException e) {\n            caught = e;\n\n            returnCode = -1;\n        }\n\n        project.fireBuildFinished(caught);\n\n        System.setOut(out);\n        System.setErr(err);\n\n        return returnCode;\n    }\n}\n\n\n\nHere are some explanations :\n\n    First, we create a new Project using the user directory as base directory and init it.\n    Then, we create a simple logger using the System.out and System.err streams and replace then with demux streams\n    After that, we create the Java task. By using setCloneVm(true), the new virtual machine will clone the properties of the current virtual machine. We must use a fork virtual machine to get the return code of the application. We set also the name of the class and the args of the launch. Finally we init and execute the task\n    Once the application is finished, we get the return code and restore the old System.out and System.err streams\n\nIt's extremely simple and portable and the code is, I think, very clean.", 
      "tags": "Apache,Java,Libraries,Tips"
    }, 
    {
      "loc": "/posts/2010/08/presentation-usage-h2-database-engine.html", 
      "title": "Presentation and use of H2 Database Engine", 
      "text": "It makes a long time now that I started to use the H2 Database Engine as embedded database in JTheque and other projects. This post is a presentation of this database engine and some informations about its utilization.\nH2 is a pure Java database. It can work as embedded database or in server mode. The developers of the database have made all to have a very small footprint for this database, it takes around 1MB jar file size.\n\n\nPerformances\n\nAnother feature the developers find important in this database is the performance.\u00a0Here are two comparison graphs for H2, Derby and HSQLDB, generated directly from the benchmark data from the official H2 site.\n\n\nAs you can see, the performances of H2 are very good. It's the main reason I've used H2 instead of HSQLDB.\nModes\n\nH2 can work in three modes. Embedded, Server or Mixed modes. In each mode, you can use memory or persistent tables.\n\nIn this mode, the database is only accessible from the current virtual machine. It's the fastest connection mode.\n\nIn this mode, the database runs in a server, so several applications can access the database engines. Of course, this mode is slower than in embedded mode, because all datas are transfered using TCP/IP.\n\nIn this mode, the first application create the application in embedded mode but also start a server to provide access to the database.\nUse\n\nThe use of this database is as simple as the use of any other database. You just have to create to the database using the JDBC Driver and the database will be automatically created if needed or the server launched if needed.\nBy example, here it's an example to create an database in embedded mode, you just have to do that :\nClass.forName(\"org.hsqldb.jdbcDriver\").newInstance();\n\nConnection connexion = DriverManager.getConnection(\"jdbc:h2:test\", \"sa\",  \"\");\n\n\n\ntest is the name of the database. If the database already exists, the data will be loaded.\nYou can also create a database in memory. There is no persisting data. When you close the database, there is no data persisted. It's useful for benchmarking by example.  It's also the mode with the best performances. Here is an example to create a memory database (named test) :\nConnection connexion = DriverManager.getConnection(\"jdbc:h2:mem:test\", \"sa\",  \"\");\n\n\n\nTo start the server, you have two choice. You can launch it from the command line :\njava -cp h2*.jar org.h2.tools.Server\n\n\n\nOr programmatically :\nServer server = Server.createTcpServer(args).start();\n\n...\n\nserver.stop();\n\n\n\nAnd to connect to a remove server, just change the JDBC URL :\nConnection connexion = DriverManager.getConnection(\"jdbc:h2:tcp://localhost/~/test\", \"sa\",  \"\");\n\n\n\nThe database is closed when the last connection to the database is closed.\nThe SQL used is strandard SQL with some adds to support the features of H2. The syntax is described on the oficial site : SQL Grammar. By example, here are the SQL requests for creating the different types of database of H2 :\nCREATE CACHED TABLE cachedTable ...\nCREATE MEMORY TABLE memTable ...\nCREATE MEMORY TEMPORARY TABLE memTempTable ...\nCREATE CACHED TEMPORARY TABLE memTempTable ...\n\n\n\n\n    A cached table is the default type of table. The data are persistent and not limited by the memory.\n    A memory table is also persistent but the index of data is kept in the memory, so memory table cannot be too large.\n    A temporary table is deleted when closing the database.\n\n\nSo, I think we covered here the main things we must know to start using H2 Database Engine.\nFor more informations, consult the official site.", 
      "tags": "Java,Performances"
    }, 
    {
      "loc": "/posts/2010/08/java-file-copy-benchmarks-update.html", 
      "title": "Java File Copy Benchmarks Update", 
      "text": "I've made an update of my benchmark about file copy methods in Java. I've been asked for new informations about this benchmark and for new test, so I've included more results and informations.\nThis new version include two new complete benchmarks :\n\n    Benchmark on the same disk (Ext4)\n    Benchmark between two disks (Ext4 -> Ext4)\n\n\nAnd of course the old benchmark is always here : Benchmark between two disks (Ext4 -> NTFS).\nI've also included more informations about the disk and the benchmark. The statistics informations about the results are also included in the post. So you can found the standard deviation of the results and the confidence intervals of the results stats.\nAnd last but not least I've included a new method to copy files using the cp executable of Linux.\nThe results are always available at the same place : File Copy in Java - Benchmark", 
      "tags": "Benchmarks,I/O,Java,Performances"
    }, 
    {
      "loc": "/posts/2010/08/file-copy-in-java-benchmark.html", 
      "title": "File copy in Java - Benchmark", 
      "text": "Yesterday I wondered if the copyFile method in JTheque Utils was the best method or if I need to change. So I decided to do a benchmark.\nSo I searched all the methods to copy a File in Java, even the bad methods and found 5 methods :\n\n    Native Copy : Make the copy using the cp executable of Linux\n    Naive Streams Copy : Open two streams, one to read, one to write and transfer the content byte by byte.\n    Naive Readers Copy : Open two readers, one to read, one to write and transfer the content character by character.\n    Buffered Streams Copy : Same as the first but using buffered streams instead of simple streams.\n    Buffered Readers Copy : Same as the second but using buffered readers instead of simple readers.\n    Custom Buffer Stream Copy : Same as the first but reading the file not byte by byte but using a simple byte array as buffer.\n    Custom Buffer Reader Copy : Same as the fifth but using a Reader instead of a stream.\n    Custom Buffer Buffered Stream Copy : Same as the fifth but using buffered streams.\n    Custom Buffer Buffered Reader Copy : Same as the sixth but using buffered readers.\n    NIO Buffer Copy : Using NIO Channel and using a ByteBuffer to make the transfer.\n    NIO Transfer Copy : Using NIO Channel and direct transfer from one channel to other.\n    Path (Java 7) Copy : Using the Path class of Java 7 and its method copyTo()\n\nI think, this is the principal methods to copy a file to another file. The different methods are available at the end of the post. Pay attention that the methods with Readers only works with text files because Readers are using character by character reading so it doesn't work on a binary file like an image. Here I used a buffer size of 4096 bytes. Of course, use a higher value improve the performances of custom buffer strategies.\nFor the benchmark, I made the tests using different files.\n\n    Little file (5 KB)\n    Medium file (50 KB)\n    Big file (5 MB)\n    Fat file (50 MB)\n    And an enormous file (1.3 GB) only binary\n\n\nAnd I made the tests first using text files and then using binary files. I made the tests using in three modes :\n\n    On the same hard disk. It's an IDE Hard Disk of 250 GB with 8 MB of cache. It's formatted in Ext4.\n    Between two disk. I used the first disk and an other SATA Hard Disk of 250 GB with 16 MB of cache. It's formatted in Ext4.\n    Between two disk. I used the first disk and an other SATA Hard Disk of 1 TB with 32 MB of cache. It's formatted using NTFS.\n\n\nI used a benchmark framework, described here, to make the tests of all the methods. The tests have been made on my personal computer (Ubuntu 10.04 64 bits, Intel Core 2 Duo 3.16 GHz, 6 Go DDR2, SATA Hard Disks). The Java version used is a Java 7 64 bits Virtual Machine.\nI've cut the post into several pages due to the length of the post :\n\n    Introduction about the benchmark\n    Benchmark on the same disk\n    Benchmark between Ext4 and Ext4\n    Benchmark between Ext4 and NTFS\n    Conclusions about the benchmark results\n\n\n\n\nBenchmark on the same disk (Ext4)\n\nSo let's start with the results of the benchmarking using the same disk.\n\nWe can see that here the native and naive streams methods are a lot slower than the other methods. So lets remove the naive \u00a0streams method from the graph to have a better view on the other methods :\n\nThe first conclusion we can do is that the naive readers is a lot faster than the naive streams. It's because Reader use a buffer internally and this is not the case in streams. The others methods are closer, so we'll see with the next sizes what happens.\n\nHere, we have removed the two naive methods because they are too slows compared to the others.\nThe readers methods are slower than the equivalent streams methods because readers are working on chars, so they must make characters conversion for every char of the file, so this is a cost to add.\nAnother observation is that the custom buffer strategy is faster than the buffering of the streams and than using custom buffer with a buffered stream or a single stream doesn't change anything. The same observation can be made using the custom buffer using readers, it's the same with buffered readers or not. This is logical, because with custom buffer we made 4096 (size of the buffer) times less invocations to the read method and because we ask for a complete buffer we have not a lot of I/O operations. So the buffer of the streams (or the readers) is not useful here.\nThe NIO Buffer, NIO Transfer and Path strategies are almost equivalent to custom buffer.\n\nHere we see the limits of the simple buffered stream (and readers methods). And another really interesting thing we see is that the native is now faster than buffered streams and readers. Native method must start an external program and this has a cost not negligible. But the copy using the cp executable is really fast and that's because when the file size grows, the native method becomes interesting. All the other methods except the readers are almost equivalent.\n\nThis time we can see that the native copy method is here as fast as the custom buffer streams. The fast method is the NIO Transfer method.\nIt's interesting to see that it doesn't take 100 ms to copy a 50 MB file.\nWe'll see with binary now. We'll directly start with a 5 MB file.\n\nWe see exactly the same results as with a text file. The native method start to be interesting. We see precisely that the NIOand Path methods are really interesting here.\n\nWe can see that all the methods are really, really close, but the native, NIO Buffer, NIO Transfer and Path methods are the best. Just to be sure of these results, let's test with a bigger file :\n\nHere we can see that the native method become to be the fastest one. The other method are really close. I thought the NIO Transfer will be normally faster. Due to the size of the file the benchmark has been made only a little number of times, so the number can be inaccurate. We see that he Path method is really close to the other.\nThe detailed informations (standard deviation, confidence intervals and other stats stuff) are available in the conclusion page.\n\n\nBenchmark between two disks (Ext4 -> Ext4)\n\nHere are the results of the same tests but using two hard disk with the same formatting (Ext4).\n\nWe see exactly the same results as in the first benchmark. The naive streams iscompletely useless for little files. So let's remove itand see what happens for interesting methods :\n\nHere again, the conclusion are the same and the times are not enough big to make global conclusions.\n\nHere, we have the limits of the buffered strategy and see a real advantage of custom buffer strategy. We also see that the NIO Transfer and Path methods are taking a little advantage. But again, the times are really short.\n\nWe can see the reintroduction of the native method on the interesting methods.\n\nSo we covered the text files. If we compare the times between the first benchmark (the same disk) and this method (between two disk), we can see that the times are almost the same, just a little slower for some methods. So let's watch the big binary files :\n\nAgain, the results are close to using the same disk. So let's see with the last file :\n\nThis time, the differences are impressive. The native and NIO Buffer methods are the fastest methods. The NIO Transfer is a little slower but the Path method is a lot slower here.\nThis transfer is a lot faster than on the same disk. I'm not sure of the cause of these results. The only reason I can found is that the operating system can made the two things at the same time, reading on the first disk and writing on the second disk. If someone has a better conclusion, don't hesitate to comment the post.\nThe detailed informations (standard deviation, confidence intervals and other stats stuff) are available in the conclusion page.\n\n\nBenchmark between two disks (Ext4 -> NTFS)\n\nHere are the results of the first version of this post. The first disk is always the same, but the second disk is a NTFS. For concision, I removed some graphes. I've also removed the conclusion that are the same as the first two benchmarks. The native method is not covered in these results.\n\nThe best two versions are the Buffered Streams and Buffered Readers. Here this is because the buffered streams and readers can write the file in only one operation. Here the times are in microseconds, so there is really little differences between the methods. So the results are not really relevant.\nNow, let's test with a bigger file.\n\nWe can see that the versions with the Readers are a little slower than the version with the streams. This is because Readers works on character and for every read() operation, a char conversion must be made, and the same conversion must be made on the other side.\nAnother observation is that the custom buffer strategy is faster than the buffering of the streams and than using custom buffer with a buffered stream or a single stream doesn't change anything. The same observation can be made using the custom buffer using readers, it's the same with buffered readers or not. This is logical, because with custom buffer we made 4096 (size of the buffer) times less invocations to the read method and because we ask for a complete buffer we have not a lot of I/O operations. So the buffer of the streams (or the readers) is not useful here. The NIO buffer strategy is almost equivalent to custom buffer. And the direct transfer using NIO is here slower than the custom buffer methods. I think this is because here the cost of invoking native methods in the operating system level is higher than simply the cost of making the file copy.\n\nHere, it's now clear that the custom buffer strategy is a better than the simple buffered streams or readers and that using custom buffer and buffered streams is really useful for bigger files. The Custom Buffer Readers method is better than Custom Buffer Streams because FileReader use a buffer internally.\nAnd now, continue with a bigger file :\n\nYou can see that it doesn't take 500 ms to copy a 50 MB file using the custom buffer strategy and that it even doesn't take 400 ms with the NIO Transfer method. Really quick isn't it ? We can see that for a big file, the NIO Transfer start to show an advantage, we'll better see that in the binary file benchmarks. We will directly start with a big file (5 MB) for this benchmark :\n\nSo we can make the same conclusion as for the text files, of course, the buffered streams methods is not fast. The other methods are really close.\n\nWe see here again that the NIO Transfer is gaining advantages more the files is bigger.\nAnd just for the pleasure, a great file (1.3 GB) :\n\nWe see that all the methods are really close, but the NIO Transfer method has an advantage of 500 ms. It's not negligible.\nA conclusion we can make is that transfering a file from Ext4 to Ext4 is a lot faster than from Ext4 to NTFS. I think it's logical because the operating system must made conversions. I think it's not because of the disk, because the NTFS disk is the faster I've.\n\n\nConclusion\n\nIn conclusion, the NIO Transfer method is the best one for big files but it's not the fastest for little files (< 5 MB). But the custom buffer strategy (and the NIO Buffer too) are also really fast methods to copy files. We've also see that the method using the native utility tools to make the copy is faster as NIO for big files (< 1 GB) but it's really slow for little files because of the cost of invoking an external program.\nSo perhaps, the best method is a method that make a custom buffer strategy on the little files and a NIO Transfer on the big ones and perhaps use the native executable on the really bigger ones. But it will be interesting to also make the tests on an other computer and operating system.\nWe can take several rules from this benchmark :\n\n    Never made a copy of file byte by byte (or char by char)\n    Prefer a buffer in your side more than in the stream to make less invocations of the read method, but don't forget the buffer in the side of the streams\n    Pay attention to the size of the buffers\n    Don't use char conversion if you only need to tranfer the content of a file, so don't use Reader if you need only streams.\n    Don't hesitate to use channels to make file transfer, it's the fastest way to make a file transfer.\n    Consider the native executable invocation only for really bigger files.\n    The new Path method of Java 7 is really fast except for the transfer of an enormous file between two disks.\n\n\nI hope this benchmark (and its results) interested you.\nHere are the sources of the benchmark :\u00a0File Copy Benchmark Version 3\nHere are the informations complete for the benchmark between two disks : Complete results of first two benchmarks", 
      "tags": "Benchmarks,I/O,Java,Performances"
    }, 
    {
      "loc": "/posts/2010/07/effective-java-second-edition-book-review.html", 
      "title": "Effective Java, second edition \u2013 Book Review", 
      "text": "Before reading that book, I read the translation in French of the first edition, but I've thinked that it will be interesting to read the second edition and this time in\u00a0English.\n\nThis book is the book to read if you want to write good Java code. All the advices are really useful. It's really\u00a0comfortable\u00a0to read book from a person who master Java. In fact, Joshua led the design and implementation of numerous Java features.\n\n\nThe book is separated into 10 chapters :\n\n    Creating and destroying objects : This first chapter is about how to create the objects. It describes methods to improve the creation of objects, like static factories, builders or singletons.\n    Methods common to all objects : This chapter explains how, and when, to implement the equals, hashCode, clone, toString and compareTo methods. Here, the contract of these methods \u00a0are described and explained and the examples show you how to code these methods.\n    Classes and interfaces : \u00a0Here, we learn how to use the interfaces and abstract classes to have a good design. It describe also when to use inheritance or composition.\n    Generics :This chapter explains how to work with generics. We learn how to avoid unchecked warnings and how to create generics methods.\n    Enum and annotations : The fifth chapter is about the use of enums and annotations in your API. We learn how to create powerful enums and annotations to improve code. We also learn how to use the power of these two concepts to create flexible and powerful code.\n    Methods : This chapter cover the creation of methods. How to write them, what to do with the parameters and what to return from a method.\n    General programming : Here you'll found about 10 general advices like avoiding float and double if exact answers are needed or avoid wrappers.\n    Exceptions : This chapter teach you how to work with exceptions and how to create code that throws exceptions.\n    Concurrency : Here you will learn what you to use when you need to work with several threads. It shows what the standard API contains for concurrency utilities. Moreover you will see what to avoid to use when making concurrent programs.\n    Serialization : \u00a0The last chapter is about the serialization. We'll see how to make a class Serializable and how to work with Serializable classes. We see also several advanced techniques (readResolve or serialization proxies) for instance control.\n\n\nIf you follow the advices of all the chapters, you'll be able to create really flexible,\u00a0maintainable\u00a0and usable API.\nTo conclude, I must say that this book must be read by every advanced programmers. It's not a book to learn Java from the basis, but a book to learn how to write good Java especially how to create API for others.", 
      "tags": "Books,Java"
    }, 
    {
      "loc": "/posts/2010/07/intellij-idea-10-eap-is-here.html", 
      "title": "IntelliJ Idea 10 Early Acces Program is here", 
      "text": "Today, the Early Access Program (EAP) has been opened for IntelliJ Idea 10.\nThere is a lot of changes, here are some of them (the most interesting in my point of view) :\n\n    Faster indexing speed\n    Java - Faster method usage search\n    Spring Web Services support\n    Spring testing support\n    New Spring live templates (patterns and frameworks)\n    intelligent resources support (smart completion and warnings for resource types)\n    Maven Refactorings\n    Maven pom.xml editor new features\n    Maven Dependencies Diagram\n    Discover & download libraries from maven repositories even in plain java projects\n    XML editing improvements in IntelliJ IDEA X\n    Git support improvements, including 'Git Log' view.\n    Mercurial support\n    Hibernate Criteria API supported\n    JDBC Console UI revised\n    Initial support for AspectJ and Spring Roo frameworks\n    A lot of other interesting features\n\n\nTo consult the full list of new features, read the release notes. And if you want to test this version, download it here.", 
      "tags": "IntelliJ Idea,Java,Releases,Tools"
    }, 
    {
      "loc": "/posts/2010/07/discover-java-visualvm-1-3.html", 
      "title": "Discover Java VisualVM 1.3", 
      "text": "2 days ago, Java VisualVM 1.3 has been released. We'll see what's new with this release. \nAt this time, there is no package for Ubuntu, so we'll install it manually : \nwget https://visualvm.dev.java.net/files/documents/7163/151728/visualvm_13.zip\nunzip visualvm_13.zip\n\nAnd then we can directly launch it : \ncd visualvm_13/bin\nsh visualvm\n\nYou'll be asked for the license agreement and after that the tool is launched : \n\n\n\nHere there is nothing new, except for the change of version of course. So let's profile something. In my case, I profile IntelliJ Idea for the test, but this doesn't change anything. We immediately see that there is a new tab (Sampler). If we watch the three first tabs (Overview, Monitor and Threads), we see that there is no changes. \nThe Sampler tab is simply a plugin (VisualVM Sampler Plugin) that has been integrated by default in VisualVM. Sampling is not like profiling. There is no instrumentation, so no setup time and almost no overhead, the application run at full speed. This is achieved by periodically polling the monitored application for thread dumps or memory histograms. So let's test to the Sampler tab : \n\nLike, int the Profiler tab, we can launch CPU or Memory sampling. So let's try CPU : \n\nYou will immediately see the speed of the results, there is no time to wait, but the refreshes are slower of course, because, it's periodic. The results are like in the Profiler tab. If we start Memory Sampling : \n\nOnce again, the results are the same as with the Profiler, but we see a new feature, the PermGen histogram : \n\nThat could be really useful to see why your application takes a lot of PermGen space or simply to see that there is not enough PermGen space. \nThere is another new feature in this version. The Tracer Probes. But by default, there is no installed probes, so you must install plugins to see them : \n\nThen, just click install, accept the license agreement and let the application restart. And then, if you launch the profiling of an application, you'll see the Tracer tab : \n\nYou see that there is a lot of probes that we can enable. So let's enable some probes and Start the Tracer : \n\nLike the profiler, there is a needed time of instrumentation and after that, you will see some graphs. There is a graph for each probe you selected. Each probe display some specific data, by example, the Threads Probe display the number of threads and the number of Deamon threads and the JIT Compiler Probe display the activity of the JIT compiler. Here I've also enabled some Swing probes because IntelliJ Idea use Swing, but you have also Probes for JavaFX by example.  If you pass the mouse on the graphs, you will see the exact values at the time where the cursor is : \n\nIt's think this new Tracer is just awesome. It's really useful and really good-looking. \nSo we've now covered the main new features of this new version. I think this version adds some great new features and improvements and that will make of VisualVM an essential profiler. \nFor the complete information about this new version, read the release notes.", 
      "tags": "Java,Performances,Releases,Tools"
    }, 
    {
      "loc": "/posts/2010/07/top-15-best-wordpress-plugins.html", 
      "title": "Top 15 Best Wordpress Plugins", 
      "text": "When working on a Wordpress site or blog, it's essential to install several plugins to optimize the site readibility, accessibility, performances, ...\nHere are 15 plugins that I think the best of the Wordpress plugins and that I use everyday. The list is not in interest order but in alphabetical order.\nAkismet - Avoid spam\nThis plugin automatically filters spams for you. It's really simple, you just have to install it and it works great. In my little blog, it filters more than hundred spams a day.\n\n\n\nAll in One SEO Pack - Improve your SEO\nThis plugin helps you to improve the SEO capability of your website. It can automatically generate the keywords and description of the posts and it give you forms to set the meta informations of the post.\nDagon Design Sitemap Generator - Simple sitemap generator\nThis plugin generate a simple sitemap for your website content. You can see an example on my website.\nGoogle Analytics for Wordpress - Get stats of your visitors\nThis plugin integrates Google Analytics in your website. But this plugin makes a lot more, it also add custom variables to your stats to track your tags and categories in Google Analytics.\nGoogle XML Sitemap Generator - Generate a XML Sitemap for Google\nThis plugin generate a XML Sitemap for search engines and keep it up to date with your site content. For referencing your website it's really important to have a XML sitemap and to update it regularly. With this plugin, you have nothing to do. Just write your posts and they will be included in the sitemap.\nMost Commented Widget - Add a widget with the most commented posts\nBy default, WordPress don't provide a widget to display the most commented posts of the blog. But I think, it's really an interesting things for the readers. So this reader adds this widget and allows you to choose the number of posts to display and the number of days in which we take the posts.\n\nRandom Posts widget - Add a widget with some random posts\nAn other interesting widget is this one that display some random posts. It's a good idea to improve the visibility of some posts. In this widget you can choose how many posts you want to be displayed and from which category we must take them.\n\nOptimize DB - Avoid overhead on your tables\nThis plugin is one of the little you'll find but one of the most useful. It allows you to optimize your database from your admin panel to avoid overhead in WordPress tables.\n\nSecure WordPress - Improve security\nThis plugin is not useful for your users but to prevent simple attacks to your blog. This plugin executes several tasks to secure your WordPress installation.\nSubscribe To Comments - Let the users subscribe to comments\nWhen a user post a comment in your website, he want perhaps be notified about the next comments on the same post. This plugin adds exactly this feature to your blog. The users can subscribe to the comments on one post to be notified by email of the next comments.\nTwitter Widget Pro - Add a widget with your tweets\nThis plugin add a widget to display your last tweets and a link to follow you on Twitter.\n\nW3 Total Cache - Improve your performances\nIf you want good performances on your WordPress blog, W3 Total Cache is the best plugin you can ever found. For more informations, don't hesitate to read this article I wrote about it : Improve performances of WordPress with W3 Total Cache\nWordPress Related Posts - Generate related posts\nThis plugin generate a list of related post to each of your post. This is a great way to give to your users a list of post related to their current reading.\n\nWP-Syntax - Syntax higlighting\nIt's an essential plugin for all persons who post code in their blog. It provide syntax higlighting for a lot of languages (more than 70). I principally use Java, HTML and XML. The renderering is quite simple but works well.\n\nWPtouch iPhone Theme - Make your site accessible on Iphone\nThis little plugin create an iPhone theme for your website. It's generated automatically, you have nothing to do, so when a visitor visit your blog from iPhone, it automatically see a theme adapted to this phone.\n\nAll these plugins are available in the WordPress repository so you can automatically install them from your blog without any problem.", 
      "tags": "Web,WordPress"
    }, 
    {
      "loc": "/posts/2010/07/tip-optimize-images-on-ubuntu-linux.html", 
      "title": "Tip : Optimize images on Ubuntu Linux", 
      "text": "When working with a lot of images by example for galleries on a website, it could be really interesting to optimize the images to save a lot of space and directly improve the performances of the website and save some traffic if this is limited by your hosting. \nOptimize JPEG images with jpegoptim\n\nA great tool to optimize JPEG images is jpegoptim. It's a simple command line tool available as Ubuntu package. You can install it easily : \nsudo apt-get install jpegoptim\n\nAnd it's also really simple to use. First, to optimize an image without loss : \njpegoptim image.jpg\n\nOr with a loss of max 25% : \njpegoptim --max=75 image.jpg\n\nMore informations on the official site.\nOptimize PNG, BMP and GIF images with optipng\n\nAn other tool to optimize other types of images is optipng. Here again you can install it with apt-get : \nsudo apt-get install optipng\n\nIt's as easy as the first tool : \noptipng image.png\n\nYou can also configure the tool to use the best optimization level, but also the slowest : \noptipng -o7 image.png\n\nSo here we are : You have now enough informations to optimize all you images on Ubuntu. I hope this will be useful to somebody.", 
      "tags": "Linux,Tips,Tools"
    }, 
    {
      "loc": "/posts/2010/07/intellij-idea-9-0-3-is-here.html", 
      "title": "IntelliJ Idea 9.0.3 is here !", 
      "text": "A new version of IntelliJ Idea is available : IntelliJ Idea 9.0.3\n\n    A new UI for\u00a0merging Subversion branches\n    A new tool to store encrypted passwords for VCS, proxy server etc.\n    A lot of bugfixes, more than 350\n    The HTML editor comes with initial support for HTML 5\n    The Flex debugger has been improved a lot\n    This version supports now Grails 1.3.x\n    Several little performance improvements in specific part (XHTML editing by example)\n\n\nThe change notes are available on the site of JetBrains.\nYou can download it from now and install it manually or just launch Idea and the patch will be downloaded and applied.", 
      "tags": "IntelliJ Idea,Java,Releases,Tools"
    }, 
    {
      "loc": "/posts/2010/07/osgi-spring-dynamic-modules-hello-world.html", 
      "title": "OSGI and Spring Dynamic Modules - Simple Hello World", 
      "text": "In this post, we'll take the first implementation we made using OSGi and use Spring Dynamic Modules to improve the application. \nSpring Dynamic Modules (Spring Dm) makes the development of OSGi-based applications a lot more easier. With that, the deployment of services is a lot easier. You can inject services like any other Spring beans. \nSo let's start with Spring dm. \n\n\nFirst of all, you need to download the Spring Dm Distribution. For this article, I used the distributions with dependencies and I will only use this libraries : \ncom.springsource.net.sf.cglib-2.1.3.jar\ncom.springsource.org.aopalliance-1.0.0.jar\nlog4j.osgi-1.2.15-SNAPSHOT.jar\ncom.springsource.slf4j.api-1.5.0.jar\ncom.springsource.slf4j.log4j-1.5.0.jar\ncom.springsource.slf4j.org.apache.commons.logging-1.5.0.jar\norg.springframework.aop-2.5.6.SEC01.jar\norg.springframework.beans-2.5.6.SEC01.jar\norg.springframework.context-2.5.6.SEC01.jar\norg.springframework.core-2.5.6.SEC01.jar\nspring-osgi-core-1.2.1.jar\nspring-osgi-extender-1.2.1.jar\nspring-osgi-io-1.2.1.jar \n\nOf course, you can replace the Spring 2.5.6 libraries with the Spring 3.0 libraries. But for this article, Spring 2.5.6 will be enough. \nSo, start with the service bundle. If we recall, this bundle exported a single service : \npackage com.bw.osgi.provider.able;\n\npublic interface HelloWorldService {\n    void hello();\n}\n\n\n\npackage com.bw.osgi.provider.impl;\n\nimport com.bw.osgi.provider.able.HelloWorldService;\n\npublic class HelloWorldServiceImpl implements HelloWorldService {\n    @Override\n    public void hello(){\n        System.out.println(\"Hello World !\");\n    }\n}\n\n\n\nThere is no changes to do here. Now, we can see the activator : \npackage com.bw.osgi.provider;\n\nimport org.osgi.framework.BundleActivator;\nimport org.osgi.framework.BundleContext;\nimport org.osgi.framework.ServiceRegistration;\nimport com.bw.osgi.provider.able.HelloWorldService;\nimport com.bw.osgi.provider.impl.HelloWorldServiceImpl;\n\npublic class ProviderActivator implements BundleActivator {\n    private ServiceRegistration registration;\n\n    @Override\n    public void start(BundleContext bundleContext) throws Exception {\n        registration = bundleContext.registerService(\n                HelloWorldService.class.getName(),\n                new HelloWorldServiceImpl(),\n                null);\n    }\n\n    @Override\n    public void stop(BundleContext bundleContext) throws Exception {\n        registration.unregister();\n    }\n}\n\n\n\nSo, here, we'll make simple. Let's delete this class, this is not useful anymore with Spring Dm. \nWe'll let Spring Dm export the bundle for us. We'll create a Spring context for this bundle. We just have to create a file provider-context.xml in the folder META-INF/spring. This is a simple context in XML file but we use a new namespace to register service, \"http://www.springframework.org/schema/osgi\". So let's start : \n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n       xmlns:osgi=\"http://www.springframework.org/schema/osgi\"\n       xmlns:context=\"http://www.springframework.org/schema/context\"\n       xsi:schemaLocation=\"\n            http://www.springframework.org/schema/beans\n            http://www.springframework.org/schema/beans/spring-beans-3.0.xsd\n            http://www.springframework.org/schema/osgi\n            http://www.springframework.org/schema/osgi/spring-osgi.xsd\">\n\n    <bean id=\"helloWorldService\" class=\"com.bw.osgi.provider.impl.HelloWorldServiceImpl\"/>\n\n    <osgi:service ref=\"helloWorldService\" interface=\"com.bw.osgi.provider.able.HelloWorldService\"/>\n</beans>\n\n\n\nThe only thing specific to OSGi is the osgi:service declaration. This line indicates that we register the helloWorldService as an OSGi service using the interface HelloWorldService as the name of the service. \nIf you put the context file in the META-INF/spring folder, it will be automatically detected by the Spring Extender and an application context will be created. \nWe can now go to the consumer bundle. In the first phase, we created that consumer : \npackage com.bw.osgi.consumer;\n\nimport javax.swing.Timer;\nimport java.awt.event.ActionEvent;\nimport java.awt.event.ActionListener;\nimport com.bw.osgi.provider.able.HelloWorldService;\n\npublic class HelloWorldConsumer implements ActionListener {\n    private final HelloWorldService service;\n    private final Timer timer;\n\n    public HelloWorldConsumer(HelloWorldService service) {\n        super();\n\n        this.service = service;\n\n        timer = new Timer(1000, this);\n    }\n\n    public void startTimer(){\n        timer.start();\n    }\n\n    public void stopTimer() {\n        timer.stop();\n    }\n\n    @Override\n    public void actionPerformed(ActionEvent e) {\n        service.hello();\n    }\n}\n\n\n\nAt this time, there is no changes to do here. Instead of the injection with constructor we could have used an @Resource annotation, but this doesn't work in Spring 2.5.6 and Spring Dm (but works well with Spring 3.0). \nAnd now the activator : \npackage com.bw.osgi.consumer;\n\nimport org.osgi.framework.BundleActivator;\nimport org.osgi.framework.BundleContext;\nimport org.osgi.framework.ServiceReference;\nimport com.bw.osgi.provider.able.HelloWorldService;\n\npublic class HelloWorldActivator implements BundleActivator {\n    private HelloWorldConsumer consumer;\n\n    @Override\n    public void start(BundleContext bundleContext) throws Exception {\n        ServiceReference reference = bundleContext.getServiceReference(HelloWorldService.class.getName());\n\n        consumer = new HelloWorldConsumer((HelloWorldService) bundleContext.getService(reference));\n        consumer.startTimer();\n    }\n\n    @Override\n    public void stop(BundleContext bundleContext) throws Exception {\n        consumer.stopTimer();\n    }\n}\n\n\n\nThe injection is not necessary anymore. We can keep the start of the timer here, but once again, we can use the features of the framework to start and stop the timer. So let's delete the activator and create an application context to create the consumer and start it automatically and put in the  META-INF/spring folder : \n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n       xmlns:osgi=\"http://www.springframework.org/schema/osgi\"\n       xmlns:context=\"http://www.springframework.org/schema/context\"\n       xsi:schemaLocation=\"\n            http://www.springframework.org/schema/beans\n            http://www.springframework.org/schema/beans/spring-beans-3.0.xsd\n            http://www.springframework.org/schema/osgi\n            http://www.springframework.org/schema/osgi/spring-osgi.xsd\">\n\n    <bean id=\"consumer\" class=\"com.bw.osgi.consumer.HelloWorldConsumer\" init-method=\"startTimer\" destroy-method=\"stopTimer\"\n          lazy-init=\"false\" >\n        <constructor-arg ref=\"eventService\"/>\n    </bean>\n\n    <osgi:reference id=\"eventService\" interface=\"com.bw.osgi.provider.able.HelloWorldService\"/>\n</beans>\n\n\n\nWe used the init-method and destroy-method attributes to start and stop the time with the framework and we use the constructor-arg to inject to reference to the service. The reference to the service is obtained using osgi:reference field and using the interface as a key to the service. \nThat's all we have to do with this bundle. A lot more simple than the first version isn't it ? And more than the simplification, you can see that the sources aren't depending of either OSGi or Spring Framework, this is plain Java and this is a great advantage. \nThe Maven POMs are the same than in the first phase except that we can cut the dependency to osgi. \nThe provider : \n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <modelVersion>4.0.0</modelVersion>\n    <groupId>OSGiDmHelloWorldProvider</groupId>\n    <artifactId>OSGiDmHelloWorldProvider</artifactId>\n    <version>1.0</version>\n    <packaging>bundle</packaging>\n\n    <build>\n        <plugins>\n            <plugin>\n                <groupId>org.apache.maven.plugins</groupId>\n                <artifactId>maven-compiler-plugin</artifactId>\n                <version>2.0.2</version>\n                <configuration>\n                    <source>1.6</source>\n                    <target>1.6</target>\n                </configuration>\n            </plugin>\n\n            <plugin>\n                <groupId>org.apache.felix</groupId>\n                <artifactId>maven-bundle-plugin</artifactId>\n                <extensions>true</extensions>\n                <configuration>\n                    <instructions>\n                        <Bundle-SymbolicName>OSGiDmHelloWorldProvider</Bundle-SymbolicName>\n                        <Export-Package>com.bw.osgi.provider.able</Export-Package>\n                        <Bundle-Vendor>Baptiste Wicht</Bundle-Vendor>\n                    </instructions>\n                </configuration>\n            </plugin>\n        </plugins>\n    </build> \n</project>\n\n\n\nThe consumer : \n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <modelVersion>4.0.0</modelVersion>\n    <groupId>OSGiDmHelloWorldConsumer</groupId>\n    <artifactId>OSGiDmHelloWorldConsumer</artifactId>\n    <version>1.0</version>\n    <packaging>bundle</packaging>\n\n    <dependencies>\n        <dependency>\n            <groupId>OSGiDmHelloWorldProvider</groupId>\n            <artifactId>OSGiDmHelloWorldProvider</artifactId>\n            <version>1.0</version>\n        </dependency>\n    </dependencies>\n\n    <build>\n        <plugins>\n            <plugin>\n                <groupId>org.apache.maven.plugins</groupId>\n                <artifactId>maven-compiler-plugin</artifactId>\n                <version>2.0.2</version>\n                <configuration>\n                    <source>1.6</source>\n                    <target>1.6</target>\n                </configuration>\n            </plugin>\n\n            <plugin>\n                <groupId>org.apache.felix</groupId>\n                <artifactId>maven-bundle-plugin</artifactId>\n                <extensions>true</extensions>\n                <configuration>\n                    <instructions>\n                        <Bundle-SymbolicName>OSGiDmHelloWorldConsumer</Bundle-SymbolicName>\n                        <Bundle-Vendor>Baptiste Wicht</Bundle-Vendor>\n                    </instructions>\n                </configuration>\n            </plugin>\n        </plugins>\n    </build>\n</project>\n\n\n\nAnd we can build the two bundles using maven install. So let's test our stuff in Felix : \nwichtounet@Linux-Desktop:~/Desktop/osgi/felix$ java -jar bin/felix.jar \n_______________\nWelcome to Apache Felix Gogo\ng! install file:../com.springsource.slf4j.org.apache.commons.logging-1.5.0.jar\nBundle ID: 5\ng! install file:../com.springsource.slf4j.log4j-1.5.0.jar\nBundle ID: 6\ng! install file:../com.springsource.slf4j.api-1.5.0.jar\nBundle ID: 7\ng! install file:../log4j.osgi-1.2.15-SNAPSHOT.jar\nBundle ID: 8\ng! install file:../com.springsource.net.sf.cglib-2.1.3.jar\nBundle ID: 9\ng! install file:../com.springsource.org.aopalliance-1.0.0.jar\nBundle ID: 10\ng! install file:../org.springframework.core-2.5.6.SEC01.jar\nBundle ID: 11\ng! install file:../org.springframework.context-2.5.6.SEC01.jar\nBundle ID: 12\ng! install file:../org.springframework.beans-2.5.6.SEC01.jar\nBundle ID: 13\ng! install file:../org.springframework.aop-2.5.6.SEC01.jar\nBundle ID: 14\ng! install file:../spring-osgi-extender-1.2.1.jar\nBundle ID: 15\ng! install file:../spring-osgi-core-1.2.1.jar\nBundle ID: 16\ng! install file:../spring-osgi-io-1.2.1.jar\nBundle ID: 17\ng! start 5 7 8 9 10 11 12 13 14 15 16 17\nlog4j:WARN No appenders could be found for logger (org.springframework.osgi.extender.internal.activator.ContextLoaderListener).\nlog4j:WARN Please initialize the log4j system properly.\ng! install file:../OSGiDmHelloWorldProvider-1.0.jar\nBundle ID: 18\ng! install file:../OSGiDmHelloWorldConsumer-1.0.jar\nBundle ID: 19\ng! start 18\ng! start 19\ng! Hello World !\nHello World !\nHello World !\nHello World !\nHello World !\nHello World !\nHello World !\nHello World !\nstop 19\ng! \n\nAs you can see, it works perfectly !\nIn conclusion, Spring Dm really makes easier the development with OSGi.  With Spring Dm you can also start bundles. It also allows you to make web bundles and to use easily the services of the OSGi compendium. \nHere are the sources of the two projects : \n\nOSGiDmHelloWorldProvider Sources\nOSGiDmHelloWorldConsumer Sources\n\n\nHere are directly the two buildeds Jars : \n\nOSGiDmHelloWorldProvider-1.0.jar\nOSGiDmHelloWorldConsumer-1.0.jar\n\n\nAnd here are the complete folder including Felix and Spring Dm : osgi-hello-world.tar.gz", 
      "tags": "Java,OSGi,Spring"
    }, 
    {
      "loc": "/posts/2010/07/tip-profile-osgi-application-visualvm.html", 
      "title": "Tip : Profile an OSGi application with VisualVM", 
      "text": "When you develop applications and you've performance problems, it's really interesting to see what can cause this problems. And it that case, the profilers are the most useful tool. By example, we can use VisualVM, packed by default with the Java Virtual Machine. For more information, you can read this introduction to Java VisualVM. \nBut, when you work with OSGi application, it's not as simple as a normal application. The profiler needs that its class can be found by the profiled classes, but with OSGi, the classloader are restricted by the framework and the classes of the profiler cannot be found. \n\n\nBut there is a workaround using boot class path and boot delegation. You need to do 2 things. \n1. Add the classes to the boot class-path \n\nFirst of all, the classes of the profiler must be present in the application. For that, we use the boot class-path. You must add this library in the boot class-path : ${VISUALVM_HOME}/profiler3/lib/jfluid-server.jar.  The boot class-path is configured using the -Xbootclasspath option, but if you just add this option : \n-Xbootclasspath:${VISUALVM_HOME}/profiler3/lib/jfluid-server.jar\n\nThe classes of the JRE will not be found and you will get that kind of error : \nError occurred during initialization of VM\njava/lang/NoClassDefFoundError: java/lang/Object\n\nSo we need to keep the default boot class-path. To get this, just launch this program : \npublic class BootClassPath {\n    public static void main(String[] args) {\n        System.out.println(System.getProperty(\"sun.boot.class.path\"));\n    }\n}\n\n\n\nAnd it will give you the default boot class-path. Then, you just have to append it to the jar of VisualVM with ':'. By example, on my computer, it's the option I need : \n-Xbootclasspath:/usr/lib/jvm/java-6-sun-1.6.0.20/lib/visualvm/profiler3/lib/jfluid-server.jar:/usr/lib/jvm/java-6-sun-1.6.0.20/jre/lib/resources.jar:/usr/lib/jvm/java-6-sun-1.6.0.20/jre/lib/rt.jar:/usr/lib/jvm/java-6-sun-1.6.0.20/jre/lib/sunrsasign.jar:/usr/lib/jvm/java-6-sun-1.6.0.20/jre/lib/jsse.jar:/usr/lib/jvm/java-6-sun-1.6.0.20/jre/lib/jce.jar:/usr/lib/jvm/java-6-sun-1.6.0.20/jre/lib/charsets.jar:/usr/lib/jvm/java-6-sun-1.6.0.20/jre/classes\n\n2. Add boot delegation to the OSGi framework\n\nThis is easier. Here you just have to said to the OSGi container, to made the classes of the profiler available to all bundles. For that, you need to add this property : \n-Dorg.osgi.framework.bootdelegation=org.netbeans.lib.profiler,org.netbeans.lib.profiler.*\n\nAnd normally, it's enough. But some OSGi containers, like Felix, doesn't take the command line properties in consideration in the framework depending on how you launch it. In my case, I embed the Felix Server in my application, so I need to explicitly add this property to the framework. For that, read the documentation of the containers to know how to add properties to the framework. \nHere we are. Hope this will be useful to someone. Personally, I lost a lot of time trying several configurations before finding this successful one.", 
      "tags": "Java,OSGi,Performances,Tips,Tools"
    }, 
    {
      "loc": "/posts/2010/07/play-framework-template-engine.html", 
      "title": "Play Framework - The template engine", 
      "text": "In the previous post about Play Framework, we seen how to install Play and create a first simple application. In this post, we'll see how to customize the views and use the template engine of the framework to easily create web pages.\nPlay has its own template engine to generate HTML web pages. The template engine use Groovy as expression language. You will use Groovy language to create all the dynamic parts of the web pages. But there is no need to learn completely Grooxy, it's really close to Java and if you know already knows Java, there is no problem to use Groovy in your templates. All the templates are located in the app/views folder in your application. All the dynamic part of the web page is resolved during the execution of the template and the result is a part of the HTTP Response.\n\n\nSo first of all, we'll create a little application for our needs :\nwichtounet@wichtounet-laptop:~/dev/play$ /usr/share/play/play new views\n\n~        _            _ \n~  _ __ | | __ _ _  _| |\n~ | '_ \\| |/ _' | || |_|\n~ |  __/|_|\\____|\\__ (_)\n~ |_|            |__/   \n\n~ play! 1.0.3, http://www.playframework.org\n~ The new application will be created in /home/wichtounet/dev/play/views\n~ What is the application name? Views\n~ OK, the application is created.\n~ Start it with : play run views\n~ Have fun!\n~\n\nSo we start to inspect what has been created by Play. If you go in app/views, you will see this structure :\n\n    Application : This folder is to store the templates of the Application controller\n    errors : This folder contains the templates for the HTTP Error pages (404, 500, ...)\n    main.html : This is the main template\n\n\nIf you open Application/index.html, you obtain this kind of code :\n#{extends 'main.html' /}\n#{set title:'Home' /}\n#{welcome /}\n\n\n\nThe first line indicate that we extend an other template (main.html). The next line use a Play tag (set), to set the title of the page. A set tag has a brother, the get tag who get the value setted by the set tag. The last line use the welcome tag who print the content of the welcome page. \nNow, let's see the main.html template : \n<!DOCTYPE html>\n<html>\n    <head>\n        <title>#{get 'title' /}</title>\n        <meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\n        <link rel=\"stylesheet\" type=\"text/css\" media=\"screen\" href=\"@{'/public/stylesheets/main.css'}\">\n        #{get 'moreStyles' /}\n        <link rel=\"shortcut icon\" type=\"image/png\" href=\"@{'/public/images/favicon.png'}\">\n        <script src=\"@{'/public/javascripts/jquery-1.4.2.min.js'}\" type=\"text/javascript\" charset=\"utf-8\"></script>\n        #{get 'moreScripts' /}\n    </head>\n    <body>\n        #{doLayout /}\n    </body>\n</html>\n\n\n\nThere is some interesting things here : \n\n#{get 'title' /} : return the value of the variable title (not a Java variable, only a HTML variable)\n@{'/public/stylesheets/main.css'} : resolve the resource to its URL\n#{doLayout /} : Indicate where the sub templates (template who extends main.html) will be rendered\n\n\nPass variables to the view\n\nSo let's go further. The first important thing is to know how to pass variables to the view from the controller. With Play Framework, this is really simple. just add the variables you need to the render() method of the controller. By example, to pass a String to the view : \npackage controllers;\n\nimport play.mvc.*;\n\npublic class Application extends Controller {\n    public static void index() {\n        String hello = \"Hello World from Controller !\";\n\n        render(hello);\n    }\n}\n\n\n\nThe variable hello is now accessible from the view on the name \"hello\". To get it, you have to use ${variable_name} simply to display it : \n#{extends 'main.html' /}\n#{set title:'Home' /}\nHello from the view\n<br />\n${hello}\n\n\n\nEasy, no ? \nLet's try adding a simple class to our model : \npackage models;\n\npublic class Book {\n    private final String title;\n\n    public Book(String title) {\n        super();\n\n        this.title = title;\n    }\n\n    public String getTitle() {\n        return title;\n    }\n\n\n\nAnd pass it to the view : \n    public static void index() {\n        Book book = new Book(\"Hello Play !\");\n\n        render(book);\n    }\n\n\n\nAnd then get it from the view : \n#{extends 'main.html' /}\n#{set title:'Home' /}\nHello from the view\n<br />\nI've a book for you \"${book.title}\". \n\n\n\nThe property is getted using the JavaBeans convention, so you have to create a getTitle() method to get the title of the book. \nAll the dynamic content is directly escaped by the template engine to avoid XSS security exploits. If you really want to not escape something, you have to use the raw() method available on all the strings. By example, for our title : \n${book.title.raw()}\n\n\n\nBut this is not a really good practice, and must be used only when it's necessary. \nYou can add comments to your templates if you want : \n*{Will not be evaluated by the template engine}*\n\n\n\nIterate over a list\n\nAn important thing to do in template and that comes really soon is the iterate over a collection. By example, we can pass a list of books to the view from the controller : \n    public static void index() {\n        List<Book> books = new ArrayList<Book>(3);\n\n        books.add(new Book(\"Hello Play !\"));\n        books.add(new Book(\"Hello Template !\"));\n        books.add(new Book(\"Hello Engine !\"));\n\n        render(books);\n    }\n\n\n\nAnd then, you can iterate over the list using the list tag : \n#{extends 'main.html' /}\n#{set title:'Home' /}\nI've some books for your :\n<ul>\n    #{list items:books, as:'book'}\n        <li>${book.title}</li>\n    #{/list}\n</ul>\n\n\n\nAnd that will display a single little list in our web page. Not to complicated :)\nUsing scripts\n\nIf you have to make complicated things, you can using scripts in Groovy. In scripts, you can declare variables and use all the other variables. By example, you can make the title upper case in a script : \n#{extends 'main.html' /}\n#{set title:'Home' /}\nI've some books for your :\n<ul>\n    #{list items:books, as:'book'}\n        %{\n           bookTitle = book.title.toUpperCase();\n        }%\n        <li>${bookTitle}</li>\n    #{/list}\n</ul>\n\n\n\nBut you can also do iterations, conditions and a lot of other things. But keep in mind that the templates are not the good place to make complicated things, for that you have the controller and the models. The template must be as simple as possible. \nDefine tags\n\nThere is lot of tags in Play Framework, but you can create your own tags. For that, you just have to create a folder tags in your views folder. By example, if you create booklist.html in views/tags and add the following code : \n<ul>\n    #{list items:_items, as:'book'}\n        %{\n            bookTitle = book.title.toUpperCase();\n        }%\n        <li>${bookTitle}</li>\n    #{/list}\n</ul>\n\n\n\nThe arguments are obtained using '_' following by the name of the arguments (_items in our example). \nYou can refactor the template index.html using the new tag : \n#{extends 'main.html' /}\n#{set title:'Home' /}\nI've some books for your :\n#{booklist items:books /}\n\n\n\nYou give arguments like in any other tag. This can help you to make cleaner templates and to avoid to copy/paste some codes. \nSo we've now covered the basis of the template engine of Play Framework. With all that we've seen, we can start to create simple Play Applications. \nA really good resources for Play Developer is the Play Cheat Sheet. You can also consult the official documentation for more complete informations.", 
      "tags": "Java,Play!,Web"
    }, 
    {
      "loc": "/posts/2010/07/osgi-hello-world-services.html", 
      "title": "OSGi - Simple Hello World with services", 
      "text": "In this post, we'll develop a simple Hello World application with OSGi. We will use Felix as OSGi container. In the next post, we'll continue with this application and use Spring Dynamic Modules to improve it. \nTo make the development interesting, we will create two bundles :\n\n    A bundle providing a service of HelloWorld\n    A bundle consuming the service to print hello at regular interval time.\n\n\n\n\nSo let's start with the first bundle. What we need first is a very simple service providing a simple print in the console :\npackage com.bw.osgi.provider.able;\n\npublic interface HelloWorldService {\n    void hello();\n}\n\n\n\npackage com.bw.osgi.provider.impl;\n\nimport com.bw.osgi.provider.able.HelloWorldService;\n\npublic class HelloWorldServiceImpl implements HelloWorldService {\n    @Override\n    public void hello(){\n        System.out.println(\"Hello World !\");\n    }\n}\n\n\n\nWe cannot make easier. Then, we need to export the Service using an activator : \npackage com.bw.osgi.provider;\n\nimport org.osgi.framework.BundleActivator;\nimport org.osgi.framework.BundleContext;\nimport org.osgi.framework.ServiceRegistration;\nimport com.bw.osgi.provider.able.HelloWorldService;\nimport com.bw.osgi.provider.impl.HelloWorldServiceImpl;\n\npublic class ProviderActivator implements BundleActivator {\n    private ServiceRegistration registration;\n\n    @Override\n    public void start(BundleContext bundleContext) throws Exception {\n        registration = bundleContext.registerService(\n                HelloWorldService.class.getName(),\n                new HelloWorldServiceImpl(),\n                null);\n    }\n\n    @Override\n    public void stop(BundleContext bundleContext) throws Exception {\n        registration.unregister();\n    }\n}\n\n\n\nA lot more code here. For those who aren't confident with OSGi, some explanations. The start method will be called when the module is started and the stop when it's stopped. In the start method, we register our service in the bundle context using the name of the interface as the name of the exported service. The third parameter, null, indicate that we doesn't give any configuration for this service. In the stop method, we just unregister the service. \nNow, our first bundle is ready. We can build it. For that we'll use Maven and the maven-bundle-plugin to build the OSGi Bundle directly. Here is the pom.xml file for the project. \n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <modelVersion>4.0.0</modelVersion>\n\n    <groupId>OSGiDmHelloWorldProvider</groupId>\n    <artifactId>OSGiDmHelloWorldProvider</artifactId>\n    <version>1.0</version>\n\n    <dependencies>\n        <dependency>\n            <groupId>org.apache.felix</groupId>\n            <artifactId>org.osgi.core</artifactId>\n            <version>1.4.0</version>\n        </dependency>\n    </dependencies>\n\n    <build>\n        <plugins>\n            <plugin>\n                <groupId>org.apache.maven.plugins</groupId>\n                <artifactId>maven-compiler-plugin</artifactId>\n                <version>2.0.2</version>\n                <configuration>\n                    <source>1.6</source>\n                    <target>1.6</target>\n                </configuration>\n            </plugin>\n\n            <plugin>\n                <groupId>org.apache.felix</groupId>\n                <artifactId>maven-bundle-plugin</artifactId>\n                <extensions>true</extensions>\n                <configuration>\n                    <instructions>\n                        <Bundle-SymbolicName>OSGiDmHelloWorldProvider</Bundle-SymbolicName>\n                        <Export-Package>com.bw.osgi.provider.able</Export-Package>\n                        <Bundle-Activator>com.bw.osgi.provider.ProviderActivator</Bundle-Activator>\n                        <Bundle-Vendor>Baptiste Wicht</Bundle-Vendor>\n                    </instructions>\n                </configuration>\n            </plugin>\n        </plugins>\n    </build> \n</project>\n\n\n\nAnd then, use mvn install to build it. \nWe'll work in a folder called osgi, so we'll copy this new bundle in the osgi folder. \nWe can already test it in the OSGi container. If you dont' have already Felix, let's download it here. You have to choose the \"Felix Distribution\". \nThen extract it to the osgi folder we created before. You must now have this folder structure : \nosgi\n  - felix \n  - OSGiDmHelloWorldProvider-1.0.jar\n\nSo we can go in the felix folder and launch Felix : \nwichtounet@Linux-Desktop:~/Desktop/osgi/felix$ java -jar bin/felix.jar \n_______________\nWelcome to Apache Felix Gogo\ng! \n\nAnd install our bundle : \ng! install file:../OSGiDmHelloWorldProvider-1.0.jar         \nBundle ID: 5\n\nThe install is good installed, we can try to start it and see its status : \ng! start 5\ng! bundle 5\nLocation             file:../OSGiDmHelloWorldProvider-1.0.jar\nState                32\nVersion              1.0.0\nLastModified         1279124741320\nHeaders              [Tool=Bnd-0.0.357, Bundle-Activator=com.bw.osgi.provider.ProviderActivator, Export-Package=com.bw.osgi.provider.able, Build-Jdk=1.6.0_20, Bundle-Version=1.0.0, Created-By=Apache Maven Bundle Plugin, Bundle-ManifestVersion=2, Manifest-Version=1.0, Bundle-Vendor=Baptiste Wicht, Bnd-LastModified=1279124686551, Bundle-Name=Unnamed - OSGiDmHelloWorldProvider:OSGiDmHelloWorldProvider:bundle:1.0, Built-By=wichtounet, Bundle-SymbolicName=OSGiDmHelloWorldProvider, Import-Package=com.bw.osgi.provider.able,org.osgi.framework;version=\"1.5\"]\nBundleContext        org.apache.felix.framework.BundleContextImpl@2353f67e\nBundleId             5\nSymbolicName         OSGiDmHelloWorldProvider\nRegisteredServices   [HelloWorldService]\nServicesInUse        null\n\nAll is fine. Our service is good registered :)\nNow we'll try to consume this service in our second bundle. Our consumer class will be very simple : \npackage com.bw.osgi.consumer;\n\nimport javax.swing.Timer;\nimport java.awt.event.ActionEvent;\nimport java.awt.event.ActionListener;\nimport com.bw.osgi.provider.able.HelloWorldService;\n\npublic class HelloWorldConsumer implements ActionListener {\n    private final HelloWorldService service;\n    private final Timer timer;\n\n    public HelloWorldConsumer(HelloWorldService service) {\n        super();\n\n        this.service = service;\n\n        timer = new Timer(1000, this);\n    }\n\n    public void startTimer(){\n        timer.start();\n    }\n\n    public void stopTimer() {\n        timer.stop();\n    }\n\n    @Override\n    public void actionPerformed(ActionEvent e) {\n        service.hello();\n    }\n}\n\n\n\nAnd now, we must create the activator to get the service and then give it to the consumer. That will give use something like this : \npackage com.bw.osgi.consumer;\n\nimport org.osgi.framework.BundleActivator;\nimport org.osgi.framework.BundleContext;\nimport org.osgi.framework.ServiceReference;\nimport com.bw.osgi.provider.able.HelloWorldService;\n\npublic class HelloWorldActivator implements BundleActivator {\n    private HelloWorldConsumer consumer;\n\n    @Override\n    public void start(BundleContext bundleContext) throws Exception {\n        ServiceReference reference = bundleContext.getServiceReference(HelloWorldService.class.getName());\n\n        consumer = new HelloWorldConsumer((HelloWorldService) bundleContext.getService(reference));\n        consumer.startTimer();\n    }\n\n    @Override\n    public void stop(BundleContext bundleContext) throws Exception {\n        consumer.stopTimer();\n    }\n}\n\n\n\nWe get a service reference from the bundle context using the name of the class. After that, we get the service instance from the bundle context. \nWe create also a little pom.xml file to build the bundle : \n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <modelVersion>4.0.0</modelVersion>\n    <groupId>OSGiDmHelloWorldConsumer</groupId>\n    <artifactId>OSGiDmHelloWorldConsumer</artifactId>\n    <version>1.0</version>\n    <packaging>bundle</packaging>\n\n    <dependencies>\n        <dependency>\n            <groupId>org.apache.felix</groupId>\n            <artifactId>org.osgi.core</artifactId>\n            <version>1.0.0</version>\n        </dependency>\n\n        <dependency>\n            <groupId>OSGiDmHelloWorldProvider</groupId>\n            <artifactId>OSGiDmHelloWorldProvider</artifactId>\n            <version>1.0</version>\n        </dependency>\n    </dependencies>\n\n    <build>\n        <plugins>\n            <plugin>\n                <groupId>org.apache.maven.plugins</groupId>\n                <artifactId>maven-compiler-plugin</artifactId>\n                <version>2.0.2</version>\n                <configuration>\n                    <source>1.6</source>\n                    <target>1.6</target>\n                </configuration>\n            </plugin>\n\n            <plugin>\n                <groupId>org.apache.felix</groupId>\n                <artifactId>maven-bundle-plugin</artifactId>\n                <extensions>true</extensions>\n                <configuration>\n                    <instructions>\n                        <Bundle-SymbolicName>OSGiDmHelloWorldConsumer</Bundle-SymbolicName>\n                        <Bundle-Activator>com.bw.osgi.consumer.HelloWorldActivator</Bundle-Activator>\n                        <Bundle-Vendor>Baptiste Wicht</Bundle-Vendor>\n                    </instructions>\n                </configuration>\n            </plugin>\n        </plugins>\n    </build>\n</project>\n\n\n\nThen, we use mvn install to create the bundle and we install it in the container : \ng! start 6\ng! Hello World !\nHello World !\nHello World !\nHello World !\nHello World !\nHello World !\nHello World !\nHello World !\nHello World !\nHello World !\nHello World !\nHello World !\nHello World !\nHello World !\ng! stop 6\n\nAnd here we are :) We've created our first application using OSGi. With that technology you can build modules really independant. \nIn the next post about OSGi, we'll see how to use Spring to make the OSGi development easier and to concentrate our effort on the application not OSGi.  \nThe sources of the two bundles are available here : \n\n    OSGiDmHelloWorldProvider sources\n    OSGiDmHelloWorldConsumer", 
      "tags": "Java,OSGi"
    }, 
    {
      "loc": "/posts/2010/07/state-of-the-lambda.html", 
      "title": "State of the Lambda", 
      "text": "Brian Goetz, from Oracle, has posted an updated proposal for the lambda expressions : State of the Lambda\nHere are some examples of closures taken from the proposal : \nWe can use lambda expressions to replace the heavy usage of Single Abstract Method (SAM) interfaces : \npublic interface CallbackHandler { \n    public void callback(Context c);\n}\n\nCallbackHandler cb = { c -> System.out.println(\"pippo\") };\n\n\n\nWe can make references to methods to use it as SAM interfaces : \nclass Person { \n    private final String name;\n    private final int age;\n\n    public static int compareByAge(Person a, Person b) { ... }\n    public static int compareByName(Person a, Person b) { ... }\n}\n\nPerson[] people = ...\n\nArrays.sort(people, #Person.compareByAge);", 
      "tags": "Closures,Java,Java 7"
    }, 
    {
      "loc": "/posts/2010/07/profile-applications-java-visualvm.html", 
      "title": "Profile your applications with Java VisualVM", 
      "text": "When you need to discover what part of an application consume the more CPU or Memory, you must use a profiler to do that.\nOne profiler, packed by default with the Sun JDK is Java VisualVM. This profiler is really simple to use and really powerful.\n\nIn this post, we'll see how to install it and use it to profile an application.\n\n\nNormally, to install it, you have nothing to do, because, it's installed with the JDK. But in several Unix system, like Ubuntu, this is not the case. If you want to install it, just use apt-get (or aptitude) :\nsudo apt-get install visualvm\nTo launch it just launch jvisualvm (jvisualvm.exe in the bin directory of the jdk for Windows).\nThat will open the following window :\n\nThere is not a lot of interesting things to see here. To profile a application, you just have to launch it and VisualVM will detect it as launched :\n\nAfter that, you just have to double click to view information about your running application. You've four tabs available for your applications (Overview, Monitor, Threads, Profiler). We'll see all that 4 tabs. First of all, the default tab, the overview :\n\nThis tab contains the main informations about the launched application. You can see the main class, the arguments of the command line, the JVM arguments. You can also see what kind of JVM is running your program and where the JVM is located. \u00a0And you can see all the properties set in the program.\nA more interesting tab is the \"Monitor\" tab :\n\nThis tab follow the CPU and Memory usages of your applications. You have 4 graphs in this view. The first one, from left to right, up to down, display the CPU usage and the Garbage Collector CPU usage. The second graph display the usage of the heap space and the PermGen space. The next graph display the total number of classes loaded in the application and the last one displays the number of threads currently running. With these graphs, you can see if your application take too CPU or if there is too memory used by the application.\nThe third tab provide some details about Threads :\n\nIn this view, you can see how the different threads of the application are changing state and how they evolve. You can also see the time each time pass in each state and you can have details about the threads you want.\nAnd now, I think the most interesting tab, is the Profiler one :\n\nWhen you open this tab first, it contains no information at all. You must start one kind of profiling before seeing informations. We'll start with CPU profiling. Just click on the CPU button the instrumentation will start. During the instrumentation, the application will be blocked. After the instrumentation, you can access the application again and you will see the results of the profiling be displayed in the table. Of course the profiling has an overhead on your application. Normally it's not visible, but for certain applications, you can loose a lot of fluidity. Here are the results I have obtained with my simple application :\n\nIn my example, we can see that the waitForTimeout method takes 81.6% of the CPU time. We can also see that the notifyDecision and getSensor methods are the two next most CPU consuming methods, perhaps, it will be interesting to optimize them. \u00a0You can also look at the number of invocations of each, perhaps, you'll find a method that is invoked too much time.\nThe next profiling we can do is the Memory profiling. Here again, you have to start the profiling and the instrumentation will start and during this, the application will be frozen. Here are the results for my application :\n\nHere we can see that this application store some big double[] and float[] arrays and that EllipseIterator and BasicStroke classes take also a lot of memory spaces.\nIn both the memory and CPU profiling, you can save the results to a file to see it later. By example, you can let an application working the all night, save the results the morning and examine them or make three profiling and compare the three.\nTo conclude, I have to say that this profiler is really simple but also really powerful to use. We've the main features we want for a profiler and the results are really good. That kind of tools can really help you to improve an application to use less CPU and memory. Of course that kind of tool doesn't do everything, it just help showing what part of the application must be improved, the improvement part is the task of the developer and it's not the easiest one. But having that kind of tool is a good start.", 
      "tags": "Java,Performances,Tools"
    }, 
    {
      "loc": "/posts/2010/07/version-control-with-git-book-review.html", 
      "title": "Version Control with Git \u2013 Book Review", 
      "text": "After I had chosen to switch to Git, I thought the time has become to read a complete book on the subject to understand the concepts of Git from the base to further level.\nSo I chose \"Version control with Git\", from Jon Loeliger\nI just finished to read it, so I will try to give my impressions about this book on this post.\n\n\n\nIn the first chapter, the author describe Git, it goals and it history. The second one is about the installation of Git.\nThe next three chapters are about the basic concepts of Git.Add a file, commit the changes, track the changes and view the differences. And how to configure the repository and the global installation. More than that, these chapters explains also how Git store the different objects and track the changes of the repository. The index is also fully explained and we learn how to ignore some files.\nAfter these first chapters, the next chapters are very specific two one feature.\n\n    The sixth chapter is about the commits : Identify the commits, find a commit, view the commit history, ...\n    The seventh is about the branches : create branches, switch to another branch, delete a branch, merge 2 branches, ...\n    The next one is about the diff : how to read them, how to create them, ...\n    The ninth is about the merges. It explains with a lot of precision how the merges are done, the different strategies Git can use and how to solve the problems we can found when merging branches\n\nThese 4 chapters are really interesting, but sometimes a little boring. There is a lot of informations and the author is going really far into Git. Nevertheless, it's good written.\nAfter that we learn how to alter commits.12\nAnd after, we learn how to work with remote repositories and make our changes available to the other developers. We learn the different ways to work in a project with Git.\nThe 2 next chapters are bout the patches and the hooks. And the last two are about 2 features less used that are the possibility to combine several repositories into one and the possibility to work with Git in a SVN project.\nTo conclude, I have to say that this book is an excellent book about Git. It's not only an introduction, it's a complete reference about this great Version Control System. Sometimes, I thought that there is too details about some features, but perhaps for something a little more used to Git, it will be fine. I advice this book to everyone who want to learn almost everything about Git.", 
      "tags": "Books,Git,Programming"
    }, 
    {
      "loc": "/posts/2010/07/jr-virtual-machines.html", 
      "title": "JR Virtual machines", 
      "text": "Until now, we've always had concurrent program working in one virtual machines, but JR provides ways to declare several virtual machines on several different physical machines. A JR Virtual Machine contains a Java Virtual Machine and a layer for the JR language. Once you created some virtual machines, you can specify where an object will be created with a variant of the new operator. After that, almost all the development is transparent. By example,  a send operation on an operation serviced by an other virtual machine is exactly the same as if there is only one virtual machine. You can do exactly the same thing. We'll see that there is some differences, but it's really easy.\nAn important thing to remember is that all the virtual machines created contains the static part of the application. So all the static part is local to the virtual machines. This can cause really difficult bug to solve if we don't take care.\n\n\nSo, now that we know the basis of the virtual machines, let's create a new virtual machine :\nvm vm1 = new vm();\n\n\n\nThat will create a new virtual machine, named vm1, on the same physical machine where the code is executed. You can also choose to create a virtual machine on an other machine :\nvm vm2 = new wm() on \"192.168.1.200\"; //IP Adresse of the machine\nvm vm3 = new wm() on \"pc12\"; //Name of the machine\nvm vm4 = new vm() on vm3; //The machine where vm3 is located\n\n\n\nTo create a virtual machine on an other machine, you need to right to connect to that computer with ssh or csh without any password. For more informations, the best is to read the official installation guide. \nJR provide no way to destroy a virtual machine. Like any other objects, a vm became garbage collected when there is no reference to it and when the virtual machine is idle (all the processes are over or blocked).\nIf you want to place an object on a virtual machine, you must define it with the remote keyword :\nremote Person person = new remote Person();\n\n\n\nBy default, the object is created on the same virtual machine where the code is executed, but you can put it in an other virtual machines :\nremote Person person = new remote Person() on vm1;\n\n\n\nYou can also combine the creation of virtual machine and remote objects in one line :\nremote Person person = new remote Person() on new vm() on \"localhost\";\n\n\n\nNote that the class of any remote object must be declared public.\nWhen working with remote objects, you have access to two new predefined fields :\n\n    this.remote : Return the remote reference of the current object\n    vm.thisvm : Return the vm in which the current object has been created\n\n\nWhen you work with a single virtual machine, the parameter are always passed by value, but when you're working with remote references and several virtual machines, you cannot pass the objects by value, instead, a copy of the object is created and passed to the other virtual machines (JR use RMI and serialization to achieve that). So all the objects you pass to others virtual machines must be declared Serializable to pass through the virtual machines.\nThere is also others aspects that is interesting to know about working with several virtual machines. First of all, the System.out and System.int streams are inherited from the initial virtual machine. So you can see that the order is not always deterministic depending on the fact on the synchronization of the different prints. The first virtual machine begin the execution in the execution directory but the other virtual machines begins the execution in the user home directory.\nLet's finish with a little example. By example, if we take the problem of consumer/producer we solved with Asynchronous Message Passing and we create the producer and consumer in different virtual machines, that will give us something like this : \nclass ProducerConsumer {\n    private static final int N = 12; //Number of producers and consumers\n\n    private static op void deposit(String); //The channel\n\n    public static void main(String... args){\n        vm vmConsumer = new vm();\n        vm vmProducer = new vm();\n\n        for(int i = 0; i &lt; N; i++){\n            new remote Consumer() on vmConsumer;\n            new remote Producer() on vmProducer;\n        }\n    }\n\n    public static class Consumer {\n        private static process Consumer {\n            String data;\n            receive deposit(data);\n            System.out.println(\"Consumer \" + data);\n        }\n    }\n\n    public static class Producer {\n        private static process Producer {\n            send deposit(\"Producer\");\n        }\n    }\n\n\n\nAll the consumer are created on a specified virtual machine and the producer in an other virtual machine. Here I create the two virtual machines in the same computer, but you can distribute them along several computers. \nHere we are !  That post will be the last of the JR set of posts.", 
      "tags": "Concurrency,Java,JR"
    }, 
    {
      "loc": "/posts/2010/07/java-se-6-update-21-released.html", 
      "title": "Java SE 6 Update 21 Released", 
      "text": "Oracle has just released the Java SE 6 Update 21.\nThis version is compatible with new system configurations :\n\n    Oracle Enterprise Linux 5.5, 5.4, 4.8\n    Red Hat Enterprise Linux 5.5, 5.4\n    Oracle VM 2.2.0.0.0\n    Google Chrome 4.0\n\nThis version integrate the Java Hotspot VM 17.0. There is several improvements, by example in compressed object pointers, escape analysis, code cache management, Mark-Sweep and G1 garbage collection algorithms. You can enable G1 with\n-XX:+UnlockExperimentalVMOptions -XX:+UseG1GC\n\nThis version integrate also the last version of Java Visual VM, the 1.2.2. For more informations, consult the VisualVM official site.\nThere is an important bug fix about drag and drop. There is no security updates on this update. The list of BugFixes on the site of Java.\nYou can now add a progress indicator in Applet and Java Web Start applications really easily. For informations, you can consult this list of tutorials.\nFor complete informations about the release, consult the release notes of Java SE 6 Update 21.", 
      "tags": "Java,Releases"
    }, 
    {
      "loc": "/posts/2010/07/modular-java-book-review.html", 
      "title": "Modular Java \u2013 Book Review", 
      "text": "Some weeks ago, I finished \"Modular Java - Creating Flexible Applications With OSGi and Spring\", it's time to do a little review now.\n\nThis book is an excellent introduction to the creation of modular applications in Java. It introduces all the main concepts of the OSGi technology, Spring Dynamic Modules and tools making easier the development of OSGi applications.\nThe first chapter introduce the concept of modularity and explain how OSGi solve the problem. The main characteristics of the technology are also described.\nThe next chapter lists the main OSGi containers and we create the first Hello World using OSGi. Next we improve this simple program using an OSGi service.\nAfter that the third chapter introduce the application \"Dude, Where is my Jar ?\". This application is a simple web program allowing a develop to search for a Jar file in Maven repositories. This application is used in all the next chapters. More than this introduction, the chapter also shows how the Pax tools can make easier the development of OSGi applications.\nIn the next chapter, we create the first bundle of the application. With that bundle we see how to work with non-bundle dependencies. And in the next one, we create the services of the application and see how to publish and consume services.\nAfter that, it's time to use Spring Dynamic Modules with the next chapter. We see how to publish and consume services with Spring.\nIn the seventh chapter, we develop the web bundle. Fort hat, we include Tomcat or Jetty in the form of OSGi Bundles. We also see the differences between a simple bundle (Jar) and a web bundle (War).\nIn the next, we see how to extend OSGi bundle using fragment. With that, we see how to separate the JSP part of the application.\nThe last two chapters are about the deployment in production of an OSGi application and the services offered by the OSGi standard (logging, admin, console, ...).\nIn conclusion, this book will allows you to start developing application using OSGi. It's really comfortable to follow the development of a simple applications during the entire book. And improve it with each concept of the technology. But I think it's not a very good idea to use that log the Pax Tools. We quickly loose OSGi with Pax. It's quite interesting to know how to use Pax (I use it everyday), but when we start, it's better to see the basic concepts further.\nAnd more, the Maven output, is almost entirely displayed. This not really useful to see that every time when it's not errors, warning or important informations. But nevertheless, the reading of the book is really comfortable and fluid.", 
      "tags": "Books,Java,Modular,OSGi"
    }, 
    {
      "loc": "/posts/2010/07/rendezvous-concurrency-jr.html", 
      "title": "Rendezvous, concurrency method, in JR", 
      "text": "In this post, we'll see a new feature of JR : the rendezvous.\nLike asynchronous message passing, this synchronization method involves two processes : a caller and a receiver. But this time, the invocation is synchronous, the caller delays until the operation completes. The rendezvous does not create a new thread to the receiver. The receiver must invoke an input statement (the implementation of rendezvous) and wait for the message. Like asynchronous message passing, this is achieved using operations as message queue.\n\n\nThe rendezvous can simplify this kind of operations :\nint x;\nint y;\nsend op_command(2, 3);\nreceive(x, y);\n\n\n\nTo make a rendezvous, we'use the input statement. I think it's the harder (but also most complete) statement of the JR programming language. Here is the general form :\ninni op_command {\n//Code block\n}\n[] op_command {\n//Code block\n}..\n\n\n\nAn op_command specifiy an operation to wait for. An op_command is of this form :\nreturn_type op_exp(args) st synch by sched\n\n\n\nExplanations :\n\n    return_type : Indicate the return type of the operation we are waiting for\n    op_exp : The name of the operation or the capability\n    args : The arguments of the operation\n    st synch : Add a condition to the operations. This condition indicates which messages are acceptable\n    by sched : Dictate the order of servicing the messages. Must be numerical. The message with the lowest value of scheduling expression will be serviced in first.\n\n\nIf there is no synchronization expression and no scheduling expression, the first serviced invocation is the oldest. If there is a synchronization expression, the first serviced invocation is the oldest selectable expression and if there is a scheduling expression, the first serviced is the first selectable invocation that minimizes the scheduling expression. If there is no selectable message, the input statement delays until there is one.\nYou can also add an else statement to the input statement :\ninni op_command {\n//Code block\n} ...\n[] else {\n//Code block\n}\n\n\n\nThe else block will be executed if there is no selectable message. So an input statement with an else statement will never delays.\nLets imagine a simple example. The server return the sum of 2 numbers after receiving a message. If we write this simple program using asynchronous message, it'll give us something like that :\npublic class Calculator {\n    private static op void request(int x, int y);\n    private static op void response(int sum, int sub);\n\n    public static void main(String... args){}\n\n    private static process Client {\n        send request(33, 22);\n\n        int sum;\n        int sub;\n        receive response(sum, sub);\n\n        System.out.printf(\"Sum %d Sub %d\", sum, sub);\n    }\n\n    private static process Server {\n        int x;\n        int y;\n        receive request(x, y);\n        send response(x + y, x - y);\n    }\n}\n\n\n\nIt little bit complicated for a thing as simple, isn't it ? Let's rewrite it with input statement :\npublic class CalculatorInni {\n    private static op int compute(int x, int y);\n\n    public static void main(String... args){}\n\n    private static process Client {\n        System.out.printf(\"Sum %d\", compute(33, 22));\n    }\n\n    private static process Server {\n        inni int compute(int x, int y){\n            return x + y;\n        }\n    }\n}\n\n\n\nEasier, shorter and clearer, isn't it ?\nThe Client invoke the compute operation and get the return value directly because it's synchronous. If you have an operation with a return value, you doesn't have to use the call statement, it's implicit. If you have a void operation, you can use the call statement (but if you don't, it's the same by default) before the operation :\ncall op_command(args);\n\n\n\nAnd the Server has only to use the input statement to return the sum of the numbers.\nAs you've perhaps seen, the receive is only an abbreviation to the simplest form of input statement. So if you write :\nint x;\nint y;\nreceive op_command(x\n\n\n\nIt's the same as if you write :\ninni void op_command(int a, int b){\n      x = a;\n      y = b;\n}\n\n\n\nBut in this case, it's easier to use the receive statement.\nThe input statement can also be used to service a group of operations in an array :\ncap void (int) operations = new cap void (int)[12];\n\n//Fill the array\ninni ((int i = 0; i &amp;lt; 12; i++)) operations[i](int x) {\n   //Code b\n}\n\n\n\nMore than return, we could also use two new statements in an input statement :\n\n    reply : return a value to the caller but doesn't break the input statement, so you can still make operations in the input statement but you cannot return a value anymore.\n    forward : delegate the answer to an other operation. So this is the other operation who will answer to the caller, the input statement continues its execution but cannot return a value anymore.\n\n\nNow that we know how to use input statement, we can simplify the ResourceAllocator of the next post. We can do a lot more easier, with two operations and input statements :\nimport java.util.*;\n\npublic class ResourceAllocator {\n    private static final int N = 25; //Number of clients\n    private static final int I = 25; //Number of iterations\n\n    public static void main(String... args){}\n\n    private static op Resource request();\n    private static op void release(Resource);\n\n    private static process Client((int i = 0; i &amp;lt; N; i++)){\n        for(int a = 0; a &amp;lt; I; a++){\n            Resource resource = request();\n\n            System.out.printf(\"Client %d use resource %d \\n\", i, resource.getId());\n\n            call release(resource);\n        }\n    }\n\n    private static process Server{\n        Queue resources = new LinkedList();\n\n        for(int i = 1; i &amp;lt;= 5; i++){\n            resources.add(new Resource(i));\n        }\n\n        while(true){\n            inni Resource request() st !resources.isEmpty() {\n                return resources.poll();\n            }\n            [] void release(Resource resource){\n                resources.add(resource);\n            }\n        }\n    }\n\n    private static final class Resource {\n        private final int id;\n\n        private Resource(int id){\n            super();\n\n            this.id = id;\n        }\n\n        private int getId(){\n            return id;\n        }\n    }\n}\n\n\n\nClearer, not ?\nThe last improvement we can do is to use a send instead of a call in the Client. We doesn't need to wait for release in client and the input statement can service send invocations as well as call but the send  invocations cannot return something.\nSo we've now covered the rendezvous synchronization system in the JR system. In the next, and last, post about JR programming language, we'll see how to distribute our processes on several virtual machines.", 
      "tags": "Concurrency,Java,JR"
    }, 
    {
      "loc": "/posts/2010/07/integrate-play-framework-intellij-idea.html", 
      "title": "Tip : Integrate Play Framework in IntelliJ Idea", 
      "text": "After created a Play Framework first application, it's time to integrate it in IntelliJ Idea. \nThis is made really easy because, play provide a command to create the Iml module file for the project. You can use the command play idealize app_name to create a iml module file. \n\n\nSo let's try : \nwichtounet@Linux-Desktop:~/dev/play$ play idealize hello/\n~        _            _ \n~  _ __ | | __ _ _  _| |\n~ | '_ \\| |/ _' | || |_|\n~ |  __/|_|\\____|\\__ (_)\n~ |_|            |__/\n\n~ play! 1.0.3, http://www.playframework.org\n\n~ OK, the application is ready for Intellij Idea\n~ Use File/New Module/Import Existing module\n\nwichtounet@Linux-Desktop:~/dev/play$ \n\nIf you go on the hello folder, you'll found a \"Hello World.iml\" file. \"Hello World\" is the name of the application. So you just have to add it to a IntelliJ Idea project. And it's almost done. \n\nThe libraries are good configured, the test folder is already configured as a test folder. But a thing we can do is to ignore the logs and tmp folders, not really useful during development. \n\nAnd last, the sources of the Play Framework aren't linked, so we can add them :\n\nAnd now we've a fully configured Play Framework Project in our editor : \n\nGreat, not ?", 
      "tags": "IntelliJ Idea,Java,Play!,Tips"
    }, 
    {
      "loc": "/posts/2010/07/replace-an-old-copyright-by-a-new-one.html", 
      "title": "Tip Replace an old copyright by a new one", 
      "text": "Today, I searched a tool to replace the old copyright of the GNU GPL V3 license by the copyright of the Apache License 2.0. But I've not found a simple tool to do a multi-line replacement in a complete set of files. So like the developer I'm, I decided to do it myself. And because it can be useful to someone else and because open source is good, I also decided to give it to everything that want :)\nThe usage is quite simple :\njava -jar RCR.jar old_file new_file file\n\n    old_file is the path to a file containing the old copyright\n    new_file is the path to the file containing the new copyright\n    file is a folder to make the replacements in. If it's a folder, all the files and sub-folders will be searched for replacements.\n\n\nHere, I'm talking about a copyright, but it of course also works for any other multi-line replacement you want. \nThe jar is available here : RCR.jar\nThe sources is available here : RCR.java\nI hope that will be useful to someone.", 
      "tags": "Java,Tips,Tools"
    }, 
    {
      "loc": "/posts/2010/07/getting-started-play-framework.html", 
      "title": "Getting started with Play Framework", 
      "text": "It's time for me to test the Play Framework and I'll try to make some posts during my tests about this web framework. \nPlay Framework is a framework to create web applications in Java. The main goals of this framework are (according to the official site) : \n\n    Hot reload : You can edit your java files and html files and you just have to refresh the browser to see the results\n    Stateless model : Play is ready for REST, it can be scaled running multiple instances of the same applications on several servers\n    Efficient Template System : The template system is really easy to use, based on Groovy.\n    Resolve errors quickly : When an error occurs, Play displays directly the code source in the browser and the location of the error\n    Integration : Play provide integration for Hibernate, OpenID, MemCached and others popular frameworks\n    Pure Java : You make only Java and HTML, no other things to learn and easy integration in IDE. \n    Fast : The startup of application is really fast the rendering of the pages also very fast.\n\nIn this post, we'll see how to install the Play Framework and how to write our first Hello World. \n\n\nInstall Play Framework\n\nBefore installing Play Framework, you need Java 5.0 or later. Then, you can download a release of Play : http://download.playframework.org/releases/. The latest when I wrote this post is the 1.0.3 version. So let's download this version. After that, just unzip the given archive where you want to install the framework. After that, you just have to add the play command to the path. \nIn Ubuntu 10.04, I had to do the following : \nPLAY_HOME=/usr/share/apps/play/\n\nPATH=$PATH:$PLAY_HOME\n\nchmod +x PLAY_HOME/play\n\nDepending on your configuration, you perhaps have to use sudo for the chmod command. For other systems (Windows and Mac), you also have to add play (play.bat for Windows) to path using the system configuration. \nAnd normally, after that, you can execute the play command : \nwichtounet@Linux-Desktop:~$ play\n\n~        _            _ \n~  _ __ | | __ _ _  _| |\n~ | '_ \\| |/ _' | || |_|\n~ |  __/|_|\\____|\\__ (_)\n~ |_|            |__/   \n\n~ play! 1.0.3, http://www.playframework.org\n\n~ Usage: play cmd [app_path] [--options]\n\n~ with,  new      Create a new application\n~        run      Run the application in the current shell\n~        help     Show play help\n\nwichtounet@Linux-Desktop:~$ \n\nCreating a new application\n\nTo create a new application, you just have to use the command  \nplay new app_name\nYou must be in a folder where a folder with the name app_name can be created. For example, let's create a new application \"hello\" : \nwichtounet@Linux-Desktop:~/dev/play$ play new hello\n\n~        _            _ \n~  _ __ | | __ _ _  _| |\n~ | '_ \\| |/ _' | || |_|\n~ |  __/|_|\\____|\\__ (_)\n~ |_|            |__/   \n~\n~ play! 1.0.3, http://www.playframework.org\n\n~ The new application will be created in /home/wichtounet/dev/play/hello\n\n~ What is the application name? Hello World\n\n~ OK, the application is created.\n~ Start it with : play run hello\n~ Have fun!\n\nwichtounet@Linux-Desktop:~/dev/play$ \n\nDuring the creation, Play will ask you for the name of the application. Here I put \"Hello World\" as the name of the application. If you go into the new created application folder, you will see the given folders : \n\n    app : The applications itself, Java classes and HTML files\n    conf : The configuration of the application\n    lib : Contains the Java libraries that the application needs\n    public : Contains the public files, images, CSS, JS\n    test : Contains the tests (JUnit or Selenium) file\n\n\nYou can launch your application, with the command : \nwichtounet@Linux-Desktop:~/dev/play$ play run hello\n\n~        _            _ \n~  _ __ | | __ _ _  _| |\n~ | '_ \\| |/ _' | || |_|\n~ |  __/|_|\\____|\\__ (_)\n~ |_|            |__/   \n~\n~ play! 1.0.3, http://www.playframework.org\n\n~ Ctrl+C to stop\n\nListening for transport dt_socket at address: 8000\n17:49:56,395 INFO  ~ Starting /home/wichtounet/dev/play/hello\n17:49:56,889 WARN  ~ You're running Play! in DEV mode\n17:49:56,958 INFO  ~ Listening for HTTP on port 9000 (Waiting a first request to start) ...\n17:50:01,670 INFO  ~ Application 'Hello World' is now started !\n\nAnd you can browse your application at the URL http://localhost:9000/. You will normally see a sample page : \n\nHow does it works ?\n\nSo now, let's study why this work. If you open the file conf/routes, you will see that line : \nGET     /                                       Application.index\n\nThat indicates that the index of the project will be serviced from the index method of the Application class. And if you open the app/controllers/Application.java file, you will see : \npackage controllers;\n\nimport play.mvc.*;\n\npublic class Application extends Controller {\n    public static void index() {\n        render();\n    }\n}\n\n\n\nSo at this time, the index() only renders the default template. This template is app/views/Application/index.html (like the name of the method and the class) : \n#{extends 'main.html' /}\n#{set title:'Home' /}\n#{welcome /}\n\n\n\nWe can see that this template extends the main.html template. It sets the title to home and display the welcome prompt. These tags are tags from the Play Framework. Lets change this template to : \n#{extends 'main.html' /}\n#{set title:'Hello World' /}\n<h3>Hello the world !</h3>\n\n\n\nAnd refresh the application page. You will see now only the message \"Hello the world\". If you want to see something when the controllers is called, just add a System.out.println in the Application.index : \npublic static void index() {\n    System.out.println(\"render()\");\n    render();\n}\n\n\n\nAnd you will see logs in the console when you refresh the pages : \n17:50:01,670 INFO  ~ Application 'Hello World' is now started !\nrender()\nrender()\nrender()\nrender()\nrender()\n\nAdd a simple new page\n\nTo do a little more in this post, let's add a new page : http://localhost:9000/bye. Let's start adding a new route in conf/routes : \nGET     /bye                                     Application.bye\n\nSo we have to add a method bye in the Application class : \npackage controllers;\n\nimport play.mvc.*;\n\npublic class Application extends Controller {\n    public static void index() {\n        render();\n    }\n\n    public static void bye() {\n        render();\n    }\n}\n\n\n\nAnd then, we just need to add a new template bye.html in app/views/Application/ folder : \n#{extends 'main.html' /}\n#{set title:'Bye' /}\n<h3>Bye bye !</h3>\n\n\n\nAnd now, if you go to http://localhost:9000/bye you will see our new page : \n\nConclusion\n\nHere we are ! With this framework, it's extremely easy to create web applications. And we've only see a very small part of the facilities this framework offers to create web applications. I'll try to write others posts on the subject.", 
      "tags": "Java,Play!,Web"
    }, 
    {
      "loc": "/posts/2010/07/tip-how-to-solve-agent-admitted-failure-to-sign-using-the-key-error.html", 
      "title": "Tip : How to solve \u201cagent admitted failure to sign using the key\u201d error ?", 
      "text": "A very simple tip that can save a lot of time. \nWhen i wanted to do a git clone, I had the given error : \nAgent admitted failure to sign using the key.\nPermission denied (publickey).\n\nI found that this is an SSH error. \nOne of the readers, Leonardo Hessel, pointed that out that ssh-add is also a solution: \nssh-add\n\nAnother solution is simply to login and logout and it should work.", 
      "tags": "Git,Linux,Tips"
    }, 
    {
      "loc": "/posts/2010/07/asynchronous-message-passing-jr.html", 
      "title": "Asynchronous Message Passing in JR", 
      "text": "We've now covered the basic synchronization systems (semaphore, monitors) and we know how to declare operations and capabilities . It's time to go to an other form of synchronization : Message Passing. In this post, we'll focus in Asynchronous Message Passing, we'll cover later, the synchronous message passing system with RendezVous.\nWhen we use message passing, the threads doesn't share datas anymore, they share channels. You can see channels like an abstraction of a network between several processes. The processes will send messages to other and the other will wait for receive a message. Normally, with that form of synchronization, the channels are the only objects shared between the threads. So you doesn't need to share memory. That makes possible to distribute the processes across several virtual machines or computers, of course, this also works on a simple computer, like any other program. In message passing, we often see models with several clients and a server that manage the messages. \n\n\nIn Java, you will do that with Socket or RMI but in JR, this system is really easily integrated. We'll use operations as messages queues and send/receive operations in the queue to respectively send a message to the queue and receive a message from the queue. The operations must not be implemented to achieve asynchronous message passing. If the operations is implemented, this will make a remote procedure call, but we'll not cover that system for now. And because, it's asynchronous, the operations cannot have a return type. The operations visibility is the same as the method visibility. So if an operation is static in class A, a send statement on this operation can be serviced by any process who has the visibility to access this operation. \nSo we will need that kind of operations :\nprivate static op void channel(int);\n\n\n\nTo send a message to a channel, you just have to use the send keyword followed by the name of the operations with the arguments :\nsend channel(12);\n\n\n\nThe send operation does not block, when the same is sended, the send operation is released.\nTo receive a message, you have to use the receive keyword, followed by the variables name in which put the values of the arguments :\nint x;\nreceive channel(x);\n\n\n\nThe variables must have been declared before used in the receive statement. It's a little weird when we start, but it's really practical to assign them in one operation even if we have a lot of parameters. When we the process are on the same virtual machines, the parameters are passed like for any method in Java, by value. If we put all that together in processes :\npublic class AMP1 {\n    private static op void channel(int);\n\n    private static process p1{\n        send channel(12);\n    }\n\n    private static process p2{\n        int x;      \n        receive channel(x);\n        System.out.println(x);\n    }\n\n    public static void main(String... args){}\n}\n\n\n\nThe messages are received in the order they are sent for each sender. But it's possible that a message sent by Thread 1 before an other message sent by Thread 2 will be received after the one of Thread 2. Normally this would never appears when working in a simple computer, but that could appear often when working with several computers. So don't make any assumptions on the order your messages will be received. \nWith all that, we can solve the producer-consumer problem really easily : \npublic class ProducerConsumer {\n    private static final int N = 12; //Number of producers and consumers\n\n    private static op void deposit(String); //The channel\n\n    public static void main(String... args){}\n\n    private static process Producer((int i = 0; i < N; i++)){\n        send deposit(\"Producer\" + i);\n    }\n\n    private static process Consumer((int i = 0; i < N; i++)){\n        String data;\n        receive deposit(data);\n        System.out.println(\"Consumer\" + i + \" : \" + data);\n    }\n}\n\n\n\nNo need to great explanations. A Producer send a message with the informations it has produced and doesn't wait for the receive. And a Consumer wait for a deposit (a send) with a receive statement and print the result when it has received the message. \nLike you can invoke operations with capabilities, you can also send messages through a capability. It's very easy to share channels because this is only a variable. We often send the channels in a message for an answer. \nLet's imagine a simple problem. We have N clients that needs resources shared by all the clients. We need something to manage the resources. So we'll use a kind of server to achieve that. So we can start with something really simple for the clients : \nop void request();\nop void resource(Resource);\nop void release(Resource);\nsend request();\nreceive resource(resource);\n\n//Use resources\nsend release(resource);\n\n\n\nThat seems good, but there are some problems : \n\nHow can the server distinguish the clients ? If it sends a message to resource any client can take it, we need a way to create a channel between one client and the server (also called private channels). For this we'll use a capability as a channel. \nIf the server wait for request messages, it cannot wait for release messages and vice-versa. A solution is to have two process in the servers, but with that, you must synchronize the two process. A better solution is to create an operation that give informations about the type of request. \n\n\nSo here, is the new version of client : \nenum Type {REQUEST, RELEASE};\nop void request(Type, cap void (Resource), Resource);\ncap void (Resource) channel = new op void (Resource);\n\nsend request(Type.REQUEST, channel, null);\nResource resource;\nreceive channel(resource);\nsend request(Type.RELEASE, noop, resoure); \n\n\n\nand now the server : \ncap void (Resource) client;\n\nType type;\nResource resource;\n\nQueue<Resource> resources = new LinkedQueue<Resource>();\n\n//Fill the queue of resources\n\nQueue<cap void (int)> clients = new LinkedQueue<cap void int>();\n\nwhile(true){\n    receive request(type, client, resource);\n\n    if(type == Type.REQUEST){\n        if(resources.isEmpty()){\n            clients.add(client);\n        } else {\n            send client(resource.pop());\n        }\n    } else {\n        if(clients.isEmpty()){\n            resources.put(resource);\n        } else {\n            send clients.pop()(resource);\n        }   \n    }\n}\n\n\n\nReally easy no ? And that code can be distributed with only minor changes. And it works for any number of process your want. You will find the complete code of this problem joined to this post. \nWe have now covered the complete informations about Asynchronous Message Passing in JR. I hope you found that article interesting. The next post will be about the RendezVous in JR. RendezVous are a very powerful way to achieve synchronization also with message passing, but synchronous. \nThe complete source", 
      "tags": "Concurrency,Java,JR"
    }, 
    {
      "loc": "/posts/2010/06/jr-operations-and-capabilities.html", 
      "title": "JR Operations and Capabilities", 
      "text": "Now that we've seen how to use semaphores and monitors in JR, we must go to message passing. But before, we must learn how to use operation and capabilities in JR. These concepts are used in JR to message passing, so we must learn them before. \nAn operation (or op-method) has the same form as a method declaration but are declared with a op keyword. An operation can be invoked the same way as a normal method or can be invoked with a call statement (also with a send statement as we'll see in next post about JR). \n\n\nA little example : \npublic class Operations1 {\n    public static op int sum(int i1, int i2){\n        System.out.println(\"sum()\");\n\n        return i1 + i2;\n    }\n\n    public static void main(String... args){\n        System.out.println(sum(2, 2));\n        call sum(3, 3);\n    }\n}\n\n\n\nYou can also write the operation in two part : \npublic static op int sum(int i1, int i2);\n\npublic static int sum(int i1, int i2){\n    System.out.println(\"sum()\");\n\n    return i1 + i2;\n}\n\n\n\nThis is exactly the same. As you will see in the next post, we'll also use operations only declared with no method body. \nWhen you've operations, you can refer to them using capabilities. The capabilities are a kind of function pointer. You can declare a capability like that : \ncap operation_signature cap_name\nYou can invoke a capability like a normal method. Here is a little example : \npublic class Operations3 {\n    public static op int sum(int i1, int i2){\n        System.out.println(\"sum()\");\n\n        return i1 + i2;\n    }\n\n    public static void main(String... args){\n        cap int (int, int) cap_sum; //Declare the capability\n\n        cap_sum = sum;              //Make a reference to sum operations\n\n        System.out.println(cap_sum(2, 2));\n    }\n}\n\n\n\nAnd you can also pass them as arguments, that can be useful to generify a code. Here is a little example that use \nimport java.util.Random;\n\npublic class Operations3 {\n    public static op int square(int x){\n        return x * x;\n    }\n\n    public static op int dec(int x){\n        return x - 3;\n    }\n\n    public static op int inc(int x){\n        return x + 11;\n    }\n\n    public static op int add(cap int (int) f1, cap int (int) f2, int result){\n        return f1(result) + f2(result);\n    }\n\n    public static op int sub(cap int (int) f1, cap int (int) f2, int result){\n        return f1(result) + f2(result);\n    }\n\n    public static void main(String... args){\n        cap int (int) functions[] = new cap int (int)[3];\n        functions[0] = square;\n        functions[1] = dec;\n        functions[2] = inc;\n\n        cap int (cap int (int), cap int (int), int)[] double_functions = new cap int (cap int (int), cap int (int), int)[2]\n        double_functions[0] = add;\n        double_functions[1] = sub;\n\n        int result = 100;\n        Random random = new Random();       \n\n        for(int i = 0; i &lt; 10; i++){\n            int index1 = random.nextInt(double_functions.length);\n            int index2 = random.nextInt(functions.length);\n\n            result = double_functions[index1](functions[index2], functions[index2], result);\n        }\n\n        System.out.println(result);\n    }\n}\n\n\n\nNow you know everything about operations and capabilities. In the next post, we'll learn asynchronous message passing in JR.", 
      "tags": "Java,JR"
    }, 
    {
      "loc": "/posts/2010/06/monitor-programming-in-jr.html", 
      "title": "Monitor programming in JR", 
      "text": "Like I promised, I will restart to write articles now that the evaluation period is over. \nAfter seeing how to develop using the JR programming language, we'll see now how to use monitors in JR.\nMonitors provide a higher-level abstraction than semaphores and produce a better code with several advantages :\n\n    All the synchronization code is centralized in one location and the users of this code doesn't need to know how it's implemented.\n    The code doesn't depends on the number of processes, it works for as much process as you want\n    You doesn't need to release something like a mutex, so you cannot forget to do it\n\n\nThe mutual exclusion is implicit with monitors. Only one process is allowed in the monitor, so all the method are automatically guarded with synchronization code. The synchronization between threads is made using signaling system, with condition variables. A condition variable is a kind of queue of process who are waiting on the same condition. You have several operations available on a condition, the most important is to signal a process waiting to be awaken and to wait on a condition. There are some similitudes between signal/wait operations and P and V of semaphores, but this is a little different. The signal operation does nothing if the queue is empty and the wait operation put always the thread in the waiting queue. The process queue is served in a first come, first served mode. \nNow we'll see how to use them in JR. \n\n\nIn JR, you doesn't have directly the possibility to create monitors, but there is a preprocessor that transform a file with both JR and monitors operations into a plain JR file. This processor is called m2jr (monitor to JR) and is directly available in the JR distribution. So you only have to use the m2jr command to translate a .m file (conventional monitor extension file) into several JR files (one for the monitor and one for the condition variables). This file is normal JR with several comments to make the debugs easier (corresponding between lines in m and JR).\nAll the keywords of the m2jr language start with _ (underscore). To declare a monitor, it's as easily as use the _monitor keyword : \n_monitor MonitorTest {\n    //...\n}\n\n\n\nTo add methods to the monitor, you just have to create method prefixed with _proc : \n_monitor MonitorTest {\n    _proc void testA(){\n        //Some code\n    }\n}\n\n\n\nOnly with that the mutual exclusion is guaranteed. Only one process is allowed into the monitor. If you want methods with a return type, you must use _return instead of return : \n_monitor MonitorTest {\n    _proc void testA(){\n        //Some code\n    }\n\n    _proc int testB(){\n        _return 1;\n    }\n}\n\n\n\nTo declare condition variables, the keyword is _condvar. You don't have to initialize them, just declare them : \n_monitor MonitorTest {\n    _condvar condVar1;\n    _condvar condVar2;\n}\n\n\n\nTo use global variables, you must prefix them with _var : \n_monitor MonitorTest {\n    _var var1;\n    _var var2;\n}\n\n\n\nAnd to make operations on condition variables, you have to use _signal and _wait methods inside a proc method : \n_monitor MonitorTest {\n    _condvar a;\n    _condvar b;\n\n    _proc void test(){\n        _wait(a);\n        //Some computations\n        _signal(b);\n    }\n}\n\n\n\nAnd you compile that to JR using the simple commmand : \nm2jr MonitorTest.m\nThat will create two files (MonitorTest.jr and c_m_condvar.jr). Of course, you can use this monitor in a normal JR class, you don't have to compile classes who use monitors with m2jr, only with the JR compiler. There is just a single thing to worry about. m2jr generates a constructor that take a String in every monitors class, you when you instantiate the monitor, you have to provide a String representing its name as the first parameter. And if you want to create a new constructor in a monitor, you just have to call super with a String.  We'll see an example later. \nBefore going further, we must have more informations about the signal operations. When writing monitors, you have the choice between several philosophies for the signaling operation : \n\n    Signal & Continue (SC) : The process who signal keep the mutual exclusion and the signaled will be awaken but need to acquire the mutual exclusion before going. \n    Signal & Wait (SW) : The signaler  is blocked and must wait for mutual exclusion to continue and the signaled thread is directly awaken and can start continue its operations. \n    Signal & Urgent Wait (SU) : Like SW but the signaler thread has the guarantee than it would go just after the signaled thread\n    Signal & Exit (SX) : The signaler exits from the method directly after the signal and the signaled thread can start directly. This philosophy is not often used. \n\n\nBy default, m2jr make the compilation with SC, but you can configure it to use other philosophies. Just add the abbreviation of the philosophy (lower case) as an option to the m2jr compiler. By example, to compile using Signal & Exit : \nm2jr -sx MonitorTest.m\nThe main differences, is that the SC create a signal stealers problem. You will quickly understand with an example. With what we know now, we can create a monitor to manage a bounded buffer : \n_monitor BoundedBuffer {\n    private static final int N = 5; //Size of the buffer\n\n    _var String[] buffer = new String[N];\n    _var int front;\n    _var int rear;\n    _var int count;\n\n    _condvar notFull;\n    _condvar notEmpty;  \n\n    _proc void deposit(String data){\n        while(count == N){\n            _wait(notFull);\n        }\n\n        buffer[rear] = data;\n        rear = (rear + 1) % N;\n        count++;\n\n        _signal(notEmpty);\n    }\n\n    _proc String fetch(){\n        while(count == 0){\n            _wait(notEmpty);\n        }\n\n        String result = buffer[front];\n        front = (front + 1) % N;\n        count--;\n\n        _signal(notFull);\n\n        _return result;\n     }\n}\n\n\n\nA thing that some of you will certainly find weird is the loop around the wait operation. Is to avoid the signal stealers problem. If there were not while loop, imagine that situation in SC : \n\n    The thread 1 try to make a fetch(), there is no data, so it wait for the notEmpty condition variable\n    The thread 2 make a deposit(), that awake the thread 1, but it needs to acquire again the mutual exclusion. \n    Before the thread 2 has acquired the mutual exclusion, the thread 3 make a fetch(), there is enough data, so thread 3 make a fetch and get the data. So now, it's empty. \n    The thread 2 acquire the right to go into the monitor and get a data. But wait a minute, there is no data and it will fetch a null data or perhaps an old data still fetched depending on the current state of the buffer \n\n\nTo avoid that situation, you just have to wrap the wait in a while loop instead of a if and that's done ! Or you can also use SW instead of SC. \nWith that monitor, we can easily solve the producer and consumer problem : \npublic class ProducerConsumer {\n    private static final int N = 12; //Number of producers and consumers\n\n    private static BoundedBuffer bb = new BoundedBuffer(\"Bounded Buffer monitor\"); //The monitor\n\n    public static void main(String... args){}\n\n    private static process Producer((int i = 0; i &lt; N; i++)){\n        bb.deposit(\"Producer\" + i);\n    }\n\n    private static process Consumer((int i = 0; i &lt; N; i++)){\n        System.out.println(\"Consumer\" + i + \" : \" + bb.fetch());\n    }\n}\n\n\n\nThat will provide output like that : \nConsumer10 : Producer0\nConsumer0 : Producer1\nConsumer1 : Producer2\nConsumer2 : Producer4\nConsumer3 : Producer5\nConsumer4 : Producer3\nConsumer8 : Producer7\nConsumer11 : Producer10\nConsumer6 : Producer8\nConsumer5 : Producer6\nConsumer7 : Producer11\nConsumer9 : Producer9\n\nSo it works well. \nMore than signal and wait operations, m2jr provide also others operations on condition variables : \n\n    _signal_all : Awake all the process of the waiting queue. This operation is only provided in Signal & Continue mode. \n    _empty : Test if the condition variable has any process waiting on it\n    _wait(condvar, int priority) : Enqueue the process with the given priority. If you use that, the queue is now managed as a priority queue. You cannot use both wait without priority and wait with priority on the same condition variable \n    _minrank : Return the min priority on the given condition variable. If the condition variable has no waiters, the returned given number doesn't seem anything. \n\n\n\nWith all that stuff, you can create monitors to solve almost all concurrency problems like barber shop, philosopher dinner, kwai cross or a lot of others problem. \nI hope you found that post interesting. The next post about JR will be about operations and capabilities.", 
      "tags": "Concurrency,Java,JR"
    }, 
    {
      "loc": "/posts/2010/06/wordpress-3-0-installed.html", 
      "title": "Wordpress 3.0 installed !", 
      "text": "Wordpress 3.0 (Thelounious) has been released this week. I just updated the blog with the new version. I had no problem during the upgrade process, all automatically. Good job !\nThis major release of Wordpress solve more tan 1200 bug, add several performance improvements and add several new features :\n\n    Merge of Wordpress MU : You can now add several different blogs on the same installation of Wordpress\n    New default Theme : Twenty Ten\n    Bulk updates for the plugins. You can updates all your plugins and themes at once.\n     More possibilities for the themes : custom background, headers, shortlinks, ...\n    Custom post types\n    Lighter interface\n\n\nIf you want more information, this video can help you :", 
      "tags": "Personal,The site,Web,WordPress"
    }, 
    {
      "loc": "/posts/2010/06/jtheque-is-migrating-to-git.html", 
      "title": "JTheque is migrating to Git", 
      "text": "Some informations about the current state of JTheque. I'm currently migrating it from SVN to Git. Actually the projet is hosted at Developpez.com, a french community. For more visibility, i wanted to host it in an english website. After several days of comparative, I chosen Github has host. Because i chose Git, i think it's the best and easier community to share projects using Git.\nI will use a subdomain in this website (jtheque.baptiste-wicht.com) to host the Javadoc and maven reports, because it take too space to store it at GitHub. I will use GitHub for the sources, issues and Wiki.\nAfter only several days of work with Git, I found it really fun and comfortable to work with.\nHere are the already created projects on GitHub :\n\n    jtheque-utils\n    jtheque-unit-utils\n    jtheque-xml-utils\n    jtheque-core\n    jtheque-primary-utils\n    jtheque-movies-module\n    jtheque-memory-module\n    jtheque-osgi-wrap\n\n\nMost of them are not completed at all. But the start is here. Don't hesitate to comment on how I did that. I've also already created a site for jtheque-xml-utils (http://jtheque.baptiste-wicht.com/xml-utils/).\nI will migrate all the projects into Git and complete the GitHub repositories and Maven Site the next few weeks.\nIf I didn't post a lot these last weeks, it's because, it's the end of the semester, so it seems a lot of exams and projects to finish, so not a lot of time to post. I will do better the next month.", 
      "tags": "Git,Java,JTheque"
    }, 
    {
      "loc": "/posts/2010/06/how-to-choose-a-monitor.html", 
      "title": "How to choose a monitor for your computer ?", 
      "text": "The monitor is a very important part of your computer. Indeed without it you cannot display anything. There is several types of monitors and the price varying a lot. The most limiting criteria will be your budget when you've to choose a new monitor.\nIn this post, we'll see what to watch before buying a new monitor.\n\n\n1. Type\n\nThere is several types of monitors :\n\n    CRT Monitor : This is the old type of monitor. They were a lot bigger than the current monitors. That type is no longer being sold.\n    LCD Monitor : \u00a0This is the most common type of monitor actually, a lot smaller and lighter than CRT. It works with liquid crystals.\n    LED Monitor : Recent technology using LED. This kind of monitor is a LCD monitor that use a LED backlight. The image is a bit better than with LCD and you'll have a better contrast. The life time of a LED monitor is better than LCD and the power consumption is also lower. And you can find very thin monitor.\n\n\nToday, the norm is the LCD monitors. The CRT doesn't have any advantages versus the LCD. Depending on your budget, you'll have to choose between LCD and LED, a bit more expensive.\n2. Size\n\nThe first thing we watch when buying a monitor is of course its size, in inches. The size of a computer monitor is between 15\" and 30\". Bigger the monitor is better the resolution it can display is. With a 22\" you can by example watch 2 A4 pages side by side.\nThe most common size today is 19\" and you'll find that kind of monitor from 150$. I think it's a good start to buy a least a 19\" monitor. Today, it's not interesting to buy a smaller monitor. You will also find 20\" monitors at almost the same prices.\nIf you watch a lot of films on your computer or playing games, I advice you to choose 22\" or 24\" moniors. You can find them from 200$ to 400$.\nTake care that big monitor, like 30\", needs a big graphics card and often needs the DVI Dual Link technology. It seems that you need two cables to connect your monitor but only one port on your graphics card. This technology allows to display very high resolution using two TMDS transmitters on one cable. So be sure that your graphics cards supports DVI Dual Link before buying 30\" monitor.\nYou'll also have to pay attention to the resolution of your monitor. Indeed there is 19\" monitor that only displays 1024x768\u00a0resolution instead of the normal 1280x1024. Here are the recommended resolutions for several sizes :\n\n    15\" : 1024*768 on 4:3\n    17\" : 1280*1024 on\u00a04:3 and 1440*900 on\u00a016:10\n    19\" : 1280*1024 on\u00a04:3 and 1440*900 on\u00a016:10\n    20\" : 1600*1200 on\u00a04:3 and 1680*1050 on\u00a016:10\n    22\" : 1680*1050 on\u00a016:10\n    24\" : 1920*1200 on\u00a016:10\n    30\" : 2560*1600 on\u00a016:10\n\n\nMore than the sizes and the resolutions, you can also pay attention to the format of the monitor :\n\n    4/3 : This is the \"normal\" format of the monitor.\n    16/9 : This is the wide format of monitor. The resolution will be by example 1280x720 or 1366x768. This is the base resolution for a lot of video stuff.\n    16/10 : This format is also a wide format. The constructors prefer sometimes to use 16/10 instead of 16/9, because the resolutions are better and easier to build. If you watch video in 16/9 format with this monitor you'll have black band but the same size of video. This monitor is also better for gaming.\n\n\nIf you can, take a wide monitor. I found it a lot better to work on, play videos and play games. Personnally, I prefer 16/10 but if you play only videos, take a 16/9.\n3. Response time\n\nA very important criteria is the response time, mainly for the gamers. This is the time, in milliseconds, that take the monitor to put a pixel from white to black. If you do only office work, this criteria is not important. But for the gamers, it's an other problems. In fact, with a high response time, you may have a blurring effect due to changes too fast for the monitor. It's why I advice to take monitors with 5ms or less for gamers.\n4. LCD Panel Technology\n\nThere is several types of LCD panels :\n\n    TN : This is the fastest and cheapest panel. But the viewing angle is not the best and the colors are not optimal. The color schema is only coded with 6 bits, so it cannot display the full color schema of the operating system. It uses dithering to display all colors but that put some swarming effects on the display when there is a lot of moves. This type of panel is for the big FPS gamers, the low budget and for the office worker.\n    VA : This is the most polyvalent panels. The color scheme is 8 bits. The response time is higher than TN, but we've some good monitors. This is a bit more expensive than TN. This is a good panel for persons who play games and play videos.\n    IPS : This is the panels with the better viewing angle, also with a color schema of 8 bits. This is the best panels for the video and photos. The response time of IPS is lowering this last times, so you can find IPS panels with 5ms of response time. So it's interesting also for gamers.\n\n\nTo resume, if you search the best prices or the best response time, use a TN panels. If you want a multipurpose monitors, take a MVA and if you do a lot of photo/video edition, choose a IPS.\nThis last times, the differences between the panels are reduced, so don't block your choice on a type of panel, compare different monitors with different panels type.\n5. Brightness / Contrast\n\nHere are two others important criterias to choose a monitor. Start with the brightness. This defines the visibility of a monitor in a very enlightened environment and is calculated in candela by square meter (cd/m\u00b2). This is not the most import criteria, but I think a minimum is 250 cd/m\u00b2.\nThe contrast is more import than the brightness, in my point of view. This is the difference between the brightest point and the darkest point of the monitor. More the constrast is, more the colors are good. The minimum is 500:1.\nPay attention to the fact that the displayed contrast is sometimes dynamic and not real. The dynamic contrast is computed with numerical modifications of the images with a software in the monitors. This contrast is not a good as the real monitors and the numbers are to take with care. The real contrast is the best criteria. So take only the dynamic contrast as a second criteria to compare monitors.\n6. Others\n\nOne thing that we don't consider at this time is a multi-monitor configuration. With the recent graphics cards it's really easy to put several monitors on your computers. This allows you to display several things at the same time. For a developer, it's really useful. It can see it's code in a monitor\u00a0and the result in an other monitor or documentation on the second monitor. It works also with games, the game on a screen and your playlist on an other. If you've the budget, it's a very interesting things to have.\nFor the connectors, the recent monitors have DVI connectors and sometimes HDMI (HD connector). There is still several old monitors with VGA connectors, but avoid them and prefer DVI connectors. DVI have better performances than VGA.\nSome monitors allows you to switch from landspace to portrait . So you can change mode depending on what you're doing.\nPay also attention to the guarantee\u00a0you've with the monitors. You can find 0 pixel warranty during x months, that can be interesting with expensive monitors.\nAn argument that the sellers give you is the HD labels. There is several labels :\n\n    Compatible HD : This label doesn't give you the ability to read videos in high definition but only that a HD video can be read but converted in a standard format. This label must be avoided.\n    HD Ready : This label needs a resolution of at least 720 lignes and a 16/9 format. You can see your videos in high defintion but this label doesnt guarantee that the image will not modified so you can have a less good quality.\n    Full HD : This label needs a resolution of at least 1080 lines. This is the best label for HD videos. But it is not certified.\n\n\nI advice you to take a monitors with the Full HD monitors but take also cares that the monitor characteristic are good.\nThe viewing angle can also be interesting. This define at how much degrees you can still watch the monitors with a good quality. This angle is calculated vertically and horizontally. The interest of the viewing angle is strongly depending on your usage of your monitor.\nYou can also see glossy monitors. The colors and the contrast are a little bit better than matte but the reflects are a lot more disturbing.\n7. Conclusion\n\nTo conclude, the first thing to consider is the size of the monitor and the usage we'll have with this monitor. And after that we can take care of the details to compare the different monitors.\nPersonnally, I have two 24\" monitors. This is awesome to work, develop, play games and videos.\nFor a developer, I can strongly\u00a0recommend\u00a0to take big wide monitors (22\" or 24\" inches wide) and if you've the budget, two monitors will be really comfortable.\nI hope that these advices will help you to choose the good monitors.", 
      "tags": "Hardware"
    }, 
    {
      "loc": "/posts/2010/06/java-7-translucency-shaped-windows.html", 
      "title": "Java 7 : Translucency and shaped windows", 
      "text": "Java 7 introduces very interesting features for desktop windows :\n\n    Transclucency for windows : Make a full window translucent with a specified alpha level\n    Per pixel translucency : Make a part of the window translucent.\n    Shaped windows : You can now create windows with a certain shape, like circle, ovale, triangle, ...\n\n\nWe'll see all this features in that post. All the examples are tested in Windows Seven 64 bits, because the transclucency isn't supported in Ubuntu 10.04 at the time I write the article.\n\n\nFirst of all, you can now set the opacity of the window with the setOpacity(float opacity) of the Window class. With that, the entire window is made translucent. There is some limitations with that new method. An opacity less than 1.0 isn't supported if the window use full-screen mode or if the simple translucency isn't supported. You can test if the window transclucency is supported with the isWindowTranslucencySupported() method added to the GraphicsDevice class :\nGraphicsEnvironment ge = GraphicsEnvironment.getLocalGraphicsEnvironment();\nif (ge.getDefaultScreenDevice().isWindowTranslucencySupported(GraphicsDevice.WindowTranslucency.TRANSLUCENT)) {\n    System.out.println(\"Window translucency isn't supported on your system. \");\n}\n\n\n\nWe know enough to write a first translucent window :\npackage com.wicht.java7.swing;\n\nimport javax.swing.*;\nimport javax.swing.event.ChangeEvent;\nimport javax.swing.event.ChangeListener;\nimport java.awt.*;\n\npublic class TranslucentWindow extends JFrame {\n    public TranslucentWindow() {\n        super(\"Simple Translucency Demo\");\n\n        setSize(300, 200);\n\n        setDefaultCloseOperation(EXIT_ON_CLOSE);\n\n        getRootPane().setDoubleBuffered(false);\n        setOpacity(0.5f);\n\n        setLocationRelativeTo(null);\n        setVisible(true);\n    }\n\n    public static void main(String[] args) {\n        SwingUtilities.invokeLater(new Runnable(){\n            @Override\n            public void run() {\n                GraphicsEnvironment ge = GraphicsEnvironment.getLocalGraphicsEnvironment();\n\n                if (ge.getDefaultScreenDevice().isWindowTranslucencySupported(GraphicsDevice.WindowTranslucency.TRANSLUCENT)) {\n                    new TranslucentWindow();\n                }\n            }\n        });\n    }\n}\n\n\n\nNote : We disable double buffering to remove artifacts that come when double buffer a translucent window.\nThat produce this result on my computer :\n\nSo, it's really simple to make a window translucent. But there is more you can do. You can also make only a set of pixel translucent using their background color. Like the translucent window, there is some limitations, the window must not be in full-screen and the system must support the per pixel translucency. You can test it the same way as the first time :\nGraphicsEnvironment ge = GraphicsEnvironment.getLocalGraphicsEnvironment();\n\nif (ge.getDefaultScreenDevice().isWindowTranslucencySupported(GraphicsDevice.WindowTranslucency.PERPIXEL_TRANSLUCENT)) {\n    System.out.println(\"Window translucency isn't supported on your system. \");\n}\n\n\n\nA simple making a grid of 16 panels more and more translucent :\npackage com.wicht.java7.swing;\n\nimport javax.swing.*;\nimport java.awt.*;\nimport java.awt.event.ActionEvent;\nimport java.awt.event.ActionListener;\n\npublic class GriddedTranslucentWindow extends JFrame {\n    public GriddedTranslucentWindow() {\n        super(\"Java 7 Per Pixel Translucency\");\n\n        setSize(300, 320);\n\n        getContentPane().setLayout(new GridLayout(4, 4));\n\n        for(int i = 0; i &amp;lt; 16; i++){\n            add(new AlphaPanel(255 - i * 12));\n        }\n\n        setBackground(new Color(0, 0, 0, 0));\n\n        setLocationRelativeTo(null);\n        setVisible(true);\n    }\n\n    public static void main(String[] args) {\n        SwingUtilities.invokeLater(new Runnable(){\n            @Override\n            public void run() {\n                GraphicsEnvironment ge = GraphicsEnvironment.getLocalGraphicsEnvironment();\n\n                if (ge.getDefaultScreenDevice().isWindowTranslucencySupported(GraphicsDevice.WindowTranslucency.PERPIXEL_TRANSLUCENT)) {\n                    new GriddedTranslucentWindow();\n                }\n            }\n        });\n    }\n\n    private class AlphaPanel extends JPanel {\n        private AlphaPanel(int alpha) {\n            super();\n\n            setBackground(new Color(0, 0, 255, alpha));\n        }\n    }\n}\n\n\n\nThat give me this kind of result :\n\nThe example is very simple of course, but you can imagine doing a lot of things using that feature.\nAnd now a crazy new feature : shaped windows !\nJava 7 allows you to create Window of whatever shape you want. You can create circle, triangle, elliptic windows or more complex shape, a smiley by example. To do that, you have now access to the setShape(Shape shape)  method in the Window class. Like the other two, full screen mode is not allowed and the per pixel transparency must be supported by your computer :\nGraphicsEnvironment ge = GraphicsEnvironment.getLocalGraphicsEnvironment();\n\nif (ge.getDefaultScreenDevice().isWindowTranslucencySupported(GraphicsDevice.WindowTranslucency.PERPIXEL_TRANSPARENT )) {\n    System.out.println(\"Window translucency isn't supported on your system. \")\n}\n\n\n\nHere is a little example combining a triangle and a circle :\npackage com.wicht.java7.swing;\n\nimport javax.swing.*;\nimport java.awt.*;\nimport java.awt.geom.Ellipse2D;\nimport java.awt.geom.GeneralPath;\n\npublic class ShapedWindow extends JFrame {\n    public ShapedWindow() {\n        super(\"Shaped Window\");\n\n        setUndecorated(true);\n\n        setSize(new Dimension(200, 300));\n\n        Polygon polygon = new Polygon();\n        polygon.addPoint(0, 200);\n        polygon.addPoint(100, 0);\n        polygon.addPoint(200, 200);\n\n        Ellipse2D.Double theCircle = new Ellipse2D.Double(0, 100, 1.0*200, 1.0*200);\n\n        GeneralPath path = new GeneralPath();\n        path.append(polygon, true);\n        path.append(theCircle, true);\n\n        setShape(path);\n\n        getContentPane().setLayout(new BoxLayout(getContentPane(), BoxLayout.X_AXIS));\n\n        add(Box.createHorizontalGlue());\n        JLabel label = new JLabel(\"Shaped window\");\n        label.setForeground(Color.white);\n        add(label);\n        add(Box.createHorizontalGlue());\n\n        getContentPane().setBackground(Color.blue);\n\n        setLocationRelativeTo(null);\n        setVisible(true);\n    }\n\n    public static void main(String[] args) {\n        SwingUtilities.invokeLater(new Runnable(){\n            @Override\n            public void run() {\n                GraphicsEnvironment ge = GraphicsEnvironment.getLocalGraphicsEnvironment();\n\n                if (ge.getDefaultScreenDevice().isWindowTranslucencySupported(GraphicsDevice.WindowTranslucency.PERPIXEL_TRANSPARENT)) {\n                    new TranslucentShapedWindow();\n                }\n            }\n        });\n    }\n}\n\n\n\nThis produce that sort of window :\n\nAnd of course you can combine translucency and shaped windows adding setOpacity(0.5f) to your frame. For that the Per Pixel Translucency and the Per Pixel Transparency must be supported. That give us this kind of window :\n\nHere we are. We've now covered the new translucency features of Java 7. I think it's really interesting and make Java Desktop Applications more competitive. But I think there is still work to do in Swing before doing that kind of fun stuff.", 
      "tags": "Java,Java 7,Swing"
    }, 
    {
      "loc": "/posts/2010/05/java-7-add-public-defender-methods-to-java-interfaces.html", 
      "title": "Java 7 : Add \"public defender methods\" to Java interfaces", 
      "text": "At this time, we aren't sure that the closures will be included in the Java 7 release. But these doubts have generated a new project : The \"public defender methods\" proposal.\nThis new proposal for Java 7 wants to improve the interfaces allowing to add new methods to existing interfaces. The classes implementing the interfaces doesn't need implements these methods. The implementation of these methods are provided using static methods. This could be called virtual extension method.\n\n\nTo illustrate the problem the proposal want to solve, let's take the example of reversing a List. When you have a List and you want to reverse it, you have to use the Collections.reverse() method :\nList strings = new ArrayList();\n//...\nCollections.reverse(strings);\n\n\n\nBut there is some problems with that code. Because it's a static method, there is no way to override it. We could imagine data structures where the reverse must be made using special algorithms to be efficient. An other problem is that the reverse() method is not in the List interface, so must learn two classes to make a simple thing as reversing a list.\nThe \"public defender methods\" give an other way to do that extending the List interface :\npublic interface List extends Collection {\n  ...\n  extension void reverse() default Collections.reverse;\n}\n\n\n\nThis add a new method to the List with a default implement that use the Collections.reverse(List list) static method. The list will be passed as the first argument of the static method. So, now that you have a method reverse on the List, you can do that :\nList strings = new ArrayList();\n//...\nstrings.reverse();\n\n\n\nThis code is a lot better than the other, isn't it ?\nYou can now override the reverse method providing an implementation specific to your class. But the implementation is now optional. That solve all the problems we see earlier.\nTo solve multiple inheritance issue a class implementing two interfaces providing a default implementation for the same method name and signature must provide an implementation of the method.\nAn other objective of this proposal is to \"closur-ize\" the Java 7 librairies. By example, we could think of a filter() method to the List interface :\npublic interface List extends Collection {\n  ...\n\n  extension void filter(Predicate predicate) default Collections.filter;\n}\n\n\n\nAnd a predicate like that :\npublic interface Predicate {\n   boolean accept(E object);\n}\n\n\n\nThat type of method can take advantage of closures. We can also imagine reduce, forEach, expand, ....\nAt this time, this is only a proposal, so we aren't sure it'll be included in Java 7 and the syntax is not definitive.\nPersonally, i think this is a great improvement and that will make the closures (if we have them a day) more interesting for the Java language.\nIf you want more information on the implementation, you could read the proposal in PDF.", 
      "tags": "Closures,Java,Java 7"
    }, 
    {
      "loc": "/posts/2010/05/oracle-pushes-a-first-version-of-closures.html", 
      "title": "Java 7 : Oracle pushes a first version of closures", 
      "text": "2 days ago, Oracle pushed a first version of the closures implementation. We can see the evolving syntax in the test cases they made for the Java compiler. You can see these test cases here.\nThis revision supports the following features (copied from revision) :\n\n    Function types syntax\n    Function types subtyping\n    Full support for lambda expression of type 1 and 2\n    Inference of thrown types/return type in a lambda\n    Lambda conversion using rules specified in v0.1.5 draft\n    Support references to 'this' (both explicit and implicit)\n    Translation using method handles\n\n\nThe function types aren't enabled by default, so you have to use  -XDallowFunctionTypes to enable it.\nHere are some examples of lambda expression of type 1 taken from the test cases : \nint i1 = #()(3).(); //i1 = 3\nInteger i2 = #()(3).(); //i2 = 3\nint i3 = #(int x)( x + 1 ).(3); //i3 = 4\nint i4 = #(Number x)(x.intValue()).(new Float(3.0f)); //i4 = 3\n\n\n\nAnd with type 2 : \nint i1 = #(){ return 3; }.(); //i1 = 3\nInteger i2 = #(){ return 3; }.(); //i2 = 3\nint i3 = #(int x){ return x + 1; }.(3); //i3 = 4\nint i4 = #(Number x){ return x.intValue(); }.(new Float(3.0f)); //i4 = 3\n\n\n\nFor those who didn't understand the syntax, #(int x)( x + 1 ) declares a lambda expression that takes a int and return this int plus 1. And the . (dot) is used to invoke the lambda expression. So #(int x)( x + 1 ).(3) declares the lambda expression and invoke it with 3 as parameter. \nThis syntax is a little bit shocking, but I think we'll get used.", 
      "tags": "Closures,Java,Java 7"
    }, 
    {
      "loc": "/posts/2010/05/15-years-birthday-of-java-a-bit-late.html", 
      "title": "15 years birthday of Java (a bit late)", 
      "text": "I didn't notice that earlier, but the 23 May 2010 was the 15 years birthday of Java !\nI started using Java only 5 years ago, but I've always been happy of this language. \nIt makes now a long time that we've this wonderful language to develop :)\nThanks a lot to James Gosling and Sun Microsystems for this great language.", 
      "tags": "Java,Others"
    }, 
    {
      "loc": "/posts/2010/05/improve-performance-builds-maven-cli-plugin.html", 
      "title": "Improve the performance of your Maven builds with maven-cli-plugin", 
      "text": "When you makes a lot of build using Maven, this is quickly a pain to wait for the end of the build. So this is always good to have solutions to improve the performances of the builds.\nThe better improvement i found until now is the maven-cli-plugin. This plugin provides an interactive command line interface to launch builds. The improvement is that the first phases of the build are made only once. So multiple builds are really faster. We loose a little time at the first build to make some caching improvements.\nWith these features, I save a lot of time when I made a lot of builds. For example a simple clean takes sometimes 20 seconds on a big multimodule project. When using the cli, it takes 20 seconds including the time to load the shell for the first time and then it takes only 1 second the make the following cleans. The effect is the same on other phases like install, package, compile, ...\nThe installation is quite simple. First you must add a plugin group to the settings.xml file :\n<settings>\n  <pluginGroups>\n    <pluginGroup>org.twdata.maven</pluginGroup>\n    ...\n  </pluginGroups>\n  ...\n</settings>\n\n\n\nAnd then add a new repository for the manve-cli-plugin : \n<pluginRepositories>\n     <pluginRepository>\n          <id>twdata-m2-repository</id>\n          <name>twdata.org Maven 2 Repository</name>\n          <url>http://twdata-m2-repository.googlecode.com/svn/</url>\n     </pluginRepository>\n</pluginRepositories>\n\n\n\nAnd you just have to use the following command on a Maven project : \nmvn cli:execute-phase\nWith that the plugin will be downloaded automatically and the next commands will be executed directly. \nThe usage is very easy. This plugin has 2 useful goals : \n\n    execute : Open a shell and allows you to execute goals of plugins. \n    execute-phase : Open a shell and allows you to execute phases of the maven build. \n\n\nThe main difference is that if you launch install from the execute-phase, all the preceding phases will be executed, but that's not the case with execute, only install will be executed. \nPersonally, I only execute phases, so I always use the execute-phase of the cli plugin. \nWhen you're in the shell, you can launch several phases or goals : \nmaven> clean install\n\nAnd you can directly add arguments in the command : \nmaven> clean install -Dmaven.test.skip=true\n\nAnd when you are building a multimodule projects, you can also execute phases only on several modules : \nmaven> module1 module2 module3 clean install\n\nYou can use the ls command in a multi module project to list all the modules of the project. You can use the \"Tab\" key to auto complete the goals, phases and modules name. \nWhen you've finished your builds, you can simply use the \"exit\" command to exit from the command line. \nI think it's really a great essential plugin for each person who make Maven builds.  \nMore information on the official site.", 
      "tags": "Java,Maven,Tools"
    }, 
    {
      "loc": "/posts/2010/05/evernote-a-very-smart-note-book.html", 
      "title": "Evernote : A very smart note-book", 
      "text": "Like any developer, I write a lot of notes with different tools :\n\n    A lot of paper\n    Office Word\n    My iPhone\n    My emails\n    Web applications like RememberTheMilk\n\n\nI use them depending on what I do and \u00a0where I am. But this not a really good way to manage notes. The notes are not centralized and I've not always them when I need them.\nSome days ago, I discovered a new web application than can perhaps solve my problem. This web tool is Evernote.\nThe site allows you to store elements on the web or offline in your storage space and organize all the elements like you want. With Evernote, you can :\n\n    Write TODO List\n    Write some notes\n    Send them by email\n    Take screenshot\n    Add photo\n    Capture contents of web pages\n    Record audio records\n\n\nBut there is more, this service make also Optical Character Recognition (OCR) in your images. So when you take a picture and send them in the Evernote account, the text in the photo is indexed and taken for your next searches. All the text of the other documents is of course also indexed. So with that you can search documents easily.\nEvernote is also more than an web application, it's also a desktop client for Windows and Mac OS. There is also Windows Mobile, Java and soon iPhone versions. With the client versions, you can directly drag and drop content to your account.\nSo to resume, Evernote is a kind of aggregator for your content. So after writing something on paper, you can take a picture and add it to your Evernote and then make searches in your content. With the free registration, you have 40MB of upload monthly. To have more upload capacity, you can pay the premium account for 5$/month.\nFor more informations, you can consult the Official site", 
      "tags": "Others,Tools"
    }, 
    {
      "loc": "/posts/2010/05/java-concurrency-part-2-manipulate-threads.html", 
      "title": "Java Concurrency : Part 2 - Manipulate Threads", 
      "text": "After seeing how to create Threads, we'll see in this article what we can do to manipulate Threads.\nWhen we've Threads, we can make several operations on the Threads :\n\n    Make the current Thread sleeping during x milliseconds\n    Wait for an other thread to complete\n    Manage the priorities of Threads and pause a thread to give an other thread the opportunity to run\n    Interrupt a thread\n\n\nWe'll now see how to do all these things.\n\n\nFirst and easier, we can make a thread sleeping for a certain number of milliseconds. To do that, the Thread class has a method sleep(long millis). But this method is static, so you can only make the current Thread sleeping. You cannot choose the thread you want to make sleeping, your only choice is the current Thread so :\nThread.sleep(1000);\n\n\n\nmakes the current Thread sleep during 1000 milliseconds (1 second). But, you have to catch an exception, InterruptedException. This exception occurs if the sleeping thread is interrupted. So you have to do that :\ntry {\n    Thread.sleep(1000);\n} catch (InterruptedException e){\n    e.printStackTrace();\n}\n\n\n\nBut this not the good way to manage the InterruptedException. We'll see in one moment, how to deal with this exception. \nIf you want more precision, you can use the overloaded version of sleep that takes the number of milliseconds plus a certain number of nanoseconds to sleep. The precision of this sleep depends on the system timers and clocks.\nFor example, if you want to sleep 1000 milliseconds and 1000 nanoseconds (1 microsecond), you can do like that :\ntry {\n    Thread.sleep(1000, 1000);\n} catch (InterruptedException e){\n    e.printStackTrace();\n}\n\n\n\nHere is a little example to test that :\npublic class SleepThread {\n    public static void main(String[] args) {\n        System.out.println(\"Current time millis : \" + System.currentTimeMillis());\n\n        try {\n            Thread.sleep(1000);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n\n        System.out.println(\"Current time millis : \" + System.currentTimeMillis());\n\n        System.out.println(\"Nano time : \" + System.nanoTime());\n\n        try {\n            Thread.sleep(2, 5000);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n\n        System.out.println(\"Nano time : \" + System.nanoTime());\n    }\n}\n\n\n\nIn my computer, this produce this result :\nCurrent time millis : 1273959308480\nCurrent time millis : 1273959309480\nNano time : 5878165216075\nNano time : 5878166730976\n\nYou can see that the sleep of milliseconds is very precise, but with nanoseconds the result can vary a lot. And of course, the result depends of your computer, your operating system and your configuration.\nAn other thing, you can do with Threads, is waiting for an other thread to die. For example, you can create five thread to compute sub result and wait for these 5 threads to finish to compute the final results based on the results of the five threads. To do that, you can use the join() method of the Thread class. This method is not static, so you can use it on any thread to wait for it to die. Like sleep() this method throws InterruptedException in the when the thread is interrupted during waiting for an other thread. So to wait on thread2, you just have to do that :\ntry {\n    thread2.join();\n} catch (InterruptedException e){\n    e.printStackTrace();\n}\n\n\n\nThat will make the current Thread waiting for thread2 to die. You can also add a timeout in millis, or millis + nanos, with the overloaded versions of join(), join(long millis) and join(long millis, int nanos). Here is little example that shows all that stuff :\npublic class JoinThread {\n    public static void main(String[] args) {\n        Thread thread2 = new Thread(new WaitRunnable());\n        Thread thread3 = new Thread(new WaitRunnable());\n\n        System.out.println(\"Current time millis : \" + System.currentTimeMillis());\n\n        thread2.start();\n\n        try {\n            thread2.join();\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n\n        System.out.println(\"Current time millis : \" + System.currentTimeMillis());\n\n        thread3.start();\n\n        try {\n            thread3.join(1000);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n\n        System.out.println(\"Current time millis : \" + System.currentTimeMillis());\n    }\n\n    private static class WaitRunnable implements Runnable {\n        @Override\n        public void run() {\n            try {\n                Thread.sleep(5000);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        }\n        }\n}\n\n\n\nThat produce this result on my computer :\nCurrent time millis : 1274015478535\nCurrent time millis : 1274015483538\nCurrent time millis : 1274015484538\n\nYou can see that the first join() wait 5 seconds for the other thread and when we set a timeout, we wait only 1 seconds and return from join method.\nWhen working with Threads, it's also possible to change the priority of a Thread. In the Java Virtual Machine, the Thread scheduler, use a priority-based scheduling. So if a Thread enter in Runnable state with a higher priority than the running Thread, the new Thread will run and the current running thread will return to Runnable state and waits for its turn. But this behavior is not guaranteed and is completely depending on the virtual machine you are working on. So, do not rely on thread priorities, just use them to improve efficiency of your program.\nNormally, the priority range of Threads is an integer from 0 to 10, but some virtual machine have lower or higher ranges. To know the range of priority, you can use constants of the Thread class :\npublic class ThreadPriorityRange {\n    public static void main(String[] args) {\n        System.out.println(\"Minimal priority : \" + Thread.MIN_PRIORITY);\n        System.out.println(\"Maximal priority : \" + Thread.MAX_PRIORITY);\n        System.out.println(\"Norm priority : \" + Thread.NORM_PRIORITY);\n         }\n}\n\n\n\nOn my computer, I've the most current values :\nMinimal priority : 1\nMaximal priority : 10\nNorm priority\n\nTo set the priority of a Thread, you can use the setPriority(int priority) method of the Thread class. If you enter a value greater than the maximal priority, the maximal value will be used. If you don't specify a priority, the used priority, will be the priority of the current Thread.\nAn other way to works with priority is the yield() method. This method is static, so this works on the current Thread. The purpose of this method is to make the Thread going to Runnable again and to give the opportunity to other threads to get their turn. But in practice, the behavior of this method is not guaranteed. It can be implemented as a no-op on certain systems. It's not easy to test that in practice, because the results can truly depends on your computer, virtual machine and operating system. It's a good things to not use the priorities of Threads in practice.\nThe last thing you can do with a Thread, is to interrupt it. In Java, you have no way to force a Thread to stop, if the Thread is not well-done, it can continue its execution infinitely. But you can interrupt a Thread with the interrupt() method. This method interrupt the thread, if the thread is sleeping or joining an other Thread, an InterruptedException is thrown. You have to know that if the thread was sleeping or joining, the interrupted status of the Thread will be cleared. Namely, the method isInterrupted() will return false. A little example to demonstrate that :\npublic class InterruptThread {\n    public static void main(String[] args) {\n        Thread thread1 = new Thread(new WaitRunnable());\n\n        thread1.start();\n\n        try {\n            Thread.sleep(1000);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n\n        thread1.interrupt();\n    }\n\n    private static class WaitRunnable implements Runnable {\n        @Override\n        public void run() {\n            System.out.println(\"Current time millis : \" + System.currentTimeMillis());\n\n            try {\n                Thread.sleep(5000);\n            } catch (InterruptedException e) {\n                System.out.println(\"The thread has been interrupted\");\n                System.out.println(\"The thread is interrupted : \" + Thread.currentThread().isInterrupted());\n            }\n\n            System.out.println(\"Current time millis : \" + System.currentTimeMillis());\n        }\n        }\n}\n\n\n\nThat produce that kind of result :\nCurrent time millis : 1274017633151\n\nThe thread has been interrupted\n\nThe thread is interrupted : false\n\nCurrent time millis : 1274017634151\n\nYou can see that after one second, the second thread is interrupted and that the interrupted status has been set to false. If you are not sleeping, but making a lot of heavy actions, you can test for interrupt like that to make your thread correctly interrupts :\npublic class InterruptableRunnable implements Runnable {\n    @Override\n    public void run() {\n        while(!Thread.currentThread().isInterrupted()){\n            //Heavy operation\n        }\n    }\n}\n\n\n\nNow that you know how to interrupt a thread, you can imagine, that simply catch the InterruptedException is not enough to make your thread \"interrupt safe\". Imagine that your thread something like that : \npublic class UglyRunnable implements Runnable {\n    @Override\n    public void run() {\n        while(!Thread.currentThread().isInterrupted()){\n            //Heavy operation\n            try {\n                Thread.sleep(5000);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n            //Other operation\n        }\n    }\n}\n\n\n\nAnd now, an other thread want to interrupt your thread while your thread is sleeping. The sleep will be interrupted, but the interrupted status will be cleared so the loop will continue. A solution to make a better thread is to interrupt again the thread after an InterruptedException : \npublic class BetterRunnable implements Runnable {\n    @Override\n    public void run() {\n        while(!Thread.currentThread().isInterrupted()){\n            //Heavy operation\n            try {\n                Thread.sleep(5000);\n            } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n            }\n            //Other operation\n        }\n    }\n}\n\n\n\nWith that code, the interrupted status will be restored and the loop will be stopped after interrupt. Depending on your code, you can also add a continue statement after the interrupt() to not make operations after interrupt. In some cases, you'll also needs to make several if statements to test the interrupted status to do or not to do some operations. \nSo, we've now covered the main operations you can do on threads. I hope you found this article interesting.\nYou can download the sources of this article here : Java Concurrency Sources - Part 2\nIn the next article about Java Concurrency, we'll see how to synchronize code to make it Thread-safe.", 
      "tags": "Concurrency,Java"
    }, 
    {
      "loc": "/posts/2010/05/tip-add-resources-dynamically-to-a-classloader.html", 
      "title": "Tip : Add resources dynamically to a ClassLoader", 
      "text": "Theoretically, it's not possible to ad resources to a ClassLoader in Java after creation. I say theoretically, because, we can do that using Reflection. \nIn fact, the URLClassLoader class has a addUrl(URL url) method to add a new URL, so we can invoke that method to add an URL where the ClassLoader can search to load a class. But this method is protected. So here is an example taking advantage of Reflection to add URL to the system ClassLoader : \npublic static void addURLToSystemClassLoader(URL url) throws IntrospectionException { \n  URLClassLoader systemClassLoader = (URLClassLoader) ClassLoader.getSystemClassLoader(); \n  Class<urlclassloader> classLoaderClass = URLClassLoader.class; \n\n  try { \n    Method method = classLoaderClass.getDeclaredMethod(\"addURL\", new Class[]{URL.class}); \n    method.setAccessible(true); \n    method.invoke(systemClassLoader, new Object[]{url}); \n  } catch (Throwable t) { \n    t.printStackTrace(); \n    throw new IntrospectionException(\"Error when adding url to system ClassLoader \"); \n  } \n}\n\n\n\nThis is easy and that can be done for any URLClassLoader. But of course, this is an ugly hack and that must not be always used but can be useful sometimes. An other way to do that is to create a new Class extending URLClassLoader and make the addUrl(URL url) public, but that can be done with the system ClassLoader.", 
      "tags": "Java,Tips"
    }, 
    {
      "loc": "/posts/2010/05/modular-application-loading-modules.html", 
      "title": "Develop a modular application - The loading", 
      "text": "Now that we've seen how to describe a module in Java, we'll see how to load it dynamically in our application.\nIn Java, all the classes are loaded using several ClassLoader.In this article, we'll develop a loader for our modules and watch the problems that arrive when working with custom ClassLoaders.\n\n\nNormally, Java use the system ClassLoader to load all the classes of our application. So it contains all the classes of our application and all the classes our application needs to work. But the problem is that we cannot add our modules jar files into classpath because the application doesn't know the modules jar files names.\nMoreover, we cannot theoretically add files to the system ClassLoader. I say theoretically because, we can add files using reflection and call to a private method, but i thing it's not a really good practice.\nSo we've to create a new ClassLoader to load our modules. We'll do that in two phases :\n\n    Browse the module files to get the classes of the modules and the URLs of the modules Jar files\n    Load the modules into our ClassLoader using the URLs of the first phase\n\n\nWe'll do all the loading in a new class ModularLoader. so let's create a create a method that return the list of classes to load :\npublic class ModuleLoader { \n  private static List<URL> urls = new ArrayList<URL>(); \n\n  private static List<String> getModuleClasses(){ \n    List<String> classes = new ArrayList<String>(); \n\n    //Get all the modules of the modules folder\n    File[] files = new File(\"folder\").listFiles(new ModuleFilter()); \n\n    for(File f : files){ \n      JarFile jarFile = null; \n\n      try { \n        //Open the Jar File\n        jarFile = new JarFile(f); \n\n        //We get the manifest\n        Manifest manifest = jarFile.getManifest(); \n\n        //We get the class name from the manifest attributes\n        classes.add(manifest.getMainAttributes().getValue(\"Module-Class\")); \n\n        urls.add(f.toURI().toURL()); \n      } catch (IOException e) { \n        e.printStackTrace(); \n      } finally { \n        if(jarFile != null){ \n          try { \n            jarFile.close(); \n          } catch (IOException e) { \n            e.printStackTrace(); \n          } \n        } \n      } \n    } \n\n    return classes; \n  } \n\n  private static class ModuleFilter implements FileFilter { \n    @Override \n    public boolean accept(File file) { \n      return file.isFile() &amp;&amp; file.getName().toLowerCase().endsWith(\".jar\"); \n    } \n  } \n}\n\n\n\nLike you see, it's not complicated at all. We search all the module files and then for each jar file, we open it, get the manifest et read the class name of the module. And then, for the second phase, we get the URL to the Jar file. \nOf course, this loader is not perfect. We can have modules with no manifest or manifest with no class name and the errors must be correctly treated, but this is not the objective of this post to be perfect. \nNow we can do the second phase, adding a method to create the ClassLoader, instantiate the modules and return them : \nprivate static ClassLoader classLoader; \n\npublic static List<IModule> loadModules(){ \n  List<IModule> modules = new ArrayList<IModule>(); \n\n  AccessController.doPrivileged(new PrivilegedAction<Object>(){ \n    @Override \n    public Object run() { \n      classLoader = new URLClassLoader( \n          urls.toArray(new URL[urls.size()]),  \n          ModuleLoader.class.getClassLoader()); \n\n      return null; \n    } \n  }); \n\n  //Load all the modules\n  for(String c : getModuleClasses()){ \n    try { \n      Class<?> moduleClass = Class.forName(c, true, classLoader); \n\n      if(IModule.class.isAssignableFrom(moduleClass)){ \n        Class<IModule> castedClass = (Class<IModule>) moduleClass; \n\n        IModule module = castedClass.newInstance(); \n\n        modules.add(module); \n      }  \n    } catch (ClassNotFoundException e) { \n      e.printStackTrace(); \n    } catch (InstantiationException e) { \n      e.printStackTrace(); \n    } catch (IllegalAccessException e) { \n      e.printStackTrace(); \n    } \n  } \n\n  return modules; \n}\n\n\n\nSo we start creating a new ClassLoader taking the urls of the Jar files. Then, we use this ClassLoader to load all the module classes and instantiate them. We only verify if the class is of type IModule. \nThis is all for our ModuleLoader. We can now test our simple modular application. We create a JAR file for the module of the previous post and then we create a very simple application to test that : \nList<IModule> modules = ModuleLoader.loadModules(); \n\nfor(IModule module : modules){ \n  System.out.println(\"Plug : \" + module.getName()); \n  module.plug(); \n} \n\nSystem.out.println(\"Lot of other things done by the application. \"); \n\nfor(IModule module : modules){ \n  module.unplug(); \n}\n\n\n\nAnd here is the output of the application : \nPlug : Simple module\nHello kernel !\nLot of other things done by the application. \nBye kernel !\n\nLike you can see, we just created a modular applications ! The application doesn't know the modules, but the modules can do things in the application. \nOf course, to create a real applicatio, we have to develop all the extension points and services, but this is a base to start with. \nHowever, there is some problems with the current implementations : \n\n    We cannot deploy modules without restarting the application, because we must create a new ClassLoader for the modules. This is possible if there is no interation between modules, but that's not often the case. You have also the possibility to isolate all the modules in a specific ClassLoader, but with that second solution, the interations between modules are made harder. \n    Using a second ClassLoader may be problematic with libraries loading dynamically the classes like Spring or Hibernate. To make these libraries working with your ClassLoader, you have to look at case by case depending on the library. Often, you achieve specifying the contextClassLoader using the method  Thread.currentThread().setContextClassLoader(ClassLoader cl) with your ClassLoader\n\n\nSo here is the end of this four posts about creating a modular application. I hope you find these posts interesting.", 
      "tags": "Conception,Java,Modular"
    }, 
    {
      "loc": "/posts/2010/05/develop-a-modular-application-implementation.html", 
      "title": "Develop a modular application \u2013 Implementation", 
      "text": "Now that we saw in details the characteristics of the modules, we'll see how to implement a module.\nWe need a simple container for our module to load it after with a loader from the modular application.\nIn this post, we'll only see what will be a module in Java, we'll the loading of the modules in the next (and last) post.\n\n\nA module is completely independent of the module, so we cannot include it directly in the application. We must distinguish the file of the module and the file of the application.\nSo what will be these files ? Because we're in Java, we use Jar files. So the modules will be Jar files extending the applications.\nAnd now in Java, a module will be an interface  describing the main characteristics of the module. We'll be simple for the moment. A module must be pluggable to the application and unpluggable. Moreover the module has also a name and we can get this name. At this moment, this is all we need :\nWe must have a simple interface to describe a module :\npublic interface IModule {\n  public void plug();\n  public void unplug();\n  public String getName();\n}\n\n\n\nWith that interface, we can create the most simple module that only prints to the console :\npackage org.modules.simple; \n\npublic class SimpleModule implements IModule {\n  @Override\n  public void plug(){\n    System.out.println(\"Hello kernel !\");\n  } \n\n  @Override\n  public void unplug(){\n    System.out.println(\"Bye kernel !\");\n  } \n\n  @Override\n  public String getName(){\n    return \"Simple module\";\n  }\n}\n\n\n\nSo we'll create a Jar file containing our class. We need a solution for the application to know which class to launch. So we need write this somewhere.\nA na\u00efve solution is to browse the Jar file and test each class if it implements the interface. This method works but is not optimal but that can be really inefficient in large Jar file. So we'll use the tools offered by Java and add an information in the Jar manifest to indicate to the application which class must be loaded.\nSo here it's the manifest for our example :\nManifest-Version: 1.0\nModule-Class: org.modules.simple.SimpleModule\n\nWith that the module loader will know which class it must instantiate to create a module.  An other solution is to use the ServiceLoader of Java 6.\nIn the next post, we'll see how to load our module and we'll test an application with two simples modules.", 
      "tags": "Conception,Java,Modular"
    }, 
    {
      "loc": "/posts/2010/05/modular-application-modules.html", 
      "title": "Develop a modular application \u2013 The modules", 
      "text": "After explaining what's a modular application, I'll now explain with more details the concept of modules.\nWe said that a module add features to the application. But before writing any code, we've to define exactly what are the modules, what they can do if there is several types of modules, ...\nThis is what we'll see in this post.\n\n\nThe first question to ask is \"What can a module do ?\". Namely, defining all the things a module can add to the application and how they can add these things. Moreover, a module can also modify the application.\nWhat the modules can do depends on the type of the modular application :\n\n    For the first type (simple application with extension capability), the module adds specific features depending on the application. By example, in the case of an application that allows to watch television from internet, the modules can add a new channel or the support of a new video format. It can also adds a complete feature like statistics about channels. \n    For the second type (empty application and modules that make the application features), the modules don't add features to the application, they do the application. In this case, the modules are often bigger than in the first case, because, modules are applications. There is often no links between modules, one can create a calculator and the other a video editor. \n\n\nIn the two cases, we've to define several extension points. By example, here are the extension points I created for JTheque : \n\n    Add tabs in the main view\n    Add components in the state bar\n    Add features to the menu\n    Add configuration options\n\n\nWith there extension points, the modules can do a lot of things. If we want to make a calculator, we can add a tab in the main view or add a feature in the menu that displays a calculator in a dialog. Of course, this extension points depends of the developer and the application, but this is really important to define well a list of this points. \nMore than providing extension points, the core of the application provide also a set of services to the modules. These services can be simple utility classes or by example a persistence manager or a file manager. \nOne more time, you've to decided which services the core will provide to the modules. This services are not essential, but that enables to simplify a lot the modules. And that improve the code standard of the modules. With that model, the modules will always use the same type of services, this is easier to manage.  \nBy example, here are some of services, JTheque Core offers to the modules : \n\n    Error manager : To display some errors. \n    View manager : To create easily new views, display messages, ask something to the user. \n    Resource manager : Provide an image cache and utility methods to load image, create thumbnail, ...\n    Persistence manager : Give the ability to modules to persist objects\n    State manager : Store states for modules\n\n\nWe can also think if we want only one type of modules or several. By example, you can imagine primary modules and normal modules. Only a primary module can be launched at the same time. \nThe last point I see, is the point of the dependencies between modules. We can allows that a module depends on an other modules. This add a difficulty level for the implementation, because we must verify that the dependencies are solved before launch a module. And what about circular dependencies ? This is the choice of developer, but if you don't allow dependencies between modules, it can e difficult to create good applications. \nSo I've finished to talk about modules. Don't hesitate to comment if you doesn't agree with something or if you have questions. In the next I'll implement the first modules and in the last, I will create a simple loader for modules.", 
      "tags": "Conception,Java,Modular"
    }, 
    {
      "loc": "/posts/2010/05/java-concurrency-part-1-threads.html", 
      "title": "Java Concurrency - Part 1 : Threads", 
      "text": "This post is the first of set of posts about Java Concurrency.\nThe concurrency is the fact to made several things at the same time using several threads.\nA thread, also called Lightweight Process, is treatment unity. Threads executes code in parallel of each other threads currently running. When you've only one processor, there is a thread running at the same time of the others, you only have the impression of concurrency (I don't say it's not useful, I say it's different), but when you've multiple processors, you'll see the power of multithreading. In this case, you can have your threads distributed on the processors of the computer.\n\n\nIn Java, a thread is an instance of the class java.lang.Thread. A Thread can be managed in one of these two ways :\n\n    Directly mapped to a native thread of the operating system. This is used when the operating system provide a preemptive threading system.\n    Managed by the virtual machine in a preemptive way.\n\n\nA preemptive system, is a system in which the threads are managed by a scheduler and can be interrupted at any time to give processor to an other thread. When you program, you doesn't have to pay attention of which type of threads you use, the result will normally be the same. But you've to know that there can differences between operating systems.\nThere is three very important concepts when doing concurrent programming :\n\n    Atomicity : An operation is said atomic when it cannot be interrupted. There is almost no atomic operations in Java, the only we've is the assignation a = 5, but a = b++ is not atomic. In some cases, you'll have to make atomic some actions with synchronization, we'll see later how to do that.\n    Visibility : This occurs when a thread must watch the actions of an other threads by example the termination of the thread. This also implies some kind of synchronization.\n    Order of execution : When you have normal program, all you lines of code run in the same order every time you launch the application. This is not the case when you make concurrent programming. You first instruction can followed by an instruction of the thread B or by the first instruction. And that can change every time you launch the application. The order of execution is not guaranteed ! I will certainly repeat that sometimes, but that's important to know.\n\n\nWe'll see these concepts more deeply in the others parts of the set.\nLets start introducing the Thread class in Java. You can create threads in two ways :\n\n    Extends Thread\n    Implements Runnable and pass an instance of your news class to the Thread constructor\n\n\nThe first solution isn't a good solution because what you're creating is not a new specialized thread, but several instructions to run in a new Thread, namely a Runnable. Implementing Runnable is also better because Runnable is an interface and so, you can also extends a class and\u00a0implementing\u00a0Runnable, that's useful in some cases.\nIn my examples, I'll always use the second way. So let's declare our first Runnable :\npublic class MyFirstRunnable implements Runnable{\n    @Override\n    public void run() {\n        System.out.println(\"In a thread\");\n    }\n}\n\n\n\nAnd use it to create a new Thread and start it :\nThread thread = new Thread(new MyFirstRunnable());\nthread.start();\n\n\n\nThe Thread will stopped when the end of the run() will be reached. You cannot force a thread to stop (there is stop() method, but deprecated), we'll see later how to properly stop a thread.\nAnd now, what happens if we add a simple line of code to our program :\nThread thread = new Thread(new MyFirstRunnable());\nthread.start();\nSystem.out.println(\"In the main Thread\");\n\n\n\nCan you predict the result of this code ? Nobody can't, it's not predictable, you can have :\nIn a thread\nIn the main Thread\n\nor\nIn the main Thread\nIn a thread\n\nAnd we cannot do better than that.\nYou can use the Runnable several times :\nRunnable runnable = new MyFirstRunnable();\n\nfor(int i = 0; i &amp;lt; 25; i++){\n    new Thread(runnable).start();\n}\n\n\n\nNow, 25 threads are launched.\nYou can also give names to Thread using the setName() method. You can get the name of the current thread using Thread.currentThread().getName(). Let's do a little example :\npublic class MySecondRunnable implements Runnable{\n    @Override\n    public void run() {\n        System.out.printf(\"I'm running in thread %s \\n\", Thread.currentThread().getName());\n    }\n}\n\n\n\nRunnable runnable = new MySecondRunnable();\n\nfor(int i = 0; i &amp;lt; 25; i++){\n    Thread thread = new Thread(runnable);\n    thread.setName(\"Thread \" + i);\n    thread.start();\n}\n\n\n\nThis is the best example to see that the other is unpredictable. Here are two executions on my machine :\n1.\nI'm running in thread Thread 0\nI'm running in thread Thread 1\nI'm running in thread Thread 2\nI'm running in thread Thread 3\nI'm running in thread Thread 4\nI'm running in thread Thread 5\nI'm running in thread Thread 7\nI'm running in thread Thread 14\nI'm running in thread Thread 13\nI'm running in thread Thread 12\nI'm running in thread Thread 11\nI'm running in thread Thread 10\nI'm running in thread Thread 9\nI'm running in thread Thread 8\nI'm running in thread Thread 6\nI'm running in thread Thread 15\nI'm running in thread Thread 16\nI'm running in thread Thread 17\nI'm running in thread Thread 18\nI'm running in thread Thread 19\nI'm running in thread Thread 20\nI'm running in thread Thread 21\nI'm running in thread Thread 22\nI'm running in thread Thread 23\nI'm running in thread Thread 24\n\n2.\nI'm running in thread Thread 0\nI'm running in thread Thread 1\nI'm running in thread Thread 2\nI'm running in thread Thread 3\nI'm running in thread Thread 4\nI'm running in thread Thread 5\nI'm running in thread Thread 6\nI'm running in thread Thread 7\nI'm running in thread Thread 8\nI'm running in thread Thread 9\nI'm running in thread Thread 10\nI'm running in thread Thread 11\nI'm running in thread Thread 12\nI'm running in thread Thread 13\nI'm running in thread Thread 14\nI'm running in thread Thread 15\nI'm running in thread Thread 16\nI'm running in thread Thread 17\nI'm running in thread Thread 18\nI'm running in thread Thread 19\nI'm running in thread Thread 20\nI'm running in thread Thread 21\nI'm running in thread Thread 22\nI'm running in thread Thread 23\nI'm running in thread Thread 24\n\nLike you can see, the order the threads instructions are executed is not guaranteed at all.\nSo here we are with the first part of this suite of articles about Java Concurrency. In the next post, we'll see the operations you can make directly on threads (stopping, joining, sleeping, ...).\nI hope you found that post interesting.\nThe sources of this post are available here : Java Concurrency Sources Part 1.", 
      "tags": "Concurrency,Java"
    }, 
    {
      "loc": "/posts/2010/05/develop-a-modular-application-bases.html", 
      "title": "Develop a modular application \u2013 Bases", 
      "text": "This is the first post of four posts about modular applications.\nI'll try to explain all the things we must think of when we develop a modular application. I'm developing a generic core for modular applications, JTheque. So what I'm saying in this posts are taken from my experience developing this framework. \nIn this post, i'll start talking of the bases of the conception of modular application. So what's a modular application, a module and what give to the developer and the user to have a modular application ? In the next posts, I'll describe the problems we could found relating to modules and loading. The examples will be in Java, but all the concepts can be applied to every language. I'll not talk about OSGi, this is more an introduction to modular programming without specific framework, but of course, OSGi is a very good solution to modular programming.\nOf course, I don't think i'm a professional in modular programming and what I'll say in this post, is nothing else than my point of view. If you think there is better solutions than what I present, don't hesitate to say that in comments.\n\n\nTo start, what's a modular application ? A modular application is made of 2 distinct parts : \nThe core : Like its name says, this is the central part of the application. This part must be completely independent of the modules. \nThe modules : It's the dynamic parts we'll add to the application to add features. There is other name for modules : add-ons, plugins and lot of other name, but the concept is the same. \nI think there is two types of modular applications. The first type is a normal application who provide several features and give the user the possibility to add functionalities with modules. The second type is an application who has a core without feature. All the features are provided by the modules, so, \"All is module\". \nThe main difference is that the first type can be used like any other application without modules, but the second one is not useful without modules. \nIn these two types of applications, you've to define some extension points for the modules. With that extension points, the modules can add features to the application or modify some features. \nJTheque is based on the second type. JTheque Core is a simple core to develop modular applications. We can also talk of Eclipse that is a fully modular framework. \nNow the question is : that seems good but what the hell does that offer ? First, from the point of view of a developer, this allows to clearly separate the different parts of its application. We've distinct modules easier to maintain than a big applications. It's also easy to add features to applications. And last but not least, you can use the core several times for building different applications. From the point of view of the user, he can choose which modules he want to launch, add new modules and perhaps create some modules if he can. So he can customize applications. \nBut, that not trivial to make, you've to make a good conceptions and implement it in a clean way. When you do, you find some problmens to solve and a lot of questions to ask. We'll see all the problems and questions in the next post.", 
      "tags": "Conception,Java,Modular"
    }, 
    {
      "loc": "/posts/2010/05/sonar-2-1-has-been-released.html", 
      "title": "Sonar 2.1 has been released", 
      "text": "The version 2.1 of Sonar has just been released. This version includes 51 bugfixes and improvements. The major new features are :\n\n    A new page \"Librairies\" displays all the librairies of the project (Maven dependencies)\n    A new page \"Dependencies\" searches for library usages\n    A new page \"System Info\" display the system properties, installed plugins, database and VM memory stats.\n    New rules to detect unused methods.\n\n\nNormally, all the plugins compatible with version 2.0 should be compatible with this new version.", 
      "tags": "Java,Releases,Sonar"
    }, 
    {
      "loc": "/posts/2010/05/better-exception-handling-in-java-7-multicatch-and-final-rethrow.html", 
      "title": "Better exception handling in Java 7 : Multicatch and final rethrow", 
      "text": "I'm happy to announce that an other improvement from the Project Coin has be marked for inclusion in Java 7 : Improved Exception Handling for Java, from Neal Gafter. This has been announced by Joe Darcy on his blog. \nThis improvement add two litlte improvements to exception handling :\n\n    Multicatch : You'll now be able to catch multi exceptions type in one catch block\n    Final Rethow : Allows you to catch an exception type and it's subtype and rethrow it without having to add a throws clause to the method signature.\n\nOften, we have that kind of code :\n} catch (FirstException ex) {\n     logger.error(ex);\n     throw ex;\n} catch (SecondException ex) {\n     logger.error(ex);\n     throw ex;\n}\n\n\n\nBut that code is heavy for nothing really interesting. A solution is to find a common supertype of these two exceptions type and catch just that type and rethrow it. But that can catch more exceptions than you want. \nSo now, with that new feature, you can do : \n} catch (FirstException | SecondException ex) {\n     logger.error(ex);\n    throw ex;\n}\n\n\n\nA lot more cleaner, isn't it ?\nAnd the second improvement is a little more complicated. Imagine that you want to catch all exceptions, make several operations and then rethrow it. The code isn't hard to make, but the big problem is that you must add a throws clause to your method signature to manage the new exception launched by your code and this is not the objective. Now, you can do that without adding an exception throws clause : \ntry {\n     // some code\n} catch (final Throwable ex) {\n     // some more code\n    throw ex;\n}\n\n\n\nUsing the final keyword it allows you to throw an exception of the exact dynamic type that will be throwed. So if an IOException occurs, an IOException will be throwed. Of course, you have to declare the exceptions not caught. You throws clauses will exactly the same if you use the code (in //some code) without catching anything but now you can do something if that happens. \nI think multi-catch is a great feature, but for me the final rethrow is not often useful for programmers and perhaps a little weird using the final keyword.", 
      "tags": "Java,Java 7"
    }, 
    {
      "loc": "/posts/2010/05/jtheque-licensed-under-apache-license-2-0.html", 
      "title": "JTheque licensed under Apache License 2.0", 
      "text": "I decided to change the licence of all the JTheque Projects (The Core, the Utils and all the applications) to Apache Licence 2.0. The current license was GNU GPL V3. \nI wanted to remove the copyleft clause of the GPL License to make the use of JTheque more simple and more open. For me the copyleft is not really important, I need only the copyright clause. \nSo, all the next versions of one of the JTheque Projects will now be made available under the Terms of the Apache License 2.0.", 
      "tags": "Apache,JTheque,Others"
    }, 
    {
      "loc": "/posts/2010/05/switch-kubuntu-to-ubuntu.html", 
      "title": "Tip : How to switch from KUbuntu to Ubuntu", 
      "text": "After installed the new version of KUbuntu Lucid Lynx, I have changed the display manager from KDE (KUbuntu) to Gnome (Ubuntu).\nThis is easier than we could think.\nThe first thing to do is to install the Ubuntu desktop :\nsudo apt-get install ubuntu-desktop\n\nThat will install the Ubuntu Display Manager. You'll be asked for the Display Manager to use, choose gdm (Gnome Display Manager).\nAfter that, you'll have the Gnome\u00a0Display Manager, but you've also all the applications of the KUbuntu Desktop distribution.\nTo remove them, you can use this command :\nsudo apt-get remove akonadi-server akregator amarok amarok-common amarok-utils apport-kde apturl-kde ark cdrdao dolphin dragonplayer exiv2 foomatic-db-gutenprint freespacenotifier gdebi-kde gnupg-agent gtk2-engines-qtcurve gwenview hpijs-ppds ibus-qt4 icoutils ijsgutenprint install-package jockey-kde k3b k3b-data kaddressbook kamera kate kbluetooth kcalc kcm-gtk kcm-touchpad kde-window-manager kde-zeroconf kdebase-bin kdebase-data kdebase-plasma kdebase-runtime kdebase-runtime-data kdebase-workspace kdebase-workspace-bin kdebase-workspace-data kdebase-workspace-kgreet-plugins kdegraphics-strigi-plugins kdelibs-bin kdelibs5 kdelibs5-data kdemultimedia-kio-plugins kdepasswd kdepim-groupware kdepim-kresources kdepim-runtime kdepim-strigi-plugins kdepim-wizards kdepimlibs-data kdepimlibs5 kdesudo kdm kfind khelpcenter4 klipper kmag kmail kmix kmousetool knm-runtime knotes konqueror konqueror-nsplugins konqueror-plugin-searchbar konsole kontact kopete kopete-message-indicator korganizer kpackagekit kppp krdc krfb krosspython ksnapshot ksysguard ksysguardd ksystemlog ktimetracker ktorrent ktorrent-data kubuntu-debug-installer kubuntu-default-settings kubuntu-desktop kubuntu-docs kubuntu-firefox-installer kubuntu-konqueror-shortcuts kubuntu-notification-helper kvkbd kwalletmanager language-selector-qt libakonadiprivate1 libao2 libattica0 libaudio2 libboost-program-options1.40.0 libclucene0ldbl libdbusmenu-qt2 libepub0 libexiv2-6 libflac++6 libibus-qt1 libindicate-qt0 libiodbc2 libk3b6 libkcddb4 libkdcraw8 libkdecorations4 libkdepim4 libkephal4 libkexiv2-8 libkfontinst4 libkipi7 libkleo4 libkonq5 libkonq5-templates libkonqsidebarplugin4 libkopete4 libkpgp4 libkscreensaver5 libksgrd4 libksieve4 libksignalplotter4 libkwineffects1 libkworkspace4 liblastfm0 libmimelib4 libmng1 libmodplug0c2 libmpcdec3 libmsn0.3 libmysqlclient16 libokularcore1 libotr2 libpackagekit-glib2-12 libpackagekit-qt-12 libphonon4 libplasma-applet-system-monitor4 libplasma-geolocation-interface4 libplasma3 libplasmaclock4 libplasmagenericshell4 libpolkit-qt-1-0 libpoppler-qt4-3 libprocesscore4 libprocessui4 libqca2 libqca2-plugin-ossl libqimageblitz4 libqt4-assistant libqt4-dbus libqt4-designer libqt4-help libqt4-network libqt4-opengl libqt4-qt3support libqt4-script libqt4-scripttools libqt4-sql libqt4-sql-mysql libqt4-sql-sqlite libqt4-svg libqt4-test libqt4-webkit libqt4-xml libqt4-xmlpatterns libqtcore4 libqtgui4 libqtscript4-core libqtscript4-gui libqtscript4-network libqtscript4-sql libqtscript4-uitools libqtscript4-xml libsolidcontrol4 libsolidcontrolifaces4 libsoprano4 libssh-4 libstreamanalyzer0 libstreams0 libtag-extras1 libtaskmanager4 libvncserver0 libweather-ion4 libxcb-shape0 libxcb-shm0 libxcb-xv0 libxine1 libxine1-bin libxine1-console libxine1-misc-plugins libxine1-x libzip1 mysql-client-core-5.1 mysql-common mysql-server-core-5.1 network-manager-kde okular okular-extra-backends openoffice.org-kde openoffice.org-style-oxygen oxygen-cursor-theme oxygen-icon-theme oxygen-icon-theme-complete packagekit packagekit-backend-apt phonon phonon-backend-xine pinentry-gtk2 pinentry-qt4 plasma-dataengines-addons plasma-dataengines-workspace plasma-desktop plasma-scriptengine-javascript plasma-scriptengine-python plasma-widget-facebook plasma-widget-folderview plasma-widget-kimpanel plasma-widget-kimpanel-backend-ibus plasma-widget-kubuntu-feedback plasma-widget-message-indicator plasma-widget-quickaccess plasma-widgets-addons plasma-widgets-workspace plymouth-theme-kubuntu-logo polkit-kde-1 printer-applet python-kde4 python-packagekit python-qt4 python-qt4-dbus python-sip quassel quassel-data shared-desktop-ontologies software-properties-kde soprano-daemon system-config-printer-kde systemsettings ttf-dejavu ttf-dejavu-extra update-manager-kde usb-creator-kde userconfig virtuoso-nepomuk\n\nIf you're under Karmic Koala (9.10), you must use this command : \nsudo apt-get remove akonadi-server akregator amarok amarok-common amarok-utils apport-kde apturl-kde ark cdrdao dolphin dragonplayer exiv2 foomatic-db-gutenprint gdebi-kde gnupg-agent gtk2-engines-qtcurve gwenview hpijs-ppds ibus-qt4 ijsgutenprint imagemagick install-package jockey-kde k3b k3b-data kaddressbook kamera kate kcm-gtk kde-icons-oxygen kde-style-qtcurve kde-window-manager kde-zeroconf kdebase-bin kdebase-data kdebase-plasma kdebase-runtime kdebase-runtime-bin-kde4 kdebase-runtime-data kdebase-runtime-data-common kdebase-workspace-bin kdebase-workspace-data kdebase-workspace-kgreet-plugins kdebase-workspace-libs4+5 kdebluetooth kdegraphics-strigi-plugins kdelibs-bin kdelibs5 kdelibs5-data kdemultimedia-kio-plugins kdepasswd kdepim-groupware kdepim-kresources kdepim-runtime kdepim-runtime-data kdepim-runtime-libs4 kdepim-strigi-plugins kdepim-wizards kdepimlibs-data kdepimlibs5 kdesudo kdm kfind khelpcenter4 kipi-plugins klipper kmag kmail kmix kmousetool knotes konq-plugins konq-plugins-l10n konqueror konqueror-nsplugins konqueror-plugin-searchbar konqueror-plugins konsole kontact kopete korganizer kpackagekit kppp krdc krfb ksnapshot ksysguard ksysguardd ksystemlog ktimetracker ktorrent ktorrent-data kubuntu-artwork-usplash kubuntu-default-settings kubuntu-desktop kubuntu-docs kubuntu-firefox-installer kubuntu-konqueror-shortcuts kvkbd kwalletmanager kwin-style-qtcurve language-selector-qt libakonadiprivate1 libao2 libaudio2 libboost-program-options1.38.0 libclucene0ldbl libepub0 libexiv2-5 libfftw3-3 libflac++6 libindicate-qt0 libjpeg-progs libk3b6 libkabcommon4 libkcddb4 libkdcraw7 libkdecorations4 libkdepim4 libkexiv2-7 libkipi6 libkleo4 libknotificationitem1 libkonq5 libkonq5-templates libkonqsidebarplugin4 libkontactinterfaces4 libkopete4 libkorundum4-ruby1.8 libkpgp4 libksane0 libksieve4 libkwineffects1 liblancelot0 liblastfm0 liblzma0 libmimelib4 libmodplug0c2 libmpcdec3 libmsn0.1 libokularcore1 libotr2 libpackagekit-glib11 libpackagekit-qt11 libplasma3 libpolkit-dbus2 libpolkit-grant2 libpolkit-qt0 libpolkit2 libpoppler-qt4-3 libqca2 libqca2-plugin-ossl libqimageblitz4 libqscintilla2-5 libqt4-assistant libqt4-dbus libqt4-designer libqt4-help libqt4-network libqt4-opengl libqt4-phonon libqt4-qt3support libqt4-ruby1.8 libqt4-script libqt4-scripttools libqt4-sql libqt4-sql-mysql libqt4-sql-sqlite libqt4-svg libqt4-test libqt4-webkit libqt4-xml libqt4-xmlpatterns libqtcore4 libqtgui4 libqtscript4-core libqtscript4-gui libqtscript4-network libqtscript4-sql libqtscript4-uitools libqtscript4-xml libruby1.8 libscim8c2a libsmokekde4-2 libsmokeqt4-2 libsoprano4 libstreamanalyzer0 libstreams0 libstrigiqtdbusclient0 libtag-extras1 libtidy-0.99-0 libvncserver0 libxcb-shape0 libxcb-shm0 libxcb-xv0 libxine1 libxine1-bin libxine1-console libxine1-misc-plugins libxine1-x libzip1 mysql-server-core-5.1 okular okular-extra-backends openoffice.org-kde openoffice.org-style-oxygen oxygen-cursor-theme packagekit packagekit-backend-apt phonon-backend-xine pinentry-gtk2 pinentry-qt4 plasma-dataengines-addons plasma-dataengines-workspace plasma-scriptengine-python plasma-widget-facebook plasma-widget-folderview plasma-widget-googlecalendar plasma-widget-indicatordisplay plasma-widget-kimpanel plasma-widget-kubuntu-qa-feedback plasma-widget-lancelot plasma-widget-networkmanagement plasma-widget-quickaccess plasma-widgets-addons plasma-widgets-workspace policykit printer-applet python-kde4 python-packagekit python-qt4 python-qt4-dbus python-sip4 quassel quassel-data ruby ruby1.8 software-properties-kde soprano-daemon speedcrunch system-config-printer-kde systemsettings ttf-arphic-uming ttf-dejavu ttf-dejavu-extra update-manager-kde update-notifier-kde usb-creator-kde userconfig\n\nI hope that will be useful to someone :)", 
      "tags": "Linux,Others,Tips"
    }, 
    {
      "loc": "/posts/2010/05/improve-performances-wordpress-w3-total-cache.html", 
      "title": "Improve performances of WordPress with W3 Total Cache", 
      "text": "Performances of a website is often a hot topic. That's not always easy to create quick websites with low response time and without high server usage.\nWordPress is not very slow but when you've a lot of readers (this is not really my case :) ) at the same time, the response time can be critical.\nBut there is some ways to improve very easily the performances of a WordPress website using some plugins. There is a lot of plugins to do that in WordPress, but the one I'm going to introduce is the one which I found the best.\nI will talk about W3 Total Cache from Frederick Townes.\n\n\nW3 Total Cache\n\nW3 Total Cache is a caching plugin. Namely, It creates static versions of your pages and serve it to clients. When changes are made to the blog, the concerned pages are invalidated and new static pages are created for the next readers. Giving static page is a lot more faster than computing the page each time a user go to your site. The caching can be made in memory (memcached) or directly in disk. More than your pages, you can also cache your feeds, useful if you've a lot of readers on your RSS feeds.\n\nBut that plugin make also a lot of others things for your site. The static pages can be compressed using gzip or deflate to reduce the needed bandwith and directly the download time of your pages. The HTML code of your pages is also minified given the same effect has compression.\n\nAfter improving your pages, the plugin can also improve your CSS and Javascript files. It can combines all the CSS files in one and the JS files in an other one. Reducing the number of files to download reduce the number of HTTP Request the browser must do and improve the response time. You can also minify the CSS and JS files and compress it like pages. The caching headers are automatically generated for all these files.\nYou can also cache Database Requests to make less requestd directly to the database.\n\nAnd last but not least, you can also use standard CDN\u00a0networks\u00a0to store your static files like CSS/JS/Images. A CDN a high performance cache distributed\u00a0throughout\u00a0the world that provide low latency access to the readers with servers in the same region as the server. W3 Total Cache automatically uploads the files you wan't to the CDN Network of your choice and make all the links himself. I've not tested this feature because I've no CDN (that's not free) and for my site, I've not enough traffic to need that type of performance improvements. But it's interesting to know that this plugin can do that for your very easily.\nFor me, W3 Total Cache has increased a lot the performances of my website. I'm passed from F to B in YSlow and from 60 to 83 in Google Page Speed indicator and I can certainly go further with it.\nYou can download the plugin on the WordPress website.", 
      "tags": "Performances,Web,WordPress"
    }, 
    {
      "loc": "/posts/2010/05/first-build-jtheque-sonar-2-0.html", 
      "title": "First build of JTheque with Sonar 2.0", 
      "text": "This week-end I updated the version of Sonar to the new version 2.0 and migrated it from Tomcat 5.5 to Tomcat 6.0. I waited until now for the plugins I use to be compatible. Now, all my plugins are compatible :\n\n    Motion Chart : An elegant chart demonstrating the evolutions of metrics build after build\n    Quality Index : Compute a quality index for each project based on 4 axes : Coding, Complexity, Coverage and Style\n    Radiator : Display a view like the main view of all projects (all the rectangles with a lot of colors) for all the components of a project\n    Rules Meter : Indicate for each project how many rules were activated during analysis\n    SCM Activity : Compute some metrics about the SCM Activity of the project\n    TagList : Analyze some tag (@TODO, @FIXME, ...) in your code and display them in the project\n    Technical Debt : Compute a technical debt estimation for all the problems of your project\n    Timeline : Display a chart of the evolution of the metrics build after build\n    Build Stability : Display the stability of the builds on the continuous integration system\n\n\nNow I made the first build of JTheque with Sonar 2.0.\nAt first view, there is not a lot of changes with this new version, but the main view has been a little improved and the new analysis are good. Now you've metrics about your design and about the dependencies to cut to make your design better. They added a good dependency matrix to each project.\nThis version works well like the older. The only things to pay attention for the update is the long time the database upgrade takes.\nI've also updated Hudson to the last version and also migrated it to my Tomcat 6.0.", 
      "tags": "Java,JTheque,Sonar"
    }, 
    {
      "loc": "/posts/2010/05/ubuntu-lucid-lynx-buttons-right.html", 
      "title": "Ubuntu Lucid Lynx Tip : Put the window buttons to the right", 
      "text": "In Ubuntu 10.04 (Lucid Lynx), the window buttons (minimize, maximize and close) are by default at the left of the window title like in Mac.\nThis is really disappoiting when you upgrade from an older version of Ubuntu to this one.\nBut it's really simple to solve that problem.\nOpen a terminal and type this command :\ngconf-editor\n\nAnd then go to : apps > metacity > general. You'll see here a key named button_layout with the default value of \"close,minimize,maximize:\". To put the buttons like in the other versions, you just have to edit this value to\n:minimize,maximize,close\n\nAnd then all your windows \u00a0will have the normal button order at the right of the window title bar.\nIf you want to include the window menu, you can change the value to :\nmenu:minimize,maximize,close\n\nAnd you will the menu at the left before the title.", 
      "tags": "Linux,Tips"
    }, 
    {
      "loc": "/posts/2010/04/ubuntu-lucid-lynx-10-04.html", 
      "title": "Ubuntu Lucid Lynx (10.04) is here !", 
      "text": "Update 1 : Sadly, the released has been delayed due to a bug in the GRUB bootloader. With this Bug, Grub display only Ubuntu when you're in a multi-boot system. To make the new release faster, they decided to respin only the Ubuntu 32/64 bit desktop CDs and the Ubuntu Netbook Edition. Normally these versions will be available later today, but perhaps tomorrow. The others versions will follow later.\nUpdate 2 : Finally the download is available :)\nThe new version of Ubuntu at just been released today : Ubuntu Lucid Lynx 10.04\nThis version is a LTS (Long Term Support) version. So you've three years of technical support for the Desktop version and five years for the Server.\nSo here are the main news of Lucid Lynx :\n\n\nNew default themes\n\nIn this version, you'll find two new main themes by default : Ambiance (Black) and Radiance (White). The colors are darker than the older versions but have light effects to shade a few the colors. The chosen icons are those of the Ubuntu-Mono theme. And the buttons are by default on the left of the window, but you can override that property in Gnome Configuration and each theme can choose where to put the buttons.\n\n\nImproved boot time\n\nThe objective for this version was to boot the system in less than 10 seconds on a Dell Mini 10 (netbook with 1.6 GHz processor and SSD Hard Disk). This objective has been achieved.\nFor a computer with a normal Hard Disk a and good processor the boot time has been divided by three. So it's a really good improvements I think.\nGnome 2.30\n\nLucid Lynx is provided with the last version of Gnome. This new version has not a lot of new functionalities, but prepare the ground for Gnome 3. This new version of Gnome include a shared display for Nautilus to easily make copy from a folder to another by example.\nMeMenu\n\nWith this new version, we'll have a new menu to replace the current user menu. This new menu (the MeMenu) is directly integrated with the social networks. So you can change your social status, go directly to microblogging, open Ubuntu One and see your avatar.\nApplications\n\nThis version integrates new applications and updates of the actual applications :\n\n    Gwibber is now installed by default. It's a microblogging platform. It's compatible with Twitter, Flickr, StatusNet, Facebook, Digg, FriendFeed, Brightkite, OCS Inventory and Qaiku.\n    With PiTiVi, you can now make basic video editing (mount images, audio sequences and video sequences).\n    OpenOffice.Org has been updated from 3.1 to 3.2\n    Ubuntu One Music Store allows you to buy music online for the Ubuntu One account.\n    Firefox has been updated to 3.6\n    Simple Scan enables you to make scan easily than with the old XScane\n    The gimp has been deleted from the default distribution\n\n\nLinux 2.6.32 Kernel\n\nThis new kernel is mostly axed on performance improvements. The time to write to disks has also been improved.\nSo here are the main feature of this new version. Of course, there is also a lot of others improvements, bug fixes, ...\nYou can download this new version on the official site.", 
      "tags": "Linux,Releases"
    }, 
    {
      "loc": "/posts/2010/04/closest-pair-of-point-plane-sweep-algorithm.html", 
      "title": "Find closest pair of point with Plane Sweep Algorithm in O(n ln n)", 
      "text": "Finding the closest pair of Point in a given collection of points is a standard problem in computational geometry. In this article I'll explain an efficient algorithm using plane sweep, compare it to the naive implementation and discuss its complexity.\n\n\nThis problem is standard, but not really easy to solve in an efficient way. The first implementation we think of is the naive one, comparing each point to each other point.\nIn my examples, I'll use the java.awt.Point class to represent a point. This naive implementation is really easy to implement :\npublic static Point[] naiveClosestPair(Point[] points) {\n    double min = Double.MAX_VALUE;\n\n    Point[] closestPair = new Point[2];\n\n    for (Point p1 : points) {\n        for (Point p2 : points) {\n            if (p1 != p2) {\n                double dist = p1.distance(p2);\n\n                if (dist < min) {\n                    min = dist;\n\n                    closestPair[0] = p1;\n                    closestPair[1] = p2;\n                }\n            }\n        }\n    }\n\n    return closestPair;\n}\n\n\n\nAs you can directly see, this naive implementation has a complexity of O(n2). But we can do a lot better using a plane sweep algorithm.\nWith that algorithm, we'll sweep the plane from left to right (right to left is also a possibility) and when we reach a point we'll compute all the interesting candidates (the candidates that can be in the closest pair).\nFor that we'll make the following operations :\n\n    We sort the list of points from left to right in the x axis\n    And then for each point :\n\n    We remove from the candidates all the point that are further in x axis that the current min distance\n    We take all the candidates that are located more or less current min distance from the current point in y axis\n    We test for the min distance all the founded candidates with the current point\n    And finally we add the current point to the list of candidates\n\n\n\n\nSo when we found a new min distance, we can make the rectangle of candidates smaller in the x axis and smaller in the y axis. So we made a lot less comparisons between the points.\nHere is a picture illustrating that :\n\nThe red points are the closest pair at this time of the algorithm. The red rectangle is the rectangle of the candidates delimited in right by the current point. And the yellow rectangle contains only the candidates interesting for the current point.\nThere is always a maximum of 6 points in the yellow rectangle, the 4 vertices, the point with the same coordinates as the current point and finally the point in the same y coordinate and in the limit of the x axis. Even if the maximum is 6, you'll almost never have more than 2 points in that list (the maximum is see in my test was 3 with a collection of 1'000'000 random points). You can see this 6 points here :\n\nIf all that stuff is not really clear for you, you can watch it in action here in a Java applet.\nThe candidates must also be always sorted. For that, we'll use a Binary Search Tree for good performances.\nIf we look at the complexity :\n\n    Sorting all the points in right axis : Cost O(n ln n) with Quick Sort by example\n    Shrinking the list of candidates take O(n) from start to end of the algorithm because we add n points to the candidates and we can remove only n points. So this is constant for each point : O(1).\n    Searching all the candidates between two values in y axis cost O(ln n) with binary search\n    The comparisons with at maximum 6 points are made in O(1)\n    Add the candidates and keep the list of candidates sorted cost O(ln n).\n\n\nSo the total complexity is O(n ln(n) + n * ( 1 + ln(n) + 1 + ln(n) ) ) = O(n ln n).\nSo it's really better than O(n2) for the naive implementation.\nSo now, we can go to the implementation in Java.\npublic static Point[] closestPair(Point[] points) {\n    Point[] closestPair = new Point[2];\n\n    //When we start the min distance is the infinity\n    double crtMinDist = Double.POSITIVE_INFINITY;\n\n    //Get the points and sort them\n    Point[] sorted = Arrays.copyOf(points, points.length);\n    Arrays.sort(sorted, HORIZONTAL_COMPARATOR);\n\n    //When we start the left most candidate is the first one\n    int leftMostCandidateIndex = 0;\n\n    //Vertically sorted set of candidates\n    SortedSet<Point> candidates = new TreeSet<Point>(VERTICAL_COMPARATOR);\n\n    //For each point from left to right\n    for (Point current : sorted) {\n        //Shrink the candidates\n        while (current.x - sorted[leftMostCandidateIndex].x &amp;gt; crtMinDist) {\n            candidates.remove(sorted[leftMostCandidateIndex]);\n            leftMostCandidateIndex++;\n        }\n\n        //Compute the y head and the y tail of the candidates set\n        Point head = new Point(current.x, (int) (current.y - crtMinDist));\n        Point tail = new Point(current.x, (int) (current.y + crtMinDist));\n\n        //We take only the interesting candidates in the y axis\n        for (Point point : candidates.subSet(head, tail)) {\n            double distance = current.distance(point);\n\n            //Simple min computation\n            if (distance < crtMinDist) {\n                crtMinDist = distance;\n\n                closestPair[0] = current;\n                closestPair[1] = point;\n            }\n        }\n\n        //The current point is now a candidate\n        candidates.add(current);\n    }\n\n    return closestPair;\n}\n\n\n\nThe code isn't overcomplicated. We see all the steps explained in the article and that works well. The Horizontal and Vertical comparators are really simple : \nprivate static final Comparator<Point> VERTICAL_COMPARATOR = new Comparator<Point>() {\n    @Override\n    public int compare(Point a, Point b) {\n        if (a.y < b.y) {\n            return -1;\n        }\n        if (a.y > b.y) {\n            return 1;\n        }\n        if (a.x < b.x) {\n            return -1;\n        }\n        if (a.x > b.x) {\n            return 1;\n        }\n        return 0;\n    }\n};\n\nprivate static final Comparator<Point> HORIZONTAL_COMPARATOR = new Comparator<Point>() {\n    @Override\n    public int compare(Point a, Point b) {\n        if (a.x < b.x) {\n            return -1;\n        }\n        if (a.x > b.x) {\n            return 1;\n        }\n        if (a.y < b.y) {\n            return -1;\n        }\n        if (a.y > b.y) {\n            return 1;\n        }\n        return 0;\n    }\n}\n\n\n\nHere is a performance comparison for some sizes with a Benchmark Framework I described here for some sizes of collection points.\n\n\n\n \nNaive\nSweeping\n\n\n100\n189.923 us\n53.685 us\n\n\n500\n4.448 ms\n279.042 us\n\n\n1000\n17.790 ms\n556.731 us\n\n\n5000\n458.728 ms\n3.320 ms\n\n\n\n\nLike you can see, this is really better than the naive implementation. So we make a good job. But if we make one more test with 10 elements :\n\n\n\n \nNaive\nSweeping\n\n\n10\n1.932 us\n4.746 us\n\n\n\n\nNow our good sweeping algorithm is slower than the naive !\nWhen we think about that, we realize that it's logical. In fact we made a lot of computations before starting the algorithm like sorting the points, creating a list of candidantes, ... All that stuff is heavier than make n2 comparisons in little number. So what can we do to have good performances with small number of points ?\nIt's really easy to solve. We just have to found the number before which the naive algorithm is quicker than the sweeping and when the size of the points collection is smaller than this pivot number we use the naive implementation. On my computer I found that before 75 elements, the naive implementation was faster than the sweeping algorithm, so we can refactor our method :\npublic static Point[] closestPair(Point[] points) {\n    if(points.length < 75){\n        return naiveClosestPair(points);\n    }\n\n    //No changes\n}\n\n\n\nAnd we've good performances for little set of points :)\nSo our method is now complete. I hope you found that post interesting and that will be useful to someone.", 
      "tags": "Algorithm,Benchmarks,Conception,Java,Performances"
    }, 
    {
      "loc": "/posts/2010/04/write-corrects-benchmarks.html", 
      "title": "How to write correct benchmarks", 
      "text": "Several months ago, I wrote an article to compare the performances of short indexes for loops. I wrote that code to achieve my goal :\npackage com.wicht.old;\n\npublic class TestShortInt {\n    public static void main(String[] args){\n        long startTime = System.nanoTime();\n\n        int resultInt = 0;\n\n        for (int i = 0; i &amp;lt; 100000; i++){\n            for (int j = 0; j &amp;lt; 32760; j++){\n                resultInt += i * j;\n            }\n        }\n\n        System.out.println(\"Temp pour int : \" + (System.nanoTime() - startTime) / 1000000 + \" ms\");\n\n        startTime = System.nanoTime();\n\n        int resultShort = 0;\n\n        for (int k = 0; k &amp;lt; 100000; k++){\n            for (short f = 0; f &amp;lt; 32760; f++){\n                resultShort += k * f;\n            }\n        }\n\n        System.out.println(\"Temp pour short : \" + (System.nanoTime() - startTime) / 1000000 + \" ms\");\n\n        System.out.println(resultInt);\n        System.out.println(resultShort);\n    }\n}\n\n\n\nAnd i found as a result that short was two times slower than int and I was convinced of these results until a week ago.\nAt this time, a reader (Jean) criticized the results of my tests and gave me links to several articles about micro-benchmarking. I've read these articles and understand why my results were incorrect.\nIn fact, my test doesn't pay attention to several things that can change results of tests :\n\n    JVM warmup : Due to several parameters, the code is first often slow and becomes faster and faster when the execution time grows until it goes to steady-state.\n    Class loading : The first time you launch a benchmark, all the used classes must be loaded, increasing the execution time.\n    Just In Time Compiler : When the JVM identify a hot part of the code\n    Garbage Collector : A garbage collection can happen during the benchmark and with that the time can increase a lot.\n\n\nDue to all these factors, the first runs (perhaps 10 seconds of run) are slower than the other and than can make your benchmarks completely false.\nSo, how can we do to have good benchmarks results ?\nIt's really difficult, but we can have help using a benchmark framework introduced by Brent Boyer, a software developer from Elliptic Group. This framework take care of all the previously introduced factors and made good benchmarks.\nThe use of this framework is really simple, you just have to create a new instance of the Benchmark class passing to it a Callable or a Runnable and the test is directly launched. Here is the example with the test of short and int in loop indexes :\npublic class ShortIndexesLoop {\n    public static void main(String[] args) {\n        Callable callableInt = new Callable(){\n            public Long call() throws Exception {\n                long result = 0;\n\n                for (int f = 0; f &amp;lt; 32760; f++){\n                      result += 444;\n                  }\n\n                return result;\n            }\n        };\n\n        Callable callableShort = new Callable(){\n            public Long call() throws Exception {\n                long result = 0;\n\n                for (short f = 0; f &amp;lt; 32760; f++){\n                      result += 444;\n                  }\n\n                return result;\n            }\n        };\n\n        try {\n            Benchmark intBenchmark = new Benchmark(callableInt);\n\n            System.out.println(\"Result with int \");\n            System.out.println(intBenchmark.toString());\n\n            Benchmark shortBenchmark = new Benchmark(callableShort);\n\n            System.out.println(\"Result short \");\n            System.out.println(shortBenchmark.toString());\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n    }\n}\n\n\n\nTo get the results, you can use Benchmark.toString() or Benchmark.toStringFull() for more statistics. You can also directly access some stats like standard deviation using Benchmark.getSd() or directly with Benchmark.getStats() to get all the stats.\nHere is the result with the preceding code :\nResult int\nfirst = 807.056 us, mean = 46.032 us (CI deltas: -261.393 ns, +408.932 ns), sd = 230.929 us (CI deltas: -68.201 us, +105.262 us)\nResult short\nfirst = 721.912 us, mean = 48.234 us (CI deltas: -198.625 ns, +254.774 ns), sd = 160.196 us (CI deltas: -32.764 us, +37.882 us)\n\nAs you can see, the short version is only 104.78% slower than the int. That show that the first results were completely false.\nHere is the full results of the int version :\naction statistics: first = 807.056 us, mean = 46.032 us (CI deltas: -261.393 ns, +408.932 ns), sd = 230.929 us (CI deltas: -68.201 us, +105.262 us) WARNING: EXECUTION TIMES HAVE EXTREME OUTLIERS, SD VALUES MAY BE INACCURATE\n    ----------\n    --the action statistics were calculated from block statistics\n    --each block measured 32768 task executions\n    --the user says that task internally performs m = 1 actions\n    --then the number of actions per block measurement is a = 32768\n    --block statistics: mean = 1.508 s (CI deltas: -8.565 ms, +13.400 ms), sd = 41.803 ms (CI deltas: -12.346 ms, +19.054 ms)\n    --the forumla used to convert block statistics to action statistics (mean scales as 1/a, sd scales as 1/sqrt(a)) assumes that the action execution times are iid\n    ----------\n    --each confidence interval (CI) is reported as either +- deltas from the point estimate, or as a closed interval ([x, y])\n    --each confidence interval has confidence level = 0.95\n    ----------\n    --EXECUTION TIMES APPEAR TO HAVE OUTLIERS\n    --this was determined using the boxplot algorithm with median = 1.498 s, interquantileRange = 34.127 ms\n    --3 are EXTREME (on the high side): #57 = 1.621 s, #58 = 1.647 s, #59 = 1.688 s\n    --2 are mild (on the high side): #55 = 1.570 s, #56 = 1.582 s\n    ----------\n    --block sd values MAY NOT REFLECT TASK'S INTRINSIC VARIATION\n    --guesstimate: environmental noise explains at least 55.89418621876822% of the measured sd\n    ----------\n    --action sd values ALMOST CERTAINLY GROSSLY INFLATED by outliers\n    --they cause at least 98.95646276911543% of the measured VARIANCE according to a equi-valued outlier model\n    --model quantities: a = 32768.0, muB = 1.5083895562166663, sigmaB = 0.04180264914581472, muA = 4.603239612477619E-5, sigmaA = 2.3092919283255957E-4, tMin = 0.0, muGMin = 2.3016198062388096E-5, sigmaG = 5.754049515597024E-6, cMax1 = 1252, cMax2 = 322, cMax = 322, cOutMin = 322, varOutMin = 0.0017292260645147487, muG(cOutMin) = 2.3034259031465023E-5, U(cOutMin) = 0.002363416110812895\n\nLike you can perhaps see when you use this framework, it gives you some warnings when by example you have extreme outliers that can make the standard deviation completely false.\nYou can download this framework on the web page of the Elliptic Group. I found it really powerful and easy to use and I'll use it everytime I have to do a benchmark.\nTo conclude, I must also say that even if you use that kind of framework, you can make very bad benchmarks if you don't test the right part of the code. Here are two really interesting articles from Brent Boyer :\n\n    Robust Java benchmarking, Part 1: Issues\n    Robust Java benchmarking, Part 2: Statistics and solutions", 
      "tags": "Benchmarks,Java,Libraries,Performances,Tools"
    }, 
    {
      "loc": "/posts/2010/04/maven-3-0-beta-1-is-here.html", 
      "title": "Maven 3.0 Beta 1 is here !", 
      "text": "The Maven team has just announced the release of Maven 3.0-beta-1.\nThere is still several things to do for the final releases, but Maven 3 is now ready to go from Alpha to Beta.\nIf you're interested on migrating to this new version, you should have a look at this page from the Maven site : Maven 3 Compatibility Notes. This page lists all the known differences between Maven 2 and Maven 3 for compatibility purpose.\nSome news of Maven 3 :\n\n    Complete Kernel Rewriting\n    New languages for POM : YAML and Groovy\n    POM Composition\n    Extensibility : Easier to create plugins extending an other plugin\n    Create the build at start and not step by step\n    Mercury for repositories and dependencies access\n    Maven Shell : Shell environment to execute Maven commands\n\n\nYou can download it here.", 
      "tags": "Apache,Java,Maven,Releases,Tools"
    }, 
    {
      "loc": "/posts/2010/04/jetbrains-released-intellij-idea-9-0-2.html", 
      "title": "JetBrains has released IntelliJ IDEA 9.0.2", 
      "text": "IntelliJ Idea 9.0.2 has just been released. \nThis version includes these new features and improvements : \n\n    View vertical indent guides\n    New action \"Show in Explorer\" from the contextual menu\n    The detection of the necessity of rebuild project indexes has been improved\n    Some code samples have been added for Java, JavaScript and PHP\n    The source can be directly attached to decompiled class file from the edit window\n    The Java debugger supports autoboxing\n    A diff tool for UML\n    New consoles for SQL and HQL\n    Improvements of the Spring configuration file editor view\n    Improvements of the remote projects support\n    Stacktrace folding for Groovy code\n    Support of GWT 2.0 UIBinder\n    Package Adobe AIR applications\n    Better support of CSS3\n    Tracking of Grails 1.2 Ivy dependencies\n    Flex\n\n    Live templates for Flex\n    Parralel compilation of indenpendent Flex modules\n\n\n\n    PHP\n\n    New options for code style programming\n    New inspections\n    New quickfixes and intentions\n\n\n\n\n\nYou can view the complete release notes \u00a0of this new version.\nThere is no great new features, but the bug fixes and little enhancements make that version really interesting (like all new versions of IntelliJ IDEA).", 
      "tags": "IntelliJ Idea,Java,Releases,Tools"
    }, 
    {
      "loc": "/posts/2010/04/java-7-new-io-features-asynchronous-operations-multicasting-random-access-with-jsr-203-nio-2.html", 
      "title": "Java 7 : New I/O features (Asynchronous operations, multicasting, random access) with JSR 203 (NIO.2)", 
      "text": "Like I've said in other post, we will have a new API to access File System in Java 7, but we'll have several others new features in NIO.2 that I've not covered\nSo I'll try to cover them in that post. Indeed the JSR 203 (also known as NIO.2) add several new classes that improve I/O code.\nIn this post I cover the following features :\n\n    SeekableByteChannel : A random access channel\n    MulticastChannel : A channel that allow for IP multicasting\n    NetworkChannel : The new super interface for the network-oriented channels\n    Asynchronous I/O API : The new API to make I/O operations in an asynchronous way.\n\n\n\n\nSeekableByteChannel\nFirst of all, the Java 7 includes a new ByteChannel, the SeekableByteChannel. This Channel maintains a current position, so you can read and write from this position. That allows random access positions. With that type of Channel, you can even add several threads reading/writing the same threads at different positions.\nSeekableByteChannel channel1 = Paths.get(\"Path to file\").newByteChannel(); //Simply READ\nSeekableByteChannel channel2 = Paths.get(\"Path to file\").newByteChannel(StandardOpenOption.READ, StandardOpenOption.WRITE); //READ and WRITE\n\n\n\nYou can use these methods to manipulate the positions and size of the channel :\n\n    long position() : Return the current position\n    long size() : Return the current size of the entity this channel is connected to, by example the size of the file the channel is connecting to\n    position(long newPosition) : Move the current position to the given one\n    truncate(long size) : Truncates the entity to the given size.\n\n\nThe position() and truncate() methods simply returns the current Channel to allow chained invocations.\nNow, FileChannel implements this new interface, so you can make random access with all FileChannels.\nYou can of course read a file with that channel :\nSeekableByteChannel channel = null;\n\ntry {\n    channel = Paths.get(\"Path to file\").newByteChannel(StandardOpenOption.READ);\n    ByteBuffer buffer = ByteBuffer.allocate(4096);\n\n    System.out.println(\"File size: \" + channel.size());\n\n    while (channel.read(buffer) &amp;gt; 0) {\n        buffer.rewind();\n\n        System.out.print(new String(buffer.array(), 0, buffer.remaining()));\n\n        buffer.flip();\n\n        System.out.println(\"Current position : \" + channel.position());\n    }\n} catch (IOException e) {\n    System.out.println(\"Expection when reading : \" + e.getMessage());\n    e.printStackTrace();\n} finally {\n    if (sbc != null){\n        channel.close();\n    }\n}\n\n\n\nMulticastChannel\n\nThis new interface enable to make Internet Protocol (IP) Multicasting. So you can send and receive IP datagrams from a complete group. The multicast implementations are directly bind to the native multicast facility. This interface is implement by DatagramChannel and AsynchronousDatagramChannel.\nA simple example taken from the Javadoc to open a DatagramChannel t :\nNetworkInterface networkInterface = NetworkInterface.getByName(\"hme0\");\n\nDatagramChannel dc = DatagramChannel.open(StandardProtocolFamily.INET)\n         .setOption(StandardSocketOption.SO_REUSEADDR, true)\n         .bind(new InetSocketAddress(5000))\n         .setOption(StandardSocketOption.IP_MULTICAST_IF, networkInterface);\n\nInetAddress group = InetAddress.getByName(\"225.4.5.6\");\n\nMembershipKey key = dc.join(group, networkInterface);\n\n\n\nWith that, you can use your DatagramChannel as all others DatagramChannel you used in the past, but the operations are made with multicast, so you receive all the packets of the interface and you send packets to all the group.\nNetworkChannel\n\nNow, all the network-oriented channels implements the new NetworkChannel interface. With that, you easily bind the channel socket, set and query for socket options. Furthermore, the socket optioins are now extensible, so you can use operating system specific options, that could be interesting for high performances servers.\nAsynchronous I/O\n\nAnd after that little introduction, we go to the main new feature : The new Asynchronous I/O API. Its name indicate all the purpose of this new features, indeed enable Asynchronous I/O operations.This new channels provide asynchronous operations for both sockets and files.\nOf course, all that operations are non-blocking, but there is also blocking operations that you can do with all the asynchronous channels.\nAll the asynchronous I/O operations have one of two forms :\n\n    The first one returns a java.util.concurrent.Future that represent the pending result. You can use that Future to wait for the I/O operations to finish.\n    The second one is created using \u00a0a CompletionHandler. That handler is invoked when the operation is has completed, like callbacks systems.\n\n\nSo here are the examples of the two forms :\nThe first form, using Future :\nAsynchronousFileChannel channel =\u00a0AsynchronousFileChannel.open(Paths.get(\"Path to file\"));\nByteBuffer buffer = ByteBuffer.allocate(capacity);\nFuture result = channel.read(buffer, 100); //Read capacity bytes from the file starting at position 100\nboolean done = result.isDone(); //Indicate if the result is already terminated&lt;/pre&gt;\n\n\n\nYou can also wait for completion :\nint bytesRead = result.get();\n\n\n\nOr wait with a timeout :\nint bytesRead = result.get(10, TimeUnit.SECONDS); //Wait at most 10 seconds on the result\n\n\n\nThe second form, using CompletionHandler :\nFuture result = channel.read(buffer, 100, null, new CompletionHandler(){\n    public void completed(Integer result, Object attachement){\n        //Compute the result\n    }\n\n    public void failed(Throwable exception, Object attachement){\n        //Answer to the fail\n    }\n}\n\n\n\nAs you can see, you can give an attachement to the operation. This attachement is given to the CompletionHandler at the end of the operation. You can give null as attachement with no problem. But you can pass anything you want, like the Connection for a AsynchronousSocketChannel or the ByteBuffer for our read :\nFuture result = channel.read(buffer, 100, buffer, new CompletionHandler(){\n    public void completed(Integer result, ByteBuffer buffer){\n        //Compute the result\n    }\n\n    public void failed(Throwable exception, ByteBuffer buffer){\n        //Answer to the fail\n    }\n}\n\n\n\nAnd as you can see, the form with the CompletionHandle gives also you a Future element representing the pending result, so you can merge the two forms.\nHere, are all the asynchronous channels available in NIO.2 :\n\n    AsynchronousFileChannel : An asynchronous channel for reading and writing from and to a file. This channel has no global positions, so each read/write operations needs a position to operate. You can access concurrently to different parts of the file using different threads. You have to specify the options (READ, WRITE, but not APPEND) when you open this channel.\n    AsynchronousSocketChannel : A simple asynchronous channel to a Socket. The connect, read/write and scatter/gather methods are all asynchronous. The read/write method supports timeouts.\n    AsynchronousServerSocketChannel : An asynchronous channel to a ServerSocket. The accept() method is asynchronous and the CompletionHandler is called when a connection has been accepted. The result of this kind of connection is an AsynchronousSocketChannel.\n    AsynchronousDatagramChannel :\n\n\nAn channel to datagram-oriented socket. The read/write (connected) and receive/send (unconnected) methods are asynchronous.\nGroups\n\nWhen you use AsynchronousChannels, there is of course threads that invoke the completion handlers. These threads are bound to an AsynchronousChannelGroup. This group contains a thread pool and encapsulates the resources shared by all the threads working for the channels. You can greate these groups using thread pool. The AsynchronousFileChannel can be created with its own group, passing an ExecutorService as argument to the open() method. The channels are created using an AsynchronousChannelGroup in the open method, if you don't give it a group or you pass null, the default group is used. The channel is said to be owned by the group, so, if the group is closed, the channel is closed too.\nYou can create a group with a ThreadFactory :\nThreadFactory myThreadFactory = Executors.defaultThreadFactory();\nAsynchronousChannelGroup channelGroup = AsynchronousChannelGroup.withFixedThreadPool(25, myThreadFactory);\n\n\n\nOr with an ExecutorService :\nExecutorService service = Executors.newFixedThreadPool(25);\nAsynchronousChannelGroup channelGroup = AsynchronousChannelGroup.withThreadPool(service);\n\n\n\nAnd you easily use it :\nAsynchronousSocketChannel socketChannel = AsynchronousSocketChannel.open(channelGroup);\n\n\n\nYou can close the group using the shutdown() method on the group. After that, you cannot create more channels using this group and the group effectively terminates when all the channels are closed, the completion handlers terminated and the resources released.\nYou must give attention to a points when you use any type of pools and CompletionHandler : DO NOT USE blocking or long operation inside a CompletionHandler. That can block the entire application if all the threads are blocking. If you've custom or cached thread pool, that can make the queue growing infinitely and cause OutOfMemoryError.\nI think (and I hope), I've covered the main news from this new Asynchronous I/O API. This is not simple stuff of course and that will not be used by every one but that can be useful in several cases and it's a good thing that Java will have this kind of I/O. I therefore apologize if I made some errors in my code or my explanations, is not a easy subject and I tried to explain it for everyone.\nYou have also others informations in the overview of Asynchronous I/O at JavaOne 2009, by Alan Bateman and Jean-Fran\u00e7ois Arcand.", 
      "tags": "I/O,Java,Java 7,Performances"
    }, 
    {
      "loc": "/posts/2010/04/links-of-the-week-3.html", 
      "title": "Links of the week (April 20)", 
      "text": "Some interesting links of the week:\n\n    Poll Results: We're Not Quite Ready For Web Based IDEs : Interesting poll results on how the developers are ready about web based IDEs\n    How to localise a Play Framework application : Peter Hilton explain how internationalize a Play! Framework application\n    The Top 15 Google Products for People Who Build Websites \n    Swinging Task Dialog (part 5) : Eugene Ryzhikov continue its suite on developing a Swing Task Dialog, adding new functionaly. \n    How to determine a prime number in Java : An interesting development on how to determine a prime number in an efficent way", 
      "tags": "Google,Java,Links,Performances,Play!,Swing,Tools,Web"
    }, 
    {
      "loc": "/posts/2010/04/using-substance-look-and-feel-in-osgi.html", 
      "title": "Using Substance Look And Feel in OSGi", 
      "text": "I experienced some problems with Substance in OSGi. Using this code :\nSubstanceLookAndFeel.setSkin(new BusinessBlackSteelSkin());\n\n\n\nI got different errors, like :\nException in thread \"AWT-EventQueue-0\" java.lang.NullPointerException at \norg.pushingpixels.substance.internal.utils.SubstanceColorUtilities.getDefaultBackgroundColor(SubstanceColorUtilities.java:823)\n\nI found a simple solution to make Substance work in OSGi : \ntry {\n      UIManager.setLookAndFeel(new SubstanceBusinessBlackSteelLookAndFeel());\n} catch (UnsupportedLookAndFeelException e) {\n      LoggerFactory.getLogger(getClass()).error(e.getMessage(), e);\n}\nUIManager.getLookAndFeelDefaults().put(\"ClassLoader\", SubstanceBusinessBlackSteelLookAndFeel.class.getClassLoader());\n\n\n\nWith that code, i've no more problems using Substance Look And Feel. \nHope that will help someone.", 
      "tags": "OSGi,Swing"
    }, 
    {
      "loc": "/posts/2010/04/java-7-updates-project-coin.html", 
      "title": "Java 7 : Languages updates from Project Coin", 
      "text": "I continue my posts on the new features of Java 7. In this post, I'll detail the news coming from the Project Coin. This project has computed more than 70 new features proposal from the Java community for integration in Java 7.\nIn this post, I'll detail the Final Five (or So) features\u00a0chosen\u00a0from this project to be included in Java 7.\nDiamond Syntax\n\nThis feature is a really simple syntax improvement for generics. With that feature, you can avoid to write twice the generics type in a generics declaration. A little  example :\nInstead of writing this :\nMap<String, Collection<Integer>> map = new LinkedHashMap<String, Collection<Integer>>();\n\n\n\nYou can now write that :\nMap<String, Collection<Integer>> map = new LinkedHashMap<>();\n\n\n\nThat's really practical, but not essential.\nSimplified Varargs Method Invocation\n\nThis improvement is not a new functionality, but only a move of a warning. Like you must know, we cannot create arrray of generics type because the type verification is not made at the same time. But with the Ellipse of Java 5, you can made that type of array implicitely and the compiler generate warning at each invocation of that kind of method, so the warning has moved to the method declaration to have less warnings.\nIntegers declaration\n\nYou'll can declare integers using binary values :\nint binary = 0b11001001001;\n\n\n\nand you can use _ (underscores) in the declaration :\ndouble amount = 1_999_888_777.25;\nint color = 0xdd_dd_dd;\nint binary = 0b110_0100_1001;\n\n\n\nThat's allow to make more verbose code, but it's only sugar.\nCollections manipulations and declaration\n\nAnother improvements to code verbosity, is the support of collections in the language. You'll have code facility to access and edit indexed collections like list and maps and to declare easily collections.\nFirst, you can access to an element using the same syntax as the array :\nList<String> list = ...;\nMap<String, String> map = ...;\nString firstValue = list[0];\nmap[\"Test\"] = firstValue;\nString valueFromMap = map[\"Test\"];\n\n\n\nFor the maps, that works with any type of key. So if you have one of your class for key, you can directly pass it in the code like the Strings in my example.\nAnd, you can also quickly declare collections like array :\nLists with [] :\nList<Integer> numbers = [ 1, 2, 4, 8, 16, 32, 64, 128 ];\n\n\n\nSets with {}\nSet<Integer> numbers = { 256, 512, 1024, 2048, 4096 };\n\n\n\nAnd Maps with {} and : to split value and key :\nMap<String, String> translations = {\n  \"Hi\" : \"Bonjour\",\n  \"Goodbye\" : \"Au revoir\",\n  \"Thanks\" : \"Merci\"\n} \n\n\n\nAll that created collections are immutables.\nStrings switch\n\nA really good feature : Switch with Strings values. You can now do that kind of switch : \u00a8\nString value = \"\";\n\nswitch (language) {\n  case \"fr\":\n    value = \"Bonjour\";\n    break;\n  case \"en\":\n    value = \"Hi\";\n    break;\n  case \"de\":\n    value = \"Guten tag\";\n    break;\n  default:\n    value = \"Hello\";\n    break;\n}\n\n\n\nI thinks, it's really great. With that, we can delete a lot of ugly list of if/else if code.\nAutomatic Resource Management (ARM)\n\nAnother great feature, you can automatically close the resources using a new try clause :\npublic void write(URL url, File file) throws IOException {\n  try ( FileOutputStream fos = new FileOutputStream(file); InputStream is = url.openStream() ) {\n    byte[] buf = new byte[2048];\n    int len;\n    while ((len = is.read(buf)) &amp;gt; 0) {\n      fos.write(buf, 0, len);\n    }\n}\n\n\n\nIn that code, the FileOutputStream and the InputStream will automatically be closed after the try, making a cleared code and you cannot forgot a resource with that.\nAnd last, the modifications to support the JSR 292 directly in the language. I've already described that features in other post : Java 7 : More Dynamics\nThat's all for these new language enhancements from the Project Coin.\nFor me, i like the new ARM and the Strings Switch, but i think this is simple enhancements, they were others proposals in the Project Coin i found better, like the \"Improved Exception Handling for Java\", \"Improved Wildcard Syntax for Java\" or \"Elvis and Other Null-Safe Operators\", but this a good start.", 
      "tags": "Java,Java 7"
    }, 
    {
      "loc": "/posts/2010/04/jtheque-problems-migrating-osgi.html", 
      "title": "JTheque : Problems when migrating to OSGi", 
      "text": "Like you perhaps know, i'm currently migrating JTheque to OSGi. During this migration i found several problems in the JTheque architecture that made the migration impossible without changing some concepts. In this post I'll detail all the problems I found.\nResources\n\nFirst of all, i had to completely change the way to cache resources. Before, i used a ResourceManager to cache images/icons. To get an image/icon, i gave to it the path to the resource and the manager made the rest. I used Spring to load the resources (using the Resource class). That worked well because all the modules and the core were in the same application context.\nBut now, there is an application context for each OSGi bundle, so that doesn't work at all. So i had to find an other way. The manager cannot load the resources because they're accessible from the other bundles. So I changes the way the manager works :\n\n    The modules must register all the resources they need in the resource manager. They can always use Spring to load the resource or direct use the Resource class to load it.\n    When the module need an image/icon, it ask the resource manager. The manager watch on the cache (the cache associates the Resource to the loaded image/icon) if the image is already cached. If it's cached, it directly return the image else, it load the image from the resource and return the loaded image\n\n\nIn that way, the resource manager doesn't have to access directly to resources on other bundles and everything works well.\nStates\n\nThe states are a way to store configuration for the modules. Before, the states must implements an interface and when they we're saved, the class were saved in a file and at startup created by reflection. But that's was not possible anymore, because the class was not accessible from the state bundle.\nSo I changed the way the data were saved using directly methods of the interface to get the stored data and to restore them at startup. Moreover, I also replaced the interface by annotations.\nMiscellaneous\n\nMore than these other major changes, i've also some others problems :\n\n    The JDBC driver class was not accessible. I add the package import to the manifest headers and get the driver version from SpringSource Repository to works with OSGi\n    Substance doesn't work anymore. At this time, i don't know i that comes from OSGi or from other changes i made in the application, but i've not solved this problem.", 
      "tags": "Conception,JTheque,OSGi"
    }, 
    {
      "loc": "/posts/2010/04/10-most-useful-google-tools.html", 
      "title": "10 most useful Google Tools", 
      "text": "More than provide an extremely powerful search engine used by almost everybody, Google provides also a lot of very useful tools. In this post, i list the 10 most useful Google tools from my point of view.\n1. Gmail\n\nFor me, this is the best email client ever. The interface is quick and reactive and there are many interesting features. The spam filter is really powerful, i have no more spams since i've switched to GMail a long time ago. The storage capacity (~7.4 Go) is also totally enough. Moreover, this client is totally integrated with the other tools of the Google network (Documents, Buzz, Agenda, ...). With the plugins, you can also add several others features to GMail including integrating with other tools like RememberTheMilk by example.\nThe included chat is also a great functionality. I use it everyday.\nNo more spam with : Google Mail\n\n\n2. Google Chrome\n\nCertainly the most efficient browser. The performances of this browser are simply amazing.\nThere are perhaps less plugins now that in Firefox, but it's a lot more lighter than the others browsers. \u00a0The tab system is really well done. If a site crashes, you can simply close the tabs ands that's fine. You can also move a tab to an other window with drag&drop facilities.\nIn the last months, the number of modules tend to grow quickly and provides the more useful plugins that we could have used in other browsers before switching to Chrome. And Google Chrome support without plugins the synchronization of bookmarks and execution of GreaseMonkey scripts.\nAnd last but not least, this is the most simplistic (not pejorative at all) browser i use and really easy and\u00a0comfortable\u00a0to use.\nTry it and why not like it : Google Chrome\n3. Google Analytics\n\nGoogle Analytics is a really great web analytics solution. This is the most used solution. This tool is free for website with less than 5 million page views by month or for those who have an AdWords account. The interface is really simple to use but powerful. All the stats are displayed with number metrics and graphs. And, really important, the traffic analyzer is powerful and light. You can even use an asynchronous\u00a0JavaScript\u00a0code to produce less overhead on the page load time.\nYou can create scheduled reports and email it at a specific time rate. You can also analyze only a fragment of the traffic and follow accomplishments of objectives. You can also use Google Analytics from other\u00a0languages like PHP.\nFor me, as a webmaster, this tool is completely essential and I cannot live without it (exaggerate, but I use it everyday).\nIf you try it, you will not regret : Google Analytics\n4. Google Reader\n\nGoogle Reader is a web aggregator to read RSS and Atom. This web application can work in offline mode accessing all the previously downloaded articles.\nMore to be an aggregator, Google Reader has also social network features. In fact, you can share you\u00a0favorite\u00a0articles and comment them. You can\u00a0access\u00a0to the shared articles of your friends.\nYou can create folders to sort your\u00a0subscriptions\u00a0by theme (or any kind of sort you \u00a0like) and quickly find what's new in any folder. Google Reader can also give you a list of subscriptions take can interest you based on your current\u00a0subscriptions\u00a0themes.\nAggregate your RSS and Atom : Google Reader\n5. Google Webmaster Tools\n\nGoogle Webmaster Tools is an essential tools for all webmaster. With it, you can manage all your websites.\nFirst of all, you can verify how your site is referenced on Google Search Engine. You can see in which position you are for the most important query for your website. You can see which keywords are the significant for your pages, you can obtain the number of links pointing to your website and to which pages there is the more links. You can also notify Google for updates in your sitemaps. Your internal links are also displayed. You can even consult the Google Reader subcribers to your feeds.\nNext, you have also diagnostics about your site. The available diagnostics are the malware detected by the Google robots, crawl errors and crawl stats. Google Webmaster Tools give you some suggestions about your HTML pages.\nYou will love : Google Webmaster Tools\n6. Google Documents\n\nGoogle Documents is an online documents sharing application. In that application, you can create and share documents, presentation, spreadsheets, forms and drawings.\nMore than creating and editing the documents, you \u00a0can sharing them to anybody that have a Google Acount. The documents are saved by revisions and you can come back to an older revision or merge some revisions. This a really powerful feature when several persons work on the same documents.\nAll the type of documents can be edited in Wysiwyg way with powerful editors. You can also upload any files you want to your Google Documents account.\nTry : Google Documents\n7. Google Agenda\n\nGoogle Agenda is a simple tools to keep appointments in mind. You have recall for your events.\nYou can create events and share them to any other Google contacts.\nTake a look : Google Agenda\n8. Google Friend Connect\n\nGoogle Friend Connect is web tools to add social networking features to a website. You can create a community around your website. The visitors can register to your site with simple widgets and no registration using their Google, Facebook or OpenID accounts.\nYou can add a lot of widgets to your website, by example to give the users the possibility to rate your contact, ask questions to your visitors or send newsletters to them.\nGive it a try : Google Friend Connect\n9. Keyword Tool\n\nKeyword Tool is an application uuseful to get ideas of keywords for your website or to compare some keywords by Advertiser Competition and Search Volume. That can really help you to choose the keywords you will to\u00a0focus\u00a0on to improve the referencing of a website.\nYou can directly give a page of your website to the program. The page will be inspected for keywords and the tool will give you a list of keywords ideas based on the content of the site. Or you can give a list of keywords you're interested in and the program will compute a list of other keywords based on yours.\nI think it's an essential tool for all webmaster that like to improve its websites referencing.\nTry it : Google Adwords : Keyword Tool\n10. Google Language Tools\n\nGoogle Language Tools is a simple set of tools to translate text from a language to another. You have several choices : translate some search results, translate a complete web page or translate a given text. There is a lot of available languages. The page give also an access too Google Homepage in all languages. You can note that this tool is integrated with Google Chrome in which you can translate (automatically or manually) pages to your languages with actions in the browser.\nYes, this very simple, but that works well and that's really useful.\nTry it : Google Language Tools\nOf course, there is a lot of others powerful Google Tools. Here are only the \u00a0most useful from my point of view. Perhaps a photograph will like Picasa, an advertiser will like AdWords and AdSense and Android, Google Maps Navigation and Google SkyMap for a mobile user.", 
      "tags": "Google,Tools,Web"
    }, 
    {
      "loc": "/posts/2010/04/drag-and-drop-files-to-gmail.html", 
      "title": "Drag and drop files to Gmail", 
      "text": "The Gmail team has just added a great new functionality to Gmail.\nUntil now, to add attachment to your mails, you had to click \"Attach a file\", find the good file and click it.\nNow, you can directly drag the file from your file system to Gmail :\n\n\n\nIt's a little functionality, but that save a lot of time and that's the kind of feature we (computer scientist) love.\nTry it, that's awesome !", 
      "tags": "Google,Tools,Web"
    }, 
    {
      "loc": "/posts/2010/04/substance-6-0-is-out.html", 
      "title": "Substance 6.0 is out", 
      "text": "Kirill Grouchnikov has just announced the release of the final release of Substance 6.0. Substance is a really powerful look and feel for Java. This look and feel looks pretty good and is skinnable, you have several themes to apply to the look and feel to customize the\u00a0appearance\u00a0of your applications.\nThis version includes the following new features :\n\n    Multi-state animated transitions\n    New look for text components\n    Custom components states\n    Support for drop location\n\n\nThe deprecated APIs have been removed from this release. There is also revisited APIs that can break your code. The animations are now powered by Trident 1.2.\nMore information on the official announce.", 
      "tags": "Java,Releases,Swing"
    }, 
    {
      "loc": "/posts/2010/04/java-7-more-concurrency.html", 
      "title": "Java 7 : More concurrency", 
      "text": "With Java 7 (Dolphin), we'll have some concurrency and collections updates with the JSR166y, extension of the JSR166 of Doug Lea.\nIn this post, we'll see the most important news :\n\n    Fork/Join Framework\n    TrasnferQueue\n    ThreadLocalRandom\n\n\n\n\nFork/Join Framework\n\nThe most important improvement is a new Fork/Join Framework. Fork/Join is basically the parralel version of the divide-and-conquer algorithm resolution. Here is the typical form of that problems (taken from Doug Lea) :\nResult solve(Problem problem) {\n    if (problem is small)\n        directly solve problem\n    else {\n        split problem into independent parts\n        fork new subtasks to solve each part\n        join all subtasks\n        compose result from subresults\n    }\n}\n\n\n\nJava 7 provide a new class ForkJoinPool to run ForkJoinTask. A ForkJoinTask is lighter than a thread. If you have a lot of ForkJoinTask, you can host them with a smallest number of threads. Two implementations of ForkJoinTask are provided :\n\n    RecursiveAction : A recursive resultless ForkJoinTask\n    RecursiveTask : A recursive ForkJoinTask that return an object of type E\n\n\nOf course, you can also directly use the ForkJoinTask class but the recursive actions are enough in almost all the cases.\nFrom a ForkJoinTask you can invoke other task (fork them) using invokeAll methods.\nSo, now that we have covered the main concepts of this framework, we could start with a little example (directly taken from Javadoc build 87). We'll use divide and conquer to increment all the elements of an array. To know if the problem is small enough to solve it directly, we'll use a threshold representing the number of elements that we can increment directly. If we have more elements than the threshold, we will fork in two task otherwise, we'll compute directly the incrementation on the array. So here is our task :\npublic class IncrementTask extends RecursiveAction {\n   private final long[] array;\n   private final int low;\n   private final int high;\n\n   private static final int THRESHOLD = 5000;\n\n   public IncrementTask(long[] array, int low, int high) {\n      super();\n\n      this.array = array;\n      this.low = low;\n      this.high= high;\n   }\n\n   @Override\n   protected void compute() {\n      if (high - low < THRESHOLD) {\n           for (int i = low; i < high; ++i){\n              array[i]++;\n           }\n        } else {\n           int mid = (low + high) >>> 1;\n\n           invokeAll(new IncrementTask(array, low, mid), new IncrementTask(array, mid, high));\n      }\n   }\n}\n\n\n\nAnd you can launch that on an array using ForkJoinPool :\nRecursiveAction mainTask = new IncrementTask (anArray, 0, anArray.length);\nForkJoinPool mainPool = new ForkJoinPool();\nmainPool.invoke(mainTask\n\n\n\nAll the elements of the array will be incremented. Depending on the size of the array and of the threshold, the problem will be divided in several sub problems and all these task will be managed by the ForkJoinPool.\nYou can also make action that return something. By example, we can compute the sum of all the elements of an array :\npublic class SumTask extends RecursiveTask {\n   private final long[] array;\n   private final int low;\n   private final int high;\n\n   private static final int THRESHOLD = 5000;\n\n   public SumTask(long[] array, int low, int high) {\n      super();\n\n      this.array = array;\n      this.low = low;\n      this.high= high;\n   }\n\n   @Override\n   protected Long compute() {\n      if (high - low < THRESHOLD) {\n          long sum = 0;\n\n          for (int i = low; i < high; ++i){\n              sum += array[i];\n           }\n\n           return sum;\n       } else {\n           int mid = (low + high) >>> 1;\n\n          RecursiveTask left = new SumTask(array, low, mid);\n          RecursiveTask right = new SumTask(array, mid, high);\n\n          right.fork();\n\n          return left.compute() + right.join();\n      }\n   }\n}\n\n\n\nAnd you can use it like that :\nRecursiveTask sumTask = new SumTask(anArray, 0, anArray.length);\nForkJoinPool mainPool = new ForkJoinPool();\nLong sum = mainPool.invoke(sumTask);\n\n\n\nI think it's a clean way to solve big problems with divide-and-conquer.\nYou can also imagine others ways to divide the problems. An example is to compute the THRESOLD left elements in the task and create a new task to compute the right elements. With that, we create less tasks, but it depends on the context and on the problems. In practive, you'll have \u00a0normally more complex problems but if you can find a way to divide the problems, you can use that new framework and have a very clean code.\nTransferQueue\n\nA new interesting collection. This collection is a blocking queue especially made for producers/consumers. With that kind of queue, the producers can await for receipt of by the consumers with a new transfer(E) method or like normal queue without waiting for receipt with the put(E) method. It's also possible to make a transfer with timeout with the tryTransfer method. There is no change in the consumer part, you always use take() to get an element and waiting for an element. You've also access to the number of waiting consumer with the getWaitingConsumerCount().\nThe implementation to use is the\u00a0LinkedTransferQueue based on linked nodes. The elements are ordered with FIFO. Here are some methods you can use with that new collection :\nTransferQueue<String> transfer = new LinkedTransferQueue<String>();\n\ntransfer.transfer(\"Hello\"); //Wait for a consumer\n\nif(transfer.tryTransfer(\"World\")){//Don't wait for a consumer\n    //The element has been transfered to a consumer\n} else {\n    //There were no waiting consumer. The element has not been enqueued.\n}\n\nboolean transfered = transfer.tryTransfer(\"Goodbye\", 5, TimeUnit.SECONDS);\n\nwhile(transfer.hasWaitingConsumer()){\n    //There is at least one consumer waiting for a transfer\n}\n\n\n\nIt's also an interesting stuff. Useful by example in the case of message passing.\nThreadLocalRandom\n\nA really simple but useful enhancement is the add of the ThreadLocalRandom class. This class is a random number generator linked to the current Thread. It seems that if you use this generator from two different thread, you will have two different random generators. The generator is initialized with a generated seed that you cannot modify (setSeed() throws an UnsupportedOperationException).\nYou can use that class like that :\nlong l = ThreadLocalRandom.current().nextLong(22L);\n\n\n\nIf you always use this form, you have the guarantee that the random generator will never be shared between two threads. Moreover, this new class provide \u00a0methods to generate a bounded numbers. By example, to generate a pseudo-random number between 10, inclusive and 33, exclusive, you can type :\nint i = ThreadLocalRandom.current().nextInt(10, 33);\n\n\n\nThis is a little improvement but really useful, i think.\nSo here we are. I've covered the main features added on Java 7 for concurrency. I hope you find that stuff interesting and that discovering this features will help you to make concurrent programming in Java 7.", 
      "tags": "Concurrency,Java,Java 7"
    }, 
    {
      "loc": "/posts/2010/04/links-of-the-week-2.html", 
      "title": "Links of the Week", 
      "text": "Here are some interesting links of this week :\n\n    Three Monitors for Every User : Jeff Atwood explain how to works with three monitors on the same computers and what that give to the user.\n    Tip: When you can't throw an exception : Elliotte Rusty Harold explore solutions on how to works with exceptions in public APIs\n    How to Write a Memory Leak Unit Test : Tor Norbye explain how to make unit test to verify for memory leak\n    8 Tips for Performance Metrics by Jurgen Appelo\n\nI hope you'll find this links interesting.", 
      "tags": "Hardware,Java,Links,Performances,Tests"
    }, 
    {
      "loc": "/posts/2010/04/passed-scjp-exam.html", 
      "title": "I just passed the SCJP exam !", 
      "text": "I'm happy to say that I passed the Sun Certified Java Programmer for Java SE 6.0 this morning :)\nI passed the exam with 93%. I'm really happy of my score. \nTo prepare this exam, I read the SCJP Sun Certified Programmer for Java 6 Exam 310-065 and exercise the chapters for which I wasn't good enough. \nSo i started my exam this morning at 8.30 (Switzerland time) and after 2 hours of work, I was happy to see my score and to rest my poor brain. \nSo now i'm waiting of the certificate sended by post.", 
      "tags": "Java,Personal"
    }, 
    {
      "loc": "/posts/2010/04/java-7-more-dynamics.html", 
      "title": "Java 7 : More dynamics", 
      "text": "Like you know (or perhaps not, nevermind), the Java bytecode doesn't support dynamic method invocation. There are three supported invocations modes : invokestatic, invokespecial, invokeinterface or invokevirtual. These modes allows to call methods with known signature. We talk of strongly typed language. This allows to to make some checks directly at compile time.\nOn the other side, the dynamic languages use dynamic types. So we can call a method unknown at the compile time, but that's completely impossible with the Java bytecode. The dynamic languages based on the Java Runtime must use Java Reflection to make dynamic invocations.\nIn Java 7, we'll see a new feature, the JSR 292. This JSR add new method invocation mode : invokedynamic. With that new bytecode keyword, we can call method only known at runtime.\n\n\nThis JSR only impact the bytecode not the language. But with Java 7 we'll see a new package java.dyn that use this new functionality. That package will improve the performances of Java reflection and mainly the performances of the others languages that run in the JVM. \nMethodHandle\n\nThe MethodHandle class allows to manipulate a reference to a method. It's like a pointer to a method. With that features, we avoid the heavy process of reflection.\nWith that class, we can have informations about the method (return type and parameters) and invoke that method with a special invoke() method that can be called with any number of parameters. To create a MethodHandle we use the MethodHandles factory.\nHere is an example :\nJComboBox combo = new JComboBox();\n\nMethodHandle handle = MethodHandles.lookup().findVirtual(JComboBox.class, \"setModel\", MethodType.make(void.class, ComboBoxModel.class));\n\nhandle.invoke(combo, new CustomComboModel());\n\n\n\nOf course, this example is completely useless but shows the process of invoking a method using Method. There are some differences with Reflection :\n\n    The call to invoke() is optimized by the JVM with calling directly the target method like any other call.\n    The performances are a lot better, almost the same as a standard call.\n    The cheks on the method are made when we create the MethodHandle Object not at all the invoke() calls.\n\n\nInvokeDynamic\n\nThe second class of this new package is the InvokeDynamic class. This is even more weird than the first one, because this class has no methods. But we can invoke any methods on it.\nInvokeDynamic.setModel(new CustomComboModel());\nInvokeDynamic.init();\nDate today = InvokeDynamic.getDate();\n//... You can call any valid method\n\n\n\nAll that calls will be compiled with InvokeDynamic. Namely, all that calls will not be checked at compile time but at runtime. \nTo use that mechanism, we must define a bootstrap mechanism who will do the conversion between the method calls on InvokeDynamic and the really Method (through MethodHandle) to invoke. When we invoke the method, the JVM use that bootstrap method to get the MethodHandle and invoke it.The JVM use a cache for the MethodHandle to improve performances. So, only the first dynamic call will be searched in the bootstrap method.  \nTo register the bootstrap method, we have to use the Linkage.registerBootstrapMethod(String methodName) method. \nHere is a really basic example of a boot strap method. That method only use the name of the called method and return the MethodHandle to the same method in the Utility class with no args. Of course, that kind of bootstrap method must not be used, but that shows the basics of develop that kind of methods. \nprivate static CallSite bootstrap(Class caller, String name, MethodType type) {\n    CallSite site = new CallSite(caller, name, MethodType.make(void.class));\n    site.setTarget(MethodHandles.lookup().findStatic(Utility.class, name, MethodType.make(void.class)));\n    return site;\n}\n\n\n\nReferences of type InvokeDynamic can take any types of objects : \nInvokeDynamic dynamicString = \"Hello World\";\nInvokeDynamic dynamicCombo = new JComboBox();\nInvokeDynamic dynamicNumber = 1;\n\n\n\nWith that, we can dynamically call a method on the target : \ndynamicString.aSimpleMethod();\n\n\n\nHere we are. I think we've covered the main features of this new package. \nOf course these classes will mostly be used by dynamic languages developers instead of standard programmers but the MethodHandle class can be useful to improve reflection performances in simple programs. I think it's a great new features but that will not be used by everybody.", 
      "tags": "Java,Java 7,Performances"
    }, 
    {
      "loc": "/posts/2010/04/java-links-of-the-week.html", 
      "title": "Java Links of the week", 
      "text": "I will try to reference my personal best of links about Java, Swing, ... every week at monday.\nHere is the most interesting links i found about Java Programming this week :\n\n    Swing event departure board : Gerrit of Java User Group M\u00fcnster has developed an event departure board like those in the airports in Swing. with an amazing style.\n    Swinging Task Dialog Part 4 : Eugene Ryzhikov announces \u00a0the 0.5.0 release of his really interesting Task Dialog library, dedicated to Mac OS support.\n    A clean implementation of Chain of Responsibility, by James Sugrue\n    Dynamic Usage of ServiceTracker : Rafael Sobek show a way to use ServiceTracker in a dynamic way tracking minutes after minutes for the service.\n\n\nAnd just for pleasure, my favourite April fools :\n\n    A different kind of company name : Google is now Topeka to honour this town who's itself rename to Google\n    Linus Torvalds monetizes Linux\n    Google Annotations Gallery : A set of annotations from Google like @Lol, @Hack or @Noop\n\n\nI hope you will find this compilation interesting.", 
      "tags": "Java,Links,OSGi,Swing"
    }, 
    {
      "loc": "/posts/2010/04/java-7-the-new-java-util-objects-class.html", 
      "title": "Java 7 : The new java.util.Objects class", 
      "text": "In Java 7, we'll see a new class : java.util.Objects. This class contains 9 static methods to work on Objects. I found these methods really useful.\nFirst, two really simple methods to assert non-null objects in getter/setter (or other methods, of course) :\n\n     T nonNull(T\u00a0obj) : If obj is not null, return obj else throw a NullPointerException.\n     T nonNull(T\u00a0obj, String\u00a0message) : If obj is not null return obj else throw a customized NullPointerException with the given message\n\n\nSome simple examples :\npublic void setFoo(Foo foo){\n    this.foo = Objects.nonNull(foo);\n}\n\npublic void setBar(Bar bar){\n    this.foo = Objects.nonNull(bar, \"bar cannot be null\");\n}\n\n\n\nAlthough simple, these methods can improve the readability of code and avoid having to write the is-null check ourselves.\nThen, we have two methods to compute a toString() value for Object supporting null objects :\n\n    String toString(Object\u00a0o) : Return the toString() value of a non-null object otherwise \"null\".\n    String toString(Object\u00a0o, String\u00a0nullDefault) : Return the toString() value of a non-null object otherwise return nullDefault\n\n\nAgain, this is useful for code readibility :\npublic class Bar {\n    private Foo foo;\n    private Bar parent;\n\n    @Override\n    public String toString(){\n        return \"Bar {foo = \" + Objects.toString(foo) + \", parent = \" + Objects.toString(parent, \"no parent, orphan\") + \"}\";\n    }\n}\n\n\n\nI think, it's a lot better than :\npublic class Bar {\n    private Foo foo;\n    private Bar parent;\n\n    @Override\n    public String toString(){\n        return \"Bar {foo = \" + (foo == null ? \"null\" : foo.toString()) + \", parent = \" + (parent == null ? \"o parent, orphan\" : parent.toString()) + \"}\";\n    }\n}\n\n\n\nIsn't it ?\nAfter that, we also two similar methods for hashing :\n\n    int hash(Object...\u00a0values) : Compute a hash code for all the given values\n    int hashCode(Object\u00a0o) : If 0 is null return 0 othewise return o.hashCode()\n\n\nIf we take again the exemple of the Bar class. If we have to write the hashCode() method without Objects, we could do that :\npublic class Bar {\n    private Foo foo;\n    private Bar parent;\n\n    @Override\n    public int hashCode(){\n        int result = 17;\n\n        result = 31 * result + (foo == null ? 0 : foo.hashCode());\n        result = 31 * result + (parent == null ? 0 : parent.hashCode());\n\n        return result;\n    }\n}\n\n\n\nWith Java 7, we only have to do that :\npublic class Bar {\n    private Foo foo;\n    private Bar parent;\n\n    @Override\n    public int hashCode(){\n        return Objects.hash(foo, parent);\n    }\n}\n\n\n\nAnd that's it :)\nOn the same model, we've also two methods for equality checks :\n\n    boolean equals(Object a, Object b) : Return true if the two arguments are null or they are both not null and a.equals(b) return true, otherwise false.\n    boolean deepEquals(Object a, Object b) : Almost the same as the first method except that if both a and b are arrays, the equality is evaluated using Arrays.deepEquals method.\n\n\nOnce again, that can really ease the coding of equals() methods :\npublic class Bar {\n    private Foo foo;\n    private Bar parent;\n\n    @Override\n    public boolean equals(Object obj){\n        if (obj == this) {\n            return true;\n        } \n\n        if (obj instanceof Bar) {\n            Bar other = (Bar) obj; \n\n            if (foo != other.foo) {\n                if (foo == null || !foo.equals(other.foo)) {\n                    return false;\n                }\n            } \n\n            if (parent != other.parent) {\n                if (parent == null || !parent.equals(other.parent)) {\n                    return false;\n                }\n            } \n\n            return true;\n        } \n\n        return false;\n    }\n}\n\n\n\nbecome :\npublic class Bar {\n    private Foo foo;\n    private Bar parent;\n\n    @Override\n    public boolean equals(Object obj){\n        if (obj == this) {\n            return true;\n        } \n\n        if (obj instanceof Bar) {\n            Bar other = (Bar) obj; \n\n            return Objects.equals(foo, other.foo) &amp;amp;&amp;amp; Objects.equals(parent, other.parent);\n        } \n\n        return false;\n    }\n}\n\n\n\nBetter, no ?\nAnd the last one :\u00a0 int compare(T\u00a0a, T\u00a0b, Comparator<? super T>\u00a0c). This method returns 0 if a == b or if both are null otherwise c.compare(a, b). The support of null is delegated to the comparator.\nWe've covered all the features offered by this new class.\nOf course, there is already some methods like that in librairies like Jarkarta Commons or Google Guava, but it's always better when we doesn't have to include a library for that kind of features.\nI hope you found this post interesting.", 
      "tags": "Java,Java 7"
    }, 
    {
      "loc": "/posts/2010/03/nio-2-path-api-java-7.html", 
      "title": "NIO.2 : The new Path API in Java 7", 
      "text": "In Java 7 we'll see a new API to manipulate file paths. This is part of the NIO.2 API.\nInstead of using the class java.io.File to manipulate a file of the file system of the computer we will now use the java.nio.file.Path class to manipulate a file in any file system (FileSystem). This FileSystem can use any storage place (FileStorage). To support several implementations, this new API is based on factories. With that, you doesn't have to care about the real implementation.\n\n\nA little example to start : In Java < 7, you do that :\nFile file = new File(\"index.html\");\n\n\n\nand with Java 7, you can do that :\nPath path = Paths.get(\"index.html\");\n\n\n\nTo make the migration easier, the File class has a new method toPath() that allows you to transform File to Path :\nPath path = new File(\"index.html\").toPath();\n\n\n\nBut, it's only useful for migration purpose, we will not use that normally.\nBy default, all the Path will refers to files in the basic file system (the file system of the computer), but this new API is totally modular. We could imagine an implementation of FileSystem for data in memory, on the network or a virtual file system.\nLike File, a Path can also refer to a not existing file. That's only file path, not the data containing in a file.\nIf we look at the methods of this new class, we can see that we have almost the same methods than the File class. But there is an important difference. The methods of the Path class throws Exception and that's a really good points. In fact, with the old File methods, we doesn't know anything if there is a problem. Sometimes we know that a problem occured with a simple boolean, but that's all.\nNow we can have the cause of the Exception, that's far better. Here is a little example to delete a file using File :\nif (!file.delete()){\n    //What happens ?\n}\n\n\n\nand now using Path :\ntry {\u00a0 \u00a0\u00a0\u00a0\u00a0\n    path.delete();\u00a0 \u00a0\u00a0\n} catch (IOException e) {\n    // We can know the cause and have a good reaction\n}\n\n\n\nAn other enormous difference is the access to the attributes of the denoted file. In the old style, we have only access to the properties available in all the operating system. Now with views we can access the basic views, existing for all the operating systems and more specific views (DOS and POSIX) for properties available only in certain operating systems.\nHere is a little example to get the basic attributes of a Path :\nBasicFileAttributeView basicView = path.getFileAttributeView(BasicFileAttributeView.class, LinkOption.NOFOLLOW_LINKS); \n\n//This attribute view is perhaps not available in this system\nif (basicView != null) {\n    BasicFileAttributes basic = basicView.readAttributes(); //Get the attributes of the view\n\n    System.out.println(\"Path refers to a regular file : \" + basic.isRegularFile());\n    System.out.println(\"Path refers to a directory : \" + basic.isDirectory());\n    System.out.println(\"Path refers to a symbolic link : \" + basic.isSymbolicLink());\n    System.out.println(\"Path refers to a file with a size of : \" + basic.size());\n    System.out.println(\"Path refers to a file last created at : \" + basic.creationTime());\n    System.out.println(\"Path refers to a file last accessed at : \" + basic.lastAccessTime());\n    System.out.println(\"Path refers to a file last modified at  : \" + basic.lastModifiedTime());\n}\n\n\n\nThis methods can return null if the attribute is not supported. We can also do that for the DOS attributes :\nDosFileAttributeView dosView = path.getFileAttributeView(DosFileAttributeView.class); \n\n//This attribute view is perhaps not available in this system\n\nif (dosView != null) {\n    DosFileAttributes dos = dosView.readAttributes(); //Get the attributes of the view\n\n    System.out.println(\"Path refers to a hidden file : \" + dos .isHidden());\n    System.out.println(\"Path refers to a read only file : \" + dos .isReadOnly());\n    System.out.println(\"Path refers to a system file: \" + dos .isSystem());\n    System.out.println(\"Path refers to an archive file : \" + dos .isArchive());\n}\n\n\n\nYou're really lucky if that works in Unix ;)\nAll the DOS and POSIX implementations extends the Basic view, so you can access all the basic attributes from an implementation view.\nTo make easier, there is also static methods in the Attributes class to access the attributes. By example :\nBasicFileAttributes basic = Attributes.readBasicFileAttributes(path);\n\n\n\nIn the other functionalities, we can note that this new API supports symbolic links (only if the system supports them, of course). Next, the Path class has also flows factories methods like newInputStream() or newByteChannel() to easily create streams to or from the Path. That's also an advantage because the system can choose the good stream implementations to open depending on the system specifications.\nAn other facility offered by Path, is stream on directories. It seems that you can iterate through a directory with an iterator. That's better than File.listFiles() because not all the File are loaded in memory and that's also a bit clearer in code :\nDirectoryStream directory = path.newDirectoryStream(); \n\ntry {\n    for (Path p : directory) {\n        System.out.println(p);\n    }\n} finally {\n    directory.close();\n}\n\n\n\nAnd last, but not least, you can now watch for modifications in a directory with WatchService :\nWatchService watcher = path.getFileSystem().newWatchService(); \n\npath.register(watcher,\n      StandardWatchEventKind.ENTRY_CREATE,\n      StandardWatchEventKind.ENTRY_MODIFY,\n      StandardWatchEventKind.ENTRY_DELETE); \n\nwhile (true) {\n    WatchKey watchKey = watcher.take(); \n\n    for (WatchEvent event : watchKey .pollEvents()) {\n        System.out.println(event.kind() + \" : \" + event.context());\n    } \n\n    watchKey .reset();\n}\n\n\n\nThat will use the services offered by the operating system (Notification, inotify, FSEvents). This is really easier than writing native code to do that, isn't it ?\nHere we are. We've covered the main functionalities of the new Path API in Java 7.\nI hope you find this article interesting and that helped you discovering the new features of Java 7.", 
      "tags": "I/O,Java,Java 7,Performances"
    }, 
    {
      "loc": "/posts/2010/03/4-reasons-not-using-osmorc-anymore.html", 
      "title": "4 reasons i'm not using Osmorc anymore", 
      "text": "After had many problems using Osmorc, the Intellij Idea plugin for OSGi support, i decided to no longer use it. Now, i make all manually.\nI have several reasons to not be satisfied of this plugin.\nFirst of all, this plugin display all the errors in OSGi configuration (Manifest, Activators and imports) but provide no way to quickly fix the problems by example by adding the imported package in the Import-Package Manifest Headers. Its a little disappointing when we are regular with Intellij Idea usage.\nI find it really slow to launch OSGi Instances. Moreover, we cannot really control the osgi instance we launch. I hoped that we could at least manage the OSGi server using basic command line integration, but this is not possible.\nWhen we make the project, all the OSGi modules are compiled and packaged and this could be a long process. During this process, when we have errors, the displayed messages aren't really understandable and there is no explanation on how to solve the problems.\nAnd last but not least, the plugin is very unstable. I had a lot of errors using Osmorc. And i had also problem with the imports in Maven projects. All the imports we marked invalid and sometimes not recognized. Reimporting the maven projects solve occasionally the problems but it always reappears and make the compilation impossible.\nI don't solved any of these problems and for that reasons i don't use Osmorc anymore.\nI realized that this plugin doesn't offer me a lot of things and i could easily work without it.", 
      "tags": "IntelliJ Idea,Java,OSGi"
    }, 
    {
      "loc": "/posts/2010/03/osgi-enterprise-4-2-available.html", 
      "title": "OSGi 4.2 Entreprise Release is available !", 
      "text": "Yesterday, at EclipseCon, the OSGi EEG has finished the OSGi 4.2 Entreprise Release and made it publicly available. You can downlad it here.\nThe news includes several new Entreprise use-cases and improves the OSGI programming model. Some JEE technologies has been add to the OSGi specification.\nHere is an overview of the main new features :\n\n    Blueprint : This is a standard based on Spring-DM. Like this last, it adds an IOC container to OSGi. It's reallay more comfortable to develop OSGi bundles with Spring DM and now, that's the standard. I think this a great news for the OSGi developers. With that new features, the developer can use the IOC container without binding the application to a specific container.\n    Framework Launching : If you wanted to embed an OSGi framework in your application, before this release, you needed to choose one implementation and bind your launching to this implementation. Now OSGi provides a a standard way to start an OSGi Framework.\n    Remove Services (and Admin) : Previously Distributed OSGi, this functionality enables your services to be distributed to remote consumers and enables your bundles to consume remote services. Your remote services doesn't need to implement a specific interface, you just have to configure some properties to make your services remote.\n    Web Applications : This is a standard way to deploy war files in an OSGI Framework. In the past, we can already do that with PAX-Web by example, but that was not standard. This adds several Manifest Headers (context path by example) and give a way to the web application to communicate with the others bundles.\n    JDBC specification : Adds a simple DataSourceFactory class to register the drivers and APIs to get these drivers and DataSource. So you don't need anymore to use complicated private packages to make your JDBC Driver work in your OSGi bundle.\n    JPA : Describes a way to use JPA from an OSGi application. That alllows you to update JPA implementation without restarting it and you can have several JPA Providers in the same system. This specification works in pair with the JDBC specification we talked above.\n    JNDI : Simple bridge between the OSGi Service Registry and JNDI. Now you can lookup BundleContext  or OSGi Service with JNDI. And you can also obtain a JNDI Initial context from OSGi. Your JTA Implementation will be discovered and also appeared in the Service Registry.\n    JMX : With this specification you can access to OSGi Framework with JMX. You can install, uninstall, start and stop a bundle and get informations about the installed bundles and services.\n\n\nThe main purposes of this\u00a0Enterprise\u00a0Release is to make the deploy of OSGi Framework in\u00a0enterprise\u00a0environment easier. But these features can of course also be used in not-enterprise\u00a0environment.", 
      "tags": "Java,OSGi,Releases"
    }, 
    {
      "loc": "/posts/2010/03/bundle-non-osgi-dependencies-maven.html", 
      "title": "Bundle non-OSGi dependencies with Maven", 
      "text": "When we work with OSGi, a problem we always have is how to work with dependencies non OSGi Ready.\nThis is not a really great problem because there we can work with. There is essentially two solutions :\n\n    Embed the JAR files within the bundle. That is to say putting the JAR file into the bundle JAR and reference it in the Manifest\n    Wrap the JAR files with an OSGi Manifest. Namely, transform the JAR into an OSGi bundle.\n\n\nPersonnaly, i doesn't like the first solution, because for me, having a jar into a jar sounds really weird and bad and i prefer to have real OSGi Bundle. With wrapping, if i need this library in an other bundle, i doesn't have to do anything.\n\n\nBut, yes there is a but, wrapping a jar is much complicated than embedding. Because, we much transform the JAR into a real OSGi Bundle. That is to say that we much create a new JAR with a Manifest, importing all the needed packages, exporting all the necessary packages, computing the names and version, ...\nIf we must do that by hand, that could be really long and hard to do.\nWe can do that in a simple way using Maven 2 and the maven-bundle-plugin that can generate an OSGi jar embedding the other using the BND tools. With some configurations, we can simply create a totally valid OSGi Bundle. To make several bundles \u00a0easily, i created a simple parent pom (i take the first sources from Spring Blog) and all the modules of this parent project will be simple project to wrap a dependency.\nHere is the parent pom i use :\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project\n        xmlns=\"http://maven.apache.org/POM/4.0.0\"\n        xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n        xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd\">\n\n    <modelVersion>4.0.0</modelVersion>\n    <groupId>org.jtheque</groupId>\n    <artifactId>jtheque-osgi-wrap</artifactId>\n    <name>jtheque-osgi-wrap</name>\n    <packaging>pom</packaging>\n    <version>1.0</version>\n\n    <modules>\n        <!-- Modules -->\n    </modules>\n\n    <properties>\n        <export.packages>${export.package}*;version=${unpack.version}</export.packages>\n        <import.packages>*</import.packages>\n        <private.packages>!*</private.packages>\n        <symbolic.name>${pom.groupId}.${pom.artifactId}</symbolic.name>\n        <embed-dep>*;scope=compile;type=!pom;inline=true</embed-dep>\n        <unpack-bundle>false</unpack-bundle>\n    </properties>\n\n    <build>\n        <directory>${env.BUILD_HOME}/dependencies/${symbolic.name}</directory>\n\n        <plugins>\n            <plugin>\n                <groupId>org.apache.felix</groupId>\n                <artifactId>maven-bundle-plugin</artifactId>\n                <version>1.2.0</version>\n                <configuration>\n                    <unpackBundle>${unpack.bundle}</unpackBundle>\n                    <instructions>\n                        <Bundle-Name>${artifactId}</Bundle-Name>\n                        <Bundle-SymbolicName>${symbolic.name}</Bundle-SymbolicName>\n                        <Bundle-Description>${pom.name}</Bundle-Description>\n                        <Import-Package>${import.packages}</Import-Package>\n                        <Private-Package>${private.packages}</Private-Package>\n                        <Include-Resource>${include.resources}</Include-Resource>\n                        <Embed-Dependency>${embed-dep}</Embed-Dependency>\n                        <_exportcontents>${export.packages}</_exportcontents>\n                    </instructions>\n                </configuration>\n                <extensions>true</extensions>\n            </plugin>\n        </plugins>\n    </build>\n</project>\n\n\n\nThat really simple, we use some properties to generify the process to have really simple modules. \nHere is an example to wrap the substance look and feel library : \n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n\n    <modelVersion>4.0.0</modelVersion>\n    <groupId>org.substance</groupId>\n    <packaging>bundle</packaging>\n    <artifactId>org.jtheque.substance</artifactId>\n    <name>apple-extensions</name>\n    <version>6.0.0</version>\n\n    <parent>\n        <artifactId>jtheque-osgi-wrap</artifactId>\n        <groupId>org.jtheque</groupId>\n        <version>1.0</version>\n    </parent>\n\n    <properties>\n        <unpack.version>6.0.0</unpack.version>\n        <export.package/>\n    </properties>\n\n    <dependencies>\n        <dependency>\n            <groupId>org.substance</groupId>\n            <artifactId>substance</artifactId>\n            <version>6.0</version>\n        </dependency>\n    </dependencies>\n</project>\n\n\n\nLike you can see, that's really simple and that generates a great OSGi Bundle. Here i didnt' specify any export package. Doing that all the packages are exported except the ones containing impl or internal. \nThats it :)\nI hope that this post will be useful to some of you.", 
      "tags": "Apache,Java,Maven,OSGi"
    }, 
    {
      "loc": "/posts/2010/03/mock-objects-easymock.html", 
      "title": "Mock objects with EasyMock", 
      "text": "1. Introduction\n\nThe mock objects allows to make unit tests on objects depending on other objects. We will replace this dependencies with mock objects. With that, we can by example verify than the method xyzzy() has been called 5 times and returned 33. That can be practical in a several cases. By exampe, if the object to mock is slow or undeterministic (depending on time, or why not on the weather). This objects are really difficult to test because we can make a lot of tests but we could never find the special cases. Test cases with mock objects enable us to test this cases.\n\n\nThere is several tools to make mock objects. In this article, we will use EasyMock 2.5.2 with JUnit 4.7.\nHere is the interface to test :\npublic interface ISimpleDao {\n    void save(String title);\n    void remove(String title) throws NotExistingException;\n    int count();\n    void debug();\n    boolean isValid(String title);\n    void insert(String title);\n}\n\n\n\nAnd here is our class to test :\npublic class SimpleService {\n    private ISimpleDao dao;\n\n    public void setDao(ISimpleDao dao){\n        this.dao = dao;\n    }\n\n    public void insert(String title){\n        if(dao.isValid(title)){\n            dao.insert(title);\n        }\n    }\n\n    public void save(String... titles){\n        for(String title : titles){\n            dao.save(title);\n        }\n    }\n\n    public boolean remove(String title){\n        try {\n            dao.remove(title);\n        } catch (NotExistingException e){\n            return false;\n        }\n\n        return true;\n    }\n\n    public int size(){\n        return dao.count();\n    }\n\n    public void debug(){\n        System.out.println(\"Debug informations of SimpleService\");\n        dao.debug();\n    }\n\n\n\nOur mock will implement the ISimpleDao interface and we will give it to SimpleService who's the class to test. This example is really simplistic, but it will be enough to cover the main features of EasyMock.\n\n\n2. Verify a behaviour\n\nHere is the structure i will use in this article :\nimport org.junit.Before;\n\nimport org.junit.Test;\nimport static org.junit.Assert.*;\nimport static org.easymock.EasyMock.*;\n\npublic class SimpleServiceTest {\n    private SimpleService simpleService;\n    private ISimpleDao simpleDaoMock;\n\n    @Before\n    public void setUp(){\n        simpleService = new SimpleService();\n        simpleService.setDao(simpleDaoMock);\n    }\n\n    @Test\n    public void insertValid(){}\n\n    @Test\n    public void insertNotValid(){}\n\n    @Test\n    public void save(){}\n\n    @Test\n    public void removeWithoutException() throws NotExistingException {}\n\n    @Test\n    public void removeWithException() throws NotExistingException {}\n\n    @Test\n    public void size(){}\n\n    @Test\n    public void debug(){}\n}\n\n\n\nFirst of all, we'll start with create a mock object. For that, we've to use the EasyMock class and its method createMock, with the interface in parameter. To improve code readability, we use a static import like what we do in general with JUnit.\nimport org.junit.Before;\n\nimport org.junit.Test;\nimport static org.junit.Assert.*;\nimport static org.easymock.EasyMock.*;\n\npublic class SimpleServiceTest {\n    private SimpleService simpleService;\n    private ISimpleDao simpleDaoMock;\n\n    @Before\n    public void setUp(){\n        simpleDaoMock = createMock(ISimpleDao.class);\n\n        simpleService = new SimpleService();\n        simpleService.setDao(simpleDaoMock);\n    }\n}\n\n\n\nThis will create a mock objet implementing ISimpleDao interface. The first thing we can do with EasyMock is verify than a method has been called. EasyMock works like a recorder :\n\n    We play the desired sequence on the mock object.\n    We record the played sequence.\n    We test the object\n    We verify that the test sequence correspond to the recorded one\n\n\nSo, we'll test to start that the debug() method of SimpleService call the debug() method of our Dao :\n@Test\npublic void debug(){\n    simpleDaoMock.debug();\n    replay(simpleDaoMock);\n    simpleService.debug();\n    verify(simpleDaoMock);\n}\n\n\n\nThe replay method enable to save the record and the verify method compare the two records are equals. If not equals, the verify method will launch AssertionError. If you launch the written test, it will executes fines, but if we comment the dao.debug() statement in SimpleSerivce, the test will fail :\njava.lang.AssertionError:\n  Expectation failure on verify:\n    debug(): expected: 1, actual: 0\n    at org.easymock.internal.MocksControl.verify(MocksControl.java:111)\n    at org.easymock.EasyMock.verify(EasyMock.java:1608)\n    at com.dvp.wichtounet.easymock.SimpleServiceTest.debug(SimpleServiceTest.java:45)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:44)\n    at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)\n    at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:41)\n    at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)\n    at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)\n    at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:76)\n    at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)\n    at org.junit.runners.ParentRunner$3.run(ParentRunner.java:193)\n    at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:52)\n    at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:191)\n    at org.junit.runners.ParentRunner.access$000(ParentRunner.java:42)\n    at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:184)\n    at org.junit.runners.ParentRunner.run(ParentRunner.java:236)\n    at org.junit.runner.JUnitCore.run(JUnitCore.java:157)\n    at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:94)\n    at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:165)\n    at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:60)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n    at com.intellij.rt.execution.application.AppMain.main(AppMain.java:110)\n\nSo, EasyMock has detected that the method has not bee called and the test fails. If you want to verify that a non-void method has been called , you will have an IllegalStateException because no return behaviour has been specified. We will see that in the next chapter.\n\n\n3. Wait for return values\n\nWe will now work with methods returning values. In this case, we've to define a return behaviour. To do that, we must use the expect() method to encapsulate the call and the andReturn() method to specify a return value. Here is how we can test the size() method :\n@Test\npublic void size(){\n    expect(simpleDaoMock.count()).andReturn(32);\n    replay(simpleDaoMock);\n    assertEquals(32, simpleService.size());\n    verify(simpleDaoMock);\n}\n\n\n\nWith that, we make two tests, we verify that the count method has been called and that size() return the same value as count(). That is the case if we launch the test. We can see that it's really simple to specify a return value for a mocked method.\n4. Work with exceptions\n\nEasyMock can also work with exceptions. We can use again the expect() method, but this times we will use the andThrow method to specify the throwed exception. Here is what we can do with the remove() method test with and without exception :\n@Test\npublic void removeWithoutException() throws NotExistingException {\n    simpleDaoMock.remove(\"Mary\");\n    replay(simpleDaoMock);\n    assertTrue(simpleService.remove(\"Mary\"));\n    verify(simpleDaoMock);\n}\n\n@Test\npublic void removeWithException() throws NotExistingException {\n    simpleDaoMock.remove(\"Arthur\");\n    expectLastCall().andThrow(new NotExistingException());\n    replay(simpleDaoMock);\n    assertFalse(simpleService.remove(\"Arthur\"));\n    verify(simpleDaoMock);\n}\n\n\n\nOnce again, only one method call is enough to specify a behaviour. I think it's here that we can see the power of mocks objects.\n\n\n5.\u00a0Miscellaneous\n\n5.1. Verify the number of calls\n\nNow we can test the save() method :\n@Test\npublic void save(){\n    simpleDaoMock.save(\"xyzzy\");\n    simpleDaoMock.save(\"xyzzy\");\n    simpleDaoMock.save(\"xyzzy\");\n    simpleDaoMock.save(\"xyzzy\");\n    simpleDaoMock.save(\"xyzzy\");\n\n    replay(simpleDaoMock);\n\n    simpleService.save(\"xyzzy\", \"xyzzy\", \"xyzzy\", \"xyzzy\", \"xyzzy\");\n\n    verify(simpleDaoMock);\n}\n\n\n\nThis kind of code is really heavy to write with a high number of calls. We have two solutions. We can do a loop for all the calls or use the times() method of EasyMock :\n@Test\npublic void save(){\n    simpleDaoMock.save(\"xyzzy\");\n\n    expectLastCall().times(5);\n\n    replay(simpleDaoMock);\n\n    simpleService.save(\"xyzzy\", \"xyzzy\", \"xyzzy\", \"xyzzy\", \"xyzzy\");\n\n    verify(simpleDaoMock);\n}\n\n\n\nA lot clearer, no ? It's also possible to specify that a method must called any times with the anyTimes() method and an interval of times with the times(min,max) method.\n5.2. Verify calls order\n\nWe will now test the insert() method :\n@Test\npublic void insertValid(){\n    expect(simpleDaoMock.isValid(\"Arthur\")).andReturn(true);\n    simpleDaoMock.insert(\"Arthur\");\n    replay(simpleDaoMock);\n    simpleService.insert(\"Arthur\");\n    verify(simpleDaoMock);\n}\n\n@Test\npublic void insertNotValid(){\n    expect(simpleDaoMock.isValid(\"Arthur\")).andReturn(false);\n    replay(simpleDaoMock);\n    simpleService.insert(\"Arthur\");\n    verify(simpleDaoMock);\n}\n\n\n\nYou're going to say that we've already seen all that stuff. But in that kind of case, it could be interesting to verify that the calls are in the good order. Indeed, if the method isValid() is called after the insert, that's really useful. With EasyMock, there is two ways to verify calls order. First, you can use the createStrictMock insted of createMock to create your mock or you can use the checkOrder(mock, true) method to specify that the mock is strict. A strict mock is simply a mock who cares about the order of the calls. So we can keep all our tests in the current state and just use one of this two methods and the order will be checked. Of course, we can verify the order only in certain tests methods. That can be done using checkOrder(mock, true) at the start of the test method.\n5.3. Mock a class\n\nEasyMock has an extension to mock classes and not interfaces. It's EasyMock Class Extesion. All the use is the same, we just have to use this import :\nimport static org.easymock.classextension.EasyMock.*;\n\n\n\nMoreover, we can also make a partial mocking with by example only one method :\nMocked mock = createMockBuilder(Mocked.class).addMockedMethod(\"mockedMethod\").createMock();\n\n\n\nKeep in mind that the final classes are not supported and that the final methods are not mocked.\n\n\n6. Conclusion\n\nSo, we have seen all the features of EasyMock to create mock objects for unit tests. Like you've seen, it's a really simple but powerful way to verify the behaviour of an object depending on an other. There are others libraries for mock objects like JMock, JMockit or Mockito, but personally, i think EasyMock is most comfortable to use and give all the features i need to make my own unit tests. That's why i choose this library to make this article.\nI hope this article has interested you. Don't hesitate to comment it ;)", 
      "tags": "Java,Libraries,Tests"
    }, 
    {
      "loc": "/posts/2010/03/welcome-to-my-new-website.html", 
      "title": "Welcome to my new website !", 
      "text": "Welcome to my new english website :)\nI've moved all my english stuff from Developpez.com to make here a completely english website.\nI hope you'll find here some interesting stuff. I will publish articles and posts about Java, Spring, Swing, OSGi, Hardware and Web and perhaps others technologies.\nDon't hesitate to say me what you think about this website.", 
      "tags": "Others,Personal,The site"
    }, 
    {
      "loc": "/posts/2010/03/osgi-and-cyclic-dependencies.html", 
      "title": "OSGi and cyclic dependencies", 
      "text": "I'm currently working on the \"bundlisation\" of the JTheque Core. I choose to cut core into several bundles each one representing a service provided by the core. \nI quickly have experencied problems with \nI quickly realized that the decoupling of my various services was almost nil. I had a huge number of dependencies for each bundle and worse, I had a lot of cyclic dependencies, either direct or indirect.\nFor information, a direct cyclic dependency is a situation in which a bundle X depends on a bundle that depends on Y who is also depending itself of X. An indirect dependency cycle is the situation where X depends on Y, Y depends on Z and Z depends on X. I speak here of bundles, but it may relate to projects, classes or packages.\nNote that the different techniques that I will present also apply for dependencies between components non-OSGi, the principles are exactly the same.\n\n\nIn the case of packages within the same application, even if we avoid this, it is possible to live with. However, in the case of bundle or projects, it is generally not even possible for the application builder. For me, the bundles are Maven modules. It is impossible to start the build of a bundle in a cycle since the builder must first bundle before the second and the second before the first, which is obviously not possible.\nIn addition to be very bad in a system build, cyclic dependencies between components are also a huge design problem. Indeed, we cannot work on a bundle without working on the bundle B and vice versa. In addition to this, the two components are very difficult to evolve in a healthy way.\nThe cyclic dependencies at the class level within a component does not pose real problems. It is always in the same component, classes can thus be linked in a cyclical way, even if it would still avoid it as soon as possible (it is not always).\nTo return to JTheque so I had to solve the problem of cyclic dependencies before advancing further. There are many techniques to do this. Here are the tracks that I explored to resolve these dependencies. Note that these techiques cannot only solve the problem of cyclic dependencies, but also improves the architecture of its application.\n\nMove the classes to the right location : In some cases, I had classes in a bundle when they had nothing to do here. In this case, it may suffice to move them to another bundle. Note that this case is the easiest to solve and it's unfortunately not the most common. In addition to this, in case the classes to move depends on another bundles, it is possible that this creates new cyclic dependencies. An example is the collection management module, which was contained in the bundle of graphical interfaces.\nMove functionalities : I also found a lot of features, typically methods within a bundle that was not at the right place. For example, the bundle \"modules\" provided methods for updates while a bundle \"update\" existed. It was enough to move these features to the bundle update to solve my cycle.\nBadly cutted features : Often, a feature, usually a method or a class, do too much things and causes dependencies that are not welcome here. Sometimes, thing again about the functionality and the role of each class / method may be enough to solve the problem. Note that this does not concern only the concepts of dependency, but is a basic principle of object-oriented design. In the case of JTheque I had for example a method allowing to select a collection that returns true if we could open the collection with the login / password entered false otherwise. But besides that, it displays an error in the collection view if there was a problem. But that was clearly not his role. I have updated this method so it does that test if we could open the collection or not and I implemented the display of the error in the Swing Action. \nSeparate functionalities of bundle : It may happen that the bundle to do too much things or has several distinct aspects. In this case, you should immediately separate the bundle into several others with each one a clear responsibility. Often this will help solve a cyclic dependency, as fewer bundles have dependencies to each new bundles and each new bundles should have fewer dependencies to other bundles. But it can also introduce new cycles. In JTheque, I cut the modules \"views\" in 2 two bundles: views and ui. The views module contains the implementation of JTheque views and the \"ui\" module contains utility classes for creating views and generic Swing components that can be used elsewhere.\nIntroduce callback system : A callback system is a simple listeners system that could solve dependencies. Rather than a bundle directly notify another bundle, the second register as the first listener. Thus the first does not need to know the second. It is immediately obvious that listeners are more powerful than they might initially appear. In the case of JTheque, I implemented this for selecting collections. In fact, the collections manager called directly the view that the collection had been chosen. Using a listener, it is much more flexible and collections manager automatically notifies all listeners. In addition to this, if I need later a second listener, I have nothing to change in the collections bundle.\nSeparate specification and implementation : As it is not always possible to remove cyclic dependencies directly, we can bypass them by separating the specification part and the  implementation part. This technique can sometimes be useful when it is really difficult to solve the cycle. It therefore separates a bundle in any specific part that is called from the outside and part of implementation which can then have dependencies outside. Note that this is clearly not often feasible in the state because it is not always possible to completely separate the implementation of the specification without cycles. \nGroup to modules in one : In some cases, we realize that two modules are so intrinsically linked they are in fact only one module. In this case, the best solution is to group them in one bundle.\n\nWell, now I have list the various techniques I used to resolve cyclic dependencies in bundles of JTheque Core. There are certainly many others, but it was enough for me. \nI hope this will be useful to people trying to solve problems of cyclic dependencies.", 
      "tags": "Conception,Java,JTheque,OSGi"
    }, 
    {
      "loc": "/stories/legal.html", 
      "title": "Legal", 
      "text": "Terms of use\nContact\nBaptiste Wicht \nRoute du Pafuet 114 \n1724 Bonnefontaine \nCH-Suisse \nE-Mail: baptiste.wicht@gmail.com\nTerms and Conditions of Use for the baptiste-wicht.com website\nBy using this website, you acknowledge that you've read, understand and agree to be bound by these terms and conditions.\nThis website is a service maintained by Baptiste Wicht. All the contents provided through this website may be used solely under the following terms and conditions.\nThe authors of baptiste-wicht.com reserve the right to change the content of this website and to make changes to the website without notice. The authors provide no assurances that any reported problems with any content will be resolved. \u00a0The authors assume no responsibility on the use of the contents. All the content is provided on \"as is\" basis only.\nYou are prohibited from posting or transmitting to or from this website any unlawful, threatening, libelous, defamatory, obscene, scandalous, inflammatory, pornographic, or profane material or any other material that could give rise to any civil or criminal liability under the law.\nThe authors reserve the right to investigate complaints or reported violations of these Terms of Use and to take any action they deem appropriate including, without limitation, reporting any suspected unlawful activity to law enforcement officials, regulators, or other third parties and disclosing any information necessary or appropriate to such people or entities relating to user profiles, e-mail addresses, usage history, posted materials, IP addresses and traffic information.\nThrough the usage of this website you agree to the usage of cookies. This website uses tracking third-party libraries. These libraries may use information about your visits to this and other websites.\u00a0Through the usage of this website you agree to the usage of your information to serve advertisement.\nThe sources presented on the articles and blogs are free of rights and you can use them at your convenience. But no reproduction, even partial, can be done of this website and its contents.", 
      "tags": ""
    }, 
    {
      "loc": "/stories/faq.html", 
      "title": "FAQ", 
      "text": "1. What can I do if I found an error in one of your articles / blogs / pages?\nThe best way is to post a comment directly on the page. You can also contact me with the Contact form.\n2. How can I thank you?\nFirst of all, I thank you for reading my web site.\nYou can help this website (http://baptiste-wicht.com) in several ways:\n\nLink to one of my blogs/pages/articles from your blog/website\nAdd my site to your favorite social bookmaking site, e.g. DZone, Digg, ...\nLets others know about my website via \u00a0Social Networks: Facebook, Twitter, LinkedIn, Reddit, ...\nRecommend\u00a0my website to your friends\n\n3. What can I do if I've problems with one of your blog post/tutorial ?\nYou can post your questions directly as comment of the specified blog/tutorial. Try to be precise about your problem.\nIf you have a problem with the examples from my articles I try to answer each question in comments.\nPlease also note that I maintain this website on my private time, so that is not always possible for me to answer questions that go beyond the scope of my blogs/articles.", 
      "tags": ""
    }, 
    {
      "loc": "/stories/contact.html", 
      "title": "Contact", 
      "text": "There are several means to contact me: \n\nBy email: baptiste.wicht@gmail.com\nOn Google plus: +Baptiste Wicht", 
      "tags": ""
    }, 
    {
      "loc": "/stories/about.html", 
      "title": "About", 
      "text": "My name is Baptiste Wicht and I'm now 25 years old. I\u2019m currently a Ph.D student in Computer Science at the University of applied sciences in Fribourg. I've been programming in Java for years and I'm now working especially with C++.\nI\u2019ve been active in Developpez.com, a french computer science community, for more than three years. At first, I went there to ask for help about my programming problems and almost always found solutions. Then, Java responsible asked me to moderate the Java forums. After that, I started to write Java tutorials. I started with a tutorial explaining the creation of GUI with Swing. Then, I continued with an article about a simple Java update system and later wrote a lot of other articles in several categories. And after that, I was one of the two Java Community Leaders on Developpez.com. Now, I have left these responsibilities to write this blog.\nIn 2011, I started C++ for my Bachelor project and since this time wrote several projects in C++ and did my best to improve my skills with this language and its libraries.\nIt hasn't been very long since I started writing articles and tutorials in English, but I do my best to have a good writing level. If you find errors, don\u2019t hesitate to contact me.\nA (short) list of my publication is available here.\nFor all suggestions or comments on my tutorials, projects, blogs or this website, you can contact me directly with the contact form, by commenting a page or post or by email at this address:\u00a0baptiste.wicht@gmail.com.\nFor professional information, my LinkedIn profile is available.\nYou can also take a look at my Google Profile: Baptiste Wicht\nI hope you will find this website useful and will like my articles and blogs.", 
      "tags": ""
    }, 
    {
      "loc": "/posts/2010/03/sonar-2-0-released.html", 
      "title": "The version 2.0 of Sonar has been released", 
      "text": "The developers of Sonar have just released the version 2.0 of Sonar.\nSeveral major features:\n\n    Architecture analysis : The architecture of the projects are now analyzed. We can see a matrix of project dependencies and a list of dependencies to delete to improve architecture quality.\n    Object oriented analysis : New metrics for the quality of the object oriented conception.\n    Improvements of the user interface.\n\n\nOnly good stuff :)\nI didn't test this new version, i will wait that my plugins be compatibles with the new version, but i will give informations of the new version once installed.\nMore informations on the\u00a0Sonar website.", 
      "tags": "Java,Releases,Sonar"
    }, 
    {
      "loc": "/posts/2010/03/java-swing-focus.html", 
      "title": "Manage focus with Swing in Java", 
      "text": "1. Introduction\n\nThe focus is the \"selected\" state of a component. The component who has the focus is the active component. It's possible to ask focus fror a specific component but normally this is perfectly managed by Swing.\nWith this tutorial, you will learn how to ask focus for a specific component and how to define an order of focus. We will also learn a bit about the validation of input fields, the focus listen and the utility of KeyboardFocusManager.\n2. Ask focus\n\nNormally, the focus is managed by a component on the mouse click or when we come to a component with keyboard. A component who is focused is often visually modified, with a special border or an other background color.\nTo manage the focus of the windows, it's a little bit different and depends of the operating system, but nothing can give you the guarantee to have focus. On Windows, you can obtain focus on a window using toFront but nothing is guraranteed.\nFor the components, you can use the requestFocusInWindow() method :\ncomponent.requestFocusInWindow();\n\n\n\nTo obtain the focus, you have to ask focus after the add of the component but before the display of the window.\nBefore Java 1.4, you needed to use the requestFocus() method, but now it is not a good idea to use it, because it give also focus to the window of the component, and that's not always possible.\n\n\n3. Navigation keys\n\nBy default, we navigate in an application with the Tab and Shift+Tab keys. But we can edit these keys.\nFor that, we have to get the keys with getFocusTraversalKeys(int id) and add the new key. By example, here is how to add the Enter key for the forward focus navigation :\nSet keys = textField.getFocusTraversalKeys(KeyboardFocusManager.FORWARD_TRAVERSAL_KEYS);\nSet newKeys = new HashSet(keys);\nnewKeys.add(KeyStroke.getKeyStroke(KeyEvent.VK_ENTER, 0));\ntextField.setFocusTraversalKeys(KeyboardFocusManager.FORWARD_TRAVERSAL_KEYS, newKeys);\n\n\n\nIf you want to add a key for the backward navigation, you need to use BACKWARD_TRAVERSAL_KEYS instead of FORWARD_TRAVERSAL_KEYS.\n4. Validate an input\n\nYou often need to validate to validate the inputs of the user in a field. The best way to do that is to test the content directly after the focus lost. Of course, there is still Formatter to do that, but it's possible that you must use the validation on a custom component.\nTo do that, we'lll use InputVerifier. This InputVerifier enable to get the value of a field when this field lost focus. If the value is not valid, the InputVerifier can execute a particular action by example set the old value in the field insted of the new invalid value or give focus again to the field.\nTo use it, we've to create a class extending InputVerifier and use the setInputVerifier() method on the component to test :\nCustomInputVerifier verifier = new CustomInputVerifier();\n...\nmonComposant.setInputVerifier(verifier)\n\n\n\nThe inputVerifier class has only two methods :\n\n    verifiy(JComponent input) : Indicate if the value of the component is correct. It's must be overriden.\n    shouldYieldFocus(JComponent input) : This method idnicate if the component can loose focus or not. If it's return true, the focus change normally to the next component else the focus remains in the\n\n\ncurrent component while the input is invalid. By default, it's only return the value of verify().\nFor lisibility reasons, it's better to only implement the test of the input value in the verify method and add the other functionalities by example a beep it it's invalid in the shouldYieldFocus method.\nWe will see a simple example of InputVerifier. This verifier verify that the value is a number greater than zero but lower than x. If the value is not valid, we simple emit a beep.\nimport java.awt.Toolkit;\nimport javax.swing.InputVerifier;\nimport javax.swing.JComponent;\nimport javax.swing.JTextField;\n\npublic class NumberInputVerifier extends InputVerifier {\n    private int max = 0;\n\n    public NumberInputVerifier(){\n        this(100);\n    }\n\n    public NumberInputVerifier(int maximum){\n        super();\n\n        this.max = maximum;\n    }\n\n   public boolean shouldYieldFocus(JComponent input) {\n        boolean valid = verify(input);\n\n        if (valid) {\n            return true;\n        } else {\n            Toolkit.getDefaultToolkit().beep();\n            return false;\n        }\n    }\n\n    public boolean verify(JComponent input) {\n        JTextField field = (JTextField)input;\n\n        String value = field.getText();\n        int intValue;\n\n        try {\n            intValue = Integer.parseInt(value);\n        } catch (NumberFormatException pe) {\n            return false;\n        }\n\n        if(intValue &amp;lt; 0 || intValue &amp;gt; max){\n            return false;\n        }\n\n        return true;\n    }\n}\n\n\n\nYou can of course make a lot of things with this class. You can use it to change the format of a number adding \" or , or modify everithing else in the input component.\nYou can also use the same InputVerifier for several components. You just have to test the concerned component with the parameter of the verify method. But don't make too complex InputVerifier.\n\n\n5. Listen the focus\n\nA first way to know which component has the focus is to use a focus listener. You just have to create a class implementing FocusListener and add this listerner to every components you want to manage. Then, you just have to make things in the methods of the listener : focusGained and focusLost. This way is quite simple, but if you have a lot of components, it will be really heavy to implement.\nAn other way is to use the KeyboardFocusManager class. You just have to add a PropertyChangeListener on this class and verify the property focusOwner. You can also listener some other things : the focus of the windows, the changes on the focus order, ... You can find here a complete liste of properties. This times, you'll directly see all the focus changes for all the components in your application. If you want to restrain the set of components, you have to use the first way with FocusListener.\nHere is an example with KeyboardFocusManager :\n\nKeyboardFocusManager focusManager = KeyboardFocusManager.getCurrentKeyboardFocusManager();\n\nfocusManager.addPropertyChangeListener(\n    new PropertyChangeListener() {\n        public void propertyChange(PropertyChangeEvent e) {\n            String properties = e.getPropertyName();\n            if ((\"focusOwner\".equals(properties)) &amp;amp;&amp;amp; (e.getNewValue() != null)) {\n                Component component = (Component)e.getNewValue();\n                String name = component.getName();\n\n                System.out.println(name + \" take focus\");\n            }\n        }\n    }\n}\n\n\n\n6. Manage the order of focus\n\nSwing has a correct focus order by default and normally it's enough. But you can change this order, by example to navigate in a complex form. By default, Swing determinate the focus order using the order of adding the components to the content pane.\nBefore Java 1.4, you had to use setNextFocusableComponent() on every component to specify the next component to have the focus. This method is now deprecated. We'll use the LayoutFocusTraversalPolicy class to define the focus order in a Swing application.\nFor that, we have to create a new class extending FocusTraversalPolicy and define this set of methods :\n\n    getComponentAfter : Indicate which component will have focus after the component in parameter.\n    getComponentBefore : Indicate which component has the focus before the component in parameter.\n    getDefaultComponent : Indicate which component is the default component of the container on which we've applied the policy. It's used when we swith to this focus cycle.\n    getLastComponent : Indicate which component is the last of this continer. It's used when we swith to this focus cycle.\n    getFirstComponent : Indicate which component is the first of this container. It's used when we swith to this focus cycle.\n    getInitialComponent : Indicate which component must have the focus when the window is displayed.\n\n\nHere is a little example :\npublic class TestFocusTraversalPolicy extends FocusTraversalPolicy {\n    public Component getComponentAfter(Container focusCycleRoot, Component aComponent) {\n        if (aComponent.equals(component1)) {\n            return component2;\n        } else if (aComponent.equals(component2)) {\n            return component3;\n        } else if (aComponent.equals(component3)) {\n            return component4;\n        } else if (aComponent.equals(component4)) {\n            return component5;\n        } else if (aComponent.equals(component5)) {\n            return component1;\n        } \n\n        return component1;\n    }\n\n    public Component getComponentBefore(Container focusCycleRoot, Component aComponent) {\n        if (aComponent.equals(component1)) {\n            return component5;\n        } else if (aComponent.equals(component2)) {\n            return component1;\n        } else if (aComponent.equals(component3)) {\n            return component2;\n        } else if (aComponent.equals(component4)) {\n            return component3;\n        } else if (aComponent.equals(component5)) {\n            return component4;\n        }\n\n        return component1;\n    }\n\n    public Component getDefaultComponent(Container focusCycleRoot) {\n        return component1;\n    }\n\n    public Component getLastComponent(Container focusCycleRoot) {\n        return component5;\n    }\n\n    public Component getFirstComponent(Container focusCycleRoot) {\n        return component1;\n    }\n}\n\n\n\nThe disadvantage of this technique is that the policy must know all the components. That why we often use an inner class to give it access to the member of the current class. Here is a simple example :\npublic class View {\n    private Component component1;\n    private Component component2;\n    private Component component3;\n    private Component component4;\n    private Component component5;\n\n    class TestFocusTraversalPolicy extends FocusTraversalPolicy {\n        //Traversal policy methods\n        }\n}\n\n\n\nYou can also use an inner anonymous class, but with that kind of class, you cannot use it for several components.\nTo apply this policy, you have to use the setFocusTraversalPolicy() method of the Container class :\nTestFocusTraversalPolicy newPolicy = new TestFocusTraversalPolicy();\nmyContainer.setFocusTraversalPolicy(newPo\n\n\n\nOf course you can define several strategies for several panels or the same policy for several panels.\nIf you want to restore the default focus policy, you just have to call setFocusTraversalPolicy() with null as parameter.\nYou can also edit the default FocusTraversalPolicy with one of yours with the setDefaultTraversalPolicy() method from the KeyboardFocusManager class.\n6.1. Simplification\n\nBut it's not very easy to do that and that can quickly be heavy. So here is a simple class to manage the positions of all the components with an integer :\nimport java.awt.Component;\nimport java.awt.Container;\nimport java.awt.FocusTraversalPolicy;\nimport java.util.HashMap;\n\n/**\n * A focus traversal policy who manage the order of components in the focus cycle using a int.\n * The first component of the cycle  has the position of 0 and all the others follows with an interval of 1.\n * The last component must have the position (size() -1).\n *\n * @author Baptiste Wicht\n *\n */\npublic class MapFocusTraversalPolicy extends FocusTraversalPolicy {\n    private HashMap components = new HashMap();\n    private HashMap positions = new HashMap();\n\n    /**\n     * Add the component to the order with the specfieid position.\n     *\n     * @param component The component to add.\n     * @param position The position of the component in the focus cycle root.\n     */\n    public void addComponent(Component component, int position){\n        components.put(position, component);\n        positions.put(component, position);\n    }\n\n    @Override\n    public Component getComponentAfter(Container parent, Component component) {\n        int position = positions.get(component);\n\n        if(position = positions.size() - 1){\n            position = 0;\n        }\n\n        return components.get(position + 1);\n    }\n\n    @Override\n    public Component getComponentBefore(Container parent, Component component) {\n        int position = positions.get(component);\n\n        if(position = 0){\n            position = positions.size() - 1;\n        }\n\n        return components.get(position - 1);\n    }\n\n    @Override\n    public Component getDefaultComponent(Container parent) {\n        return components.get(0);\n    }\n\n    @Override\n    public Component getFirstComponent(Container parent) {\n        return components.get(0);\n    }\n\n    @Override\n    public Component getLastComponent(Container parent) {\n        return components.get(components.size() - 1);\n        }\n}\n\n\n\nVous can use this class as every other focus traversal policy we saw before. Just add all the components before using the policy.\nAn other way that you can explore it's to make all your components implementing an interface like Focusable with a getFocusPosition() method and use a policy to make the order with that Focusable components.\n7. The KeyboardFocusManager class\n\nThere is also other utilities to the KeyboardFocusManager class.\nFirst, you can change the component who has the focus with the focusXXX methods. By example, you can use the focusNextComponent() method to give the focus to the next component. you can also give the focus to a specific component with the setFocusOwner method or to a window with with the setActiveWindows method.\nThen, you can also get the active window, the component with the focux and the container who contains the active component. If the components are in an other thread, you have to use the getGlobalXXX methods to get it.\n\n\n8. Conclusion\n\nTo conclude, you can do almost everithing with the focus system. You can modify the order of focus for the components, say which components must have the focus, make tests on the input fields, know who has the focus. But that's sometimes weird when we start. But once we've understand which classes to use, it is quite simple.", 
      "tags": "Java,Swing"
    }, 
    {
      "loc": "/posts/2010/03/bookmarks-bar-disappears-google-chrome.html", 
      "title": "Tip : The bookmarks bar disappears on Google Chrome !", 
      "text": "I Found that my bookmarks bar on Google Chrome disappear sometimes. This behavior is very confusing, is searched a few and i find that it was me that make it disappears and appears.\nOn Google Chrome, you can hide/display the bookmarks bar using  + .\nHope that will help someone.", 
      "tags": "Google,Tips,Tools,Web"
    }, 
    {
      "loc": "/posts/2010/03/hardware-guide-memory.html", 
      "title": "Hardware Guide : The memory chips", 
      "text": "1. Introduction\n\nThe RAM memory (Random Access Memory) of a computer is used to stock data during their treatment. The operating system will load in memory the useful files and all the datas of the launched programs. Its necessary to have an adequate quantity of memory.\nThe RAM has two important caracteristics :\n\n    Speed data access : The access to data in RAM is very fast, a lot more than access to hard disks. It's essential to give access to data in a quick way.\n    Volatility : The data doesn't remain in memory after computer shutdown. So this is not a storage device only a temporary data storage device.\n\n\nIf a computer doesn't have enough memory, the operating system will simulate virtual memory using the hard disks, but like said above, the access on the hard disk is a lot slower than memory and the performances of the system will decrease.\nSo this is essential to make the good choice when choosing memory chips.\n\n\n\n2. Size\n\nThe first thing to define is the quantity of memory do you need. The minimum memory is 512 Mo, but the this will be just enough even in Windows XP and it's absolutely not enough for Windows Vista. For Windows Seven, you can have 512 Mo, but it will not be confortable.\nThats why i will advise at least 1 Go of RAM, but better is 2 Go. After, you have also to see the used applications to estimate the needed memory size. If you need to do images/movies treatments or play recent games 2Go is necessary. If you use more than 3 Go of RAM, be sure that you operating system can support that. Only 64 bit operating system support more than 3 Go of RAM. Generally, the last motherboards use the Dual Channel technologies for memory chips. Namely we control the chips by pair to have better bandwith. With this technology, you must use 2 chips with the same caracterics (two same chips will be better). Some motherboards have Quad Channel technology support. This is the same as Dual Channel but for 4 chips.\nThe motherboards have normally 4 memory locations. I advise to use only 2 for the start. This will make the update easier. It's not really useful to buy 4 chips of 512 Mo instead of 2 chips of 1 Go. The prices are almost the same.\n\n\n3. Type\n\nThere is several types of memory with for each type several standards. Here are the 4 main types :\n\n    SDR-SDRAM : This is an obsolete type of RAM, but you can still find it in very old computers. A chip had 168 pins and 2 keyways.\n    DDR-SDRAM : This is an evolution of the SDR, with better frequencies. It has 184 pins and one keyway. It's not selled today and have been replaced by DDR2.\n    DDR2-SDRAM : This is the standard type of mmemory. All the new motherboards support this type. It has better frequencies. It has 240 pins.\n    DDR3-SDRAM : Really recent technology and still almost few used. The motherboards support more and more that technology.\n\n\nNow, the main used chips are DDR2 and the new motherboards are all compatible with this norm. This is why, i'll advise to directly buy DDR2. If you want better performances use DDR3, but it's only necessary with big configurations.\nFor each technology there is several formats. This formats indicate the frequency of the chip. The DDR have a internal frequency and an external one. Here are the different formats :\n\n    DDR2 400 - PC2-3200 : External Frequency (EF) : 200Mhz, Internal Frequency (IF) : 100Mhz\n    DDR2 533 - PC2-4200 : EF : 266, IF : 133\n    DDR2 667 - PC2-5300 : EF : 333, IF : 166\n    DDR2 800 - PC2-6400 : EF : 400, IF : 200\n    DDR2 1000 - PC2-8000 : EF : 500, IF : 250\n    DDR2 1066 - PC2-8500 : EF : 533, IF : 266\n    DDR2 1200 - PC2-10000 : EF : 600, IF : 300\n\n\nMore the frequency is high, more the access to the data is fast. Nevertheless, like you will see in the next chapter, it's not enough to have a high frequency. In fact, a very high frequency has no utility with high latencies.\nThe motherboard have also a frequency, so have to keep in mind to not decrease the performances of the memory with the motherboard and vice-versa. The motherboards doesn't support any formats, so you have to control the compatibility between the memory and the motherboard. More the frequency is high, more it will be costly. So have to choose the right middle between performances and price.\nNote : Some mainboards have limitations on the supported number of chips of a certain type of chips. For example a mainboard XXX can support only three chips of type YYY.\nFor the persons that want to make overclocking, i will advise to take chips with very high frequencies (DDR2 1066 and superior). But for all that want a simple configuration, lower frequencies will be enough.\nFor the persons interested of the very high frequencies, here are the caracteristics of the DDR3 norm :\n\n    DDR3-800 : 100 MHz- 400 MHz\n    DDR3-1066 : 133 MHz - 533 MHz\n    DDR3-1333 : 166 MHz -\u00e0 667 MHz\n    DDR3-1600 : 200 MHz - 800 MHz\n    DDR3-1800 : 225 MHz - 900 MHz\n    DDR3-1866 : 233 MHz - 933 MHz\n    DDR3-2000 : 250 MHz - 1000 MHz\n    DDR3-2133 : 266 MHz - 1066 MHz\n    DDR3-2200 : 275 MHz - 1100 MHz\n    DDR3-2300 : 287 MHz - 1150 MHz\n\n\nTo choose the DDR3 memory, the best criteria is the price. Take the format the most according to your budget.\n4. Synchronisation\n\nAn other caracteristic of memory is the number of clock cycles necessary to access a data. This caracteristic is represented by 4 numbers (x-x-x-x) :\n\n    CAS (Column Address Strobe) Delay or CAS Latency : Time to access a column. Namemly the number of cycles between the read request and the answer.\n    RAS (Row Address Strobe) Precharge Time : Number of cycles between 2 RAS operations.\n    RAS To CAS Delay : Access time to swith from a row to a column.\n    RAS Active Time : Access time for a row.\n\n\nMore the timings are low more the chips is fast. But you have to balance the 4 numbers.\nIt's possible to change timings in The BIOS, but these operations can be dangerous for the stability of the chips and also for their life time.\nThis parameter is not the most important to keep in minde, but you cannot ignore it. Timings of 3-3-3-8 or less will be fine. If you have the budget, you can choose 2-2-2-5, but it's very expensive. Keep in mind that timings are lower for DDR3 than for DDR3.\n\n\n5. Miscellaneous\n\nAn other question that we can have is \"brand chip or noname ? \". This depends on the tastes and the budget, but for the memory i will advice brand chips. The performances are in general really good and the chip is often guaranteed for a long times (sometimes for all the life). In the big constructors of chips we can include Corsair, Kingston or Crucial. You will rarely have problems with chips of these brands.\nNormally the memory chips doesn't need to be specially freezed, but on the big configurations very used, it's useful to freeze the chips. The best way is to use a simple heatsink (a lot of chips are directly selled with heatskins. There is also other systems like liquid cooling of fan system. But i've never seen a case where the heatsink isn't enough.\n6. Conclusion\n\nSo the first thing to think about is the necessary quantity of memory. Once this is done, you have to see with your mainboard which chips you can use and make the good choice considering the budget and the need of performances.\nI hope that this article will be useful for the choice of memory chips.", 
      "tags": "Hardware"
    }, 
    {
      "loc": "/posts/2010/03/jtheque-is-going-to-osgi.html", 
      "title": "JTheque is going to OSGi", 
      "text": "Just a little post to inform you that i'm currently migrating JTheque Core to OSGI / Spring Dynamic Modules. The core will be fractioned into several bundles. The JTheque Modules will also be OSGi bundles.\nIt will increase the modularity of the different services of the Core. And it will also be a more standard way to develop modules. And last but not least, it's an opportunity for me to learn OSGi and Spring Dm.", 
      "tags": "Java,JTheque,Modular,OSGi,Spring"
    }, 
    {
      "loc": "/posts/2010/02/modular-application-jtheque-core-2-0-3.html", 
      "title": "Develop a modular application with JTheque Core 2.0.3", 
      "text": "1. Introduction\n\nThis article will teach you how to develop a first application with JTheque Core.\nWe will develop a basic modular application, like an hello world. This little program will be composed of :\n\n    A JTheque application\n    A JTheque module who display an Hello World on the main view\n    A module who will add an option menu to display one more time \"Hello World\"\n\n\n\n\n2. JTheque environment\n\nThe first thing to do before starting develop our application and our modules is to download the \"development environment\" of JTheque Core. A JTheque application needs some files and librairies to work.\nYou can download an archive containing all necessary files on the website of the projects. Then you must choose the dev-base-XXX.zip file where XXX is the version number. In our case, we need the dev-base-2.0.3.zip file.\nWhen you've downloaded the file, unzip it. Here is the content of the folder :\n\n    core : Contains JTheque Core, the configuration and the application\n    lib : Contains all the librairies\n    modules : Contains all the modules\n    JTheque-Launcher.jar : The launcher of the application. You must execute this file to launch your application.\n\n\nWe only have two things to change in this folder. First, we have to add our application (application.xml) and its resources in the core folder. Then, we have to add our modules in the \"modules\" folder and declare it in the JTheque configuration.\n\n\n3. Application\n\nNow that we seen what is a JTheque Application, we'll develop it, the first part of our program.\nAn application is basically a container for modules. It has a name, a version but adds no functionaly to the application, this a function of the modules. An application without modules is not useful and vice-versa.\nAn application is composed of several things :\n\n    An XML file (application.xml) describing the application\n    Some images (in the core/images folder)\n    Eventually some .properties i18n files in the core/i18n folder\n\n\nTo define the internationalization values of the application, there is 2 ways. We can define the values directly in the XML file or use some i18n .properties files. This is this solution we will use in our case. The resource bundle must be named application and be in the core/i18n folder. Here are the files to create :\napplication.properties\nname=JTheque Demos\nauthor=Baptiste Wicht\nemail=baptistewicht@redaction-developpez.com\n\napplication_en.properties\nsite=http://jtheque.developpez.com/en\ncopyright=JTheque 2009 All rights reserved\n\napplication_fr.properties\nsite=http://jtheque.developpez.com/\ncopyright=JTheque 2009 Tous droits reserv\u00e9s\n\nThen, we can write the application.xml file :\nWe declared than our application is available in french and in english. Moreover, we declare () to use the i18n files. i18n properties.\nThe core is translated in english, french and german.\nFor the images, we start to declare a logo.png file and a icon.png file for the application. We can use other extension specifying type=\"jpg\" for exemple for a .jpg file.\nHere are the used images :\n\n\nWe will now make a first try. For that, you just have to launch the JTheque-Launcher.jar at the root of the JTheque folder. It will launch the core with our application.\nHere is the result :\n\nWe can see that the application launches weel, but there is nothing really interesting to do in this application because there is no modules to add functionalities.\n\n\n4. The first module\n\nNow that our module has been developed and is functional, we can make our first module of the application.\nThis module will be very simple. It just display \"Hello World !\" on the main componnent of the application in an internationalized way.\nTo declare a module, we need to create class with the @Module annotation. Then, we have to declare it in the Spring context and declare this last in the manifest of the jar.\nIt's not necessary to know Spring to use JTheque. If you don't want to use Spring in your application, you can just declare the module in the Spring context withtout using it and then develop your application without use Spring context. You just have to know that the module will be created by Spring.\nThe life cycle of a module is composed of three states :\n\n    pre-plug : To make pre-configuration\n    plug : Here you must add the module in the application. It means edit view, add config elements, ...\n    unplug : Remove the module from the application\n\n\nTo make operations in this 3 phases, you just have to add annotations on methods, respectively @PrePlug, @Plug et @Unplug. Then the application will detect this methods and invoke them.\nIn our case, we need to edit the main component of the view in the plug phase. So we doesn't need the other phases.\nStarting with declaring our module with necessary annotations :\npackage org.jtheque.demos.first;\n\nimport org.jtheque.core.managers.module.annotations.Module;\n\nimport org.jtheque.core.managers.module.annotations.Plug;\n\n@Module(id = \"jtheque-demo-module-1\", i18n = \"classpath:org/jtheque/demos/first/i18n/first\", version = \"1.0\", core = \"2.0.3\",\n        jarFile = \"jtheque-demo-module-1.jar\")\npublic final class DemoFirstModule {\n    @Plug\n    public void plug(){\n\n    }\n}\n\n\n\nHere again, there is nothing hard. The annotation Module declare the informations about the module. The plug method is for this time empty. The i18n annotation contains the path (Spring resource convention) to the resource bundle of the module. bundle du module.\nNow we can declare informations about the module in the i18n files.\nA i18n file is a simple .properties file who contains a list of key/value couples. A i18n file represent a language. We use a set of this files to internationalize the application. They must have the same base name and finish with _language where \"language\" is the short form of the language$ (de, fr, en, it, ...).\nThe key will be search depending on the id of the module. We directly add also the internationalization of the main view :\nfirst_en.properties\njtheque-demo-module-1.name=JTheque Demo Module 1\njtheque-demo-module-1.author=Baptiste Wicht\njtheque-demo-module-1.description=First demo module\nlabel.message=Hello World !\n\nfirst_fr.properties\njtheque-demo-module-1.name=JTheque Demo Module 1\njtheque-demo-module-1.author=Baptiste Wicht\njtheque-demo-module-1.description=Premier module de d\u00e9mo\nlabel.message=Bonjour le monde !\n\nThe application will automatically search and resolve this messages to internationalize the module. We put this files in the org/jtheque/demos/module/first/resources/18n folder.\nTo extend the application or access to the services of JTheque, we always have to use the Managers class who provide access to the managers (services) of JTheque Core. In our case, we need to access IViewManager who manage the view of the application.\nIn the plug() method, we just have to add a JLabel with an internationalizable text. In JTheque, to make a component internationalizable, we have to implement the Internationalizable interface and add it to ILanguageManager to keep it in the good language. In the case of a label, this component exists in JTheque Core, its the JThequeI18nLabel who takes a i18n key as constructor parameter :\n@Plug\npublic void plug(){\n    SwingUtils.inEdt(new Runnable(){\n        @Override\n        public void run(){\n            JThequeI18nLabel label = new JThequeI18nLabel(\"label.message\");\n            label.setFont(label.getFont().deriveFont(36f));\n\n            Managers.getManager(IViewManager.class).setMainComponent(label);\n        }\n    });\n}\n\n\n\nIt's easy. We get our manager with the Managers class, then, we set our label as the main component.\nNow we'll declare our module in Spring context. It's a simple XML file :\nfirst.xml\nWe put this file at the same level of DemoFirstModule. For those who doesn't know spring, it's exactly if we create a new instance of our module and assign it to a variable named firstModule.\nWe'll try this module. Then, we have to generate a jar of our project. The manifest of the jar must have the link to our XML file. Here is our manifest file :\nManifest-Version: 1.0\nModule-Context: org/jtheque/demos/first/first.xml\n\nThen we generate our Jar file and put it on the modules files of the JTheque environment with the name of jtheque-demo-module-1.jar.\nNow we have to configure JTheque to put our module in the application. To do that, we have to edit the config.xml file in the core.file. We just add the discovery tag to say that all the modules in the modules folder to the application.\nconfig.xml\nWe can now test the result launching JTheque-Launcher.jar and here is what we get :\n\nLike we can see, our module is good integrated in our application.\n\n\n5. The second module\n\nWe will now create a second module who will add an option menu to display another Hello World. We could of course do that in the first module, but it's to show how to create several modules.\nTo add options menu, we just need the plug pahse. Here is the base of the new module (DemoSecondModule) :\n@Module(id = \"jtheque-demo-module-2\", i18n = \"classpath:org/jtheque/demos/second/i18n/second\", version = \"1.0\",\n        core = \"2.0.3\", jarFile = \"jtheque-demo-module-2.jar\")\npublic final class DemoSecondModule {\n    @Plug\n    public void plug() {\n    }\n}\n\n\n\nWith this i18n files :\nsecond_fr.properties\njtheque-demo-module-2.name=JTheque Demo Module 2\njtheque-demo-module-2.author=Baptiste Wicht\njtheque-demo-module-2.description=Deuxi\u00e8me module de d\u00e9mo\ndialog.message=Bonjour le monde !\n\nsecond_en.properties\njtheque-demo-module-2.name=JTheque Demo Module 2\njtheque-demo-module-2.author=Baptiste Wicht\njtheque-demo-module-2.description=Second demo module\ndialog.message=Hello world !\n\nIt's basically the same things than for the first module. We'll now add an option to the \"File\" menu. For that, we have to add an internationalizable action, JThequeAction.\nSo here is our simple action :\npackage org.jtheque.demos.second;\n\nimport org.jtheque.core.managers.view.able.IViewManager;\nimport org.jtheque.core.managers.view.impl.actions.JThequeAction;\nimport org.jtheque.core.managers.Managers;\nimport java.awt.event.ActionEvent;\n\nfinal class HelloWorldAction extends JThequeAction {\n    HelloWorldAction() {\n        super(\"dialog.message\");\n    }\n\n    @Override\n    public void actionPerformed(ActionEvent e) {\n        Managers.getManager(IViewManager.class).displayI18nText(\"dialog.message\");\n    }\n}\n\n\n\nNothing hard, we use the IViewManager to display an internationalizable text in a dialog box. We can now add this action on the menu using the IFeatureManager. From JTheque Core 2.0.3, there is a declarative way to create menu actions with the Menu interface. For that, we can extends the AbstractMenu class and choose the methods to override to add menus (features).\n@Plug\n\npublic void plug() {\n    Managers.getManager(IFeatureManager.class).addMenu(new DemoMenu());\n}\n\nprivate static final class DemoMenu extends AbstractMenu {\n    @Override\n    protected List getFileMenuSubFeatures(){\n        return features(\n                createSubFeature(150, new HelloWorldAction())\n        );\n    }\n}\n\n\n\nWe just add an action on the \"File\" menu, with our action and we give it the 150 position (0 is the first position and 1000 is the last (exit)).\nThen we create the Spring xml file of the second module :\nsecond.xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n       xsi:schemaLocation=\"\n            http://www.springframework.org/schema/beans\n            http://www.springframework.org/schema/beans/spring-beans.xsd\">\n\n    <bean id=\"secondaryModule\" class=\"org.jtheque.demos.second.DemoSecondModule\" lazy-init=\"false\" />\n</beans>\n\n\n\nWe can now generate the Jar file of the second module with this manifest :\nManifest-Version: 1.0\nModule-Context: org/jtheque/demos/second/test.xml\n\nFinally, we can test the complete application using JTheque-Launcher.jar :\n\n\nOur second module is well integrated.\n\n\n6. Conclusion\n\nWith relatively few code, we have developed a modular applications with 2 modules and that can have a lot more of modules.\nThe services given by JTheque are many more. If you want to know more, for the moment, i'll guide you to the Javadoc of the last version of the core. I will try to create a full guide to present all the functionalities of the core.\nIf you want to comment this article, don't hesitate to add a comment on the comment form at the end of the page.\nIf you want to make a comment, a suggestion or talk about the JTheque project, you can also come to the dedicated forum. It's a french forum, but you can post in english.", 
      "tags": "Conception,Java,JTheque,Modular"
    }, 
    {
      "loc": "/posts/2010/02/hardware-guide-hard-disks.html", 
      "title": "Hardware Guide : The Hard Disks", 
      "text": "You want buy a new computer, but you cannot which hard disk to buy ? Or you want to buy a new hard disk for your computer ? So, this article is done for you. It will describe all the things you must be careful of when choosing a hard disk.\n\n\n1. Introduction\n\nThe hard disk is the element who enables you to store data of your computer. The operating system, your programs, your games and your documents will be stored in this device. So be careful not to stifle your computer choosing an inadequate hard disk.\nSo you have to control some criterias, like the capacity or the rotation speed.\n\n2. Capacity\n\nThe capacity of the hard disk is the quantity of informations it can store. This is the first choice critera, people often search some storage space. But this capacity depends of your needs. The capacity is calculated in Go (Gigaoctets) and the price is directly depending of the capacity.\nFor informations, 1 Go = 1024 Mo = 1 048 576 Ko = 1 073 741 824 octets. It now common to find hard disks with more than one To (Teraoctets). 1 To = 1024 Go.\nTo evaluate the necessary capacity, here are the capacity for some applications or files :\n\n    A program : Between 10 and 500 Mo\n    A video game : Between 200 Mo and several Go\n    A Word document of several pages : 50 Ko\n    A song in MP3 : 3 to 7 Mo\n    A numeric photography : 1 Mo\n    A film (DivX format) : 700 Mo\n    Windows XP : 5 to 10 Go\n    Windows Vista : 10 to 20 Go\n    Linux : 5 to 10 Go\n\n\nOf course, this is only estimations, but that can allow you to make an idea of what you need.\nIt's not usefull to buy a enormous hard disk when you have only some Word documents to store. The sellers will often try to sell you the biggest hard disks. So keep in mind your needs.\nFor example, a 1 To hard disk can contains :\n\n    More than 1400 movies in DivX format or\n    1 million of photos in medium format or\n    200'000 songs in MP3 format or\n    Several tens of millions of pages in Word format\n\n\nSo you can see that this kind of hard disk is often not necessary. I don't say that's a bad idea but it's a good thing to estimate your need before choosing an enormous (or too small). It's not really interesting to use moyen for space that we'll never use.\n\n\n3. Physical format\n\nThe first thing to decide is the physical format of the hard disk. There is 2 main formats of hard disks, namely :\n\n    3\"1/2 : This is the format of hard disks for desktop computer.\n    2\"1/2 : This is the hard disks for laptop.\n\n\nSo the choice is simple, if you need a hard disk for your laptop, you need a 2\"1/2 hard disk otherwise one 3\"1/2.\nThere is still the problem of external hard disk. In this case, the hard disk is directly inside a container, so this is not a big problem. If you search a little hard disk, opt for a 2\"1/2 else in most cases, choose a 3\"1/2.\n4. Interface\n\nThe next thing to verify in the interface of the hard disk. That is the way the hard disk will be connected to the motherboard. You cannot connect a SATA hard disk on a motherbord that have only IDE. Here are the main existing formats :\n\n    IDE (PATA) : This is the oldest interface, but also the most used one. The transfer rate is lowe than the other, but is even so acceptable for a normal usage. In its ATA133 version, the theorical transfer rate is 133 Mo/s\n    SATA : This interface has better transfer rates than PATA. There is two versions (SATA I and II). They have transfer rates of, respectively 150 Mo/s and 300 Mo/s.\n    SCSI : This interface is still better than SATA, but really the expansive and especially made for servers. Its theoretical transfert can go to 640 Mo/s.\n    SAS : Serial Attached SCSI : This is the evolution of SCSI. The transfer rate is better and not distributed between hard disks. But this format is not really widespread and exclusively reserved for servers at this time.\n\n\nYou also have to keep in mind that hard disk are limited in tranfer rate due to their mechanic state. So the transfer rate of the interface is mostly useful when several hard disks are connected on the same bus.\nFor a new PC, it's recommended to opt for SATA hard disks who are the new standard for hard disk. If you really want big transfer rates with many disks or if you want to build a server, you can choose SCSI or SAS depending on your budget.\n\n\n5. Rotation speed\n\nThe hard disk is often the slowest element of a PC. It's a lot slower than a processor. It's especially because it's mechanic. A disk is composed of a plate in constant rotation and a read/write head who moves on the plate to read and write the data. So we can improve the data transfer rate improving the rotation speed of the plate. But keep in mind that doesn't really improve the access time because for the transfer time, the principal problem is the shift of the head.\nWe have to distinguish here the 2\"1/2 and 3\"1/2 format because the speeds are not the same.\n5.1. Hard disk for laptop : 2\"1/2 format\n\nHere are the different speeds for a 2\"1/2 hard disk :\n\n    4200 rpm : It's the old version of the hard disk. That's not a good idea to buy one now.\n    5400 rpm : It's the standard speed for laptop hard disk.\n    7200 rpm : More and more hard disks are sell with this speed\n\n\nA hard disk with 5400 rpm is still comfortable, but it's really a good investment to buy a 7200rpm hard disk.\n5.2. Hard disks for desktop computer : 3\"1/2 format\n\nHere are the different speeds for a 3\"1/2 hard disk :\n\n    5400 Tours/min : It's the old version of the hard disk, not used anymore.\n    7200 Tours/min : It's the standard speed for desktop hard disk.\n    10'000 Tours/min : This is only SATA and SCSI hard disk. The capacity of this kind of disk is often limited.\n    15'000 Tours/min : This is only SCSI hard disk. You'll find only this disks in servers, very expensive.\n\n\nFor the hard disks for store your data, I recommend to use 7200rpm hard disk. But for the main disk, to store operating system and your programs, i recommend a 10'000 rpm with little capacity (36 or 72 Go). That will improve the start of your system and of your programs. It's really comfortable to work with.\n6. Memory cache\n\nThe actual hard disk have also a cache memory. This memory is used to store the most used data bits that can be reused. When this data are requested, they come directly from the memory cache so without mechanical access, this is faster. We have several memory cache sizes :\n\n    2Mo\n    8Mo\n    16Mo\n    32Mo\n    64Mo (very rare)\n\n\nIt's a bad idea to buy disk with less than 8Mo of memory cache. If you can, i recommend you to buy hard disk with at least 16Mo. 32Mo or 64Mo will be better but more expensive.\n\n\n7. Internal / External\n\nWe call an external hard disk an hard disk who stay outside the computer. This kind of hard disk is inside a container and connected to the computer with a FireWire or USB interface. This is really practical to move data.\nAn other possibility is an eSata interface who start to be available with the last computer and laptop, but not on all the computers. This the external version of the SATA format.\nIf you choose an external hard disk in USB, take care to the supported USB version of your computer. Indeed, the USB 1.0 is really slow to make data transfer. If you don't have USB 2.0 in your computer, don't buy an USB hard disk. Otherwise choose an hard disk with USB 2.0 or 3.0 if you have a really recent computer. Normally the USB 3.0 hard disk are compatible with older standard.\n8. SSD\n\nThe SSD (Solid State Drive) is a recent technology but that grows quickly. This is a hard disk but without any mechanic element. The transfer rates are better, the time to start the device is almost null and the device make no noise. Moreover the power consumption is lower and the crashworthiness is also better.\nNevertheless, the SSD have a limited life duration. Indeed, the memory cells supports only a maximal number of write cycles. This tend to be improved. By example Intel has announced a life duration of 5 years for his SSD X25-M.\nBut, the price is really more expensive than the price of a tranditional hard disk, 10 to 15 times more if we take the price per Go. En plus de cela, le prix est bien plus \u00e9lev\u00e9 que pour un disque dur traditionnel, environ 10 \u00e0 15 fois plus en prenant le prix au Go.\nIf you want to try SSD, this can really improve the start time of your computer and of your applications. So it's interesting to opt for a little SSD for the operating system (32 or 64 Go). But it's not reasonable to use a SSD to store data.\n9. Conclusion\n\nIn conclusion, although the capacity is really important, this is not the only criteria. You have to keep in mind the performances of the hard disk (memory cache, rotation speed, interface) to not decrease performances of your computer.\nBe also careful of the constructor and the series of the hard disk. It's a good thing to buy a more expensive one of a good construtor instead of a noname hard disk with several problems. Indeed, some series have problems and don't keep their promises at the level of the transfer rate. To know if a hard disk has a good reputation, the best thing is to consult comments of buyers in the sell website.", 
      "tags": "Hardware"
    }, 
    {
      "loc": "/posts/2010/02/java-keywords.html", 
      "title": "The reserved keywords of the Java Language", 
      "text": "This article will present you all the keywords of the Java Language and their purpose.\nFirst of all, what's a reserved keyword ? It's a keyword of the language, for example true.\nWhat does that change for the developer ? You cannot use one of there keywords to name a variable, a method, a class or a package. So you cannot have something like that :\nBoolean true = new Boolean(true);\n\npublic class true{}\n\npackage com.wichtounet.true;\n\n\n\nThis example will not pass the compilation. But you can use it into a variable identifier or by changing the case :\nBoolean trueBoolean = new Boolean(true);\n\npublic class TrueBoolean{}\n\npackage com.wichtounet.trueBoolean;\n\n\n\nIt's also really important for a developer to know all the keywords and to know how to use them.\n\n\nHere are the meanings of all the keywords.\nabstract\nModifier of class or method. This indicate that the class or method is abstract. A class must be declared abstract when one or more methods are abstract. An abstract class cannot be instanciated. You must create a subclass to use it. An abstract class can have abstract and normal methods.\nAn abstract method has no body and must be overriden by the subclass. An abstrac method cannot be final, static or private.\nAn interface is implicitely abstract like all its methods.\nHere is a little example of an abstract class.\npublic abstract class Person{\n    public abstract String getName(){}\n\n    @Override\n    public String toString(){\n        return \"My name is \" + getName();\n    }\n}\n\n\n\nNote that you can call an abstract method from a non-abstrac one.\nassert\nThis keyword enable to guarantee a boolean condition before continuing execution. This is like contract programming. We often verify the methods parameters with an assertion.\nAn AssertionError is launched if the condition is not true. The assertions are disabled by default. You have to use -ea or --enableassertions options to enable them. An assertion must never edit the state of something, because they can be disabled.\nprivate double divise(int a, int b){\n    assert b != 0 : \"Unable to divide by zero\";\n}\n\n\n\nNote that this example is not very good, in practice, it's better for this kind of test to throw an IllegalArgumentException.\nThis keyword is present since java 1.4.\nboolean\nboolean is a primitive type of Java. It's a type indicating if something is true or false. This is the only two values than a boolean variable can take. This keyword can be used for the type of a variable, a parameter or the return of a method.\nboolean test = true;\n\n\n\nbreak\nThis keyword enable to go out of a control instruction, an iteration operator or a try block.\nfor(int i = 0; i &amp;lt; 1555; i++){\n    if(condition){\n        break; //We go out of the loop\n    }\n}\n\n\n\nI't also often used to go out of a switch case statement :\nswitch(id) {\n  case 1 : System.out.println(\"I'm first\"); break;\n  case 2 : System.out.println(\"I'm second\"); break;\n  case 3 : System.out.println(\"I'm third\"); break;\n  default : System.out.println(\"I don't know where i'm\");\n}\n\n\n\nWe can also use the break operation with a label to specify which statemetn we want to break. But it's a really bad practice.\nbyte\nbyte is primitive type of Java. It represent a signed integer of 8 bits. So it can take values from -128 to 127.\nbyte var = 27;\n\n\n\ncase\nThis keyword indicate a label of the switch control instruction. It's used to make an action for a specific case :\nswitch(id) {\n  case 1 : System.out.println(\"I'm first\"); break;\n  case 2 : System.out.println(\"I'm second\"); break;\n  case 3 : System.out.println(\"I'm third\"); break;\n  default : System.out.println(\"I don't know where i'm !\");\n}\n\n\n\ncatch\nThis statement enable to catch an exception and to treat it. The catch block always follow a try block. If an exception is throwed inside of the try block, we arrive in the catch block and we can treat the exception.\ntry{\n    //Something\n} catch(AnException e){\n    //If AnException is throwed we go\n}\n\n\n\nchar\nchar is a primitive type of Java. It represent a character. Because character are only integer in Java, you can also see it like an unsigned integer of 16 bits from 0 to 65535. But if you do that, your code can quickly be hard to understand.\nchar var = 'a';\n\nchar var = 4;\n\n\n\nclass\nThis keyword declare a class. All declaration of a class must start with this keyword.\npublic class Test{\n    //...\n\n    private static class InnerClass {\n        //..\n        }\n}\n\n\n\nconst\nThis keyword is reserved but not used.\ncontinue\nThis keyword jump to the next iteration of a loop. So we go directly to the head (or the foot in the case of a do while) of the loop without executing the following instructions.\nwhile(i &amp;gt; 100){\n    if(i % 25 == 0){\n        continue; //We go to the next iteration without executing \"Others iterations\"\n    }\n\n    //Others operations\n}\n\n\n\ndefault\nThis word is the default label of a switch case. The code affected to the default case will be executed if there is no case that have been executed or if the last case has not used break statement.\nswitch(i){\n    case 1 :\n        System.out.println(\"i equals 1\");\n        break;\n    case 2 :\n        System.out.println(\"i equals 2\");\n        break;\n    default :\n        System.out.println(\"i doesn't equals 1\");\n}\n\n\n\ndo\nThis keyword introduce a do... while loop. The stop condition of the loop is verified after the execution of the body of the loop. So the first iteration is always done.\ndo{\n    //Operations\n} while(condition);\n\n\n\ndouble\ndouble is a primitive type of Java. It's a floating-point number coded with 64 bits (8 octets). So it can take any value from 4.9E-324 to 1.7976931348623157E308. But take in memory than there is a loss of precision when you make double operations.\ndouble var = 2.2335;\n\n\n\n\n\nelse\nThis keyword introduce the facultative part of the if condition operation. This part is executed if there is no other verified if condition.\nif(i == 2){\n    System.out.println(\"i equals 2\");\n} else {\n    System.out.println(\"i doesn't equals 2\");\n}\n\n\n\nenum\nThis keyword declare a enumeration. It seems a type who has only a finished set of values.\npublic enum Season {\n   SPRING, SUMMER, FALL, WINTER;\n}\n\n\n\nThis keyword is present since Java 5.0.\nextends\nThis keyword is used to say than a class extends an other class or an interface extends an other interface.\npublic class Actor extends Person{ //Actor IS-A Person\n    //...\n}\n\n\n\nfalse\nThis keyword is a value of the boolean type, it's the opposite of true.\nboolean var = false;\n\n\n\nfinal\nThis keyword is a modifier for method, variable or field or class :\nIn the declaration of a class, final indicate that this class cannot be extended.\nIn the declaration of a method, final indicates that this methods cannot be overriden (if the method is static or private, she's automatically final).\nIn the case of variable or field, final indicate that this reference is constant, we cannot change it anymore after declaration. In the case of objects, only the reference is constant, not the object. This is also useful to enable the usage of a variable in a anonymous class.\nfinally\nStatement follow by an instructions block. This block must follow a try or try-catch block. Regardless of how we go out of the try block, the finally block is executed. It's often used to close resources after usages.\ntry {\n    //Simple instructions\n} finally {\n    //Instructions always done after \"Simple instructions\"\n}\n\n\n\nfloat\nfloat is a primitive type of Java. It's a floating-point number coded with 32 bits (4 octets). So it can take any value from 1.4E-45 to 3.4028235E38.\nfloat variable = 4.44f;\n\n\n\nfor\nThis keyword introduce a for loop (while condition, we iterate, execute the for instruction). This loop has the particularity to allow instructions in its declaration. This declaration is made of 3 parts, separated by ;. The first is made from declare iteration variables, the second one is a condition and the third one can take any instruction.\nfor(int i = 0; i &amp;lt; 10; i++){\n      //Operations\n}\n\n\n\nThere is also an other kind of this loop, the foreach loop, introduced with Java 5.0. This extended for loop enabled to iterate on the content of a collection easily :\nSimpleObject[] objects = new SimpleObject[x];\n\n//...\n\nfor(SimpleObject object : objects){\n    object.doSomething();\n}\n\n\n\ngoto\nThis keyword is reserved but not used.\nif\nThis operator enabled to define facultative block code. This block of instructions will only be executed if the condition is verified.\nif(i == 1){ //Condition\n    i = 3; //Only execute if (i == 1)\n}\n\n\n\n\n\nimplements\nThis keyword is used in the declaration of a class to say that this class implements the functionalities of an interface. When a class implements an interface, she must define all the methods of the interface or be declared abstract.\npublic class JavaTester implements Tester{\n    @Override\n    public boolean test(){//Method defined in Tester\n                //Do something\n    }\n}\n\n\n\nimport\nThis keyword allow to make a shortcut to the name of the name. So we cannot have to write the complete path to the path, but only the name of the class. It makes the code really clearer.\nimport com.test.Tester;\n\nTester.test();\n\n\n\nIf we doesn't import the class, we must write the complete path :\ncom.test.Tester.test();\n\n\n\nFrom Java 5.0, we have also the import static who allow us to import directly the static methods and fields of an other class. This is practical to make the code clearer.\nimport static java.lang.Math.*;\n\npublic Class Test {\n   public void calc (int i) {\n      round(cos(i*(PI / 2)*E);\n   }\n}\n\n\n\ninstanceof\nIt's a condition instruction to verify than an object is of a certain type. If this object is of the asked type, the instruction will return true else false.\nif(myObject instanceof Reader){\n    System.out.println(\"myObject is of type Reader\");\n}\n\n\n\nint\nint is a primitive type of Java. It represent a signed integer of 32 bits (4 octets). So it can take values from -2'147'483'648 to 2'147'483'647.\nint var = 3;\n\n\n\ninterface\nThis keyword declare an interface. An interface define a functionality or a behavior who are the same for some classes. An interface has no concrete code, all the methods are abstract. An interface can also have public static final constants.\npublic interface Tester(){\n\npublic void test();\n\n}\n\n\n\nlong\nint is a primitive type of Java. It represent a signed integer of 64 bits (8 octets). So it can take values from -9'223'372'036'854'775'808 to 9'223'372'036'854'775'807.\nlong var = 33;\n\n\n\nnative\nThis keyword is used in the declaration of a method to indicate than she's not coded in Java, but in a native language in a separated file. So this kind of method has no body because the code is not in Java.\npublic native void openCDRomTray();\n\n\n\nnew\nThis operator instanciate a new object of a certain class. It will create a new object and class and call the constructor of the class.\nObject objet = new Object();\n\n\n\nnull\nnull is a special value indicating that the reference doesn't point on an object but on nothing. We say that this reference is null.\nString str = null;\n\n\n\npackage\nThis keyword is used at the top of the class to indicate in which package is this class.\npackage com.mypackage;\n\npublic lass MyClass {\n\n}\n\n\n\nprivate\nThis keyword is used in the declaration of variabbles, fields, methods or classes. When we declare it private, this attributes are only accessibles by the class in which they are declared.\nprivate int var = 11;\n\n\n\n\n\nprotected\nThis keyword is used in the decleration of field, methods or classes. When we declare it procted, this attributes are only accessibles by the sub classes and the classes of the same package.\nprotected int var = 11;\n\n\n\npublic\nThis keyword is used in the declaration of fields, methods or classes. When we declare it public, this attributes are acessible by all classes.\npublic int var = 11;\n\n\n\nreturn\nThis method exit of the curren method. We can use it without parameter to go out of a void method or with a value to return something from the method. Of course, in a void method we cannot use return with a value and vice-versa.\npublic int getInt(){\n    return 1;\n}\n\npublic void doSomething(){\n    return;\n}\n\n\n\nshort\nshort is primitive type of Java. It represent a signed integer of 16 bits (2 octets). So it can take values from -32768 to 32767.\nshort var = -22565;\n\n\n\nstatic\nThis keyword can be used in the declaration of a field, a method, a class or before a code block.\nIn a method, field or class declaration, static indicate that this member doesn't need an instance of the bounding class.\n//Access to the static method abs of the Math class.\n\nMath.abs(-1);\n\n\n\nOf course, a static being independant of the instance, cannot access to instance variables and methods.\nFrom a code block, we indicate that this block must be executed at the loading of the class.\npublic static ArrayList list = new ArrayList();\n\nstatic {\n    list.add(new String(\"x\"));\n    list.add(new String(\"y\"));\n}\n\n\n\nstrictfp\nThis keyword can be used in the declaration of a class, interface or method. It force the JVM to make calculation in accordance with the specification of the language so you have the guarantee that your calculation will have the same result regardless of the used VM.\nThis keyword is available from Java 1.2.\nsuper\nThis keyword is a reference on the super class, it seems the class we extends.\npublic class Child extends Mother(){\n\npublic Child(){\n    super(); //We call the constructor of the super class\n}\n\n@Override\npublic void myMethod(){\n    super.myMethod();//We call the method myMethod of the super class\n}\n\n\n\nswitch\nThis keyword introduce a control statement. This instruction test the value of an integer or an enum value and in function of the value execute the corresponding case. So we define some labels with the values we need to treat and the actions to execute in the specified case.\nswitch(value){\n    case 1 :\n        //Actions if value equals1\n        break;\n    case 2 :\n        //Actions if value equals 2\n        break;\n    case default :\n        //  in the other cases\n        break;\n}\n\n\n\nsynchronized\nThis keyword is used in concurrent programming in the declaration of a method or an instruction block to indicate that only one thread can access at the same time at this bloc or method.\npublic void synchronized method(){\n    System.out.println(\"Two threads cannot acess this method at the same time\");\n}\n\n\n\nThis is almost equivalent to :\npublic void methode(){\n    synchronized(this){\n        System.out.println(\"Two threads cannot call this method at the same time\");\n    }\n}\n\n\n\nIf the method is static, you can do like that :\npublic class MaClass {\n    public static void methode() {\n        synchronized(MaClass.class) {\n            // code\n        }\n    }\n}\n\n\n\nYou can also use an object as lock :\nsynchronized(monObjet) {\n    // code\n}\n\n\n\nthis\nThis keyword is a reference to the current object.\npublic MyClass(String attribute){\n    super();\n    this.attribute = attribute; //We take the attribute field of the class\n    this.refreshAttributes();   //We class the refreshAttributes methods on the current object\n}\n\n// We can also call the constructors of the current class\n\npublic MyClass(){\n    this(\"une valeur par d\u00e9faut\");\n    //We call the constructor defined at the top of the code\n}\n\n\n\n\n\nthrow\nThis instruction throw a new exception. The class of the exception must be in the hierarchy of Throwable. When an exception is launched, we go to the calling method or to the bouding catch block if there is one.\nif(error)throw new Exception(\"There is an error\");\n\n\n\nthrows\nThis keyword is used int the declaration of methods to indicate that this one can throw exceptions who are not caught.\npublic void read throws IOException {\n    //Code that can throws an IOException\n}\n\n\n\ntransient\nThis keyword enable to say than a field must not saved during the serialization of the class.\nprotected transient int variable = 2;\n\n\n\ntrue\nThis keyword is a value of the boolean type, it's the opposite of false.\nboolean variable = true;\n\n\n\ntry\nThis keyword introduce an instruction block. It doesn't have any other utility than allow the use of a catch and/or finally block.\ntry{\n    //Instruction\n} finally {\n    //Instructions\n}\n\n\n\nvoid\nThis keyword declare a method with no return type. This method returns nothing.\npublic void methodThatReturnsNothing(){\n    //Instructions diverses\n}\n\n\n\nvolatile\nWe use this keyword on fields to force the VM to refresh it's value at each use. With that we are sure to tuse the real value and not the cached value. This is only useful in concurrent programming.\npublic volatile int var = 5;\n\n\n\nwhile\nThis last keyword introduce a while loop. This loop will iterate while the condition is verified (true). The condition is verified before entering the loop, so it's possible to not enter in the loop if the condition is the condition is not verified.\nwhile(condition){\n    //Instructions\n}", 
      "tags": "Java"
    }, 
    {
      "loc": "/posts/2010/02/logging-with-slf4j.html", 
      "title": "Logging with SLF4J", 
      "text": "I. Introduction\n\nSLF4J is an abstract layer for logging APIs. The principle is roughly the same as Jakarta Commons Logging. The advantages of the use of such a layer enable to be completely independant of the logging implementation. So it's possible to easily change the logging implementation without modifying the existing code. You only have to change the configuration of the implementation. And finally in the case of the conception of a library, this leaves the user to choose the logging system.\nYou gonna tell me : if Commons Logging makes already that, why an other framework of logging abstraction ? Simply, because Commons Logging as his defaults. The first one concern the loading of the logging implementation. Indeed, the search is made dynamically at the execution through a classloader system. And this method can be problematic in several situations by example when the application use custom classloaders or when using OSGi. And finally the implementation of the Commons Logging can cause some memory leaks.\nFurthermore, Commons Logging constrain the user to test if a loging level is enabled or not before making logging containing heavy concatenation.\nWe will see than SLF4J solve this problems in an efficient way.\nYou can download the official distribution on the SLFJ4J website.\n\n\n2. Select the logging implementation\n\nUnlike of Commons Logging, SLF4J doesn't resolve the logging implementation at execution, but directly at the compilation with a bridging API. So more than the JAR of SLF4J you need the following JARs : the bridging JAR and the JAR of the implementation. Here is what you get with Log4J :\n\nAll that is made only by adding a JAR to the classpath. No need to configure nothing else than the implementation. You just have to be careful to call only the interface of SLF4J otherwise there is no more interest to use an abstract layer\n3. Redirect calls from others implementations\n\nMore than offer a logging abstraction, SLF4J give the user the possibility to redirect calls for an implementation to SLF4J who will himself redirect them to the used implementation.\nFor that, you just have to replace the Jar of the xxx implementation by the xxx-to-slf4j.jar file who will intercept the calls and redirect them to the SLF4J implementation.\nThe following diagram show exactly how the calls are redirected :\n\nWarning : Of course, you mustn't add the implementation and the jar of redirection in the classpath at the same time. And more important, you must never use the jar of redirection of the used SLF4J implementation. This creates an infinite circle that will be make your application crashes.\n\n\n4. API use\n\nThe API of SLF4J is not really hard to use and is very like the others implementations or abstractions like Log4J or Commons Logging. Here is how to get a logger :\norg.slf4j.Logger logger = org.slf4j.LoggerFactory.getLogger(HelloWorld.class);\n\n\n\nThen, you can use it like any other implementation with the methods debug(), info(), warn(), trace() et error(). Par exemple :\nlogger.info(\"Hello World\");\n\n\n\nBut this is not the strength of SLF4J. Let's take a simple logging example :\nlogger.debug(\"Info : x = \" + info.getX() + \", y = \" + info.getY() + \", str = \" + infos.getStr());\n\n\n\nThat means than all times this line is executed, a concatenation is done. This can quickly be heavy for the performance if the code is executed regularly. It's because we must first test if the level is enabled :\nif(logger.isDebugEnabled()){\n    logger.debug(\"Info : x = \" + info.getX() + \", y = \" + info.getY() + \", str = \" + infos.getStr());\n}\n\n\n\nThis times the performances are guaranteed, but this kind of code is not esthetical and is quickly heavy. Moreover the test is already done in the debug method who displays nothing if the debug level is not enabled. So why do the work twice ? SLF4J offer a new alternative really interesting :\nlogger.debug(\"Info : x = {}, y = {}, str = {}\", new Object[]{info.getX(), info.getY(), infos.getStr()});\n\n\n\nThe {} will be replaced by the parameters. The, the concatenation is only done if the logging level is enabled. Furthermore, this code is really cleaner than the two previous.\nWarning : In the case when the recuperation of the informations is heavy, you must test use the first method and test the level of log before logging the informations. By example we could imagine a getDebugInfos() on an object who mades a lot of informations to get informations. This method must not be executed if the log level is not enabled.\n5. Marker API\n\nThe Marker allow essentially to associate tags to logs. This tags enable the different appenders to take only some logs. Lets imagine an appender who write the log using encryption and that must only be used on logs marked as confidentials. The Marker enable us to implement that.\nThis functionaly is only available with the LogBack implementation : it's the only who implements the Marker. Nevertheless, you could use the Marker API with the other implementation, but that will have no effect.\nImagine by example an appender named CryptAppender who encode the log using some algorithm. We could configure it thus :\n<appender name=\"CRYPTED\" class=\"CryptAppender\">\n  <layout class=\"ch.qos.logback.classic.html.HTMLLayout\">\n    <pattern>%date%-5level%logger%msg</pattern>\n    <throwableRenderer class=\"ch.qos.logback.classic.html.DefaultThrowableRenderer\" />\n  </layout>\n  <evaluator class=\"ch.qos.logback.classic.boolex.OnMarkerEvaluator\">\n    <marker>CONFIDENTIAL</marker>\n  </evaluator>\n</appender>\n\n\n\nThe OnMarkerEvaluator enable to select only logs than have been marked with some tag. In our case, we have to mark to confidential logs with CONFIDENTIAl. Here is how to do that :\nMarker confidentialMarker = MarkerFactory.getMarker(\"CONFIDENTIAL\");\nlogger.error(confidentialMarker, \"C'est confidentiel !\");\n\n\n\nThat will not display the log directly but crypted.\nAn other use of this functionality could by example be the send by mail of some logs.\nYou could of course configure several appenders for the same tag. You could also create a Marker hierarchy :\nMarker parentMarker = MarkerFactory.getMarker(\"parent\");\nMarker childMarker = MarkerFactory.getMarker(\"child\");\nparentMarker.add(childMarker);\n\n\n\nDoing that, all that is logged with parentMarker or childMarker will be treated in appenders configured for parent and the appenders configured for child will only see what is logged with child.\n\n\n6. Mapped Diagnostic Context (MDC)\n\nThe \"Mapped Diagnostic Context\" (MDC) is, in summary, a simple map (key-value set) maintained by the logging framework. In that map, the application can put some key-value couple that could be used to add some informations in the logs.\nImagine that we treat informations on persons and that we display in logging. The name and the firstname of the person must be displayed in each lines of logging. We could can use MDC to automate the include of the name and the firstname in the logs.\nIt is possible to add values in MDC with the put method :\nMDC.put(\"prenom\", \"Baptiste\");\nMDC.put(\"nom\", \"Wicht\");\n\n\n\nThen, we can use them in the layout of logging. This layout can be configured in the implementation. At this time only Log4J, JUL and Logback support MDC. Here is a layout using MDC :\n%X{prenom} %X{nom} - %m%n\n\nThen, to display informations, we just have to do :\nlogger.info(\"Age {}\", age);\nlogger.info(\"Localisation {}\", localisation); \n\n\n\nThat will display :\nBaptiste Wicht - Age 22\nBaptiste Wicht - Localisation Suisse\n\nAnd finally if the MDC is configured between to logging instructions, this will directly change the logging :\nlogger.info(\"Age {}\", age);\nMDC.put(\"prenom\", \"Jacques\");\nlogger.info(\"Localisation {}\", localisation);\n\n\n\nwill display :\nBaptiste Wicht - Age 22\nJacques Wicht - Localisation Suisse\n\nThat can be very practical to stock and display global informations. For example a login, a session id or any other data.\n7. Conclusion\n\nIn conclusion, SLF4J is really good abstraction layer. It's really powerful, but remains really simple to use and the style is the same as the other existing logging systems.\nThe author of SLF4J advises to use LogBack as implementation. This is the reference implementation.\nIf you any comment to do on this article, don't hesitate to put it on the above form.", 
      "tags": "Java,Libraries"
    }, 
    {
      "loc": "/posts/2010/01/jr-introduction.html", 
      "title": "Introduction to JR programming language", 
      "text": "1. Language overview\n\nJR is a programming language especially created to solve concurrent programming problems. This language is an overview of Java who add to this last the main paradigms of concurrent programming. Moreover JR make easier the concepts still implemented in Java like process or semaphores. There is also several extensions for JR to add more functionalities like monitors and Conditional Critical Region (CCR). JR is the implementation of the SR language for Java.\nJR makes nothing else than add a layer over Java. Once we use the JR compiler, the JR source files are transformed in Java files and are executed by the virtual machine like any other Java class.\nJR is often used as a school support to learn concurrent programming.\nIn this article, we will see the bases of the programmation with JR.\nThe presented version is the one of June 2009, the version 2.00602 who are based on Java 6.0.\nThis article need that you've installed the JR environment on your system. An article is available here for the installation under Windows.\nIn this article, we will especially focus on the apports of the JR language for the concurrent programming. We will not see the the integrality of the language. JR has other benefits than make easier concurrent programming, but we will not see that in this article. Moreover, all the aspects of concurrent programming in JR will not be treated here.\n\n\n2. Hello World\n\nLike all other languages, we must start with a simple Hello World. Thus we'll create a file Hello.jr. Nothing special here, it's pure Java :\npublic class Hello {\n    public static void main(String[] args){\n        System.out.println(\"Hello World\");\n    }\n}\n\n\n\nThen we can compile it :\njrc Hello.jr\n\nThis will create a jrGen folder containing Java files. The result of a JR compilation is always a set of Java files corresponding to the translation of the JR files.\nTo launch your JR program, use the jr command followed by the name of the main class (class containing the main method) :\njr Hello\n\nThat will display :\nHello World\n\nThe jr command will also launch the compilation of Java files. This compilation will be done every time. If you want to make only the launch of compiled files, you can use the jrrun command.\nLike said in introduction, the JR language extends the Java language. So, you can code in Java with JR. Thus an Hello World is only Java.\n3. Processes\n\nThe first thing to see is the declaration of processes. This is done in an easier way than in Java. No need to instanciate some objects, this is done in a declarative way and JR make the rest.\nFor the declaration of process, JR introduce a new keyword process who enable to declare a process. Here is the simplest declaration of a process :\nprocess Hello {\n    System.out.println(\"Processus\");\n\n\n\nLike you can see it, it's easier than in Java. And better, no need to launch it, you just have to instanciate the class. A process can also be declared static. This times, it will not be launched at the instanciation of the class but at the resolution of the class by the virtual machine. By example, we can rewrite an HelloWorld in that way :\npublic class HelloProcess {\n    static process Hello {\n        System.out.println(\"Hello World\");\n    }\n\n    public static void main(String[] args){}\n\n\n\nwho display exactly the same thing as the first version of the Hello World. At the difference that our display is made from a thread.\nMoreover, JR enable to declare a big set of threads in a declaration with the following syntax :\nstatic process Hello((int id = 0; id &amp;lt; n; id++)){}\n\n\n\nThis will declare n threads. The syntax is the same as the for loop. Let's declare 25 threads Hello World :\npublic class HelloProcess {\n    static process Hello((int id = 0; id &amp;lt; 25; id++)){\n        System.out.println(\"Hello World from thread \" + id);\n    }\n\n    public static void main(String[] args){}\n\n\n\nWhen we launch that, we could have the following result :\nHello World from thread 2\nHello World from thread 24\nHello World from thread 11\nHello World from thread 22\nHello World from thread 0\nHello World from thread 4\nHello World from thread 6\nHello World from thread 8\nHello World from thread 10\nHello World from thread 12\nHello World from thread 14\nHello World from thread 16\nHello World from thread 18\nHello World from thread 20\nHello World from thread 23\nHello World from thread 21\nHello World from thread 19\nHello World from thread 17\nHello World from thread 15\nHello World from thread 13\nHello World from thread 9\nHello World from thread 7\nHello World from thread 5\nHello World from thread 3\nHello World from thread 1\n\nLike you can see, if you launch several times the program, the display is not same and the message commes in an order completely different order at each launch. Nothing can guarantee the order of the threads launches and still less the order of the execution of the instructions and you must not count on it.\nIt's the basis of the concurrent programming. You cannot predict the order of the instructions in the different threads.\n\n\n4. Quiescence action\n\nJR introduce a new concept, really powerful, the quiescence action. It's an action who's executed when the system is quiescent. It seems that all the process are finished or remains in deadlocks.\nBefore that, we use to introduce the concept of operations. In our case, an operation is a simple method declared with the op keyword. But in JR an operation is more than a method and could be invoked in different ways and permit other things that methods, but this is beyond the scope of this article.\nHere is a declaration of a simple operation.\npublic static op void end(){\n    System.out.println(\"End\")\n\n\n\nSo, this is a simple method with the op prefix. You can invoke it like any other method. But you can also declare it like the action to execute when the system is in quiescence state. If we take our example of the 25 hello world and if we define the quiescence action here is what we get :\nimport edu.ucdavis.jr.JR;\n\npublic class QuiescenceProcess {\n    static process Hello((int id = 0; id &amp;lt; 25; id++)){\n        System.out.println(\"Hello World from thread \" + id);\n    }\n\n    public static void main(String[] args){\n        try {\n            JR.registerQuiescenceAction(end);\n        } catch (edu.ucdavis.jr.QuiescenceRegistrationException e){\n            e.printStackTrace();\n        }\n    }\n\n    public static op void end(){\n        System.out.println(\"End\");\n\n\n\nWe use the registerQuiescenceAction(op) method of the JR class. This class provide some utility methods for the JR programs\nAnd a launch, we see something like that :\nHello World from thread 0\nHello World from thread 22\nHello World from thread 23\nHello World from thread 21\nHello World from thread 24\nHello World from thread 20\nHello World from thread 19\nHello World from thread 18\nHello World from thread 17\nHello World from thread 16\nHello World from thread 15\nHello World from thread 14\nHello World from thread 13\nHello World from thread 12\nHello World from thread 11\nHello World from thread 10\nHello World from thread 9\nHello World from thread 8\nHello World from thread 7\nHello World from thread 6\nHello World from thread 5\nHello World from thread 4\nHello World from thread 3\nHello World from thread 2\nHello World from thread 1\nEnd\n\nThis is really useful to execute an action after the end of the system and verify something on the system. By example, display a message in the case of a deadlock or display debug informations on the executed operations.\n\n\n5. Semaphores\n\nWe will now see how to use one of the basic concept of concurrent programming : the semaphores. The semaphores are a really simple concept but very powerful. A semaphore represent a certain integer valur representing the number of threads that can go in a certain portion of code, call it \"s\". A semaphore has two actions :\n\n    P : make the thread wait while s equals 0 and then decrement s.\n    V : increment s.\n\n\nThis two operations are atomic. We use the semaphores to protect a critical section who need to be executed in an atomic way. We can also use semaphores to restrain the number of threads that can execute some instructions in parralel.\nThe declaration and the use of semaphores is really easy. Here is how you can declare a semaphore with a initial value of 1 :\nsem mutex = 1;\n\n\n\nThen, the operations P et V are extremely simple to use :\nP(mutex);\n//Critical section\nV(mutex);\n\n\n\nThe semaphores are principally used to solve the critical section problem. Imagine a simple example, but who show exactly the problem that the semaphore can solve :\nprivate static int value = 0;\n\nstatic process Calculator((int id = 0; id &lt; 50; id++)){\n    for(int i = 0; i &lt; 5; i++){\n        value = value + 2;\n    }\n}\n\n\n\nBecause this code launch 50 threads who add each one 5 times 2 to value, we could think that value must be 500 at the end of the execution, isnt'it ?\nBut nothing guarantee that result. This is known as the interleaving in concurrent programming. This is because the + 2 operation is in reality 3 operations :\n\n    read the value of value\n    add 2 to the read value\n    set the new value to value\n\n\nA thread can be put in wait just after 1 and do the incrementation on the old value but other threads have still made the incrementation, but it has the old value when it mades the +2 and write and false value to value. To prove that to you, execute the following code several times :\nimport edu.ucdavis.jr.JR;\n\npublic class SemaphoreProcess {\n    private static int value = 0;\n\n    static process Calculator((int id = 0; id &lt; 50; id++)){\n        for(int i = 0; i &lt; 5; i++){\n            value = value + 2;\n        }\n    }\n\n    public static void main(String[] args){\n        try {\n            JR.registerQuiescenceAction(end);\n        } catch (edu.ucdavis.jr.QuiescenceRegistrationException e){\n            e.printStackTrace();\n        }\n    }\n\n    public static op void end(){\n            System.out.println(value);\n    }\n}\n\n\n\nOn my computer, i've the following results.\n498\n500\n500\n500\n496\n\nAnd if we use greater values, it's even worse. By example, with 100 threads and 100 iterations :\n20000\n19560\n19912\n19758\n20000\n\nBut this problem can be solved with semaphores :\nprivate static sem mutex = 1;\nprivate static int value = 0;\n\nstatic process Calculator((int id = 0; id &amp;lt; 50; id++)){\n    for(int i = 0; i &amp;lt; 5; i++){\n        P(mutex);\n        value = value + 2;\n        V(mutex)\n        }\n}\n\n\n\nWith that, we have the guarantee that only one thread can do the incrementation at a time and make it atomic. Then all the executions will finish with a value of 500. But that of course impact the performances because instead of x threads who made operations in a parralel way, we've now only one thread at a time. The example with 100 threads and 100 iterations is really slow. We can improve performance using the mutex semaphore around the loop. But the performances are to be considered differently in each example. So we must use wisely the synchronization methods of threads.\n\n\n6. Conclusion\n\nSo, we've now discover the main concepts of the JR programming language. Like you have see in this article, this programming language enable to make easier the use of concurrent programming concepts.\nI hope that this article has been useful to you to discover the JR Programming Language, and why not, to learn and use this language.", 
      "tags": "Java,JR"
    }, 
    {
      "loc": "/posts/2010/01/install-jr-windows.html", 
      "title": "Install the JR environment on Windows", 
      "text": "1. JR Programming language\n\nThis article will present you the installation of JR on Windows. It's not an article to learn the JR programming language, this article focus on the installation of JR on Windows.\nJR is a programming language especially created to resolve concurrent programming problems. This language is an overlay of Java who add to this last the main paradigms of the concurrent programming. Moreover, JR make easier some concepts also implemented in Java like the process or the semaphores. There is also extensions to JR to implement other functionalities like monitors and Conditional Critical Region (CCR). JR is the implemenation of the SR language for Java.\nJR is mainly used as a school support to learn concurrent programming.\nIn this article, we'll see how to install the JR environment under Windows.\nThe used version is the one of June 2009, the 2.00602 who is based on Java 6.0.\n2. Prerequisites\n\nThe prerequisites of JR are not many, you need two things :\n\n    Java : in the case of the last version of JR, you need Java 6.0. An older version (1.00601) is still available for Java 1.4. To install it if it's not yet the cas, go to the website of Sun and follow the described procedure.\n    Perl : go on the official site and download the last version of ActivePerl. Then, you just have to follow the installation procedure.\n\n\nOnce this two programs installed, we can go to the installation of JR.\n\n\n3. Installation\n\nThe installation under Linux is quite simple, but under Windows, it's a little more complicated.\nThe first thing to do is to download JR :\n\n    Tar format\n    Tar.Gz format\n    Zip format\n\n\nOnce the donwload finished, you have to decompress the file where you want to install the program. In the rest of the article, we will use C:\\Program Files\\JR\\ for installation folder. If you doesn't install the program here, you just have to replace this with your installation folder.\nThen, you have to configure several environment variables. First of all, you have to set the JR_HOME variable who must point to the installation folder : JR_HOME=C:\\Program Files\\JR.\nAfter that, you have to add JR_HOME to the PATH : PATH=%PATH%;%JR_HOME%\\bin\\ to use the JR commands.\nYou have also to create the CLASSPATH to integrate the classes of JR : CLASSPATH=.;%JR_HOME%\\classes\\jrt.jar;%JR_HOME%\\classes\\jrx.jar. Be careful to not forget the dot at the beginning of the variable.\nThe, you have to configure two constants : JRSH=cmd et JRSHC=/C.\nTo resume, here are all the environments variables and their value.\nJR_HOME=C:\\Program Files\\JR\\\nPATH=%PATH%;%JR_HOME%\\bin\\\nCLASSPATH=.;%JR_HOME%\\classes\\jrt.jar;%JR_HOME%\\classes\\jrx.jar\nJRSH=cmd\nJRSHC=/C\n\nThen, JR must works fine.\n4. Test the installation\n\nNow, we can test the installation. For that, open a command line (Start menu -> Execute -> cmd) et move to the JR folder with the cd command :\ncd %JR_HOME%\n\nAnd then launch this two commands :\ncd vsuite\n..\\jrv\\jrv quick\n\nThis should start serveral tests. It will just display some informations about your system. And if all works fine, you should see something like that :\nC:\\Program Files\\JR\\vsuite>..\\jrv\\jrv quick\nStarting JRV\nJR_HOME= C:\\Program Files\\JR\\\nJRC=     perl \"C:\\Program Files\\JR\\/bin/jrc\"\nJRRUN=   perl \"C:\\Program Files\\JR\\/bin/jrrun\"\nJAVAC=   \"C:\\Program Files\\Java\\jdk1.6.0_17/bin\\javac.EXE\"\nJAVA=    \"C:\\Program Files\\Java\\jdk1.6.0_17/bin\\java.EXE\"\nccr2jr=  perl \"C:\\Program Files\\JR\\/bin/ccr2jr\"\ncsp2jr=  perl \"C:\\Program Files\\JR\\/bin/csp2jr\"\nm2jr=    perl \"C:\\Program Files\\JR\\/bin/m2jr\"\nWHICH=   perl \"C:\\Program Files\\JR\\/bin/which.pl\"\nCMP=     perl \"C:\\Program Files\\JR\\/bin/cmp.pl\"\nGREP=    perl \"C:\\Program Files\\JR\\/bin/grep.pl\"\nSORT=    perl \"C:\\Program Files\\JR\\/bin/sort.pl\"\nTAIL=    perl \"C:\\Program Files\\JR\\/bin/tail.pl\"\njr compiler version \"2.00602 (Mon Jun 1 10:59:20 PDT 2009)\"\njr rts      version \"2.00602 (Mon Jun 1 10:59:25 PDT 2009)\"\nHOST= DESKTOP-PC\nStart Directory= C:\\Program Files\\JR\\/vsuite\nJR.JRT = C:\\Program Files\\JR\\/classes/jrt.jar\n  -rw-rw-rw-   1 0        0          2090324 Jun  1  2009 C:\\Program Files\\JR\\/classes/jrt.jar\nJR.JRX = C:\\Program Files\\JR\\/classes/jrx.jar\n  -rw-rw-rw-   1 0        0           227198 Jun  1  2009 C:\\Program Files\\JR\\/classes/jrx.jar\nOperating System= Windows_NT\noriginal CLASSPATH= .;C:\\Program Files\\JR\\\\classes\\jrt.jar;C:\\Program Files\\JR\\\\classes\\jrx.jar\njrv sets CLASSPATH= .;C:\\Program Files\\JR\\/classes/jrt.jar;C:\\Program Files\\JR\\/classes/jrx.jar\nDATE= Thu Jan 14 19:01:35 2010\nquick/baby:\nquick/fact_2:\nquick/misc_invocation_count_st_by_0:\nDATE= Thu Jan 14 19:01:45 2010\nElapsed time (hh:mm:ss)= 00:00:10\n\nIf you want to launch more tests, you can do it launching this command :\n..\\jrv\\jrv\n\nThis time, the program will execute a lot of tests. This tests can take a long time, fast an hour on some system. Moreover, several tests needs RSH, but it's not useful in our case.\n5. Conclusion\n\nIf we follow all this steps of the installation, JR is not as hard to install. You just have to configure the variables and to launch the installation test.\nIf you want more informations about the JR language, i'll invite you to consult the official site of one of his creators, Ronald A. Olsson.", 
      "tags": "Java,JR"
    }, 
    {
      "loc": "/posts/2010/01/dont-use-shorts-in-loop.html", 
      "title": "Tip : Don\u2019t use shorts for loop indexes !", 
      "text": "After a post I read on a french forum, i asked myself of the performances using shorts as loop indexes for loop with few iterations (less than 32768).\nAt first view, it can be tempting because we save 2 octets, so why use an int instead a short ?\nBut, when we think of that, we see that the int is more adapted. Indeed, it's more performant.\nWhy ?\nIn Java language, all the operations on integers are made in int. Thus, if we use a short as loop index, at each iterations, a typecasting will be made, that's really heavier than a simple affectation to int.\nHere were my first results :\nTime for int : 1441 ms\nTime for short : 3015 ms\n\nThe short version is two times slower !\nBut like Jean have said, my first test was not correct at all because it doesn't consider some issues that could occurs with micro-benchmarks.\nSo I write a new test using a Java Benchmarking framework from Brent Boyer. Here is a little test with that framework :\npackage com.wicht;\n\nimport bb.util.Benchmark;\nimport java.util.concurrent.Callable;\n\npublic class ShortIndexesLoop {\n    public static void main(String[] args) {\n        Callable callableInt = new Callable(){\n            public Long call() throws Exception {\n                long result = 0;\n\n                for (int f = 0; f &amp;lt; 32760; f++){\n                      result += f;\n                  }\n\n                return result;\n            }\n        };\n\n        Callable callableShort = new Callable(){\n            public Long call() throws Exception {\n                long result = 0;\n\n                for (short f = 0; f &amp;lt; 32760; f++){\n                      result += f;\n                  }\n\n                return result;\n            }\n        };\n\n        try {\n            System.out.println(\"Result with int \" + new Benchmark(callableInt));\n            System.out.println(\"Result with short \" + new Benchmark(callableShort));\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n    }\n}\n\n\n\nAnd here are the results :\nResult with int first = 695.181 us, mean = 43.233 us (CI deltas: -49.358 ns, +74.073 ns), sd = 42.938 us (CI deltas: -11.634 us, +16.426 us)\nResult with short first = 733.224 us, mean = 45.679 us (CI deltas: -62.975 ns, +63.932 ns), sd = 45.567 us (CI deltas: -5.877 us, +8.020 us)\n\nSo the results are lower. This time, the short version is 5.657% slower than the int version. Note that this can vary a lot depending on your configuration.\nI talk here of for loops, but the case is the same when you use while loops with indexes.\nHere are also the results with long, double and float versions :\nResult with long first = 816.555 us, mean = 104.771 us (CI deltas: -236.563 ns, +344.219 ns), sd = 143.295 us (CI deltas: -39.149 us, +63.700 us)\nResult with float first = 1.018 ms, mean = 58.055 us (CI deltas: -87.036 ns, +113.537 ns), sd = 70.757 us (CI deltas: -14.269 us, +19.962 us)\nResult with double first = 912.115 us, mean = 57.918 us (CI deltas: -66.644 ns, +91.312 ns), sd = 55.185 us (CI deltas: -12.617 us, +25.160 us)\n\nWe can see that the long version is the slowest one and that float and double are equivalent but slower than int and short.\nTo conclude, always use int as loop indexes add a very little improvements of performances, but not a great thing and do not use long for loops indexes.", 
      "tags": "Benchmarks,Java,Performances,Tips"
    }, 
    {
      "loc": "/posts/2010/01/new-design-jtheque-website.html", 
      "title": "New design for JTheque Web site", 
      "text": "I've made a new design for the JTheque web site : http://jtheque.developpez.com/en\nI took the same design than for my personal web site. The web site is still generated with Maven 2, but i use a custom maven skin to generate the site.", 
      "tags": "JTheque,Maven"
    }, 
    {
      "loc": "/posts/2009/12/swing-user-interface-jtable.html", 
      "title": "Creation of Swing User Interface : Tables (JTable)", 
      "text": "1. Introduction\n\nThis article will introduce you to create tables in Swing. This composent often gives problems when we start with Swing. I will try to explain the different concepts linked to the use of tables in Swing.\nIn this document we will see the basic concepts of JTable, the definition of table's models, the dynamic modification of table, the way to edit the rendering of cells, the edition of the content of the table and finally the sort and the filter of the table.\n\n\n2. Elementary concepts\n\nA JTable is a Swing component enabling the program to display a table formed of a certain number of lines and columns. More than the content lines, the JTable has also a header line displaying a title for each column.\nA JTable has data and header. We can see the data like a two-dimensional array in which all data correspond to the data of a cell and we can see the header's data like a unidimentional array of String.\nJTable use diffent concepts of Swing :\n\n    A model to keep the data. A JTable use a class implementing\u00a0TableModel. We will see later how to specify a data model.\n    A renderer for the rendering of cells. We can specify a\u00a0TableCellRenderer for each column class. Once again we will see that later.\n    An editor to edit the content of a cell. We can specify a TableCellEditor for each column class.\n\n\nDuring this article, we will develop a very simple program to manage a list of friends. Here are the infromations about a friend :\n\n    A name and firnstname (Class String)\n    A favourite color (Class Color)\n    A gender (boolean man/woman)\n    A sport he like to do (Enum Sport)\n\n\nHere is the Sport enumeration :\npublic enum Sport {\n    TENNIS,\n    FOOTBALL,\n    SWIMMING,\n    NOTHING\n}\n\n\n\nWe will start with a basic first version of our application.\nThe easiest way, but not the best, is to use two arrays and to give them to the JTable constructor.\nSo, here is the most basic implementation of our program :\npublic class JTableBasicWithPanel extends JFrame {\n    public JTableBasicWithPanel() {\n        super();\n\n        setTitle(\"Basic JTable in a JPanel\");\n        setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);\n\n        Object[][] data = {\n                {\"Johnathan\", \"Sykes\", Color.red, true, Sport.TENNIS},\n                {\"Nicolas\", \"Van de Kampf\", Color.black, true, Sport.FOOTBALL},\n                {\"Damien\", \"Cuthbert\", Color.cyan, true, Sport.NOTHING},\n                {\"Corinne\", \"Valance\", Color.blue, false, Sport.SWIMMING},\n                {\"Emilie\", \"Schr\u00f6dinger\", Color.magenta, false, Sport.FOOTBALL},\n                {\"Delphine\", \"Duke\", Color.yellow, false, Sport.TENNIS},\n                {\"Eric\", \"Trump\", Color.pink, true, Sport.FOOTBALL},\n        };\n\n        String[] headers = {\"First name\", \"Name\", \"Favourite color\", \"Gender\", \"Sport\"};\n\n        JTable table = new JTable(data, headers);\n\n        getContentPane().add(table.getTableHeader(), BorderLayout.NORTH);\n        getContentPane().add(table, BorderLayout.CENTER);\n\n        pack();\n    }\n\n    public static void main(String[] args) {\n        new JTableBasicWithPanel().setVisible(true);\n    }\n\n\n\nWe use the constructor JTable(Object[][] data, Object[] entetes) to manage our data and headers. To add our table to a JPanel, we must add separately the header and the table itself.\nThat will give us this result :\n\nWith a few number of lines of code, we have a functional table. Nevertheless, this first implementation has some disadvantages :\n\n    We cannot display more lines than the lines that can ben displayed by the window.\n    The data are totally static\n    We cannot manage the way the data are rendered.\n    There is no distinction between the view and the datas\n    The column Color and Gender are not really esthetic\n\n\nThe first point is easily solvable. The good way to add a JTable in container is to use a JScrollPane who enable to display more lines than the windows has space. For the rest of the article, we will always use a JScrollPane. So, here is a new version with a JScrollPane :\npublic class JTableBasicWithScrollPane extends JFrame {\n    public JTableBasicWithScrollPane() {\n        super();\n\n        setTitle(\"Basic JTable in a JScrollPane\");\n        setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);\n\n        Object[][] data = {\n                {\"Johnathan\", \"Sykes\", Color.red, true, Sport.TENNIS},\n                {\"Nicolas\", \"Van de Kampf\", Color.black, true, Sport.FOOTBALL},\n                {\"Damien\", \"Cuthbert\", Color.cyan, true, Sport.NOTHING},\n                {\"Corinne\", \"Valance\", Color.blue, false, Sport.SWIMMING},\n                {\"Emilie\", \"Schr\u00f6dinger\", Color.magenta, false, Sport.FOOTBALL},\n                {\"Delphine\", \"Duke\", Color.yellow, false, Sport.TENNIS},\n                {\"Eric\", \"Trump\", Color.pink, true, Sport.FOOTBALL},\n        };\n\n        String[] headers = {\"First name\", \"Name\", \"Favourite color\", \"Gender\", \"Sport\"};\n\n        JTable table = new JTable(data, headers);\n\n        getContentPane().add(new JScrollPane(table), BorderLayout.CENTER);\n\n        pack();\n    }\n\n    public static void main(String[] args) {\n        new JTableBasicWithScrollPane().setVisible(true);\n    }\n\n\n\nNow, we add directly the entire JTable in the JScrollPane. Here is the result :\n\nThis version is already better than the previous, but this is not the best approach. We will improve it in the next chapters.\n\n\n3. The table's model\n\nAn essential thing to do is to use a table's model to manage the data. So, we must create a class implementing TableModel. In practice, we rarely directly implement TableModel, we normally extends AbstractTableModel and we define the necessary methods only. To start, here are the methods we must override for our static model :\n\n    int getRowCount() : Return the number of lines of the table.\n    int getColumnCount() : Return the number of columns of the table.\n    Object getValueAt(int rowIndex, int columnIndex) : Return the the value a the specified cell.\n    String getColumnName(int columnIndex) : Return the header for the specified column\n\n\nWe will create our first model. To start, we will let the data in a two-dimensional array :\npublic class ModelStatic extends AbstractTableModel {\n    private final Object[][] data;\n\n    private final String[] headers = {\"First name\", \"Name\", \"Favourite color\", \"Gender\", \"Sport\"};\n\n    public ModelStatic() {\n        super();\n\n        data = new Object[][]{\n                {\"Johnathan\", \"Sykes\", Color.red, true, Sport.TENNIS},\n                {\"Nicolas\", \"Van de Kampf\", Color.black, true, Sport.FOOTBALL},\n                {\"Damien\", \"Cuthbert\", Color.cyan, true, Sport.NOTHING},\n                {\"Corinne\", \"Valance\", Color.blue, false, Sport.SWIMMING},\n                {\"Emilie\", \"Schr\u00f6dinger\", Color.magenta, false, Sport.FOOTBALL},\n                {\"Delphine\", \"Duke\", Color.yellow, false, Sport.TENNIS},\n                {\"Eric\", \"Trump\", Color.pink, true, Sport.FOOTBALL},\n        };\n    }\n\n    public int getRowCount() {\n        return data.length;\n    }\n\n    public int getColumnCount() {\n        return headers.length;\n    }\n\n    public String getColumnName(int columnIndex) {\n        return headers[columnIndex];\n    }\n\n    public Object getValueAt(int rowIndex, int columnIndex) {\n        return data[rowIndex][columnIndex];\n    }\n\n\n\nAnd we modify the JTable to use this model :\npublic class JTableBasicWithStaticModel extends JFrame {\n    public JTableBasicWithStaticModel() {\n        super();\n\n        setTitle(\"JTable with static model\");\n        setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);\n\n        JTable table = new JTable(new ModelStatic());\n\n        getContentPane().add(new JScrollPane(table), BorderLayout.CENTER);\n\n        pack();\n    }\n\n    public static void main(String[] args) {\n        new JTableBasicWithStaticModel().setVisible(true);\n\n\n\nSo, we've created a class extending AbstractTableModel and overriding the essential methods. The data are always stored the same way, but this solution is more flexible and cleaner. If we watch the JFrame, we can see that there is no more data in this class, that's really better, isn't it ? Moreover, we have now total access to the data and the way they are stored. Nothing changed for the view :\n\nWe've now a good base, but we will improve it. Normally, it's extremely rer to have data directly in arrays. Java is an Object Orienter language, so we will use objects. We will create a class Friend :\npublic class Friend {\n    private String name;\n    private String firstName;\n    private Color color;\n    private boolean gender;\n    private Sport sport;\n\n    public Friend(String name, String firstName, Color color, boolean gender, Sport sport) {\n        super();\n\n        this.name = name;\n        this.firstName = firstName;\n        this.color = color;\n        this.gender = gender;\n        this.sport = sport;\n    }\n\n    public String getName() {\n        return name;\n    }\n\n    public void setName(String name) {\n        this.name = name;\n    }\n\n    public String getFirstName() {\n        return firstName;\n    }\n\n    public void setFirstName(String firstName) {\n        this.firstName = firstName;\n    }\n\n    public Color getColor() {\n        return color;\n    }\n\n    public void setColor(Color color) {\n        this.color = color;\n    }\n\n    public boolean isGender() {\n        return gender;\n    }\n\n    public void setGender(boolean gender) {\n        this.gender = gender;\n    }\n\n    public Sport getSport() {\n        return sport;\n    }\n\n    public void setSport(Sport sport) {\n        this.sport = sport;\n\n\n\nSo, a simple data class. And we will use it in our model :\npublic class ModelStaticObject extends AbstractTableModel {\n    private final Friend[] friends;\n\n    private final String[] headers = {\"First name\", \"Name\", \"Favourite color\", \"Gender\", \"Sport\"};\n\n    public ModelStaticObject() {\n        super();\n\n        friends = new Friend[]{\n                new Friend(\"Johnathan\", \"Sykes\", Color.red, true, Sport.TENNIS),\n                new Friend(\"Nicolas\", \"Van de Kampf\", Color.black, true, Sport.FOOTBALL),\n                new Friend(\"Damien\", \"Cuthbert\", Color.cyan, true, Sport.NOTHING),\n                new Friend(\"Corinne\", \"Valance\", Color.blue, false, Sport.SWIMMING),\n                new Friend(\"Emilie\", \"Schr\u00f6dinger\", Color.magenta, false, Sport.FOOTBALL),\n                new Friend(\"Delphine\", \"Duke\", Color.yellow, false, Sport.TENNIS),\n                new Friend(\"Eric\", \"Trump\", Color.pink, true, Sport.FOOTBALL)\n        };\n    }\n\n    public int getRowCount() {\n        return friends.length;\n    }\n\n    public int getColumnCount() {\n        return headers.length;\n    }\n\n    public String getColumnName(int columnIndex) {\n        return headers[columnIndex];\n    }\n\n    public Object getValueAt(int rowIndex, int columnIndex) {\n        switch(columnIndex){\n            case 0:\n                return friends[rowIndex].getFirstName();\n            case 1:\n                return friends[rowIndex].getName();\n            case 2:\n                return friends[rowIndex].getColor();\n            case 3:\n                return friends[rowIndex].isGender();\n            case 4:\n                return friends[rowIndex].getSport();\n            default:\n                return null; //Must never happens\n        }\n\n\n\nNow, the code starts to be interesting. It's now that we start to understand the purpose of a model. Now, if we want change the order of two columns, we just have to invert them in the getValueAt() method, but this would not have been possible without a model.\nFor the rendering, we just have to use the new model instead of the old one :\npublic class JTableBasicWithStaticModelObject extends JFrame {\n    public JTableBasicWithStaticModelObject() {\n        super();\n\n        setTitle(\"JTable with static model and objects\");\n        setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);\n\n        JTable table = new JTable(new ModelStaticObject());\n\n        getContentPane().add(new JScrollPane(table), BorderLayout.CENTER);\n\n        pack();\n    }\n\n    public static void main(String[] args) {\n        new JTableBasicWithStaticModelObject().setVisible(true);\n    }\n}\n\n\n\nOnce again, nothing change in rendering. In the next chapter, we will make our table dynamic enabling to add/remove friends of the table.\n\n\n4. Add/Remove lines\n\nWe will now make our application a litlle more interesting and especially make our model essential. It seems give the user the possibility to add/remove lines of the table. We will see at chapter 6 how to edit the values of the cells.\nThe first thing to do is to make our model dynamic. For that, we will add the methods addFriend() and removeFriend. To inform the table that there is changes on the data, we just have to call the fireXXX methods who are already defined in AbstractTableModel. Moreover, we must of course use a data structure who is dynamic. The array is not really useful for that. So we will use an ArrayList. Here is our dynamic model :\npublic class DynamicModelObject extends AbstractTableModel {\n    private final List friends = new ArrayList();\n\n    private final String[] headers = {\"First name\", \"Name\", \"Favourite color\", \"Gender\", \"Sport\"};\n\n    public DynamicModelObject() {\n        super();\n\n        friends.add(new Friend(\"Johnathan\", \"Sykes\", Color.red, true, Sport.TENNIS));\n        friends.add(new Friend(\"Nicolas\", \"Van de Kampf\", Color.black, true, Sport.FOOTBALL));\n        friends.add(new Friend(\"Damien\", \"Cuthbert\", Color.cyan, true, Sport.NOTHING));\n        friends.add(new Friend(\"Corinne\", \"Valance\", Color.blue, false, Sport.SWIMMING));\n        friends.add(new Friend(\"Emilie\", \"Schr\u00f6dinger\", Color.magenta, false, Sport.FOOTBALL));\n        friends.add(new Friend(\"Delphine\", \"Duke\", Color.yellow, false, Sport.TENNIS));\n        friends.add(new Friend(\"Eric\", \"Trump\", Color.pink, true, Sport.FOOTBALL));\n    }\n\n    public int getRowCount() {\n        return friends.size();\n    }\n\n    public int getColumnCount() {\n        return headers.length;\n    }\n\n    public String getColumnName(int columnIndex) {\n        return headers[columnIndex];\n    }\n\n    public Object getValueAt(int rowIndex, int columnIndex) {\n        switch(columnIndex){\n            case 0:\n                return friends.get(rowIndex).getFirstName();\n            case 1:\n                return friends.get(rowIndex).getName();\n            case 2:\n                return friends.get(rowIndex).getColor();\n            case 3:\n                return friends.get(rowIndex).isGender();\n            case 4:\n                return friends.get(rowIndex).getSport();\n            default:\n                return null; //Must never happens\n        }\n    }\n\n    public void addFriend(Friend friend) {\n        friends.add(friend);\n\n        fireTableRowsInserted(friends.size() -1, friends.size() -1);\n    }\n\n    public void removeFriend(int rowIndex) {\n        friends.remove(rowIndex);\n\n        fireTableRowsDeleted(rowIndex, rowIndex);\n    }\n}\n\n\n\nNothing to hard. For the addFriend() method, we add the new Friend in the list and we inform the JTable of a new insert. For the removeFriend() method, we use the same principle, we start deleting the element from the list and we inform the JTable of the deletion.\nNow we will add 2 actions in our user interface. The first to add a new friend (to make easier, it will always add the same object) and the second one to remove the selected elements. Here is what we will do :\npublic class JTableBasicWithDynamicModelObject extends JFrame {\n    private DynamicModelObject model = new DynamicModelObject();\n\n    private JTable table;\n\n    public JTableBasicWithDynamicModelObject() {\n        super();\n\n        setTitle(\"JTable with dynamic model\");\n        setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);\n\n        table = new JTable(model);\n\n        getContentPane().add(new JScrollPane(table), BorderLayout.CENTER);\n\n        JPanel buttons = new JPanel();\n\n        buttons.add(new JButton(new AddAction()));\n        buttons.add(new JButton(new RemoveAction()));\n\n        getContentPane().add(buttons, BorderLayout.SOUTH);\n\n        pack();\n    }\n\n    public static void main(String[] args) {\n        new JTableBasicWithDynamicModelObject().setVisible(true);\n    }\n\n    private class AddAction extends AbstractAction {\n        private AddAction() {\n            super(\"Add\");\n        }\n\n        public void actionPerformed(ActionEvent e) {\n            model.addFriend(new Friend(\"Megan\", \"Sami\", Color.green, false, Sport.SWIMMING));\n        }\n    }\n\n    private class RemoveAction extends AbstractAction {\n        private RemoveAction() {\n            super(\"Remove\");\n        }\n\n        public void actionPerformed(ActionEvent e) {\n            int[] selection = table.getSelectedRows();\n\n            for(int i = selection.length - 1; i &amp;gt;= 0; i--){\n                model.removeFriend(selection[i]);\n            }\n        }\n    }\n}\n\n\n\nThe action to add a friend doesn't make something special and is quite easy. On the other side, there is little things to say about the remove action. First of all, we must know that a JTable can use several selection modes. We can set the selection mode, using the setSelectionMode() method. We can use this values from ListSelectionModel for the parameter mode :\n\n    SINGLE_SELECTION : only one line\n    SINGLE_INTERVAL_SELECTION : one interval of lines\n    MULTIPLE_INTERVAL_SELECTION : several intervals of lines. This is the default value.\n\n\nWe must understand than the array of lines returned by the getSelectedRows method can return several intervals. The results are returned in ascending order. We must delete them from the end to not change the line's number of the preceding elements.\nThat will give us this result :\n\nLike you can see, we just build a dynamic table without big problems. In the next chapter, we will solve the issues of Color and Gender column who are not really useful for the moment.\n\n\n5. Cells rendering\n\nWe'll now customize the rendering of the cells. Here are the changes we are going to apply to our interface :\n\n    Display the real color instead of the toString() of the Color object\n    Display the image of the gender\n    Display the name of the fried in bold\n\n\nFor that, we must start with specifying in the model which class correspond to which column. We can only configure renderer by column. Then, we can configure a renderer for each column class in the JTable. So the first thing to do is the override the getColumnClass() method in our model :\n@Override\n\npublic Class getColumnClass(int columnIndex){\n    switch(columnIndex){\n        case 2:\n            return Color.class;\n        case 3:\n            return Boolean.class;\n        default:\n            return Object.class;\n    }\n}\n\n\n\nActually, this not really essential, because this is automatically made by AbstractTableModel. But i think, it's clearer.\nWe will now create our renderers. A renderer is a class implementing TableCellRenderer who is an interface containing only one method returning a Swing component. In practice, we generally extends DefaultCellRenderer who use a JLabel as renderer.\nWhen it's possible, we must not create new object in a renderer if we've a lot of elements in our JTable. This would mean that a new object is created each time the table render a cell and that could degrade performance. That's why, we try to keep a single object modified each time we render a cell.\nWe will create our first renderer for the Color :\npublic class ColorCellRenderer extends DefaultTableCellRenderer {\n    @Override\n    public Component getTableCellRendererComponent(JTable table, Object value, boolean isSelected, boolean hasFocus, int row, int column) {\n        super.getTableCellRendererComponent(table, null, isSelected, hasFocus, row, column);\n\n        Color color = (Color) value;\n\n        setBackground(color);\n\n        return this;\n    }\n}\n\n\n\nIt's extremely easy to implement this render. We just have to get the color of the Friend and to set it as the background of our JLabel. We can do the next renderer. For the gender, we will display an image for the gender :\npublic class GenderCellRenderer extends DefaultTableCellRenderer {\n    private Icon manImage;\n    private Icon womanImage;\n\n    public GenderCellRenderer() {\n        super();\n\n        manImage = new ImageIcon(\"man.png\");\n        womanImage = new ImageIcon(\"woman.png\");\n    }\n\n    @Override\n    public Component getTableCellRendererComponent(JTable table, Object value, boolean isSelected, boolean hasFocus, int row, int column) {\n        super.getTableCellRendererComponent(table, null, isSelected, hasFocus, row, column);\n\n        Boolean man = (Boolean)value;\n\n        if(man){\n            setIcon(manImage);\n        } else {\n            setIcon(womanImage);\n        }\n\n        return this;\n    }\n}\n\n\n\nWe start with loading the images in the constructor. Then in the render method, we display the image corresponding to the gender. So, we can go to the last renderer :\npublic class BoldCellRenderer extends DefaultTableCellRenderer {\n    private final Font boldFont = getFont().deriveFont(Font.BOLD);\n\n    @Override\n    public Component getTableCellRendererComponent(JTable table, Object value, boolean isSelected, boolean hasFocus, int row, int column) {\n        super.getTableCellRendererComponent(table, value, isSelected, hasFocus, row, column);\n\n        setFont(boldFont);\n\n        return this;\n   }\n}\n\n\n\nNothing to say here, it's more than trivial. We can now configure the renderers in the JTable :\ntable.setDefaultRenderer(Boolean.class, new GenderCellRenderer());\n\ntable.setDefaultRenderer(Color.class, new ColorCellRenderer());\n\ntable.getColumnModel().getColumn(1).setCellRenderer(new BoldCellRenderer());\n\n\n\nFor the two firsts, we can directly linked them to a column class, but for the bold renderer, we cannot linked it to String because, we want it only on the name and not for the firstname. This will give us this result :\n\nThis time, we have something a lot more interesting visually. You can also dorenderers more sophisticated with other components than JLabel like a JPanel of why not, a JTable.\nIn the next chapter, we will enable the edition of the values of the table.\n\n\n6. Enable to edit cells\n\nWe will now make our table editable. For that, we must start to make our model editable. So, we have to override the isCellEditable(int row, int column), method who indicates which cells are editables. In our case, all the cells will be editables. Then, we must apply the modifications, so we have to override the setValueAt(Object value, int column, int row) method who's automatically called when the user validate the modification. Moreover, we must also edit our getColumnClass method to add the Sport class for the 4th column because we also want to edit it. So here is our modified model :\npublic class ModelEditable extends AbstractTableModel {\n    private final List friends = new ArrayList();\n\n    private final String[] headers = {\"First name\", \"Name\", \"Favourite color\", \"Gender\", \"Sport\"};\n\n    public ModelEditable() {\n        super();\n\n        friends.add(new Friend(\"Johnathan\", \"Sykes\", Color.red, true, Sport.TENNIS));\n        friends.add(new Friend(\"Nicolas\", \"Van de Kampf\", Color.black, true, Sport.FOOTBALL));\n        friends.add(new Friend(\"Damien\", \"Cuthbert\", Color.cyan, true, Sport.NOTHING));\n        friends.add(new Friend(\"Corinne\", \"Valance\", Color.blue, false, Sport.SWIMMING));\n        friends.add(new Friend(\"Emilie\", \"Schr\u00f6dinger\", Color.magenta, false, Sport.FOOTBALL));\n        friends.add(new Friend(\"Delphine\", \"Duke\", Color.yellow, false, Sport.TENNIS));\n        friends.add(new Friend(\"Eric\", \"Trump\", Color.pink, true, Sport.FOOTBALL));\n    }\n\n    public int getRowCount() {\n        return friends.size();\n    }\n\n    public int getColumnCount() {\n        return headers.length;\n    }\n\n    public String getColumnName(int columnIndex) {\n        return headers[columnIndex];\n    }\n\n    public Object getValueAt(int rowIndex, int columnIndex) {\n        switch(columnIndex){\n            case 0:\n                return friends.get(rowIndex).getFirstName();\n            case 1:\n                return friends.get(rowIndex).getName();\n            case 2:\n                return friends.get(rowIndex).getColor();\n            case 3:\n                return friends.get(rowIndex).isGender();\n            case 4:\n                return friends.get(rowIndex).getSport();\n            default:\n                return null; //Must never happens\n        }\n    }\n\n    @Override\n    public Class getColumnClass(int columnIndex){\n        switch(columnIndex){\n            case 2:\n                return Color.class;\n            case 3:\n                return Boolean.class;\n            case 4 :\n                return Sport.class;\n            default:\n                return Object.class;\n        }\n    }\n\n    @Override\n    public boolean isCellEditable(int rowIndex, int columnIndex) {\n        return true; //All the cells editable\n    }\n\n    @Override\n    public void setValueAt(Object aValue, int rowIndex, int columnIndex) {\n        if(aValue != null){\n            Friend friend = friends.get(rowIndex);\n\n            switch(columnIndex){\n                case 0:\n                    friend.setFirstName((String)aValue);\n                    break;\n                case 1:\n                    friend.setName((String)aValue);\n                    break;\n                case 2:\n                    friend.setColor((Color)aValue);\n                    break;\n                case 3:\n                    friend.setGender((Boolean)aValue);\n                    break;\n                case 4:\n                    friend.setSport((Sport)aValue);\n                    break;\n            }\n        }\n    }\n\n    public void addFriend(Friend friend) {\n        friends.add(friend);\n\n        fireTableRowsInserted(friends.size() -1, friends.size() -1);\n    }\n\n    public void removeFriend(int rowIndex) {\n        friends.remove(rowIndex);\n\n        fireTableRowsDeleted(rowIndex, rowIndex);\n    }\n}\n\n\n\nThe first method return true because all the cells are editable. The second return the modified friend and function of the column modify the good property of the Friend object.\nNow our model is editable, but this is not enough to work alone because JTable doesn't know how to edit Color, Sport or Gender by default. We must use a new concept, the TableCellEditor. An editor is simpley an object enabling to edit a cell. By default, JTable can edit directly all the objects with a JTextField and the Boolean with checkbox. In our case, it will work with the name and first, but doesn't work with the other columns. So we must create 3 editors.\nThe first and the most simple is the one for the Sport column. For that, we'll use a simple combo box. It's more than simple because the DefaultCellEditor can take JComboBox in parameter. So we'll use it :\npublic class SportCellEditor extends DefaultCellEditor {\n    public SportCellEditor() {\n        super(new JComboBox(Sport.value));\n    }\n}\n\n\n\nWe can see that create an editor for an enumerated type is extremely easy.\nWe will now go to the editor for the color. We could use a text field with the hexadecimal value of the color or 3 text fields with each RGB component, but it would not be very practice for the user. We've a good color chooser in Swing, so we can use it. On the other side, we cannot directly use it as editor. We must use a button who display the JColorChooser. This will show us how to do an editor a little more complicated. So here is a color editor :\npublic class ColorCellEditor extends AbstractCellEditor implements TableCellEditor, ActionListener {\n    private Color color;\n    private JButton button;\n    private JColorChooser colorChooser;\n    private JDialog dialog;\n\n    public ColorCellEditor() {\n        super();\n\n        button = new JButton();\n        button.setActionCommand(\"change\");\n        button.addActionListener(this);\n        button.setBorderPainted(false);\n\n        colorChooser = new JColorChooser();\n        dialog = JColorChooser.createDialog(button, \"Pick a Color\", true, colorChooser, this, null);\n    }\n\n    @Override\n    public void actionPerformed(ActionEvent e) {\n        if (\"change\".equals(e.getActionCommand())) {\n            button.setBackground(color);\n            colorChooser.setColor(color);\n            dialog.setVisible(true);\n\n            fireEditingStopped();\n        } else {\n            color = colorChooser.getColor();\n        }\n    }\n\n    @Override\n    public Object getCellEditorValue() {\n        return color;\n    }\n\n    @Override\n    public Component getTableCellEditorComponent(JTable table, Object value, boolean isSelected, int row, int column) {\n        color = (Color)value;\n\n        return this;\n    }\n}\n\n\n\nThis time, we can see that it is a little more hard. The TableCellEditor itself is a JButton. The getTableCellEditorComponent method must return the editor component. The getCellEditorValue method retourne the edited value. We call the fireEditingStopped method when the edition is finished to say to the JTable to display again the renderer.\nAnd the last one for the gender. Once again, we have several solutions : a list with both choices, radio buttons, checkbox, .... In our case, we'll do very simple. A simple button that changes the gender each times the user click :\npublic class GenderCellEditor extends AbstractCellEditor implements TableCellEditor, ActionListener {\n    private boolean gender;\n    private JButton button;\n\n    public GenderCellEditor() {\n        super();\n\n        button = new JButton();\n        button.addActionListener(this);\n        button.setBorderPainted(false);\n    }\n\n    @Override\n    public void actionPerformed(ActionEvent e) {\n        gender = true;\n\n        fireEditingStopped();\n    }\n\n    @Override\n    public Object getCellEditorValue() {\n        return gender;\n    }\n\n    @Override\n    public Component getTableCellEditorComponent(JTable table, Object value, boolean isSelected, int row, int column) {\n        gender = (Boolean)value;\n\n        return button;\n    }\n}\n\n\n\nWe keep the simple principle than for color choice except that this time, its easier. We just have to invert the boolean value and return it.\nFinally, we configure our JTable with our editors :\ntable.setDefaultEditor(Sport.class, new SportCellEditor());\ntable.setDefaultEditor(Color.class, new ColorCellEditor());\ntable.setDefaultEditor(Boolean.class, new GenderCellEditor());\n\n\n\nThe principle is the same than for renderers, we've an editor by column class. So here is the result of the edition of a color :\n\nWe've a now a tablea fully functional. In the next chapters, we will improve the table enabling to sort/filter the content of the table.\n\n\n7. Sort content\n\nWe will now make our table sortable by column. This give the possibility to a user to sort the contenu of all the table using a column for index only by clicking on a header column. This is done with a RowSorter object. The JTable has a method to enable a default sorter : d'activer un sorter par d\u00e9faut :\ntable.setAutoCreateRowSorter(true);\n\n\n\nThis will sort all the column of class String in alphabetical order depending on the current Locale, the columns of a class implementing Comparable with their compareTo() order and the other columns with the alphabetical order of the toString() value.\nIn most of the case, it's enough. But we can customize the sorter. Of course, we could create our custom RowSorter, but it's easier to use the TableRowSorter class and to customize it to make our changes instead of create a new implementation. Here are a way to customize the sorter :\nTableRowSorter sorter = new TableRowSorter(table.getModel());\ntable.addSorter(sorter);\n\n\n\nThe first thing we can do is to specify a column not sortable with the setSortable method :\nsorter.setSortable(2, false);\n\n\n\nThis code set the column \"Color\" non sortable. Then, we can also indicate to the sorter if it must sort the table after an update in the model :\nsorter.setSortsOnUpdates(true);\n\n\n\nThis code indicate the sorter that it must resort the table after each modification of the data. An other interesting thing is that we can specify our custom comparator for a specific column. In our case, this is what we need for the Color column, because Color doesn't implement Comparable and so, is sorted by its toString() value what is not very useful. We will sort the Color by its blue level. We start defining a Comparator for our Color :\npublic class ColorComparator implements Comparator {\n    @Override\n    public int compare(Color c1, Color c2) {\n        return new Integer(c1.getBlue()).compareTo(c2.getBlue());\n    }\n}\n\n\n\nThen, we specify that the column 2 must use this new comparator :\nsorter.setComparator(2, new ColorComparator());\n\n\n\nHere is what it will display after a sort on the Color column :\n\nYou can see that it's very easy to sort a table.\nBut now, when the table is sorted, we will have problemsn to delete lines. You can try with the current code if you sort the table and then try removing lines. You will see that the removed lines are not good ones. What happens ?\nBecause the returned index by the getSelectedRows() method are the index in the view, not the model. When the table isn't sorted, this two sort of indexes are the same. So there is no problem. But when the table is sorted, the two indexes are not corresponding. We can easily solve this problem using the convertRowIndexTomodel() method of the RowSorter class. This method convert an index of the view to an index of the model. We will correct our RemoveAction with this new method :\nprivate class RemoveAction extends AbstractAction {\n    private RemoveAction() {\n        super(\"Remove\");\n    }\n\n    public void actionPerformed(ActionEvent e) {\n        int[] selection = table.getSelectedRows();\n        int[] modelIndexes = new int[selection.length];\n\n        for(int i = 0; i &amp;lt; selection.length; i++){             \n            modelIndexes[i] = table.getRowSorter().convertRowIndexToModel(selection[i]);         \n        }         \n\n        Arrays.sort(modelIndexes);         \n\n        for(int i = modelIndexes.length - 1; i &amp;gt;= 0; i--){\n            model.removeFriend(modelIndexes[i]); \n        }\n    }\n}\n\n\n\nWe start with getting the indexes of the views, then we convert them to indexes of the model. And finally we sort them to delete the elements from the end. You will see that with this new action the deletion of elements will work fine.\nAt the next chapter, we will extends this feature enabling to filter the content of the table.\n\n\n8. Filter content\n\nIn addition to sort the table, the RowSorter class enable also to filter the content of the table. We can use for that the setRowFilter method who takes a RowFilter in parameter. RowFilter has several static methods to easily create filters. So we have methods to make \"and\" or \"or\" operations on filters. Moreover we've also a very useful method to create a regex filter for one or more columns.\nWe will add a button to filter on the \"name\" and \"firstname\" columns :\nprivate class FilterAction extends AbstractAction {\n    private FilterAction() {\n        super(\"Filter\");\n    }\n\n    public void actionPerformed(ActionEvent e) {\n        String regex = JOptionPane.showInputDialog(\"Filter regex : \");\n\n        sorter.setRowFilter(RowFilter.regexFilter(regex, 0, 1));\n    }\n}\n\n\n\nLike you can see, it's very easy to filter the content of table on one or several columns. Here is the result with a filter \"mp\" :\n\nFor flexibility, you can also extends RowFilter who has only one methods include(Entry entry) who indicates if a line must be included in the table or not.\n\n\n9. Conclusion\n\nHere we are. We have now covered all the main aspects of the creation and manipulation of tables (JTable) with Swing. I hope than this tutorial enable you to master this component who is, once the aspects undestood, not that hard to use.", 
      "tags": "Java,Swing"
    }, 
    {
      "loc": "/posts/2009/12/jtheque-movies-1-0.html", 
      "title": "JTheque Movies 1.0", 
      "text": "I finished the development of JTheque Movies 1.0 :)\nThis application enable the user to manage a collection of movies and to read them directly in the application. For this last functionality, on Windows, you need Windows Media Player and on Linux you need VLC Media Player as web plugin. The user interface has been completely remade to be more esthetic.\n\n\nHere are two screenshots of this new versions.\n\n\nYou can download the both versions here :\n\n    Windows Version\n    Linux Version\n\n\nThis version integrate this modules (french forge) :\n\n    JTheque Movies Module 1.3\n    JTheque Memory Module 1.4.1\n    JTheque Tools Module 1.0.2\n\n\nAll the sources of this modules and of the core (JTheque Core) are all availabes under GPL V3 on the project management system (here (French)).\nI hope that this program will be useful for somebody.", 
      "tags": "Java,JTheque,Releases"
    }, 
    {
      "loc": "/posts/2009/12/improve-performance-web-site.html", 
      "title": "Improve performance of your web site with Page Speed", 
      "text": "Page Speed is a Firefox addon who add a new functionality to Firebug enabling the user to evaluate and improve the performances of a web site.\nAlthough as improving perofrmances of a web site is no longer as critical as in the past with the evolution of new technologies, this has some advantages :\n\n    Make your site faster and logically more cumfortable for users. Moreover, all the users doesn't have broadband and improve the rendering speed can save users.\n    Reduce the used bandwith and the hosting costs\n    Improve the web itself respecting some simple rules.\n\n\nDiscover how to achieve this objectives with Page Speed.\n\n\nPage Speed needs Firebug to work because it add a new tab to the Firebug view. The installation is very simple. You just have to download the plugin from the official page and to install it like any other Firefox plugin.\nThen, you can launch Firebug and you should see a new tab \"Page speed\" :\n\nYou can now launch the analysis with the \"Analyze Performance\" button. Once the scan is complete (a few seconds normally), Page Speed will indicate what are the critical points of your web page.\nThe advices are grouped into 5 categories :\n\n    Improve caching : Verify that the most of the objects can be cached\n    Minimize the number of requests grouping the different requests\n    Minimize the size of the request\n    Minimize the size of the page\n    Improve browser rendering\n\n\nYou can see the complete list of best practices on the site of Page Speed.\nHere are some example advices it can give to you :\n\n    CSS : Combine CSS files in a single file to limit requests, delete unused CSS and minimize the size of CSS file compacting it.\n    Optimize images. This functionality is very interesting and provide directly an optimized version of images, it seems a lighter image but with the same quality. I use a lot this function.\n    Minimize Javascript code\n    Enable GZip compression on all the pages. That could save more than 80% of the bandwith.\n    Parrallelize downloads distributing across several domains.\n    etc...\n\n\nFor fast all advices, the plugin say you how to solve the problem and improve the performances.\nTo conclude, i would say that this plugin is essential for everybody who want to keep its web site faster.\nLinks :\n\n    Page Speed on Google Code\n    Best practices for web performances", 
      "tags": "Google,Performances,Web"
    }, 
    {
      "loc": "/posts/2009/12/intellij-idea-9-review.html", 
      "title": "Review of Jetbrains Intellij Idea 9 Ultimate Edition", 
      "text": "Here is my review of the IDE Jetbrains Intellij Idea 9 Ultimate Edition.\n1. Introduction\n\nJetBrains just released the 9 version of Intellij Idea. This version is available in two editions :\n\n    Community Edition : Opensource version and free. Contains only the basic functionalities of the IDE.\n    Ultimate Edition : Complete commercial version of the IDE. I am going to introduce here this version.\n\n\nThis IDE is principally made for Java development, but now supports also a lot of others languages : JavaScript/Flex, HTML/XHTML/CSS, XML/XSL, Ruby/JRuby, Groovy, SQL, FreeMarker/Velocity and PHP.\nFor Java Development, it supports numerous frameworks and technologies : JSP, JSF, EJB, AJAX, GWT, Struts, Struts 2, JBoss Seam, Spring, JPA/Hibernate, Web Services, Rails, Grails, Java ME MIDP/CLDC, Tapestry, Google App Engine, Android or OSGi.\nI am going to introduce some of this news functionalit\u00e9s and give you my opinion about the different themes.\n\n2. Installation\n\nThe installation is very easy. It's a common installer like all others instlallers you can found, with the basic operations : License, folder, shortcuts, start menu and finish. Nothing special about that.\nOnce installation is complete, we must enter the license and choose the modules to activate like it was already the case in the previous versions. pr\u00e9c\u00e9dentes versions.\n\n\n3. General improvements\n\nThe first thing we note is a real improvement of performance. More tasks are made in background. This is the case for indexing who launches at start but doesn't block the user interface. Thus, we can start work during indexation but some actions are not available, like refactorings.\n\nWe can also see that there is much less freeze of graphical interface who is also more reactive. The feedback of the different actions has been improved. It seems that we can see that an action has been launched or done and we're not to ask us if something happens or not, like that can happens with Idea 8.\n\n\n4. User Interface\n\nAs previously stated, the reactivity of the user interface has been greatly improved.\nThe views have not major changes, but we can still note that there is some interesting new functionalities.\nFirst of all, we can now debug and launch directly from keyboard shortcuts :\n\n    Alt+Shift+F9 : Open debbuging view\n    Alt+Shift+F10 : Open launch view\n\n\nHere are these new views :\n\n\nThen, we've also a new bookmarks management functionality. We can now put bookmarks in every portion of code, either class or lines of code. We've now there shortcuts :\n\nF11 : Create a new bookmark at the selected item (file in project view or line of code in editor)\nShift + F11 : Show the bookmarks and enable the user to go to one bookmark.\n\nAn example of bookmark on a line of code :\n\nAnd the view of bookmarks :\n\nAnd last but not least, we can now copy files/directory from operating system and paste them in Idea and vice-versa. That is very practice but was not available in the previous versions.\n\n\n5. Maven support\n\nThe \"Maven Projects\" view has had little modifications. In the \"Lifecycle\" folder, only the main goals are displayed (clean, validate, compile, test, package, install, site et deploy) . I think it's a good thing, because we use especially these goals. Of course, we can display all the goals with an option in the tool bar.\nAlways in this view, we can now see the profiles (Maven 2 profiles) who are configured in settings.xml and go quickly to this settings.xml file. More than the profiles, we can now directly display the the dependencies of a project : Maven 2 :\n\nWe also have access to a dependency graph for a Maven module :\n\nIt is now possible to automatically reimport the Maven projects after a change in the pom.xml files.\nFor the reimport, we can now reimport only projects who have changes in their pom.xml or concerned by the others changes. More than this improvement, the speed of this operation has been improved by a factor of 3 or 4.\n\n\n6. OSGI support\n\nFrom this version, Idea natively integrate an OSGi plugin, Osmorc. This plugin try to make easier the development of OSGi applications in Idea. I'll try to show you the main functionalities who are now integrated in Idea.\nThe first thing to do is to configure the project for OSGi. To do that, we just need to activate the OSGi facet for the necessary modules. Then (or before, as you want), we must configure the installed OSGi instances.\n\nThen, we must configure the instance to use for the project :\n\nWe can then go to the creation of a simple OSGi project.\nThe first functionality to note is of course the code completion of the MANIFEST.MF entries :\n\nWhen you add the Import-Package header, we can use the classes of this package from the project without doing anything else.\nBut we can also define a Manifest file from Idea :\n\nEt we continue with an activator :\npackage com.pragprog.hello;\n\nimport org.osgi.framework.BundleActivator;\nimport org.osgi.framework.BundleContext;\n\npublic class HelloWorld implements BundleActivator{\n    @Override\n    public void start(BundleContext bundleContext) throws Exception {\n        System.out.println(\"I'm in OSGi :)\");\n    }\n\n    @Override\n    public void stop(BundleContext bundleContext) throws Exception {\n        System.out.println(\"I'm leaving OSGi :(\");\n    }\n}\n\n\n\nTo finish, we create a new run configuration \"OSGi bundles\". For That, we just need to add the bundle to the list and in the \"Parameters\" tab to choose the good OSGi instance to run :\n\nAnd we launch the configuration, that give us :\n\nBut we cannot interact with the OSGi instance from Idea, that's not very practical. We cannot stop modules or either manage them from the console. But the OSGi development is still facilitated by Idea. But it would have been better to have something a bit more advanced.\n\n\n7. PHP support\n\nHere is a functionality who's perhaps not interesting for everybody but that will be interesting for the Java developers who manages a PHP site or simply for the PHP developers. For me, who manages also a PHP website, it's a great news. Before that, i used other editors and IDE to edit my website, but now i can do everything from my favourite IDE.\nFirst and of course, we have syntax highlighting of PHP files :\n\nWe also have automatic code completion for PHP functions :\n\nBut the IDE make more than simple code completion. In fact, it discovers automatically the fields and methods from a class and fields and methods from the standard library. You can see this functionalities in the next images :\n\n\nMoreover, Idea also supports PHPDcod documentation and make code completion based on PHPDoc :\n\nWe can also note that it's possible to do PHP Debugging and unit tests with PHPUnit. But this is out of the scope of this article.\n\n\n8. Task management\n\nThis functionnality isn't for me a major change, but it remains interesting. It enables the user to save state of view in a specified task.\nA task save the current changelist, the open editions, the state of the project view, the run configurations and the breakpoints. If you work in two parts of a project, you can create two tasks and you have also the same properties when you switch from one to the other. And you can quickly commit only the changes of a task because of the decoupled changelists.\n\nThen, it is possible to go to a specific task, who has for effect to save the state of the current task and restore the state of the task to open.\n\nIt's also possible to synchronize the different tasks with YouTrack or JIRA.\n\n\n9. Miscellaneous\n\nMore that these new big news, there is many other changes that i will not detail including :\n\n    It is now possible to create a module from a Grails/Griffon project in the same way we can import project from Eclipse. We can also create Griffon/Grails modules or applications.\n    There is now a Spell Checking inspection for the code and resources who is enabled by default in this new version.\n    The public classes and methods who aren't used are not directly shaded like it was already the case for unused private fields and methods.\n    Grails support improvement with Griffon and Gradle support\n    Android support\n    Flex support improvements\n\n\n\n\n10. Conclusion\n\nTo conclude, JetBrains has one more times demonstrated its expertise in Java IDE presenting an excellent new version full of new functionalities and improvements that made the Java development even better.\nThe only thing i had to complain in this version, is the lack of documentation of OSGi plugin and the limitations of the latter.\nYou can download IntelliJ Idea 9 on the official site.", 
      "tags": "IntelliJ Idea,Java,Tools"
    }, 
    {
      "loc": "/posts/2009/12/google-analytics-asynchronous.html", 
      "title": "Google Analytics goes asynchronous !", 
      "text": "From this month, Google provide a new Google Analytics script that works in an asynchronous way.\nThis has several advantages :\n\n    The time to load the script has less impact on the page loading time.\n    Best data recovery and so more saved visits. The visits terminated before the script loading doesn't happens anymore. Because, due to the asynchronous way of loading, we can add the analytics code in the head of the page.\n    Less tracking errors.\n\n\nVoici le nouveau code \u00e0 ins\u00e9rer dans vos pages :\n  var _gaq = _gaq || [];\n  _gaq.push(['_setAccount', 'UA-XXXXX-X']);\n  _gaq.push(['_trackPageview']);\n\n  (function() {\n    var ga = document.createElement('script');\n    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : \n        'http://www') + '.google-analytics.com/ga.js';\n    ga.setAttribute('async', 'true');\n    document.documentElement.firstChild.appendChild(ga);\n  })();\n\n\n\nWe have to note that this code use the async parameter of HTML 5 and that functionality is not supported by all the browsers. If you use that script in a non HTML-5 Browser, the script will be executed exactly as the old Analytics script in an synchronous way. \nThat's a good news for the fans of performances. \nSource : Google Analytics Launches Asynchronous Tracking", 
      "tags": "Google,Web"
    }
  ]
}