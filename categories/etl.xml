<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Blog blog("Baptiste Wicht"); (Posts about etl)</title><link>https://baptiste-wicht.com/</link><description></description><atom:link href="https://baptiste-wicht.com/categories/etl.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><lastBuildDate>Sun, 13 Aug 2023 07:18:27 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Decrease DLL neural network compilation time with C++17</title><link>https://baptiste-wicht.com/posts/2018/02/decrease-dll-neural-network-compilation-time-with-c%2B%2B17.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;p&gt;Just last week, &lt;a class="reference external" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html"&gt;I've migrated my Expression Templates Library (ETL) library to C++17&lt;/a&gt;,
it is now also done in my Deep Learning Library (DLL) library. In ETL, this
resulted in a &lt;em&gt;much nicer code overall&lt;/em&gt;, but no real improvement in compilation
time.&lt;/p&gt;
&lt;p&gt;The objective of the migration of DLL was two-fold. First, I also wanted to
simplify some code, especially with &lt;code&gt;if constexpr&lt;/code&gt;. But I also especially
wanted to try to reduce the compilation time. In the past,
&lt;a class="reference external" href="https://baptiste-wicht.com/posts/2017/09/how-i-made-deep-learning-library-38-faster-to-compile-optimization-and-cpp17-if-constexpr.html"&gt;I've already tried a few changes with C++17&lt;/a&gt;, with good results on the compilation of the entire test suite.
While this is very good, this is not very representative of users of the library.
Indeed, normally you'll have only one network in your source file not several.
The new changes will especially help in the case of many networks, but less in
the case of a single network per source file.&lt;/p&gt;
&lt;p&gt;This time, I decided to test the compilation on the examples. I've tested the
eight official examples from the DLL library:&lt;/p&gt;
&lt;ol class="arabic simple" start="0"&gt;
&lt;li&gt;&lt;p&gt;mnist_dbn: A fully-connected Deep Belief Network (DBN) on the MNIST data set
with three layers&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;char_cnn: A special CNN with embeddings and merge and group layers for text
recognition&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;imagenet_cnn: A 12 layers Convolutional Neural Network (CNN) for Imagenet&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;mnist_ae: A simple two-layers auto-encoder for MNIST&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;mnist_cnn: A simple 6 layers CNN for MNIST&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;mnist_deep_ae: A deep auto-encoder for MNIST, only fully-connected&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;mnist_lstm: A Recurrent Neural Network (RNN) with Long Short Term Memory
(LSTM) cells&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;mnist_mlp: A simple fully-connected network for MNIST, with dropout&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;mnist_rnn: A simple RNN with simple cells for MNIST&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This is really representative of what users can do with the library and I think
it's a much better for compilation time.&lt;/p&gt;
&lt;p&gt;For reference, you can find &lt;a class="reference external" href="https://github.com/wichtounet/dll/tree/master/examples/src"&gt;the source code of all the examples online&lt;/a&gt;.&lt;/p&gt;
&lt;section id="results"&gt;
&lt;h2&gt;Results&lt;/h2&gt;
&lt;p&gt;Let's start with the results. I've tested this at different stages of the
migration with clang 5 and GCC 7.2. I tested the following steps:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;&lt;p&gt;The original C++14 version&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Simply compiling in c++17 mode (-std=c++17)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Using the C++17 version of the ETL library&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Upgrading DLL to C++17 (without ETL)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;ETL and DLL in C++17 versions&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I've compiled each example independently in release_debug mode. Here are the
results for G++ 7.2:&lt;/p&gt;
&lt;table class="align-center"&gt;
&lt;thead&gt;
&lt;tr&gt;&lt;th class="head"&gt;&lt;p&gt;Example&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;0&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;1&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;2&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;3&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;4&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;5&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;6&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;7&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;8&lt;/p&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;C++14&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;37.818&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;32.944&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;33.511&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;15.403&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;29.998&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;16.911&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;24.745&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;18.974&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;19.006&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;-std=c++17&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;38.358&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;32.409&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;32.707&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;15.810&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;30.042&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;16.896&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;24.635&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;19.134&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;19.027&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;ETL C++17&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;36.045&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;31.000&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;30.942&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;15.322&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;28.840&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;16.747&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;24.151&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;18.208&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;18.939&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;DLL C++17&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;35.251&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;32.577&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;32.854&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;15.653&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;29.758&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;16.851&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;24.606&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;19.098&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;19.146&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;Final C++17&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;32.289&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;31.133&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;30.939&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;15.232&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;28.753&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;16.526&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;24.326&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;18.116&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;17.819&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;Final Improvement&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;14.62%&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;5.49%&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;7.67%&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.11%&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;4.15%&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;2.27%&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.69%&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;4.52%&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;6.24%&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The difference by just enabling c++17 is not significant. On the other hand,
some significant gain can be obtained by using the C++17 version of ETL,
especially for the DBN version and for the CNN versions. Except for the DBN
case, the migration of DLL to C++17 did not bring any significant advantage.
When everything is combined, the gains are more important :) In the best case,
the example is 14.6% faster to compile.&lt;/p&gt;
&lt;p&gt;Let's see if it's the same with clang++ 5.0:&lt;/p&gt;
&lt;table class="align-center"&gt;
&lt;thead&gt;
&lt;tr&gt;&lt;th class="head"&gt;&lt;p&gt;Example&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;0&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;1&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;2&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;3&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;4&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;5&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;6&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;7&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;8&lt;/p&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;C++14&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;40.690&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;34.753&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;35.488&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;16.146&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;31.926&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;17.708&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;29.806&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;19.207&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;20.858&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;-std=c++17&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;40.502&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;34.664&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;34.990&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;16.027&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;31.510&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;17.630&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;29.465&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;19.161&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;20.860&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;ETL C++17&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;37.386&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;33.008&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;33.896&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;15.519&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;30.269&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;16.995&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;28.897&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;18.383&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;19.809&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;DLL C++17&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;37.252&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;34.592&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;35.250&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;16.131&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;31.782&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;17.606&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;29.595&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;19.126&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;20.782&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;Final C++17&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;34.470&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;33.154&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;33.881&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;15.415&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;30.279&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;17.078&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;28.808&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;18.497&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;19.761&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;Final Improvement&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;15.28%&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;4.60%&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;4.52%&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;4.52%&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;5.15%&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;3.55%&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;3.34%&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;3.69%&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;5.25%&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;First of all, as I have seen time after time, clang is still slower than GCC.
It's a not a big difference, but still significant. Overall, the gains are a bit
higher on clang than on GCC, but not by much. Interestingly, the migration of
DLL to C++17 is less interesting in terms of compilation time for clang. It
seems even to slow down compilation on some examples. On the other hand, the
migration of ETL is more important than on GCC.&lt;/p&gt;
&lt;p&gt;Overall, every example is faster to compile using both libraries in C++17, but
we don't have spectacular speed-ups. With clang, we have speedups from 3.3% to
15.3%. With GCC, we have speedup  from 1.1% to 14.6%. It's not very high, but
I'm already satisfied with these results.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="c-17-in-dll"&gt;
&lt;h2&gt;C++17 in DLL&lt;/h2&gt;
&lt;p&gt;Overall, the migration of DLL to C++17 was quite similar to that of ETL. You can
take a look at my &lt;a class="reference external" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html"&gt;previous article&lt;/a&gt;
if you want more details on C++17 features I've used.&lt;/p&gt;
&lt;p&gt;I've &lt;em&gt;replaced a lot of SFINAE functions&lt;/em&gt; with &lt;code&gt;if constexpr&lt;/code&gt;. I've also
replaced a lot of &lt;code&gt;statif_if&lt;/code&gt; with &lt;code&gt;if constexpr&lt;/code&gt;. There was a large
number of these in DLL's code. I also enabled all the &lt;code&gt;constexpr&lt;/code&gt; that
were commented for this exact time :)&lt;/p&gt;
&lt;p&gt;I was also thinking that I could replace a lot of meta-programming stuff with
&lt;em&gt;fold expressions&lt;/em&gt;. While I was able to replace a few of them, most of them were
harder to replace with fold expressions. Indeed, the variadic pack is often
hidden behind another class and therefore the pack is not directly usable from
the network class or the group and merge layers classes. I didn't want to start
a big refactoring just to use a C++17 feature, the current state of this code is
fine.&lt;/p&gt;
&lt;p&gt;I made some use of structured bindings as well, but again not as much as I was
thinking. In fact, a lot of time, I'm assigning the elements of a pair or tuple
to existing variables not declaring new variables and unfortunately, you can
only use structured bindings with &lt;code&gt;auto&lt;/code&gt; declaration.&lt;/p&gt;
&lt;p&gt;Overall, the &lt;em&gt;code is significantly better now&lt;/em&gt;, but there was less impact than
there was on ETL. It's also a smaller code base, so maybe this is normal and my
expectations were too high ;)&lt;/p&gt;
&lt;/section&gt;
&lt;section id="conclusion"&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;The trunk of DLL is now a C++17 library :) I think this improve the quality of
the code by a nice margin! Even though, there is still some work to be done to
improve the code, especially for the DBN pretraining code, the quality is quite
good now. Moreover, the switch to C++17 made the compilation of neural networks
using the DLL library &lt;em&gt;faster to compile&lt;/em&gt;, from 1.1% in the worst case to 15.3% in
the best case! I don't know when I will release the next version of DLL, but it
will take some time. I'll especially have to polish the RNN support and add
a sequence to sequence loss before I will release the 1.1 version of DLL.&lt;/p&gt;
&lt;p&gt;I'm quite satisfied with C++17 even if I would have liked a bit more features to
play with! I'm already a big fan of &lt;code&gt;if constexpr&lt;/code&gt;, this can make the code
much nicer and fold expressions are much more intuitive than their previous
recursive template counterpart.&lt;/p&gt;
&lt;p&gt;I may also consider migrating some parts of the cpp-utils library, but if I do,
it will only be through the use of conditionals in order not to break the other
projects that are based on the library.&lt;/p&gt;
&lt;/section&gt;</description><category>C++</category><category>C++17</category><category>clang</category><category>Compilers</category><category>Deep Learning</category><category>dll</category><category>etl</category><category>gcc</category><category>Machine Learning</category><category>Performance</category><category>projects</category><guid>https://baptiste-wicht.com/posts/2018/02/decrease-dll-neural-network-compilation-time-with-c%2B%2B17.html</guid><pubDate>Wed, 07 Feb 2018 10:39:02 GMT</pubDate></item><item><title>C++17 Migration of Expression Templates Library (ETL)</title><link>https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;p&gt;I've finally decided to migrate my Expression Templates Library (ETL) project to
C++17. I've talking about doing that for a long time and I've released several
releases without doing the change, but the next version will be a C++17 library.
The reason why I didn't want to rush the change was that this means the library
needs a very recent compiler that may not be available to everybody. Indeed,
after this change, the ETL library now needs at least GCC 7.1 or Clang 4.0.&lt;/p&gt;
&lt;p&gt;I've already made some previous experiments in the past. For instance,
&lt;a class="reference external" href="https://baptiste-wicht.com/posts/2017/09/how-i-made-deep-learning-library-38-faster-to-compile-optimization-and-cpp17-if-constexpr.html"&gt;by using if constexpr, I've managed to speed up compilation by 38%&lt;/a&gt; and I've also written an article about &lt;a class="reference external" href="https://baptiste-wicht.com/posts/2015/05/cpp17-fold-expressions.html"&gt;the fold expressions introduced in C++17&lt;/a&gt;. But I haven't migrated a full library yet. This is now done with ETL. In this article, I'll try to give some example of improvements by using C++17.&lt;/p&gt;
&lt;p&gt;This will only cover the C++17 features I'm using in the updated ETL library,
I won't cover all of the new C++17 features.&lt;/p&gt;
&lt;section id="if-constexpr"&gt;
&lt;h2&gt;if constexpr&lt;/h2&gt;
&lt;p&gt;The most exciting new thing in C++17 for me is the &lt;code&gt;if constexpr&lt;/code&gt;
statement. This is a really really great thing. In essence, it's a normal
&lt;code&gt;if&lt;/code&gt; statement, but with one very important difference. The statement that
is not taken (the &lt;code&gt;else&lt;/code&gt; if the condition is true, or the &lt;code&gt;if
constexpr&lt;/code&gt; if the condition is false) is &lt;em&gt;discarded&lt;/em&gt;. And what is interesting
is what happens to &lt;em&gt;discarded&lt;/em&gt; statements:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;&lt;p&gt;The body of a &lt;em&gt;discarded&lt;/em&gt; statement does not participate in return type
deduction.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The discarded statement is not instantiated&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The discarded statement can &lt;em&gt;odr-use&lt;/em&gt; a variable that is not defined&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Personally, I'm especially interested by points 1 and 2. Let's start with an
example where point 1 is useful. In ETL, I have a make_temporary function. This
function either forwards an ETL container or creates a temporary container from
an ETL expression. This is based on a compile-time traits. The return type of
the function is the not the same in both cases. What you did in those case
before C++17, is use SFINAE and make two functions:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code cpp"&gt;&lt;a id="rest_code_27d23e2e053c4b498773a526ffd469c1-1" name="rest_code_27d23e2e053c4b498773a526ffd469c1-1" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_27d23e2e053c4b498773a526ffd469c1-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nc"&gt;E&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;cpp_enable_iff&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;is_dma&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;E&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a id="rest_code_27d23e2e053c4b498773a526ffd469c1-2" name="rest_code_27d23e2e053c4b498773a526ffd469c1-2" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_27d23e2e053c4b498773a526ffd469c1-2"&gt;&lt;/a&gt;&lt;span class="k"&gt;decltype&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;auto&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;make_temporary&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;E&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;expr&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;a id="rest_code_27d23e2e053c4b498773a526ffd469c1-3" name="rest_code_27d23e2e053c4b498773a526ffd469c1-3" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_27d23e2e053c4b498773a526ffd469c1-3"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;return&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;forward&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;E&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;expr&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a id="rest_code_27d23e2e053c4b498773a526ffd469c1-4" name="rest_code_27d23e2e053c4b498773a526ffd469c1-4" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_27d23e2e053c4b498773a526ffd469c1-4"&gt;&lt;/a&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;a id="rest_code_27d23e2e053c4b498773a526ffd469c1-5" name="rest_code_27d23e2e053c4b498773a526ffd469c1-5" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_27d23e2e053c4b498773a526ffd469c1-5"&gt;&lt;/a&gt;
&lt;a id="rest_code_27d23e2e053c4b498773a526ffd469c1-6" name="rest_code_27d23e2e053c4b498773a526ffd469c1-6" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_27d23e2e053c4b498773a526ffd469c1-6"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nc"&gt;E&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;cpp_enable_iff&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;!&lt;/span&gt;&lt;span class="n"&gt;is_dma&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;E&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a id="rest_code_27d23e2e053c4b498773a526ffd469c1-7" name="rest_code_27d23e2e053c4b498773a526ffd469c1-7" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_27d23e2e053c4b498773a526ffd469c1-7"&gt;&lt;/a&gt;&lt;span class="k"&gt;decltype&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;auto&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;make_temporary&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;E&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;expr&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;a id="rest_code_27d23e2e053c4b498773a526ffd469c1-8" name="rest_code_27d23e2e053c4b498773a526ffd469c1-8" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_27d23e2e053c4b498773a526ffd469c1-8"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;return&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;force_temporary&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;forward&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;E&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;expr&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;
&lt;a id="rest_code_27d23e2e053c4b498773a526ffd469c1-9" name="rest_code_27d23e2e053c4b498773a526ffd469c1-9" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_27d23e2e053c4b498773a526ffd469c1-9"&gt;&lt;/a&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;One version of the function will forward and the other version will force
a temporary and the return type can be different since these are two different
functions. This is not bad, but still requires two functions where you only want
to write one. However, in C++17, we can do much better using &lt;code&gt;if constexpr&lt;/code&gt;:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code cpp"&gt;&lt;a id="rest_code_bba03820b3884bcb816284f20029f285-1" name="rest_code_bba03820b3884bcb816284f20029f285-1" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_bba03820b3884bcb816284f20029f285-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nc"&gt;E&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a id="rest_code_bba03820b3884bcb816284f20029f285-2" name="rest_code_bba03820b3884bcb816284f20029f285-2" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_bba03820b3884bcb816284f20029f285-2"&gt;&lt;/a&gt;&lt;span class="k"&gt;decltype&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;auto&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;make_temporary&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;E&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;expr&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;a id="rest_code_bba03820b3884bcb816284f20029f285-3" name="rest_code_bba03820b3884bcb816284f20029f285-3" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_bba03820b3884bcb816284f20029f285-3"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;constexpr&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;is_dma&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;E&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;a id="rest_code_bba03820b3884bcb816284f20029f285-4" name="rest_code_bba03820b3884bcb816284f20029f285-4" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_bba03820b3884bcb816284f20029f285-4"&gt;&lt;/a&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="k"&gt;return&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;forward&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;E&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;expr&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a id="rest_code_bba03820b3884bcb816284f20029f285-5" name="rest_code_bba03820b3884bcb816284f20029f285-5" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_bba03820b3884bcb816284f20029f285-5"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;a id="rest_code_bba03820b3884bcb816284f20029f285-6" name="rest_code_bba03820b3884bcb816284f20029f285-6" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_bba03820b3884bcb816284f20029f285-6"&gt;&lt;/a&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="k"&gt;return&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;force_temporary&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;forward&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;E&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;expr&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;
&lt;a id="rest_code_bba03820b3884bcb816284f20029f285-7" name="rest_code_bba03820b3884bcb816284f20029f285-7" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_bba03820b3884bcb816284f20029f285-7"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;a id="rest_code_bba03820b3884bcb816284f20029f285-8" name="rest_code_bba03820b3884bcb816284f20029f285-8" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_bba03820b3884bcb816284f20029f285-8"&gt;&lt;/a&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;I think this version is really superior to the previous one. We only have one
function and the logic is much clearer!&lt;/p&gt;
&lt;p&gt;Let's now see an advantage of the point 2. In ETL, there are two kinds of
matrices, matrices with compile-time dimensions (fast matrices) and matrices
with runtime dimensions (dynamic matrices). When they are used, for instance for
a matrix-multiplication, I use static assertions for fast matrices and runtime
assertions for dynamic matrices. Here is an example for the validation of the
matrix-matrix multiplication:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code cpp"&gt;&lt;a id="rest_code_92304d300002485b8da98e8d4ee30fa0-1" name="rest_code_92304d300002485b8da98e8d4ee30fa0-1" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_92304d300002485b8da98e8d4ee30fa0-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nc"&gt;C&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;cpp_disable_iff&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;all_fast&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;B&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a id="rest_code_92304d300002485b8da98e8d4ee30fa0-2" name="rest_code_92304d300002485b8da98e8d4ee30fa0-2" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_92304d300002485b8da98e8d4ee30fa0-2"&gt;&lt;/a&gt;&lt;span class="k"&gt;static&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;void&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;check&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;const&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;const&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;B&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;const&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;a id="rest_code_92304d300002485b8da98e8d4ee30fa0-3" name="rest_code_92304d300002485b8da98e8d4ee30fa0-3" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_92304d300002485b8da98e8d4ee30fa0-3"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;static_assert&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;all_2d&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;B&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;"Matrix multiplication needs matrices"&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a id="rest_code_92304d300002485b8da98e8d4ee30fa0-4" name="rest_code_92304d300002485b8da98e8d4ee30fa0-4" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_92304d300002485b8da98e8d4ee30fa0-4"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;cpp_assert&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
&lt;a id="rest_code_92304d300002485b8da98e8d4ee30fa0-5" name="rest_code_92304d300002485b8da98e8d4ee30fa0-5" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_92304d300002485b8da98e8d4ee30fa0-5"&gt;&lt;/a&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;dim&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dim&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;         &lt;/span&gt;&lt;span class="c1"&gt;//interior dimensions&lt;/span&gt;
&lt;a id="rest_code_92304d300002485b8da98e8d4ee30fa0-6" name="rest_code_92304d300002485b8da98e8d4ee30fa0-6" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_92304d300002485b8da98e8d4ee30fa0-6"&gt;&lt;/a&gt;&lt;span class="w"&gt;            &lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dim&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dim&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;//exterior dimension 1&lt;/span&gt;
&lt;a id="rest_code_92304d300002485b8da98e8d4ee30fa0-7" name="rest_code_92304d300002485b8da98e8d4ee30fa0-7" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_92304d300002485b8da98e8d4ee30fa0-7"&gt;&lt;/a&gt;&lt;span class="w"&gt;            &lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dim&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dim&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="c1"&gt;//exterior dimension 2&lt;/span&gt;
&lt;a id="rest_code_92304d300002485b8da98e8d4ee30fa0-8" name="rest_code_92304d300002485b8da98e8d4ee30fa0-8" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_92304d300002485b8da98e8d4ee30fa0-8"&gt;&lt;/a&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="s"&gt;"Invalid sizes for multiplication"&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a id="rest_code_92304d300002485b8da98e8d4ee30fa0-9" name="rest_code_92304d300002485b8da98e8d4ee30fa0-9" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_92304d300002485b8da98e8d4ee30fa0-9"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;cpp_unused&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a id="rest_code_92304d300002485b8da98e8d4ee30fa0-10" name="rest_code_92304d300002485b8da98e8d4ee30fa0-10" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_92304d300002485b8da98e8d4ee30fa0-10"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;cpp_unused&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a id="rest_code_92304d300002485b8da98e8d4ee30fa0-11" name="rest_code_92304d300002485b8da98e8d4ee30fa0-11" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_92304d300002485b8da98e8d4ee30fa0-11"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;cpp_unused&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a id="rest_code_92304d300002485b8da98e8d4ee30fa0-12" name="rest_code_92304d300002485b8da98e8d4ee30fa0-12" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_92304d300002485b8da98e8d4ee30fa0-12"&gt;&lt;/a&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;a id="rest_code_92304d300002485b8da98e8d4ee30fa0-13" name="rest_code_92304d300002485b8da98e8d4ee30fa0-13" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_92304d300002485b8da98e8d4ee30fa0-13"&gt;&lt;/a&gt;
&lt;a id="rest_code_92304d300002485b8da98e8d4ee30fa0-14" name="rest_code_92304d300002485b8da98e8d4ee30fa0-14" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_92304d300002485b8da98e8d4ee30fa0-14"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nc"&gt;C&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;cpp_enable_iff&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;all_fast&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;B&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a id="rest_code_92304d300002485b8da98e8d4ee30fa0-15" name="rest_code_92304d300002485b8da98e8d4ee30fa0-15" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_92304d300002485b8da98e8d4ee30fa0-15"&gt;&lt;/a&gt;&lt;span class="k"&gt;static&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;void&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;check&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;const&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;const&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;B&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;const&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;a id="rest_code_92304d300002485b8da98e8d4ee30fa0-16" name="rest_code_92304d300002485b8da98e8d4ee30fa0-16" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_92304d300002485b8da98e8d4ee30fa0-16"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;static_assert&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;all_2d&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;B&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;"Matrix multiplication needs matrices"&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a id="rest_code_92304d300002485b8da98e8d4ee30fa0-17" name="rest_code_92304d300002485b8da98e8d4ee30fa0-17" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_92304d300002485b8da98e8d4ee30fa0-17"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;static_assert&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
&lt;a id="rest_code_92304d300002485b8da98e8d4ee30fa0-18" name="rest_code_92304d300002485b8da98e8d4ee30fa0-18" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_92304d300002485b8da98e8d4ee30fa0-18"&gt;&lt;/a&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;dim&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dim&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;B&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt;         &lt;/span&gt;&lt;span class="c1"&gt;//interior dimensions&lt;/span&gt;
&lt;a id="rest_code_92304d300002485b8da98e8d4ee30fa0-19" name="rest_code_92304d300002485b8da98e8d4ee30fa0-19" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_92304d300002485b8da98e8d4ee30fa0-19"&gt;&lt;/a&gt;&lt;span class="w"&gt;            &lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dim&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dim&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;//exterior dimension 1&lt;/span&gt;
&lt;a id="rest_code_92304d300002485b8da98e8d4ee30fa0-20" name="rest_code_92304d300002485b8da98e8d4ee30fa0-20" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_92304d300002485b8da98e8d4ee30fa0-20"&gt;&lt;/a&gt;&lt;span class="w"&gt;            &lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dim&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;B&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dim&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="c1"&gt;//exterior dimension 2&lt;/span&gt;
&lt;a id="rest_code_92304d300002485b8da98e8d4ee30fa0-21" name="rest_code_92304d300002485b8da98e8d4ee30fa0-21" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_92304d300002485b8da98e8d4ee30fa0-21"&gt;&lt;/a&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="s"&gt;"Invalid sizes for multiplication"&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a id="rest_code_92304d300002485b8da98e8d4ee30fa0-22" name="rest_code_92304d300002485b8da98e8d4ee30fa0-22" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_92304d300002485b8da98e8d4ee30fa0-22"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;cpp_unused&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a id="rest_code_92304d300002485b8da98e8d4ee30fa0-23" name="rest_code_92304d300002485b8da98e8d4ee30fa0-23" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_92304d300002485b8da98e8d4ee30fa0-23"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;cpp_unused&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a id="rest_code_92304d300002485b8da98e8d4ee30fa0-24" name="rest_code_92304d300002485b8da98e8d4ee30fa0-24" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_92304d300002485b8da98e8d4ee30fa0-24"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;cpp_unused&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a id="rest_code_92304d300002485b8da98e8d4ee30fa0-25" name="rest_code_92304d300002485b8da98e8d4ee30fa0-25" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_92304d300002485b8da98e8d4ee30fa0-25"&gt;&lt;/a&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Again, we use SFINAE to distinguish the two different cases. In that case, we
cannot use a normal &lt;code&gt;if&lt;/code&gt; since the value of the dimensions cannot be taken
at compile-time for dynamic matrices, more precisely, some templates cannot be
instantiated for dynamic matrices. As for the cpp_unused, we have to use for the
static version because we don't use them and for the dynamic version because
they won't be used if the assertions are not enabled. Let's use &lt;code&gt;if constexpr&lt;/code&gt; to avoid having two functions:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code cpp"&gt;&lt;a id="rest_code_f835e4babc09425c994b1cec14bc0dca-1" name="rest_code_f835e4babc09425c994b1cec14bc0dca-1" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_f835e4babc09425c994b1cec14bc0dca-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nc"&gt;C&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a id="rest_code_f835e4babc09425c994b1cec14bc0dca-2" name="rest_code_f835e4babc09425c994b1cec14bc0dca-2" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_f835e4babc09425c994b1cec14bc0dca-2"&gt;&lt;/a&gt;&lt;span class="k"&gt;static&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;void&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;check&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;const&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;const&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;B&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;const&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;a id="rest_code_f835e4babc09425c994b1cec14bc0dca-3" name="rest_code_f835e4babc09425c994b1cec14bc0dca-3" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_f835e4babc09425c994b1cec14bc0dca-3"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;static_assert&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;all_2d&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;B&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;"Matrix multiplication needs matrices"&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a id="rest_code_f835e4babc09425c994b1cec14bc0dca-4" name="rest_code_f835e4babc09425c994b1cec14bc0dca-4" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_f835e4babc09425c994b1cec14bc0dca-4"&gt;&lt;/a&gt;
&lt;a id="rest_code_f835e4babc09425c994b1cec14bc0dca-5" name="rest_code_f835e4babc09425c994b1cec14bc0dca-5" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_f835e4babc09425c994b1cec14bc0dca-5"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;constexpr&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;all_fast&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;B&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;a id="rest_code_f835e4babc09425c994b1cec14bc0dca-6" name="rest_code_f835e4babc09425c994b1cec14bc0dca-6" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_f835e4babc09425c994b1cec14bc0dca-6"&gt;&lt;/a&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="k"&gt;static_assert&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dim&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dim&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;B&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt;         &lt;/span&gt;&lt;span class="c1"&gt;//interior dimensions&lt;/span&gt;
&lt;a id="rest_code_f835e4babc09425c994b1cec14bc0dca-7" name="rest_code_f835e4babc09425c994b1cec14bc0dca-7" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_f835e4babc09425c994b1cec14bc0dca-7"&gt;&lt;/a&gt;&lt;span class="w"&gt;                          &lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dim&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dim&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;//exterior dimension 1&lt;/span&gt;
&lt;a id="rest_code_f835e4babc09425c994b1cec14bc0dca-8" name="rest_code_f835e4babc09425c994b1cec14bc0dca-8" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_f835e4babc09425c994b1cec14bc0dca-8"&gt;&lt;/a&gt;&lt;span class="w"&gt;                          &lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dim&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;B&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dim&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="c1"&gt;//exterior dimension 2&lt;/span&gt;
&lt;a id="rest_code_f835e4babc09425c994b1cec14bc0dca-9" name="rest_code_f835e4babc09425c994b1cec14bc0dca-9" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_f835e4babc09425c994b1cec14bc0dca-9"&gt;&lt;/a&gt;&lt;span class="w"&gt;                      &lt;/span&gt;&lt;span class="s"&gt;"Invalid sizes for multiplication"&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a id="rest_code_f835e4babc09425c994b1cec14bc0dca-10" name="rest_code_f835e4babc09425c994b1cec14bc0dca-10" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_f835e4babc09425c994b1cec14bc0dca-10"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;a id="rest_code_f835e4babc09425c994b1cec14bc0dca-11" name="rest_code_f835e4babc09425c994b1cec14bc0dca-11" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_f835e4babc09425c994b1cec14bc0dca-11"&gt;&lt;/a&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;cpp_assert&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dim&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dim&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;         &lt;/span&gt;&lt;span class="c1"&gt;//interior dimensions&lt;/span&gt;
&lt;a id="rest_code_f835e4babc09425c994b1cec14bc0dca-12" name="rest_code_f835e4babc09425c994b1cec14bc0dca-12" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_f835e4babc09425c994b1cec14bc0dca-12"&gt;&lt;/a&gt;&lt;span class="w"&gt;                       &lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dim&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dim&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;//exterior dimension 1&lt;/span&gt;
&lt;a id="rest_code_f835e4babc09425c994b1cec14bc0dca-13" name="rest_code_f835e4babc09425c994b1cec14bc0dca-13" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_f835e4babc09425c994b1cec14bc0dca-13"&gt;&lt;/a&gt;&lt;span class="w"&gt;                       &lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dim&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dim&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="c1"&gt;//exterior dimension 2&lt;/span&gt;
&lt;a id="rest_code_f835e4babc09425c994b1cec14bc0dca-14" name="rest_code_f835e4babc09425c994b1cec14bc0dca-14" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_f835e4babc09425c994b1cec14bc0dca-14"&gt;&lt;/a&gt;&lt;span class="w"&gt;                   &lt;/span&gt;&lt;span class="s"&gt;"Invalid sizes for multiplication"&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a id="rest_code_f835e4babc09425c994b1cec14bc0dca-15" name="rest_code_f835e4babc09425c994b1cec14bc0dca-15" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_f835e4babc09425c994b1cec14bc0dca-15"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;a id="rest_code_f835e4babc09425c994b1cec14bc0dca-16" name="rest_code_f835e4babc09425c994b1cec14bc0dca-16" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_f835e4babc09425c994b1cec14bc0dca-16"&gt;&lt;/a&gt;
&lt;a id="rest_code_f835e4babc09425c994b1cec14bc0dca-17" name="rest_code_f835e4babc09425c994b1cec14bc0dca-17" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_f835e4babc09425c994b1cec14bc0dca-17"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;cpp_unused&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a id="rest_code_f835e4babc09425c994b1cec14bc0dca-18" name="rest_code_f835e4babc09425c994b1cec14bc0dca-18" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_f835e4babc09425c994b1cec14bc0dca-18"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;cpp_unused&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a id="rest_code_f835e4babc09425c994b1cec14bc0dca-19" name="rest_code_f835e4babc09425c994b1cec14bc0dca-19" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_f835e4babc09425c994b1cec14bc0dca-19"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;cpp_unused&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a id="rest_code_f835e4babc09425c994b1cec14bc0dca-20" name="rest_code_f835e4babc09425c994b1cec14bc0dca-20" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_f835e4babc09425c994b1cec14bc0dca-20"&gt;&lt;/a&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Since the &lt;em&gt;discarded&lt;/em&gt; won't be instantiated, we can now use a single function!
We also avoid some duplications of the first static assertion of the unused
statements. Pretty great, right ? But we can do better with C++17. Indeed, it
added a nice new attribute &lt;code&gt;[[maybe_unused]]&lt;/code&gt;. Let's see what this gives
us:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code cpp"&gt;&lt;a id="rest_code_6f6600bd7eb54dc5bdb208da4b948370-1" name="rest_code_6f6600bd7eb54dc5bdb208da4b948370-1" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_6f6600bd7eb54dc5bdb208da4b948370-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nc"&gt;C&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a id="rest_code_6f6600bd7eb54dc5bdb208da4b948370-2" name="rest_code_6f6600bd7eb54dc5bdb208da4b948370-2" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_6f6600bd7eb54dc5bdb208da4b948370-2"&gt;&lt;/a&gt;&lt;span class="k"&gt;static&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;void&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;check&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="n"&gt;maybe_unused&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;const&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="n"&gt;maybe_unused&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;const&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;B&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="n"&gt;maybe_unused&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;const&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;a id="rest_code_6f6600bd7eb54dc5bdb208da4b948370-3" name="rest_code_6f6600bd7eb54dc5bdb208da4b948370-3" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_6f6600bd7eb54dc5bdb208da4b948370-3"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;static_assert&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;all_2d&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;B&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;"Matrix multiplication needs matrices"&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a id="rest_code_6f6600bd7eb54dc5bdb208da4b948370-4" name="rest_code_6f6600bd7eb54dc5bdb208da4b948370-4" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_6f6600bd7eb54dc5bdb208da4b948370-4"&gt;&lt;/a&gt;
&lt;a id="rest_code_6f6600bd7eb54dc5bdb208da4b948370-5" name="rest_code_6f6600bd7eb54dc5bdb208da4b948370-5" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_6f6600bd7eb54dc5bdb208da4b948370-5"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;constexpr&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;all_fast&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;B&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;a id="rest_code_6f6600bd7eb54dc5bdb208da4b948370-6" name="rest_code_6f6600bd7eb54dc5bdb208da4b948370-6" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_6f6600bd7eb54dc5bdb208da4b948370-6"&gt;&lt;/a&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="k"&gt;static_assert&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dim&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dim&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;B&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt;         &lt;/span&gt;&lt;span class="c1"&gt;//interior dimensions&lt;/span&gt;
&lt;a id="rest_code_6f6600bd7eb54dc5bdb208da4b948370-7" name="rest_code_6f6600bd7eb54dc5bdb208da4b948370-7" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_6f6600bd7eb54dc5bdb208da4b948370-7"&gt;&lt;/a&gt;&lt;span class="w"&gt;                          &lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dim&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dim&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;//exterior dimension 1&lt;/span&gt;
&lt;a id="rest_code_6f6600bd7eb54dc5bdb208da4b948370-8" name="rest_code_6f6600bd7eb54dc5bdb208da4b948370-8" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_6f6600bd7eb54dc5bdb208da4b948370-8"&gt;&lt;/a&gt;&lt;span class="w"&gt;                          &lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dim&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;B&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dim&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="c1"&gt;//exterior dimension 2&lt;/span&gt;
&lt;a id="rest_code_6f6600bd7eb54dc5bdb208da4b948370-9" name="rest_code_6f6600bd7eb54dc5bdb208da4b948370-9" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_6f6600bd7eb54dc5bdb208da4b948370-9"&gt;&lt;/a&gt;&lt;span class="w"&gt;                      &lt;/span&gt;&lt;span class="s"&gt;"Invalid sizes for multiplication"&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a id="rest_code_6f6600bd7eb54dc5bdb208da4b948370-10" name="rest_code_6f6600bd7eb54dc5bdb208da4b948370-10" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_6f6600bd7eb54dc5bdb208da4b948370-10"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;a id="rest_code_6f6600bd7eb54dc5bdb208da4b948370-11" name="rest_code_6f6600bd7eb54dc5bdb208da4b948370-11" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_6f6600bd7eb54dc5bdb208da4b948370-11"&gt;&lt;/a&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;cpp_assert&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dim&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dim&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;         &lt;/span&gt;&lt;span class="c1"&gt;//interior dimensions&lt;/span&gt;
&lt;a id="rest_code_6f6600bd7eb54dc5bdb208da4b948370-12" name="rest_code_6f6600bd7eb54dc5bdb208da4b948370-12" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_6f6600bd7eb54dc5bdb208da4b948370-12"&gt;&lt;/a&gt;&lt;span class="w"&gt;                       &lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dim&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dim&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;//exterior dimension 1&lt;/span&gt;
&lt;a id="rest_code_6f6600bd7eb54dc5bdb208da4b948370-13" name="rest_code_6f6600bd7eb54dc5bdb208da4b948370-13" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_6f6600bd7eb54dc5bdb208da4b948370-13"&gt;&lt;/a&gt;&lt;span class="w"&gt;                       &lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dim&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dim&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="c1"&gt;//exterior dimension 2&lt;/span&gt;
&lt;a id="rest_code_6f6600bd7eb54dc5bdb208da4b948370-14" name="rest_code_6f6600bd7eb54dc5bdb208da4b948370-14" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_6f6600bd7eb54dc5bdb208da4b948370-14"&gt;&lt;/a&gt;&lt;span class="w"&gt;                   &lt;/span&gt;&lt;span class="s"&gt;"Invalid sizes for multiplication"&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a id="rest_code_6f6600bd7eb54dc5bdb208da4b948370-15" name="rest_code_6f6600bd7eb54dc5bdb208da4b948370-15" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_6f6600bd7eb54dc5bdb208da4b948370-15"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;a id="rest_code_6f6600bd7eb54dc5bdb208da4b948370-16" name="rest_code_6f6600bd7eb54dc5bdb208da4b948370-16" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_6f6600bd7eb54dc5bdb208da4b948370-16"&gt;&lt;/a&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;No more need for &lt;code&gt;cpp_unused&lt;/code&gt; trick :) This attribute tells the compiler
that a variable or parameter can be sometimes unused and therefore does not lead
to a warning for it. Only one thing that is not great with this attribute is
that it's too long, 16 characters. It almost double the width of my check
function signature. Imagine if you have more parameters, you'll soon have to use
several lines. I wish there was a way to set an attribute for all parameters
together or a shortcut. I'm considering whether to use a short macro to use in
place of it, but haven't yet decided.&lt;/p&gt;
&lt;p&gt;Just a note, if you have &lt;code&gt;else if&lt;/code&gt; statements, you need to set them as
&lt;code&gt;constexpr&lt;/code&gt; as well! This was a bit weird for me, but you can figure it as
if the condition is &lt;code&gt;constexpr&lt;/code&gt;, then the &lt;code&gt;if&lt;/code&gt; (or &lt;code&gt;else if&lt;/code&gt;)
is &lt;code&gt;constexpr&lt;/code&gt; as well.&lt;/p&gt;
&lt;p&gt;Overall, I'm really satisfied with the new &lt;cite&gt;if constexpr&lt;/cite&gt;! This really makes the
code much nicer in many cases, especially if you abuse metaprogramming like
I do.&lt;/p&gt;
&lt;p&gt;You may remember that I've &lt;a class="reference external" href="https://baptiste-wicht.com/posts/2015/07/simulate-static_if-with-c11c14.html"&gt;coded a version of static if in the past with C++14&lt;/a&gt; in the past. This was able to solve point 2, but not point 1 and was much uglier. Now we have a good solution to it. I've replaced two of these in the current code with the new &lt;code&gt;if constexpr&lt;/code&gt;.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="fold-expressions"&gt;
&lt;h2&gt;Fold expressions&lt;/h2&gt;
&lt;p&gt;For me, fold expressions is the second major feature of C++17. I wont' go into
too much details here, since
&lt;a class="reference external" href="https://baptiste-wicht.com/posts/2015/05/cpp17-fold-expressions.html"&gt;I've already talked about fold expression in the past&lt;/a&gt;
. But I'll show two examples of refactorings I've been able to do with this.&lt;/p&gt;
&lt;p&gt;Here was the size() function of a static matrix in ETL before:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code cpp"&gt;&lt;a id="rest_code_65cab5485da648c0987251d40d98ccab-1" name="rest_code_65cab5485da648c0987251d40d98ccab-1" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_65cab5485da648c0987251d40d98ccab-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;static&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;constexpr&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nf"&gt;size&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;a id="rest_code_65cab5485da648c0987251d40d98ccab-2" name="rest_code_65cab5485da648c0987251d40d98ccab-2" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_65cab5485da648c0987251d40d98ccab-2"&gt;&lt;/a&gt;&lt;span class="w"&gt;   &lt;/span&gt;&lt;span class="k"&gt;return&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;mul_all&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;Dims&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a id="rest_code_65cab5485da648c0987251d40d98ccab-3" name="rest_code_65cab5485da648c0987251d40d98ccab-3" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_65cab5485da648c0987251d40d98ccab-3"&gt;&lt;/a&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The Dims parameter pack from the declaration of fast_matrix:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code cpp"&gt;&lt;a id="rest_code_9cc767c6f8cd4ce88d16f6a2b038b505-1" name="rest_code_9cc767c6f8cd4ce88d16f6a2b038b505-1" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_9cc767c6f8cd4ce88d16f6a2b038b505-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nc"&gt;T&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nc"&gt;ST&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;order&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;SO&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Dims&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a id="rest_code_9cc767c6f8cd4ce88d16f6a2b038b505-2" name="rest_code_9cc767c6f8cd4ce88d16f6a2b038b505-2" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_9cc767c6f8cd4ce88d16f6a2b038b505-2"&gt;&lt;/a&gt;&lt;span class="k"&gt;struct&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nc"&gt;fast_matrix_impl&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And the mul_all is a simple helper that multiplies each value of the variadic
parameter pack:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code cpp"&gt;&lt;a id="rest_code_2b281ba2b22649c28edfae8b9c47038c-1" name="rest_code_2b281ba2b22649c28edfae8b9c47038c-1" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_2b281ba2b22649c28edfae8b9c47038c-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;F&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Dims&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a id="rest_code_2b281ba2b22649c28edfae8b9c47038c-2" name="rest_code_2b281ba2b22649c28edfae8b9c47038c-2" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_2b281ba2b22649c28edfae8b9c47038c-2"&gt;&lt;/a&gt;&lt;span class="k"&gt;struct&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nc"&gt;mul_all_impl&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;final&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;integral_constant&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;F&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;mul_all_impl&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;Dims&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{};&lt;/span&gt;
&lt;a id="rest_code_2b281ba2b22649c28edfae8b9c47038c-3" name="rest_code_2b281ba2b22649c28edfae8b9c47038c-3" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_2b281ba2b22649c28edfae8b9c47038c-3"&gt;&lt;/a&gt;
&lt;a id="rest_code_2b281ba2b22649c28edfae8b9c47038c-4" name="rest_code_2b281ba2b22649c28edfae8b9c47038c-4" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_2b281ba2b22649c28edfae8b9c47038c-4"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;F&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a id="rest_code_2b281ba2b22649c28edfae8b9c47038c-5" name="rest_code_2b281ba2b22649c28edfae8b9c47038c-5" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_2b281ba2b22649c28edfae8b9c47038c-5"&gt;&lt;/a&gt;&lt;span class="k"&gt;struct&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nc"&gt;mul_all_impl&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;F&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;final&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;integral_constant&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;F&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{};&lt;/span&gt;
&lt;a id="rest_code_2b281ba2b22649c28edfae8b9c47038c-6" name="rest_code_2b281ba2b22649c28edfae8b9c47038c-6" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_2b281ba2b22649c28edfae8b9c47038c-6"&gt;&lt;/a&gt;
&lt;a id="rest_code_2b281ba2b22649c28edfae8b9c47038c-7" name="rest_code_2b281ba2b22649c28edfae8b9c47038c-7" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_2b281ba2b22649c28edfae8b9c47038c-7"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;F&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Dims&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a id="rest_code_2b281ba2b22649c28edfae8b9c47038c-8" name="rest_code_2b281ba2b22649c28edfae8b9c47038c-8" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_2b281ba2b22649c28edfae8b9c47038c-8"&gt;&lt;/a&gt;&lt;span class="k"&gt;constexpr&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;mul_all&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;mul_all_impl&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;F&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Dims&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Before C++17, the only way to compute this result at compilation time was to use
template recursion, either with types or with constexpr functions. I think this
is pretty heavy only for doing a multiplication sum. Now, with fold expressions,
we can manipulate the parameter pack directly and rewrite our size function:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code cpp"&gt;&lt;a id="rest_code_849d2dea89ee49878d30b8c4f07e8054-1" name="rest_code_849d2dea89ee49878d30b8c4f07e8054-1" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_849d2dea89ee49878d30b8c4f07e8054-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;static&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;constexpr&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nf"&gt;size&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;a id="rest_code_849d2dea89ee49878d30b8c4f07e8054-2" name="rest_code_849d2dea89ee49878d30b8c4f07e8054-2" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_849d2dea89ee49878d30b8c4f07e8054-2"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;return&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Dims&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;...);&lt;/span&gt;
&lt;a id="rest_code_849d2dea89ee49878d30b8c4f07e8054-3" name="rest_code_849d2dea89ee49878d30b8c4f07e8054-3" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_849d2dea89ee49878d30b8c4f07e8054-3"&gt;&lt;/a&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This is much better! This clearly states that each value of the parameter should
be multiplied together. For instance &lt;code&gt;1,2,3&lt;/code&gt; will become &lt;code&gt;(1*2)*3&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Another place where I was using this was to code a traits that tests if a set of
boolean are all true at compilation-time:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code cpp"&gt;&lt;a id="rest_code_4db75bbdcce3408aac6d49c5f07d7d9e-1" name="rest_code_4db75bbdcce3408aac6d49c5f07d7d9e-1" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_4db75bbdcce3408aac6d49c5f07d7d9e-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kt"&gt;bool&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;B&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a id="rest_code_4db75bbdcce3408aac6d49c5f07d7d9e-2" name="rest_code_4db75bbdcce3408aac6d49c5f07d7d9e-2" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_4db75bbdcce3408aac6d49c5f07d7d9e-2"&gt;&lt;/a&gt;&lt;span class="k"&gt;constexpr&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;bool&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;and_v&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;is_same&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;
&lt;a id="rest_code_4db75bbdcce3408aac6d49c5f07d7d9e-3" name="rest_code_4db75bbdcce3408aac6d49c5f07d7d9e-3" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_4db75bbdcce3408aac6d49c5f07d7d9e-3"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;cpp&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;tmp_detail&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;bool_list&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nb"&gt;true&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;B&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a id="rest_code_4db75bbdcce3408aac6d49c5f07d7d9e-4" name="rest_code_4db75bbdcce3408aac6d49c5f07d7d9e-4" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_4db75bbdcce3408aac6d49c5f07d7d9e-4"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;cpp&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;tmp_detail&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;bool_list&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;B&lt;/span&gt;&lt;span class="p"&gt;...,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;true&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;I was using a nice trick here to test if all booleans are true. I don't remember
where I picked it up, but it's quite nice and very fast to compile.&lt;/p&gt;
&lt;p&gt;This was used for instance to test that a set of expressions are all
single-precision floating points:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code cpp"&gt;&lt;a id="rest_code_d8bb4cce868c4b7b9e2fb556397f961c-1" name="rest_code_d8bb4cce868c4b7b9e2fb556397f961c-1" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_d8bb4cce868c4b7b9e2fb556397f961c-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;E&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a id="rest_code_d8bb4cce868c4b7b9e2fb556397f961c-2" name="rest_code_d8bb4cce868c4b7b9e2fb556397f961c-2" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_d8bb4cce868c4b7b9e2fb556397f961c-2"&gt;&lt;/a&gt;&lt;span class="k"&gt;constexpr&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;bool&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;all_single_precision&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;and_v&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;is_single_precision&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;E&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;)...&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now, we can get rid of the and_v traits and use directly the parameter pack
directly:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code cpp"&gt;&lt;a id="rest_code_9b4d33e212714625b670d26b807a44ed-1" name="rest_code_9b4d33e212714625b670d26b807a44ed-1" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_9b4d33e212714625b670d26b807a44ed-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;E&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a id="rest_code_9b4d33e212714625b670d26b807a44ed-2" name="rest_code_9b4d33e212714625b670d26b807a44ed-2" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_9b4d33e212714625b670d26b807a44ed-2"&gt;&lt;/a&gt;&lt;span class="k"&gt;constexpr&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;bool&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;all_single_precision&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;is_single_precision&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;E&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;...);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;I think using fold expressions results in much clearer syntax and better code
and it's a pretty nice feature overall :)&lt;/p&gt;
&lt;p&gt;As a note here, I'd like to mention, that you can also use this syntax to call
a function on each argument that you have, which makes for much nicer syntax as
well and I'll be using that in DLL once I migrate it to C++17.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="miscellaneous"&gt;
&lt;h2&gt;Miscellaneous&lt;/h2&gt;
&lt;p&gt;There are also a few more C++17 features that I've used to improve ETL, but that
have a bit less impact.&lt;/p&gt;
&lt;p&gt;A very nice feature of C++17 is the support for structured bindings. Often you
end up with a function that returns several parts of information in the form of
a pair or a tuple or even a fixed-size array. You can use an object for this,
but if you don't, you end up with code that is not terribly nice:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code cpp"&gt;&lt;a id="rest_code_727cbdd2c7cb48b8b20ce805aaedb269-1" name="rest_code_727cbdd2c7cb48b8b20ce805aaedb269-1" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_727cbdd2c7cb48b8b20ce805aaedb269-1"&gt;&lt;/a&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a id="rest_code_727cbdd2c7cb48b8b20ce805aaedb269-2" name="rest_code_727cbdd2c7cb48b8b20ce805aaedb269-2" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_727cbdd2c7cb48b8b20ce805aaedb269-2"&gt;&lt;/a&gt;&lt;span class="kt"&gt;bool&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a id="rest_code_727cbdd2c7cb48b8b20ce805aaedb269-3" name="rest_code_727cbdd2c7cb48b8b20ce805aaedb269-3" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_727cbdd2c7cb48b8b20ce805aaedb269-3"&gt;&lt;/a&gt;&lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a id="rest_code_727cbdd2c7cb48b8b20ce805aaedb269-4" name="rest_code_727cbdd2c7cb48b8b20ce805aaedb269-4" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_727cbdd2c7cb48b8b20ce805aaedb269-4"&gt;&lt;/a&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;tie&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;my_function&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;It's not terribly bad, but in these cases, you should be be hoping for something
better. With c++17, you can do better:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code cpp"&gt;&lt;a id="rest_code_06e25d44e04643d89811ab6be554adea-1" name="rest_code_06e25d44e04643d89811ab6be554adea-1" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_06e25d44e04643d89811ab6be554adea-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;auto&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;alpha&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;my_function&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now you can directly use auto to deduce the types of the three variables at once
and you can get all the results in the variables at once as well :) I think this
is really nice and can really profit some projects. In ETL, I've almost no use
for this, but I'm going to be using that a bit more in DLL.&lt;/p&gt;
&lt;p&gt;Something really nice to clean up the code in C++17 is the ability to declared
nested namespaces in one line. Before, you have a nested namespace
etl::impl::standard for instance, you would do:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code cpp"&gt;&lt;a id="rest_code_40f9b90286cc4d3b9215377f53835e7f-1" name="rest_code_40f9b90286cc4d3b9215377f53835e7f-1" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_40f9b90286cc4d3b9215377f53835e7f-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;namespace&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;etl&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;a id="rest_code_40f9b90286cc4d3b9215377f53835e7f-2" name="rest_code_40f9b90286cc4d3b9215377f53835e7f-2" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_40f9b90286cc4d3b9215377f53835e7f-2"&gt;&lt;/a&gt;&lt;span class="k"&gt;namespace&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;impl&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;a id="rest_code_40f9b90286cc4d3b9215377f53835e7f-3" name="rest_code_40f9b90286cc4d3b9215377f53835e7f-3" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_40f9b90286cc4d3b9215377f53835e7f-3"&gt;&lt;/a&gt;&lt;span class="k"&gt;namespace&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;standard&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;a id="rest_code_40f9b90286cc4d3b9215377f53835e7f-4" name="rest_code_40f9b90286cc4d3b9215377f53835e7f-4" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_40f9b90286cc4d3b9215377f53835e7f-4"&gt;&lt;/a&gt;
&lt;a id="rest_code_40f9b90286cc4d3b9215377f53835e7f-5" name="rest_code_40f9b90286cc4d3b9215377f53835e7f-5" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_40f9b90286cc4d3b9215377f53835e7f-5"&gt;&lt;/a&gt;&lt;span class="c1"&gt;// Someting inside etl::impl::standard&lt;/span&gt;
&lt;a id="rest_code_40f9b90286cc4d3b9215377f53835e7f-6" name="rest_code_40f9b90286cc4d3b9215377f53835e7f-6" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_40f9b90286cc4d3b9215377f53835e7f-6"&gt;&lt;/a&gt;
&lt;a id="rest_code_40f9b90286cc4d3b9215377f53835e7f-7" name="rest_code_40f9b90286cc4d3b9215377f53835e7f-7" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_40f9b90286cc4d3b9215377f53835e7f-7"&gt;&lt;/a&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="c1"&gt;// end of namespace standard&lt;/span&gt;
&lt;a id="rest_code_40f9b90286cc4d3b9215377f53835e7f-8" name="rest_code_40f9b90286cc4d3b9215377f53835e7f-8" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_40f9b90286cc4d3b9215377f53835e7f-8"&gt;&lt;/a&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="c1"&gt;// end of namespace impl&lt;/span&gt;
&lt;a id="rest_code_40f9b90286cc4d3b9215377f53835e7f-9" name="rest_code_40f9b90286cc4d3b9215377f53835e7f-9" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_40f9b90286cc4d3b9215377f53835e7f-9"&gt;&lt;/a&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="c1"&gt;// end of namespace etl&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In C++17, you can do:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code cpp"&gt;&lt;a id="rest_code_a54f5b2c3b2c466d934af51d41af0247-1" name="rest_code_a54f5b2c3b2c466d934af51d41af0247-1" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_a54f5b2c3b2c466d934af51d41af0247-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;namespace&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;etl&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="nn"&gt;impl&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="nn"&gt;standard&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;a id="rest_code_a54f5b2c3b2c466d934af51d41af0247-2" name="rest_code_a54f5b2c3b2c466d934af51d41af0247-2" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_a54f5b2c3b2c466d934af51d41af0247-2"&gt;&lt;/a&gt;
&lt;a id="rest_code_a54f5b2c3b2c466d934af51d41af0247-3" name="rest_code_a54f5b2c3b2c466d934af51d41af0247-3" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_a54f5b2c3b2c466d934af51d41af0247-3"&gt;&lt;/a&gt;&lt;span class="c1"&gt;// Someting inside etl::impl::standard&lt;/span&gt;
&lt;a id="rest_code_a54f5b2c3b2c466d934af51d41af0247-4" name="rest_code_a54f5b2c3b2c466d934af51d41af0247-4" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_a54f5b2c3b2c466d934af51d41af0247-4"&gt;&lt;/a&gt;
&lt;a id="rest_code_a54f5b2c3b2c466d934af51d41af0247-5" name="rest_code_a54f5b2c3b2c466d934af51d41af0247-5" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_a54f5b2c3b2c466d934af51d41af0247-5"&gt;&lt;/a&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="c1"&gt;// end of namespace etl::impl::standard&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;I think it's pretty neat :)&lt;/p&gt;
&lt;p&gt;Another very small change is the ability to use the typename keyword in place of
the class keyword when declaring template template parameters. Before, you had
to declare:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code cpp"&gt;&lt;a id="rest_code_f407b4ab57614ac095d3b6cca2f7e1da-1" name="rest_code_f407b4ab57614ac095d3b6cca2f7e1da-1" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_f407b4ab57614ac095d3b6cca2f7e1da-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nc"&gt;X&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;now you can also use:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code cpp"&gt;&lt;a id="rest_code_7c19f229948547c9b5ed4b2b91b3663c-1" name="rest_code_7c19f229948547c9b5ed4b2b91b3663c-1" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_7c19f229948547c9b5ed4b2b91b3663c-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nc"&gt;X&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;It's just some syntactic sugar, but I think it's quite nice.&lt;/p&gt;
&lt;p&gt;The last improvement that I want to talk about is one that probably very few
know about but it's pretty neat. Since C++11, you can use the &lt;code&gt;alignas(X)&lt;/code&gt;
specifier for types and objects to specify on how many bytes you want to align
these. This is pretty nice if you want to align on the stack. However, this
won't always work for dynamic memory allocation. Imagine this struct:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code cpp"&gt;&lt;a id="rest_code_159e316ee54e47d4909c3525189d12d6-1" name="rest_code_159e316ee54e47d4909c3525189d12d6-1" href="https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html#rest_code_159e316ee54e47d4909c3525189d12d6-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;struct&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nc"&gt;alignas&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;test_struct&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;char&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;};&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If you declare an object of this type on the stack, you have the guarantee that
it will be aligned on 128 bytes. However, if you use &lt;code&gt;new&lt;/code&gt; to allocate it
on the heap, you don't have such guarantee. Indeed, the problem is that 128 is
greater than the maximum default alignment. This is called an over-aligned type.
In such cases, the result will be aligned on the max alignment of your system.
Since C++17, &lt;code&gt;new&lt;/code&gt; supports aligned dynamic memory allocation of
over-aligned types. Therefore, you can use a simple &lt;code&gt;alignas&lt;/code&gt; to allocate
dynamic over-aligned types :) I need this in ETL for matrices that need to be
aligned for vectorized code. Before, I was using a larger array with some
padding in order to find an aligned element inside, but that is not very nice,
now the code is much better.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="compilation-time"&gt;
&lt;h2&gt;Compilation Time&lt;/h2&gt;
&lt;p&gt;I've done a few tests to see how much impact these news features have on
compilation time. Here, I'm doing benchmark on compiling the entire test suite
in different compilation mode, I enabled most compilation options (all GPU and
BLAS options in order to make sure almost all of the library is compiled).&lt;/p&gt;
&lt;p&gt;Since I'm a bit short on time before going to vacation, I've only gathered the
results with g++. Here are the results with G++ 7.2.0&lt;/p&gt;
&lt;table&gt;
&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;debug&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;release&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;release_debug&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;C++14&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;862s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1961s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1718s&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;C++17&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;892s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;2018s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1745s&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;Difference&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;+3.4%&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;+2.9%&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;+1.5%&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Overall, I'm a bit disappointed by these results, it's around 3% slower to
compile the C++17 version than the C++14 version. I was thinking that this would
a least be as fast to compile as before. It seems that currently with G++ 7.2,
&lt;code&gt;if constexpr&lt;/code&gt; are slower to compile than the equivalent SFINAE functions.
I didn't do individual benchmarks of all the features I've migrated, therefore,
it may not be coming from &lt;code&gt;if constexpr&lt;/code&gt;, but since it's the greatest
change by far, it's the more likely candidate. Once I'll have a little more
time, after my vacations, I'll try to see if that is also the case with clang.&lt;/p&gt;
&lt;p&gt;Keep in mind that we are compiling the test suite here. The ETL test suite is
using the manual selection mode of the library in order to be able to test all
the possible implementations of each operation. This makes a considerable
difference in performance. I expect better compilation time when this is used in
automatic selection mode (the default mode). In the default mode, a lot more
code can be disabled with &lt;code&gt;if constexpr&lt;/code&gt;. I will test this next with the
DLL library which I will also migrate to C++17.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="conclusion"&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;This concludes this report on the migration of my ETL library from C++14 to
C++17. Overall, I'm really satisfied with the improvement of the code, it's much
better. I'm a bit disappointed by the slight increase  (around 3%) in
compilation time, but it's not dramatic either. I'm still hoping that once it's
used in DLL, I will see a decrease in compilation, but we'll see that when I'll
be done with the migration of DLL to C++17 which may take some time since I'll
have two weeks vacation in China starting Friday.&lt;/p&gt;
&lt;p&gt;The new version is available only through the &lt;em&gt;master&lt;/em&gt; branch. It will be
released as the 1.3 version probably when I integrate some new features, but in
itself will not be released as new version. You can take a look in the
&lt;a class="reference external" href="https://github.com/wichtounet/etl"&gt;Github etl repository&lt;/a&gt; if you are interested.&lt;/p&gt;
&lt;/section&gt;</description><category>C++</category><category>C++14</category><category>C++17</category><category>etl</category><category>projects</category><guid>https://baptiste-wicht.com/posts/2018/02/c%2B%2B17-migration-of-expression-templates-library-etl.html</guid><pubDate>Fri, 02 Feb 2018 13:03:26 GMT</pubDate></item><item><title>Expression Templates Library 1.2.1: Faster GPU and new features</title><link>https://baptiste-wicht.com/posts/2018/01/expression-templates-library-121-faster-gpu-and-new-features.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;p&gt;Happy new year to all my dear readers!&lt;/p&gt;
&lt;p&gt;It has been a while since I've posted on this blog. I've had to serve three
weeks in the army and then I had two weeks vacation. I've been actively working
on budgetwarrior with a brand new web interface! More on that later ;)&lt;/p&gt;
&lt;p&gt;Today, I'm happy to release the version 1.2.1 of my Expression Templates Library
(ETL) project. This is a minor version but with significantly better GPU support
and a few new features and bug fixes so I decided to release it now.&lt;/p&gt;
&lt;section id="faster-gpu-support"&gt;
&lt;h2&gt;Faster GPU support&lt;/h2&gt;
&lt;p&gt;Last year, I &lt;a class="reference external" href="https://baptiste-wicht.com/posts/2017/11/advanced-gpu-patterns-optimization-in-etl.html"&gt;implemented the support for the detection of advanced GPU patterns in ETL&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This will significantly reduce the number of CUDA kernel calls that are being
launched. For instance, each of the following expressions will be evaluated
using a single GPU kernel:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code C++"&gt;&lt;a id="rest_code_c9754aa00f6c403789c4432eb5e3be01-1" name="rest_code_c9754aa00f6c403789c4432eb5e3be01-1" href="https://baptiste-wicht.com/posts/2018/01/expression-templates-library-121-faster-gpu-and-new-features.html#rest_code_c9754aa00f6c403789c4432eb5e3be01-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;yy&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;1.1&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;
&lt;a id="rest_code_c9754aa00f6c403789c4432eb5e3be01-2" name="rest_code_c9754aa00f6c403789c4432eb5e3be01-2" href="https://baptiste-wicht.com/posts/2018/01/expression-templates-library-121-faster-gpu-and-new-features.html#rest_code_c9754aa00f6c403789c4432eb5e3be01-2"&gt;&lt;/a&gt;&lt;span class="n"&gt;yy&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;1.1&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;
&lt;a id="rest_code_c9754aa00f6c403789c4432eb5e3be01-3" name="rest_code_c9754aa00f6c403789c4432eb5e3be01-3" href="https://baptiste-wicht.com/posts/2018/01/expression-templates-library-121-faster-gpu-and-new-features.html#rest_code_c9754aa00f6c403789c4432eb5e3be01-3"&gt;&lt;/a&gt;&lt;span class="n"&gt;yy&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;1.1&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;1.2&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;
&lt;a id="rest_code_c9754aa00f6c403789c4432eb5e3be01-4" name="rest_code_c9754aa00f6c403789c4432eb5e3be01-4" href="https://baptiste-wicht.com/posts/2018/01/expression-templates-library-121-faster-gpu-and-new-features.html#rest_code_c9754aa00f6c403789c4432eb5e3be01-4"&gt;&lt;/a&gt;&lt;span class="n"&gt;yy&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;1.1&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;
&lt;a id="rest_code_c9754aa00f6c403789c4432eb5e3be01-5" name="rest_code_c9754aa00f6c403789c4432eb5e3be01-5" href="https://baptiste-wicht.com/posts/2018/01/expression-templates-library-121-faster-gpu-and-new-features.html#rest_code_c9754aa00f6c403789c4432eb5e3be01-5"&gt;&lt;/a&gt;&lt;span class="n"&gt;yy&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;1.1&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This makes some operation significantly faster.&lt;/p&gt;
&lt;p&gt;Moreover, I've reduced a lot the numbers of device synchronization in the
library. Especially, I've removed almost all synchronization from the
etl-gpu-blas sub library. This means that synchronization is mostly only done
when data needs to go back to the CPU. For machine learning, this means at the
end of the epoch to compute the final error. This makes a HUGE difference in
time, I didn't realize before that I was doing way too much synchronization.&lt;/p&gt;
&lt;p&gt;With these two changes, I've been able to attain &lt;em&gt;state of the art training performance on GPU&lt;/em&gt; with my Deep Learning Library (DLL) project!&lt;/p&gt;
&lt;p&gt;Moreover, I've now added for random number generations on the GPU and for
shuffle operations as well.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="new-features"&gt;
&lt;h2&gt;New Features&lt;/h2&gt;
&lt;p&gt;I've also added a few new features recently. They were especially added to
support new features in DLL.&lt;/p&gt;
&lt;p&gt;Matrices and vectors can now be normalized in order to have zero-mean and
unit-variance distribution. You can also merge matrices together. For now, there
is no GPU support, so this will use CPU anyway. I plan to fix that later.&lt;/p&gt;
&lt;p&gt;In addition to bias_batch_mean that I added before, I also added bias_batch_var
now with the variance in place of the mean. This is mainly used for Batch
Normalization in machine learning, but it may have some other usages. The GPU
support has been added as well directly.&lt;/p&gt;
&lt;p&gt;And the last feature is the support for embedding and the gradients of
embedding. Again this is totally related to machine learning, but can be very
useful as well. I haven't add the time to develop the GPU version so far, but
this will come as well.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="performance"&gt;
&lt;h2&gt;Performance&lt;/h2&gt;
&lt;p&gt;Nothing fancy on the CPU performance side, I only added vectorization for
hyperbolic versions. This makes &lt;em&gt;tanh much faster on CPU&lt;/em&gt;.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="bug-fixes"&gt;
&lt;h2&gt;Bug Fixes&lt;/h2&gt;
&lt;p&gt;I fixed quite a few bugs in this version, which is one of the main reason
I released it:&lt;/p&gt;
&lt;p&gt;1. When using large fast_matrix and aliasing was detected, there was a big chance of stack overflow occurring. This is now fixed by using a dynamic temporary.
1. Some assignables such sub_view did not perform any detection for aliasing. This is now fixed and aliasing is detected everywhere.
1. fast_dyn_matrix can now be correctly used with &lt;em&gt;bool&lt;/em&gt;
1. The use of iterators was not always ensuring correct CPU/GPU consistency. This is now correctly handled.
1. The 4D convolution in GPU were not using the correct flipping
1. Fix small compilation bug with sub_matrix and GPU&lt;/p&gt;
&lt;/section&gt;
&lt;section id="what-s-next"&gt;
&lt;h2&gt;What's next ?&lt;/h2&gt;
&lt;p&gt;I don't really know what will be in the next release. This should be the release
1.3. One possible idea would be to improve and review the support for sparse
matrix which is more than  poor as of now. But I'm not really motivated to
work on that :P Moreover, I'm now &lt;em&gt;actively&lt;/em&gt; working on the next release of
budgetwarrior which will probably still come this month.&lt;/p&gt;
&lt;p&gt;I'm also still hesitating in switching to C++17 for the library to make it
faster to compile. And also to clean some parts of the code. I would be able to
remove quite some SFINAE with the new &lt;em&gt;if constexpr&lt;/em&gt;, but I'm afraid this will
make the library to difficult to use since it would need at least GCC 7 or clang
3.9.&lt;/p&gt;
&lt;section id="download-etl"&gt;
&lt;h3&gt;Download ETL&lt;/h3&gt;
&lt;p&gt;You can download ETL &lt;a class="reference external" href="https://github.com/wichtounet/etl"&gt;on Github&lt;/a&gt;. If you
only interested in the 1.2.1 version, you can look at the
&lt;a class="reference external" href="https://github.com/wichtounet/etl/releases"&gt;Releases pages&lt;/a&gt; or clone the tag
1.2.1. There are several branches:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;master&lt;/em&gt; Is the eternal development branch, may not always be stable&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;stable&lt;/em&gt; Is a branch always pointing to the last tag, no development here&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For the future release, there always will tags pointing to the corresponding
commits. You can also have access to previous releases on Github or via the
release tags.&lt;/p&gt;
&lt;p&gt;The documentation is still a bit sparse. There are a few examples and the Wiki,
but there still is work to be done. If you have questions on how to use or
configure the library, please don't hesitate.&lt;/p&gt;
&lt;p&gt;Don't hesitate to comment this post if you have any comment on this library or
any question. You can also open an Issue on Github if you have a problem using
this library or propose a Pull Request if you have any contribution you'd like
to make to the library.&lt;/p&gt;
&lt;p&gt;Hope this may be useful to some of you :)&lt;/p&gt;
&lt;/section&gt;
&lt;/section&gt;</description><category>C++</category><category>C++14</category><category>C++17</category><category>etl</category><category>GPU</category><category>Performance</category><category>projects</category><category>Releases</category><guid>https://baptiste-wicht.com/posts/2018/01/expression-templates-library-121-faster-gpu-and-new-features.html</guid><pubDate>Tue, 09 Jan 2018 10:06:15 GMT</pubDate></item><item><title>Advanced GPU Patterns Optimization in ETL</title><link>https://baptiste-wicht.com/posts/2017/11/advanced-gpu-patterns-optimization-in-etl.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;p&gt;The GPU performance of my Expression Templates Library (ETL) is pretty good when
most of the time is spent inside expensive operations such as Matrix-Matrix
Multiplication or convolutions. However, when most of the time is spent in
linear kernels, performance is not great because this will invoke a lot of CUDA
kernels. Indeed, the way it is done is that each sub expressions compute its
result in a temporary GPU vector (or matrix) and these temporaries are passed
through the expressions. For instance, this expression:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code C++"&gt;&lt;a id="rest_code_96c932d477364701a3dbd3a6c147297d-1" name="rest_code_96c932d477364701a3dbd3a6c147297d-1" href="https://baptiste-wicht.com/posts/2017/11/advanced-gpu-patterns-optimization-in-etl.html#rest_code_96c932d477364701a3dbd3a6c147297d-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;yy&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;1.1&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;1.2&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;will be executed on the GPU as something like this:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code C++"&gt;&lt;a id="rest_code_5d703e7e0f7849c09018a87fd9ad44f9-1" name="rest_code_5d703e7e0f7849c09018a87fd9ad44f9-1" href="https://baptiste-wicht.com/posts/2017/11/advanced-gpu-patterns-optimization-in-etl.html#rest_code_5d703e7e0f7849c09018a87fd9ad44f9-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;t1&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;1.1&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;
&lt;a id="rest_code_5d703e7e0f7849c09018a87fd9ad44f9-2" name="rest_code_5d703e7e0f7849c09018a87fd9ad44f9-2" href="https://baptiste-wicht.com/posts/2017/11/advanced-gpu-patterns-optimization-in-etl.html#rest_code_5d703e7e0f7849c09018a87fd9ad44f9-2"&gt;&lt;/a&gt;&lt;span class="n"&gt;t2&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;1.2&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;
&lt;a id="rest_code_5d703e7e0f7849c09018a87fd9ad44f9-3" name="rest_code_5d703e7e0f7849c09018a87fd9ad44f9-3" href="https://baptiste-wicht.com/posts/2017/11/advanced-gpu-patterns-optimization-in-etl.html#rest_code_5d703e7e0f7849c09018a87fd9ad44f9-3"&gt;&lt;/a&gt;&lt;span class="n"&gt;yy&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;t1&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;t2&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;that will results in three GPU kernels being invoked. In the CPU case, the
complete expression will be executed as one CPU kernel, that is constructed with
Expression Templates. Unfortunately, a CUDA kernel cannot be constructed in the
same way since the CUDA compiler does not support general template
metaprogramming. That's why I've implemented by using small kernels for each
expression.&lt;/p&gt;
&lt;p&gt;Fortunately, we can do better with a bit more meta-programming. Indeed, there
are some patterns that are repeated a lot and that easily be implemented in CUDA
kernels. I've started detecting a few of these patterns and for each of them
a single CUDA kernel is executed. For instance, each of the following
expressions can be executed with a single kernel:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code C++"&gt;&lt;a id="rest_code_d7068c96535d492eb01085a69e64ec25-1" name="rest_code_d7068c96535d492eb01085a69e64ec25-1" href="https://baptiste-wicht.com/posts/2017/11/advanced-gpu-patterns-optimization-in-etl.html#rest_code_d7068c96535d492eb01085a69e64ec25-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;yy&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;1.1&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;
&lt;a id="rest_code_d7068c96535d492eb01085a69e64ec25-2" name="rest_code_d7068c96535d492eb01085a69e64ec25-2" href="https://baptiste-wicht.com/posts/2017/11/advanced-gpu-patterns-optimization-in-etl.html#rest_code_d7068c96535d492eb01085a69e64ec25-2"&gt;&lt;/a&gt;&lt;span class="n"&gt;yy&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;1.1&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;
&lt;a id="rest_code_d7068c96535d492eb01085a69e64ec25-3" name="rest_code_d7068c96535d492eb01085a69e64ec25-3" href="https://baptiste-wicht.com/posts/2017/11/advanced-gpu-patterns-optimization-in-etl.html#rest_code_d7068c96535d492eb01085a69e64ec25-3"&gt;&lt;/a&gt;&lt;span class="n"&gt;yy&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;1.1&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;1.2&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;
&lt;a id="rest_code_d7068c96535d492eb01085a69e64ec25-4" name="rest_code_d7068c96535d492eb01085a69e64ec25-4" href="https://baptiste-wicht.com/posts/2017/11/advanced-gpu-patterns-optimization-in-etl.html#rest_code_d7068c96535d492eb01085a69e64ec25-4"&gt;&lt;/a&gt;&lt;span class="n"&gt;yy&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;1.1&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;
&lt;a id="rest_code_d7068c96535d492eb01085a69e64ec25-5" name="rest_code_d7068c96535d492eb01085a69e64ec25-5" href="https://baptiste-wicht.com/posts/2017/11/advanced-gpu-patterns-optimization-in-etl.html#rest_code_d7068c96535d492eb01085a69e64ec25-5"&gt;&lt;/a&gt;&lt;span class="n"&gt;yy&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;1.1&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This results in significantly performance improvement for these expressions!&lt;/p&gt;
&lt;p&gt;I have tested these new improvements in my Deep Learning Library (DLL) project
(not yet merged) and it resulted in &lt;strong&gt;25% faster momentum computation&lt;/strong&gt; and
&lt;strong&gt;17% faster Nesterov Adam (NADAM)&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;I'm going to continue to investigate which kernels need to be made faster for
DLL and try to improve the overall performance. Currently, the GPU performance
of DLL is very good for large convolutional networks, but could be improved for
small fully-connected networks. Indeed, in that case, quite some time is spent
outside the matrix-matrix multiplication and inside serial expressions for which
GPU could be improved. Once I'm done with my optimizations, I'll probably post
again on the blog with the latest results.&lt;/p&gt;
&lt;p&gt;All these new optimizations are now in the &lt;strong&gt;master&lt;/strong&gt; branch of the ETL
project if you want to check it out. You can access the project
&lt;a class="reference external" href="https://github.com/wichtounet/etl"&gt;on Github&lt;/a&gt;.&lt;/p&gt;</description><category>C++</category><category>dll</category><category>etl</category><category>GPU</category><category>Optimization</category><category>Performance</category><category>projects</category><guid>https://baptiste-wicht.com/posts/2017/11/advanced-gpu-patterns-optimization-in-etl.html</guid><pubDate>Sun, 26 Nov 2017 14:44:29 GMT</pubDate></item><item><title>Deep Learning Library 1.0 - Fast Neural Network Library</title><link>https://baptiste-wicht.com/posts/2017/10/deep-learning-library-10-fast-neural-network-library.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;div&gt;&lt;img alt="DLL Logo" class="align-center" src="https://baptiste-wicht.com/images/dll_logo.png"&gt;
&lt;p&gt;I'm very happy to announce the release of the first version of Deep Learning
Library (DLL) 1.0. DLL is a neural network library with a focus on speed and
ease of use.&lt;/p&gt;
&lt;p&gt;I started working on this library about 4 years ago for my Ph.D. thesis.
I needed a good library to train and use Restricted Boltzmann Machines (RBMs)
and at this time there was no good support for it. Therefore, I decided to write
my own. It now has very complete support for the RBM and the Convolutional RBM
(CRBM) models. Stacks of RBMs (or Deep Belief Networks (DBNs)) can be pretrained
using Contrastive Divergence and then either fine-tuned with mini-batch gradient
descent or Conjugate Gradient or used as a feature extractor. Over the years,
the library has been extended to handle Artificial Neural Networks (ANNs) and
Convolutional Neural Networks (CNNs). The network is also able to train regular
auto-encoders. Several advanced layers such as Dropout or Batch Normalization
are also available as well as adaptive learning rates techniques such as
Adadelta and Adam. The library also has integrated support for a few datasets:
MNIST, CIFAR-10 and ImageNet.&lt;/p&gt;
&lt;p&gt;This library can be used using a C++ interface. The library is fully
header-only. It requires a C++14 compiler, which means a minimum of clang 3.9 or
GCC 6.3.&lt;/p&gt;
&lt;p&gt;In this post, I'm going to present a few examples on using the library and give
some information about the performance of the library and the roadmap for the
project.&lt;/p&gt;
&lt;p class="more"&gt;&lt;a href="https://baptiste-wicht.com/posts/2017/10/deep-learning-library-10-fast-neural-network-library.html"&gt;Read more&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;</description><category>C++</category><category>dll</category><category>etl</category><category>GPU</category><category>Machine Learning</category><category>Performances</category><category>Releases</category><guid>https://baptiste-wicht.com/posts/2017/10/deep-learning-library-10-fast-neural-network-library.html</guid><pubDate>Sat, 07 Oct 2017 13:42:16 GMT</pubDate></item><item><title>Expression Templates Library (ETL) 1.2 - Complete GPU support</title><link>https://baptiste-wicht.com/posts/2017/10/expression-templates-library-etl-1-2-complete-gpu-support.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;img alt="ETL Logo" class="align-center" src="https://baptiste-wicht.com/images/logo.png"&gt;
&lt;p&gt;I'm happy to announce the version 1.2 of my Expression Templates Library (ETL):
ETL 1.2, two months after &lt;a class="reference external" href="https://baptiste-wicht.com/posts/2017/08/expression-templates-library-etl-11.html"&gt;I released the version 1.1&lt;/a&gt;.
This version features much better GPU Support, a few new features and a lot of
changes in the internal code.&lt;/p&gt;
&lt;section id="gpu-support"&gt;
&lt;h2&gt;GPU Support&lt;/h2&gt;
&lt;p&gt;Before, only algorithms such as 4D convolution or matrix-matrix multiplication
were computed in the GPU and lots of operations were causing copies between CPU
and GPU version. Now, the support for basic operations has also been completed
and therefore, expressions like this:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code cpp"&gt;&lt;a id="rest_code_261c06c0a9d14e7aa5a8c81e7736365c-1" name="rest_code_261c06c0a9d14e7aa5a8c81e7736365c-1" href="https://baptiste-wicht.com/posts/2017/10/expression-templates-library-etl-1-2-complete-gpu-support.html#rest_code_261c06c0a9d14e7aa5a8c81e7736365c-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;sigmoid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;2.0&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;B&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Can be computed entirely on GPU.&lt;/p&gt;
&lt;p&gt;Each matrix and vector containers have a secondary GPU memory space.  During the
execution, the status of both memory spaces is being managed and when necessary,
copies are made between two spaces. In the best case, there should only be
initial copies to the GPU and then everything should be done on the GPU. I've
also considered using Unified Memory in place of this system, but this is
a problem for fast matrix and I'd rather not have two different systems.&lt;/p&gt;
&lt;p&gt;If you have an expression such as &lt;code&gt;c = a + b * 2&lt;/code&gt;, it can be entirely computed
on GPU, however, it will be computed in two GPU operations such as:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code cpp"&gt;&lt;a id="rest_code_85d45ed7928f4d81a8db7e4e2bc6fa0d-1" name="rest_code_85d45ed7928f4d81a8db7e4e2bc6fa0d-1" href="https://baptiste-wicht.com/posts/2017/10/expression-templates-library-etl-1-2-complete-gpu-support.html#rest_code_85d45ed7928f4d81a8db7e4e2bc6fa0d-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;t1&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;
&lt;a id="rest_code_85d45ed7928f4d81a8db7e4e2bc6fa0d-2" name="rest_code_85d45ed7928f4d81a8db7e4e2bc6fa0d-2" href="https://baptiste-wicht.com/posts/2017/10/expression-templates-library-etl-1-2-complete-gpu-support.html#rest_code_85d45ed7928f4d81a8db7e4e2bc6fa0d-2"&gt;&lt;/a&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;t1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This is not perfect in terms of performance but this will be done without any
copies between CPU and GPU memory. I plan to improve this system with a bit more
complex operations to avoid too many GPU operations, but there will always be
more operations than in CPU where this can easily be done in one go.&lt;/p&gt;
&lt;p&gt;There are a few expressions that are not computable on the GPU, such as random
generations. A few transformations are also not fully compatible with GPU.
Moreover, if you access an element with operators &lt;code&gt;[]&lt;/code&gt; or &lt;code&gt;()&lt;/code&gt;, this
will invalidate the GPU memory and force an update to the CPU memory.&lt;/p&gt;
&lt;p&gt;GPU operations are not implemented directly in ETL, there are coming from
various libraries. ETL is using NVIDIA CUDNN, CUFFT and CUDNN for most
algorithms. Moreover, for other operations, I've implemented a libraries with
simple GPU operations: ETL-GPU-BLAS (EGBLAS). You can have a look at
&lt;a class="reference external" href="https://github.com/wichtounet/etl-gpu-blas"&gt;egblas&lt;/a&gt; if you are interested.&lt;/p&gt;
&lt;p&gt;My Deep Learning Library (DLL) project is based on ETL and its performances are
mostly dependent on ETL's performances. Now that ETL fully supports GPU, the
GPU performance of DLL is much improved. You may remember a few weeks ago
I posted &lt;a class="reference external" href="https://baptiste-wicht.com/posts/2017/08/dll-blazing-fast-neural-network-library.html"&gt;very high CPU performance of DLL&lt;/a&gt;.
Now, I've run again the tests to see the GPU performance with DLL. Here is the
performance for training a small CNN on the MNIST data set:&lt;/p&gt;
&lt;img alt="Performances for training a Convolutional Neural Network on MNIST" class="align-center" src="https://baptiste-wicht.com/images/etl_12_dll_gpu_mnist.png"&gt;
&lt;p&gt;As you can see, the performances on GPU are now excellent. DLL's performances
are on par with Tensorflow and Keras!&lt;/p&gt;
&lt;p&gt;The next results are for training a much larger CNN on ImageNet, with the time
necessary to train a single batch:&lt;/p&gt;
&lt;img alt="Performances for training a Convolutional Neural Network on Imagenet" class="align-center" src="https://baptiste-wicht.com/images/etl_12_dll_gpu_imagenet.png"&gt;
&lt;p&gt;Again, using the new version of ETL inside DLL has led to excellent performance.
The framework is again on par with TensorFlow and Keras and faster than all the
other frameworks. The large difference between DLL and Tensorflow and Keras is
due to the inefficiency of reading the dataset in the two frameworks, so the
performance of the three framework themselves are about the same.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="other-changes"&gt;
&lt;h2&gt;Other Changes&lt;/h2&gt;
&lt;p&gt;The library also has a few other new features. Logarithms of base 2 and base 10
are now supported in complement to the base e that was already available before.
Categorical Cross Entropy (CCE) computation is also available now, the CCE loss
and error can be computed for one or many samples. Convolutions have also been
improved in that you can use mixed types in both the image and the kernel and
different storage order as well. Nevertheless, the most optimized version
remains the version with the same storage order and the same data type.&lt;/p&gt;
&lt;p&gt;I've also made a major change in the way implementations are selected for each
operation. The tests and the benchmark are using a system to force the selection
of an algorithm. This system is now disabled by default. This makes the
compilation much faster by default. Since it's not necessary in most cases, this
will help regular use cases of the library by compiling much faster.&lt;/p&gt;
&lt;p&gt;Overall, the support for complex numbers has been improved in ETL. There are
more routines that are supported and &lt;code&gt;etl::complex&lt;/code&gt; is better supported
throughout the code. I'll still work on this in the future to make it totally
complete.&lt;/p&gt;
&lt;p&gt;The internal code also has a few new changes. First, all traits have been
rewritten to use variable templates instead of struct traits. This makes the
code much nicer in my opinion. Moreover, I've started experimenting with C++17
&lt;code&gt;if constexpr&lt;/code&gt;. Most of the if conditions that can be transformed to if
constexpr have been annotated with comments that I can quickly enable or disable
so that I can test the impact of C++17, especially on compilation time.&lt;/p&gt;
&lt;p&gt;Finally, a few bugs have been fixed. ETL is now working better with parallel
BLAS library. There should not be issues with double parallelization in ETL and
BLAS. There was a slight bug in the Column-Major matrix-matrix multiplication
kernel. Binary operations with different types in the left and right hand sides
was also problematic with vectorization. The last bug was about GPU status in
case ETL containers were moved.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="what-s-next"&gt;
&lt;h2&gt;What's next ?&lt;/h2&gt;
&lt;p&gt;I don't yet know exactly on which features I'm going to focus for the next
version of ETL. I plan to focus a bit more in the near future on Deep Learning
Library (DLL) for which I should release the version 1.0 soon. I also plan to
start support for Recurrent Neural Networks on it, so that will take me quite
some time.&lt;/p&gt;
&lt;p&gt;Nevertheless, I'm still planning to consider the switch to C++17, since it is
&lt;a class="reference external" href="https://baptiste-wicht.com/posts/2017/09/how-i-made-deep-learning-library-38-faster-to-compile-optimization-and-cpp17-if-constexpr.html"&gt;a bit faster to compile ETL with if constexpr&lt;/a&gt;. The next version of ETL will also probably have GPU-support for
integers, at least in the cases that depend on the etl-gpu-blas library, which
is the standard operators. I also plan to improve the support for complex
numbers, especially in terms of performance and tests. Hopefully, I will have also time (and motivation)
to start working on  the sparse capabilities of ETL. It really needs much more
unit tests and the performance should be improved as well.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="download-etl"&gt;
&lt;h2&gt;Download ETL&lt;/h2&gt;
&lt;p&gt;You can download ETL &lt;a class="reference external" href="https://github.com/wichtounet/etl"&gt;on Github&lt;/a&gt;. If you
only interested in the 1.2 version, you can look at the
&lt;a class="reference external" href="https://github.com/wichtounet/etl/releases"&gt;Releases pages&lt;/a&gt; or clone the tag
1.2. There are several branches:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;master&lt;/em&gt; Is the eternal development branch, may not always be stable&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;stable&lt;/em&gt; Is a branch always pointing to the last tag, no development here&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For the future release, there always will tags pointing to the corresponding
commits. You can also have access to previous releases on Github or via the
release tags.&lt;/p&gt;
&lt;p&gt;The documentation is still a bit sparse. There are a few examples and the Wiki,
but there still is work to be done. If you have questions on how to use or
configure the library, please don't hesitate.&lt;/p&gt;
&lt;p&gt;Don't hesitate to comment this post if you have any comment on this library or
any question. You can also open an Issue on Github if you have a problem using
this library or propose a Pull Request if you have any contribution you'd like
to make to the library.&lt;/p&gt;
&lt;p&gt;Hope this may be useful to some of you :)&lt;/p&gt;
&lt;/section&gt;</description><category>C++</category><category>C++14</category><category>C++17</category><category>Compilers</category><category>dll</category><category>etl</category><category>GPU</category><category>Performance</category><category>projects</category><category>Release</category><guid>https://baptiste-wicht.com/posts/2017/10/expression-templates-library-etl-1-2-complete-gpu-support.html</guid><pubDate>Mon, 02 Oct 2017 08:49:02 GMT</pubDate></item><item><title>How I made my Deep Learning Library 38% faster to compile (Optimization and C++17 if constexpr)</title><link>https://baptiste-wicht.com/posts/2017/09/how-i-made-deep-learning-library-38-faster-to-compile-optimization-and-cpp17-if-constexpr.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;div&gt;&lt;p&gt;My Deep Learning Library (DLL) project is a C++ library for training and using
artificial neural networks (you can take a look at
&lt;a class="reference external" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html"&gt;this post about DLL&lt;/a&gt;
if you want more information).&lt;/p&gt;
&lt;p&gt;While I made a lot of effort to make it as fast as possible to train and run
neural networks, the compilation time has been steadily going up and is becoming
quite annoying. This library is heavily templated and all the matrix operations
are done using my Expression Templates Library (ETL) which is more than
template-heavy itself.&lt;/p&gt;
&lt;p&gt;In this post, I'll present two techniques with which I've been able to reduce
the total compilation of the DLL unit tests by up to 38%.&lt;/p&gt;
&lt;p class="more"&gt;&lt;a href="https://baptiste-wicht.com/posts/2017/09/how-i-made-deep-learning-library-38-faster-to-compile-optimization-and-cpp17-if-constexpr.html"&gt;Read more&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;</description><category>C++</category><category>C++17</category><category>clang</category><category>Compilers</category><category>dll</category><category>etl</category><category>gcc</category><category>Performance</category><category>projects</category><guid>https://baptiste-wicht.com/posts/2017/09/how-i-made-deep-learning-library-38-faster-to-compile-optimization-and-cpp17-if-constexpr.html</guid><pubDate>Thu, 21 Sep 2017 17:44:34 GMT</pubDate></item><item><title>Simplify your type traits with C++14 variable templates</title><link>https://baptiste-wicht.com/posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;p&gt;Often if you write templated code, you have to write and use a lot of different
traits. In this article, I'll focus on the traits that are representing values,
typically a boolean value. For instance, std::is_const, std::is_same or
std::is_reference are type traits provided by the STL. They are giving you some
information at compile time for a certain type. If you need to write a type
traits, let's say is_float, here is how you would maybe do it in C++11:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code c++"&gt;&lt;a id="rest_code_8a216448c84644878b288cd2377df2be-1" name="rest_code_8a216448c84644878b288cd2377df2be-1" href="https://baptiste-wicht.com/posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_8a216448c84644878b288cd2377df2be-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nc"&gt;T&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a id="rest_code_8a216448c84644878b288cd2377df2be-2" name="rest_code_8a216448c84644878b288cd2377df2be-2" href="https://baptiste-wicht.com/posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_8a216448c84644878b288cd2377df2be-2"&gt;&lt;/a&gt;&lt;span class="k"&gt;struct&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nc"&gt;is_float&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;a id="rest_code_8a216448c84644878b288cd2377df2be-3" name="rest_code_8a216448c84644878b288cd2377df2be-3" href="https://baptiste-wicht.com/posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_8a216448c84644878b288cd2377df2be-3"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;static&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;constexpr&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;bool&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;is_same&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a id="rest_code_8a216448c84644878b288cd2377df2be-4" name="rest_code_8a216448c84644878b288cd2377df2be-4" href="https://baptiste-wicht.com/posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_8a216448c84644878b288cd2377df2be-4"&gt;&lt;/a&gt;&lt;span class="p"&gt;};&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;or a bit nicer with a template type alias and std::integral constant:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code c++"&gt;&lt;a id="rest_code_5fe47aa9cc5249579e5495fb780c17f4-1" name="rest_code_5fe47aa9cc5249579e5495fb780c17f4-1" href="https://baptiste-wicht.com/posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_5fe47aa9cc5249579e5495fb780c17f4-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nc"&gt;T&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a id="rest_code_5fe47aa9cc5249579e5495fb780c17f4-2" name="rest_code_5fe47aa9cc5249579e5495fb780c17f4-2" href="https://baptiste-wicht.com/posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_5fe47aa9cc5249579e5495fb780c17f4-2"&gt;&lt;/a&gt;&lt;span class="k"&gt;using&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;is_float&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;integral_constant&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kt"&gt;bool&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;is_same&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;or since is_same is itself a type traits, you can also directly alias it:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code c++"&gt;&lt;a id="rest_code_f45475396d634412bc907efc967deb72-1" name="rest_code_f45475396d634412bc907efc967deb72-1" href="https://baptiste-wicht.com/posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_f45475396d634412bc907efc967deb72-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nc"&gt;T&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a id="rest_code_f45475396d634412bc907efc967deb72-2" name="rest_code_f45475396d634412bc907efc967deb72-2" href="https://baptiste-wicht.com/posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_f45475396d634412bc907efc967deb72-2"&gt;&lt;/a&gt;&lt;span class="k"&gt;using&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;is_float&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;is_same&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This makes for some very nice syntax, but we still have a type rather than a value.&lt;/p&gt;
&lt;p&gt;Note that in some cases, you cannot use the using technique since it cannot be
specialized and you often need specialization to write some more advanced
traits.&lt;/p&gt;
&lt;p&gt;And then you would use your traits to do something specific based on that
information. For instance with a very basic example:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code C++"&gt;&lt;a id="rest_code_9278eca933cb4a84ba0febd1dcc8c35e-1" name="rest_code_9278eca933cb4a84ba0febd1dcc8c35e-1" href="https://baptiste-wicht.com/posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_9278eca933cb4a84ba0febd1dcc8c35e-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nc"&gt;T&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a id="rest_code_9278eca933cb4a84ba0febd1dcc8c35e-2" name="rest_code_9278eca933cb4a84ba0febd1dcc8c35e-2" href="https://baptiste-wicht.com/posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_9278eca933cb4a84ba0febd1dcc8c35e-2"&gt;&lt;/a&gt;&lt;span class="kt"&gt;void&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;test&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
&lt;a id="rest_code_9278eca933cb4a84ba0febd1dcc8c35e-3" name="rest_code_9278eca933cb4a84ba0febd1dcc8c35e-3" href="https://baptiste-wicht.com/posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_9278eca933cb4a84ba0febd1dcc8c35e-3"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;is_float&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
&lt;a id="rest_code_9278eca933cb4a84ba0febd1dcc8c35e-4" name="rest_code_9278eca933cb4a84ba0febd1dcc8c35e-4" href="https://baptiste-wicht.com/posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_9278eca933cb4a84ba0febd1dcc8c35e-4"&gt;&lt;/a&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;cout&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;"I'm a float"&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;endl&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a id="rest_code_9278eca933cb4a84ba0febd1dcc8c35e-5" name="rest_code_9278eca933cb4a84ba0febd1dcc8c35e-5" href="https://baptiste-wicht.com/posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_9278eca933cb4a84ba0febd1dcc8c35e-5"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;a id="rest_code_9278eca933cb4a84ba0febd1dcc8c35e-6" name="rest_code_9278eca933cb4a84ba0febd1dcc8c35e-6" href="https://baptiste-wicht.com/posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_9278eca933cb4a84ba0febd1dcc8c35e-6"&gt;&lt;/a&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;cout&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;"I'm not a float"&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;endl&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a id="rest_code_9278eca933cb4a84ba0febd1dcc8c35e-7" name="rest_code_9278eca933cb4a84ba0febd1dcc8c35e-7" href="https://baptiste-wicht.com/posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_9278eca933cb4a84ba0febd1dcc8c35e-7"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;a id="rest_code_9278eca933cb4a84ba0febd1dcc8c35e-8" name="rest_code_9278eca933cb4a84ba0febd1dcc8c35e-8" href="https://baptiste-wicht.com/posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_9278eca933cb4a84ba0febd1dcc8c35e-8"&gt;&lt;/a&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Really nothing fancy here, but that will be enough as examples.&lt;/p&gt;
&lt;p&gt;Even though all this works pretty, it can be made better on two points. First,
every time you use a traits, you need to use the value member (via ::value).
Secondly, every time you declare a new traits, you have to declare a new type or
a type alias. But all you want is a boolean value.&lt;/p&gt;
&lt;p&gt;C++14 introduced a new feature, variable templates. As their name indicates,
they are variables, parametrized with a type. This allows us to write type
traits without using a type alias or struct, meaning we have a real value
instead of a type. If we rewrite our is_float traits with variable templates, we
have the following:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code c++"&gt;&lt;a id="rest_code_045ef625c19f452ba25228171c7178e7-1" name="rest_code_045ef625c19f452ba25228171c7178e7-1" href="https://baptiste-wicht.com/posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_045ef625c19f452ba25228171c7178e7-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nc"&gt;T&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a id="rest_code_045ef625c19f452ba25228171c7178e7-2" name="rest_code_045ef625c19f452ba25228171c7178e7-2" href="https://baptiste-wicht.com/posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_045ef625c19f452ba25228171c7178e7-2"&gt;&lt;/a&gt;&lt;span class="k"&gt;constexpr&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;bool&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;is_float&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;is_same&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;I think it's much nicer, the intent is clearly stated and there is no
unnecessary code. Moreover, it's also nicer to use:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code C++"&gt;&lt;a id="rest_code_25b61526db6f43859ff0c66e3be6f3b1-1" name="rest_code_25b61526db6f43859ff0c66e3be6f3b1-1" href="https://baptiste-wicht.com/posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_25b61526db6f43859ff0c66e3be6f3b1-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nc"&gt;T&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a id="rest_code_25b61526db6f43859ff0c66e3be6f3b1-2" name="rest_code_25b61526db6f43859ff0c66e3be6f3b1-2" href="https://baptiste-wicht.com/posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_25b61526db6f43859ff0c66e3be6f3b1-2"&gt;&lt;/a&gt;&lt;span class="kt"&gt;void&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;test&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
&lt;a id="rest_code_25b61526db6f43859ff0c66e3be6f3b1-3" name="rest_code_25b61526db6f43859ff0c66e3be6f3b1-3" href="https://baptiste-wicht.com/posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_25b61526db6f43859ff0c66e3be6f3b1-3"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;is_float&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
&lt;a id="rest_code_25b61526db6f43859ff0c66e3be6f3b1-4" name="rest_code_25b61526db6f43859ff0c66e3be6f3b1-4" href="https://baptiste-wicht.com/posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_25b61526db6f43859ff0c66e3be6f3b1-4"&gt;&lt;/a&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;cout&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;"I'm a float"&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;endl&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a id="rest_code_25b61526db6f43859ff0c66e3be6f3b1-5" name="rest_code_25b61526db6f43859ff0c66e3be6f3b1-5" href="https://baptiste-wicht.com/posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_25b61526db6f43859ff0c66e3be6f3b1-5"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;a id="rest_code_25b61526db6f43859ff0c66e3be6f3b1-6" name="rest_code_25b61526db6f43859ff0c66e3be6f3b1-6" href="https://baptiste-wicht.com/posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_25b61526db6f43859ff0c66e3be6f3b1-6"&gt;&lt;/a&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;cout&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;"I'm not a float"&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;endl&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a id="rest_code_25b61526db6f43859ff0c66e3be6f3b1-7" name="rest_code_25b61526db6f43859ff0c66e3be6f3b1-7" href="https://baptiste-wicht.com/posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_25b61526db6f43859ff0c66e3be6f3b1-7"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;a id="rest_code_25b61526db6f43859ff0c66e3be6f3b1-8" name="rest_code_25b61526db6f43859ff0c66e3be6f3b1-8" href="https://baptiste-wicht.com/posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_25b61526db6f43859ff0c66e3be6f3b1-8"&gt;&lt;/a&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;No more ::value everywhere :) I think it's really cool.&lt;/p&gt;
&lt;p&gt;Note that, unlike type alias template, they can be specialized, either fully or
partially, so no more limitation on that side.&lt;/p&gt;
&lt;p&gt;Interestingly, variable templates are used in C++17 to provide helpers for each
type traits with values. For instance, std::is_same will have a std::is_same_v
helper that is a variable template. With that, we can simplify our traits a bit
more:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code c++"&gt;&lt;a id="rest_code_715f0a48205d4cec8afcc8b77fb5c11a-1" name="rest_code_715f0a48205d4cec8afcc8b77fb5c11a-1" href="https://baptiste-wicht.com/posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_715f0a48205d4cec8afcc8b77fb5c11a-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nc"&gt;T&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a id="rest_code_715f0a48205d4cec8afcc8b77fb5c11a-2" name="rest_code_715f0a48205d4cec8afcc8b77fb5c11a-2" href="https://baptiste-wicht.com/posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_715f0a48205d4cec8afcc8b77fb5c11a-2"&gt;&lt;/a&gt;&lt;span class="k"&gt;constexpr&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;bool&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;is_float&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;is_same_v&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Personally, I replaced all the type traits inside ETL using variable templates.
If you don't want to do it, you can also introduce helpers like in the C++17 STL
and start using the wrappers when you see fit so that you don't break any code.&lt;/p&gt;
&lt;p&gt;If you want to use this feature, you need a C++14 compiler, such as any version
from GCC5 family or clang 3.6. Although I haven't tested, it should also work on
Microsoft VS2015 Update 2.&lt;/p&gt;
&lt;p&gt;Unfortunately there is a bug in both clang (fixed in clang 3.7) and GCC (fixed
in GCC 6 only) that you may encounter if you start using variable templates in
template classes or variable templates used in another variable templates. If
you plan to use variable templates inside a template, such as something like
this:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code c++"&gt;&lt;a id="rest_code_3adf558aa4884d19836b7087a72a8c96-1" name="rest_code_3adf558aa4884d19836b7087a72a8c96-1" href="https://baptiste-wicht.com/posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_3adf558aa4884d19836b7087a72a8c96-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nc"&gt;T&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a id="rest_code_3adf558aa4884d19836b7087a72a8c96-2" name="rest_code_3adf558aa4884d19836b7087a72a8c96-2" href="https://baptiste-wicht.com/posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_3adf558aa4884d19836b7087a72a8c96-2"&gt;&lt;/a&gt;&lt;span class="k"&gt;struct&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nc"&gt;outer_traits&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;a id="rest_code_3adf558aa4884d19836b7087a72a8c96-3" name="rest_code_3adf558aa4884d19836b7087a72a8c96-3" href="https://baptiste-wicht.com/posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_3adf558aa4884d19836b7087a72a8c96-3"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nc"&gt;X&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a id="rest_code_3adf558aa4884d19836b7087a72a8c96-4" name="rest_code_3adf558aa4884d19836b7087a72a8c96-4" href="https://baptiste-wicht.com/posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_3adf558aa4884d19836b7087a72a8c96-4"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;static&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;constexpr&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;bool&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;sub_traits&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;is_same&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a id="rest_code_3adf558aa4884d19836b7087a72a8c96-5" name="rest_code_3adf558aa4884d19836b7087a72a8c96-5" href="https://baptiste-wicht.com/posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_3adf558aa4884d19836b7087a72a8c96-5"&gt;&lt;/a&gt;&lt;span class="p"&gt;};&lt;/span&gt;
&lt;a id="rest_code_3adf558aa4884d19836b7087a72a8c96-6" name="rest_code_3adf558aa4884d19836b7087a72a8c96-6" href="https://baptiste-wicht.com/posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_3adf558aa4884d19836b7087a72a8c96-6"&gt;&lt;/a&gt;
&lt;a id="rest_code_3adf558aa4884d19836b7087a72a8c96-7" name="rest_code_3adf558aa4884d19836b7087a72a8c96-7" href="https://baptiste-wicht.com/posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_3adf558aa4884d19836b7087a72a8c96-7"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nc"&gt;T&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nc"&gt;X&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a id="rest_code_3adf558aa4884d19836b7087a72a8c96-8" name="rest_code_3adf558aa4884d19836b7087a72a8c96-8" href="https://baptiste-wicht.com/posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_3adf558aa4884d19836b7087a72a8c96-8"&gt;&lt;/a&gt;&lt;span class="k"&gt;constexpr&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;bool&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;outer_helper&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;outer_traits&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;sub_traits&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a id="rest_code_3adf558aa4884d19836b7087a72a8c96-9" name="rest_code_3adf558aa4884d19836b7087a72a8c96-9" href="https://baptiste-wicht.com/posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_3adf558aa4884d19836b7087a72a8c96-9"&gt;&lt;/a&gt;
&lt;a id="rest_code_3adf558aa4884d19836b7087a72a8c96-10" name="rest_code_3adf558aa4884d19836b7087a72a8c96-10" href="https://baptiste-wicht.com/posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_3adf558aa4884d19836b7087a72a8c96-10"&gt;&lt;/a&gt;&lt;span class="kt"&gt;int&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;(){&lt;/span&gt;
&lt;a id="rest_code_3adf558aa4884d19836b7087a72a8c96-11" name="rest_code_3adf558aa4884d19836b7087a72a8c96-11" href="https://baptiste-wicht.com/posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_3adf558aa4884d19836b7087a72a8c96-11"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;cout&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;outer_helper&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a id="rest_code_3adf558aa4884d19836b7087a72a8c96-12" name="rest_code_3adf558aa4884d19836b7087a72a8c96-12" href="https://baptiste-wicht.com/posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_3adf558aa4884d19836b7087a72a8c96-12"&gt;&lt;/a&gt;
&lt;a id="rest_code_3adf558aa4884d19836b7087a72a8c96-13" name="rest_code_3adf558aa4884d19836b7087a72a8c96-13" href="https://baptiste-wicht.com/posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_3adf558aa4884d19836b7087a72a8c96-13"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;return&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a id="rest_code_3adf558aa4884d19836b7087a72a8c96-14" name="rest_code_3adf558aa4884d19836b7087a72a8c96-14" href="https://baptiste-wicht.com/posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_3adf558aa4884d19836b7087a72a8c96-14"&gt;&lt;/a&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;You will encounter a not-helpful at all error message with GCC5 family, such as:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code text"&gt;&lt;a id="rest_code_6053d77025b9420089fd7b1b02d4bcb1-1" name="rest_code_6053d77025b9420089fd7b1b02d4bcb1-1" href="https://baptiste-wicht.com/posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_6053d77025b9420089fd7b1b02d4bcb1-1"&gt;&lt;/a&gt;test.cpp: In instantiation of constexpr const bool outer_helper&amp;lt;float, float&amp;gt;:
&lt;a id="rest_code_6053d77025b9420089fd7b1b02d4bcb1-2" name="rest_code_6053d77025b9420089fd7b1b02d4bcb1-2" href="https://baptiste-wicht.com/posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_6053d77025b9420089fd7b1b02d4bcb1-2"&gt;&lt;/a&gt;test.cpp:14:22:   required from here
&lt;a id="rest_code_6053d77025b9420089fd7b1b02d4bcb1-3" name="rest_code_6053d77025b9420089fd7b1b02d4bcb1-3" href="https://baptiste-wicht.com/posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_6053d77025b9420089fd7b1b02d4bcb1-3"&gt;&lt;/a&gt;test.cpp:11:20: error: template&amp;lt;class X&amp;gt; constexpr const bool outer_traits&amp;lt;float&amp;gt;::sub_traits&amp;lt;X&amp;gt; is not a function template
&lt;a id="rest_code_6053d77025b9420089fd7b1b02d4bcb1-4" name="rest_code_6053d77025b9420089fd7b1b02d4bcb1-4" href="https://baptiste-wicht.com/posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_6053d77025b9420089fd7b1b02d4bcb1-4"&gt;&lt;/a&gt;     constexpr bool outer_helper = outer_traits&amp;lt;T&amp;gt;::template sub_trait
&lt;a id="rest_code_6053d77025b9420089fd7b1b02d4bcb1-5" name="rest_code_6053d77025b9420089fd7b1b02d4bcb1-5" href="https://baptiste-wicht.com/posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_6053d77025b9420089fd7b1b02d4bcb1-5"&gt;&lt;/a&gt;                    ^
&lt;a id="rest_code_6053d77025b9420089fd7b1b02d4bcb1-6" name="rest_code_6053d77025b9420089fd7b1b02d4bcb1-6" href="https://baptiste-wicht.com/posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html#rest_code_6053d77025b9420089fd7b1b02d4bcb1-6"&gt;&lt;/a&gt;test.cpp:11:20: error: sub_traits&amp;lt;X&amp;gt; is not a member of outer_traits&amp;lt;float&amp;gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;It comes from a bug in the handling of variable templates as dependent names. If
you don't come in this cases, you can use GCC5 family directly, otherwise,
you'll have to use GCC6 family only.&lt;/p&gt;
&lt;p&gt;I hope this can help some of you to improve your type traits or at least to
discover the power of the new variable templates. Personally, I've rewritten all
the traits from the ETL library using this new feature and I'm pretty satisfied
with the result. Of course, that means that the compiler support was reduced,
but since I don't have many users, it's not a real issue.&lt;/p&gt;</description><category>C++</category><category>C++14</category><category>Compilers</category><category>etl</category><category>projects</category><guid>https://baptiste-wicht.com/posts/2017/08/simplify-your-type-traits-with-c%2B%2B14-variable-templates.html</guid><pubDate>Tue, 22 Aug 2017 12:45:11 GMT</pubDate></item><item><title>DLL: Blazing Fast Neural Network Library</title><link>https://baptiste-wicht.com/posts/2017/08/dll-blazing-fast-neural-network-library.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;p&gt;A few weeks ago, I talked about all
&lt;a class="reference external" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html"&gt;the new features of my Deep Learning Library (DLL)&lt;/a&gt;
project. I've mentioned that, on several experiments, DLL was always
significantly faster than some popular deep learning frameworks such as
TensorFlow. I'll now go into more details into this comparison and provide all
the results. So far, the paper we wrote about these results has not been
published, so I'll not provide the paper directly yet.&lt;/p&gt;
&lt;p&gt;For those that may not know, DLL is the project I've been developing to support
my Ph.D. thesis. This is a neural network framework  that supports
Fully-Connected Neural Network (FCNN), Convolutional Neural Network (CNN),
Restricted Boltzmann Machine (RBM), Deep Belief Network (DBN), Convolutional RBM
(CRBM) and Convolutional DBN (CDBN). It also supports a large variety of options
such as Dropout, Batch Normalization and Adaptive Learning Rates. You can read
read the
&lt;a class="reference external" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html"&gt;previous post&lt;/a&gt;
if you want more information about the new features of the framework. And, as those of
you that read my blog frequently may know, I'm a bit obsessed with performance
optimization, so I've spent a considerable amount of time optimizing
the performance of neural network training, on CPU. Since, at the beginning of my
thesis, I had no access to GPU for training, I've focused on CPU. Although there
is now support for GPU, the gains are not yet important enough.&lt;/p&gt;
&lt;section id="evaluation"&gt;
&lt;h2&gt;Evaluation&lt;/h2&gt;
&lt;p&gt;To see how fast, or not, the library was, it was compared against five popular
machine learning libraries:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;&lt;p&gt;Caffe, installed from sources&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;TensorFlow 1.0, from pip&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Keras 2.0, from pip&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Torch, installed from sources&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;DeepLearning4J 0.7, from Maven&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I've run four different experiments with all these frameworks and compared the
efficiency of each of them for training the same neural networks with the same
options. In each case, the training or testing error have also been compared to
ensure that each framework is doing roughly the same. I wont present here the
details, but in each experiment DLL showed around the same accuracies as the
other frameworks. I will only focus on the speed results in this article.&lt;/p&gt;
&lt;p&gt;Each experiment is done once with only CPU and once with a GPU. For DLL, I only
report the CPU time in both modes, since it's more stable and more optimized.&lt;/p&gt;
&lt;p&gt;The code for the evaluation is available online on the
&lt;a class="reference external" href="https://github.com/wichtounet/frameworks"&gt;Github repository of the frameworks project&lt;/a&gt;.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="mnist-fully-connected-neural-network"&gt;
&lt;h2&gt;MNIST: Fully Connected Neural Network&lt;/h2&gt;
&lt;p&gt;The first experiment is performed on The MNIST data set. It consists of 60'000
grayscale images of size 28x28. The goal is to classify each image of a digit
from 0 to 9. To solve this task, I trained a very small fully-connected neural
network with 500 hidden units in the first layer, 250 in the second and 10 final
hidden units (or output units) for classification. The first two layers are
using the logistic sigmoid activation function and the last layer is using the
softmax activation function. The network is trained for 50 epochs with a
categorical cross entropy loss, with mini-batches of 100 images. Here are
results of this experiment:&lt;/p&gt;
&lt;figure class="align-center"&gt;
&lt;img alt="Training time performance for the different frameworks on the Fully-Connected Neural Network experiment, on MNIST." src="https://baptiste-wicht.com/images/dll_fcnn.png"&gt;
&lt;figcaption&gt;
&lt;p&gt;Training time performance for the different frameworks on the Fully-Connected
Neural Network experiment, on MNIST. All the times are in seconds.&lt;/p&gt;
&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;In DLL mode, the DLL framework is the clear winner here! It's about 35% faster
than TensorFlow and Keras which are coming at the second place. DLL is more than
four times slower than DLL and the last two frameworks (Caffe and
DeepLearning4J) are five times slower than DLL! Once we add a GPU to the system,
the results are very different. Caffe is now the fastest framework, three times
faster than DLL. DLL is less than two times slower than Keras and TensorFlow.
Interestingly, DLL is still faster than Torch and DeepLearning4J.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="mnist-convolutional-neural-network"&gt;
&lt;h2&gt;MNIST: Convolutional Neural Network&lt;/h2&gt;
&lt;p&gt;Although a Fully-Connected Neural Network is an interesting tool, the trend now
is to use Convolutional Neural Network which have proved very efficient at
solving a lot of problems. The second experiment is also using the same data
set. Again, it's a rather small network. The first layer is a convolutional
layer with 8 5x5 kernels, followed by max pooling layer with 2x2 kernel. They
are followed by one more convolutional layers with 8 5x5 kernels and a 2x2 max
pooling layer. These first four layers are followed by two fully-connected
layers, the first with 150 hidden units and the last one with 10 output units.
The activation functions are the same as for the first network, as is the
training procedure. This takes significantly longer to train than the first
network because of the higher complexity of the convolutional layers compared to
the fully-connected layers even though they have much less weights. The results
are present in the next figure:&lt;/p&gt;
&lt;figure class="align-center"&gt;
&lt;img alt="Training time performance for the different frameworks on the Convolutional Neural Network experiment, on MNIST." src="https://baptiste-wicht.com/images/dll_cnn.png"&gt;
&lt;figcaption&gt;
&lt;p&gt;Training time performance for the different frameworks on the Convolutional
Neural Network experiment, on MNIST. All the times are in seconds.&lt;/p&gt;
&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;Again, on CPU, DLL is the clear winner, by a lot! It's already 3.6 times faster
than the second frameworks Keras and TensorFlow, more than four times faster
than Caffe and Torch and 8 times faster than DeepLearning4J that is proving very
slow on this experiment. Once a GPU is added, Keras and TensorFlow are about
twice faster than DLL. However, DLL is still faster than the other frameworks
even though they are taking advantage of the GPU.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="cifar-10"&gt;
&lt;h2&gt;CIFAR-10&lt;/h2&gt;
&lt;p&gt;The second data set that is tested is the CIFAR-10 data set. It's an object
recognition with 10 classes for classification. The training set is composed of
50'000 colour images for 32x32 pixels. The network that is used for this data
set is similar in architecture than the first network, but has more parameters.
The first convolutional layer now has 12 5x5 kernels and the second
convolutional layer has 24 3x3 kernels. The pooling layers are the same. The
first fully-connected has 64 hidden units and the last one has 10 output units.
The last layer again use a softmax activation function while the other layers
are using Rectifier Linear Units (ReLU). The training is done in the same manner
as for the two first networks. Unfortunately, it was not possible to train
DeepLearning4J on this data set, even though there is official support for this
data set. Since I've had no answer to my question regarding this issue, the
results are simply removed from this experiment. It may not seem so but it's
considerably longer to train this network because of the larger number of input
channels and larger number of convolutional kernels in each layer. Let's get to
the results now:&lt;/p&gt;
&lt;figure class="align-center"&gt;
&lt;img alt="Training time performance for the different frameworks on the Convolutional Neural Network experiment, on CIFAR-10." src="https://baptiste-wicht.com/images/dll_cifar10.png"&gt;
&lt;figcaption&gt;
&lt;p&gt;Training time performance for the different frameworks on the Convolutional
Neural Network experiment, on CIFAR-10. All the times are in seconds.&lt;/p&gt;
&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;DLL is still the fastest on CPU, but the margin is less than before. It's about
40% faster than TensorFlow and Keras, twice faster than Torch and 2.6 times
faster than Caffe. Once a GPU is added, DLL is about as fast as Torch but slower
than the other three frameworks. TensorFlow and Keras are about four times
faster than DLL while Caffe is about twice faster than DLL. We can see that
with this larger network, the GPU becomes more interesting and that there is
a smaller margin for improvements compared to the other frameworks.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="imagenet"&gt;
&lt;h2&gt;ImageNet&lt;/h2&gt;
&lt;p&gt;The last experiment is made on the ImageNet data set. I used the ILSVRC 2012
subset, that consists "only" of about 1.2 million images for training. I've
resized all the images to 256x256 pixels, this makes for 250 times more colour
values than a MNIST image. This dimension and the number of images makes it
impractical to keep the dataset in memory. The images must be loaded in batch
from the disk. No random cropping or mirroring was performed. The network is
much larger to solve this task. The network starts with 5 pairs of convolutional
layers and max pooling layers. The convolutional layers have 3x3 kernels, 16 for
the first two layers and 32 for the three following one. The five max pooling
layers use 2x2 kernels. Each convolutional layer uses zero-padding so that their
output features are the same dimensions as the input. They are followed by two
fully-connected layer. The first one with 2048 hidden units and the last one
with 1000 output units (one for each class). Except for the last layer, using
softmax, the layers all uses ReLU. The network is trained with mini-batches of
128 images (except for DeepLearning4J and Torch, which can only use 64 images on
the amount of RAM available on my machine). To ease the comparison, I report the
time necessary to train one batch of data (or two for DeepLearning4J and Torch).
The results, presented in logarithmic scale because of DeepLearning4J disastrous
results, are as follows:&lt;/p&gt;
&lt;figure class="align-center"&gt;
&lt;img alt="Training time performance for the different frameworks on the Convolutional Neural Network experiment, on ImageNet." src="https://baptiste-wicht.com/images/dll_imagenet.png"&gt;
&lt;figcaption&gt;
&lt;p&gt;Training time performance for the different frameworks on the Convolutional
Neural Network experiment, on ImageNet. The times are the time necessary to
train a batch of 128 images. All the times are in milliseconds.&lt;/p&gt;
&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;For this final experiment, DLL is again significantly faster than all the other
frameworks. It's about 40% faster than Keras, twice faster than TensorFlow and
Caffe and more than three times faster than Torch. Although 40% may seem not
that much, don't forget that this kind of training may take days, so it can save
you a lot of time. All the frameworks are much faster than DeepLearning4J. Based
on several posts on the internet, I suspect that this comes from the model of
GPU I have been used (GTX 960), but all the other frameworks seem to handle this
card pretty well.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="conclusion"&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;I hope this is not too much of a bragging post :P We can see that my efforts to
make the code as fast as possible have paid :) As was shown in the experiments,
my DLL framework is always the fastest framework when the neural network is
trained on CPU. I'm quite pleased with the results since I've done a lot of work
to optimize the speed as much as possible and since I'm competing with
well-known libraries that have been developed by several persons.  Moreover, the
accuracies of the trained networks is similar to that of the networks trained
with the other frameworks. Even when the other frameworks are using GPU, the
library still remains competitive, although never the fastest.&lt;/p&gt;
&lt;p&gt;In the next step (I've no idea when I'll have the time though), I will want to
focus on GPU speed. This will mostly come from a better support of the GPU in
the ETL library on which DLL is based. I have many ideas to improve it a lot,
but it will take me a lot of time.&lt;/p&gt;
&lt;p&gt;If you want more information on the DLL library, you can have a look at
&lt;a class="reference external" href="https://github.com/wichtounet/dll"&gt;its Github repository&lt;/a&gt; and especially at
&lt;a class="reference external" href="https://github.com/wichtounet/dll/tree/master/examples/src"&gt;the few examples&lt;/a&gt;.
You can also have a look at &lt;a class="reference external" href="https://baptiste-wicht.com/categories/dll.html"&gt;my posts about DLL&lt;/a&gt;.
Finally, don't hesitate to comment or contact me through Github issues if you
have comments or problems with this post, the library or anything ;)&lt;/p&gt;
&lt;/section&gt;</description><category>C++</category><category>dll</category><category>etl</category><category>GPU</category><category>Machine Learning</category><category>projects</category><guid>https://baptiste-wicht.com/posts/2017/08/dll-blazing-fast-neural-network-library.html</guid><pubDate>Fri, 11 Aug 2017 09:09:14 GMT</pubDate></item><item><title>Compiler benchmark GCC and Clang on C++ library (ETL)</title><link>https://baptiste-wicht.com/posts/2017/08/compiler-benchmark-gcc-clang-cpp-library-etl.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;p&gt;It's been a while since I've done a benchmark of different compilers on C++
code. Since I've recently
&lt;a class="reference external" href="https://baptiste-wicht.com/posts/2017/08/expression-templates-library-etl-11.html"&gt;released the version 1.1 of my ETL project&lt;/a&gt;
(an optimized matrix/vector computation library with expression templates), I've
decided to use it as the base of my benchmark. It's a C++14 library with a lot
of templates. I'm going to compile the full test suite (124 test cases). This is
done directly on the last release (1.1) code. I'm going to compile once in debug
mode and once in release_debug (release plus debug symbols and assertions) and
record the times for each compiler. The tests were compiled with support for
every option in ETL to account to maximal compilation time. Each compilation was
made using four threads (make -j4). I'm also going to test a few of the
benchmarks to see the difference in runtime performance between the code
generated by each compiler. The benchmark will be compiled in release mode and
its compilation time recorded as well.&lt;/p&gt;
&lt;p&gt;I'm going to test the following compilers:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;GCC-4.9.4&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;GCC-5.4.0&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;GCC-6.3.0&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;GCC-7.1.0&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;clang-3.9.1&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;clang-4.0.1&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;zapcc-1.0 (commercial, based on clang-5.0 trunk)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;All have been installed directly using Portage (Gentoo package manager) except
for clang-4.0.1 that has been installed from sources and zapcc since it does not
have a Gentoo package. Since clang package on Gentoo does not support
multislotting, I had to install one version from source and the other from the
package manager. This is also the reason I'm testing less versions of clang,
simply less practical.&lt;/p&gt;
&lt;p&gt;For the purpose of these tests, the exact same options have been used throughout
all the compilers. Normally, I use different options for clang than for GCC
(mainly more aggressive vectorization options on clang). This may not lead to
the best performance for each compiler, but allows for comparison between the
results with defaults optimization level. Here are the main options used:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;In debug mode: -g&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;In release_debug mode: -g -O2&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;In release mode: -g -O3 -DNDEBUG -fomit-frame-pointer&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In each case, a lot of warnings are enabled and the ETL options are the same.&lt;/p&gt;
&lt;p&gt;All the results have been gathered on a Gentoo machine running on Intel Core
i7-2600 (Sandy Bridge...) @3.4GHz with 4 cores and 8 threads, 12Go of RAM and
a SSD. I do my best to isolate as much as possible the benchmark from
perturbations and that my benchmark code is quite sound, it may well be that
some results are not totally accurate. Moreover, some of the benchmarks are
using multithreading, which may add some noise and unpredictability. When I was
not sure about the results, I ran the benchmarks several time to confirm them
and overall I'm confident of the results.&lt;/p&gt;
&lt;section id="compilation-time"&gt;
&lt;h2&gt;Compilation Time&lt;/h2&gt;
&lt;p&gt;Let's start with the results of the performance of the compilers themselves:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;&lt;th class="head"&gt;&lt;p&gt;Compiler&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;Debug&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;Release_Debug&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;Benchmark&lt;/p&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;g++-4.9.4&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;402s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;616s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;100s&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;g++-5.4.0&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;403s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;642s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;95s&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;g++-6.3.0&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;399s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;683s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;102s&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;g++-7.1.0&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;371s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;650s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;105s&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;clang++-3.9.1&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;380s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;807s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;106s&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;clang++-4.0.1&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;260s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;718s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;92s&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;zapcc++-1.0&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;221s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;649s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;108s&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Note: For Release_Debug and Benchmark, I only use three threads with zapcc,
because 12Go of RAM is not enough memory for four threads.&lt;/p&gt;
&lt;p&gt;There are some very significant differences between the different compilers.
Overall, clang-4.0.1 is by far the fastest free compiler for Debug mode. When
the tests are compiled with optimizations however, clang is falling behind.
It's quite impressive how clang-4.0.1 manages to be so much faster than
clang-3.9.1 both in debug mode and release mode. Really great work by the clang
team here! With these optimizations, clang-4.0.1 is almost on par with gcc-7.1
in release mode.  For GCC, it seems that the cost of optimization has been going
up quite significantly. However, GCC 7.1 seems to have made optimization faster
and standard compilation much faster as well. If we take into account zapcc,
it's the fastest compiler on debug mode, but it's slower than several gcc
versions on release mode.&lt;/p&gt;
&lt;p&gt;Overall, I'm quite impressed by the performance of clang-4.0.1 which seems
really fast! I'll definitely make more tests with this new version of the
compiler in the near future. It's also good to see that g++-7.1 also did make
the build faster than gcc-6.3. However, the fastest gcc version for optimization
is still gcc-4.9.4 which is already an old branch with low C++ standard support.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="runtime-performance"&gt;
&lt;h2&gt;Runtime Performance&lt;/h2&gt;
&lt;p&gt;Let's now take a look at the quality of the generated code. For some of the
benchmarks, I've included two versions of the algorithm. &lt;em&gt;std&lt;/em&gt; is the most
simple algorithm (the naive one) and &lt;em&gt;vec&lt;/em&gt; is the hand-crafted vectorized and
optimized implementation. All the tests were done on single-precision floating
points.&lt;/p&gt;
&lt;section id="dot-product"&gt;
&lt;h3&gt;Dot product&lt;/h3&gt;
&lt;p&gt;The first benchmark that is run is to compute the dot product between two
vectors. Let's look first at the naive version:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;&lt;th class="head"&gt;&lt;p&gt;dot (std)&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;100&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;500&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;1000&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;10000&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;100000&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;1000000&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;2000000&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;3000000&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;4000000&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;5000000&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;10000000&lt;/p&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;g++-4.9.4&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;64.96ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;97.12ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;126.07ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.89us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;25.91us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;326.49us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.24ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.92ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;2.55ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;3.22ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;6.36ms&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;g++-5.4.0&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;72.96ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;101.62ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;127.89ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.90us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;23.39us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;357.63us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.23ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.91ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;2.57ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;3.20ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;6.32ms&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;g++-6.3.0&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;73.31ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;102.88ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;130.16ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.89us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;24.314us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;339.13us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.47ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;2.16ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;2.95ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;3.70ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;6.69ms&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;g++-7.1.0&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;70.20ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;104.09ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;130.98ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.90us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;23.96us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;281.47us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.24ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.93ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;2.58ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;3.19ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;6.33ms&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;clang++-3.9.1&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;64.69ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;98.69ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;128.60ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.89us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;23.33us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;272.71us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.24ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.91ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;2.56ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;3.19ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;6.37ms&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;clang++-4.0.1&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;60.31ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;96.34ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;128.90ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.89us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;22.87us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;270.21us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.23ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.91ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;2.55ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;3.18ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;6.35ms&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;zapcc++-1.0&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;61.14ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;96.92ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;125.95ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.89us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;23.84us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;285.80us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.24ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.92ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;2.55ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;3.16ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;6.34ms&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The differences are not very significant between the different compilers. The
clang-based compilers seem to be the compilers producing the fastest code.
Interestingly, there seem to have been a big regression in gcc-6.3 for large
containers, but that has been fixed in gcc-7.1.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;&lt;th class="head"&gt;&lt;p&gt;dot (vec)&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;100&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;500&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;1000&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;10000&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;100000&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;1000000&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;2000000&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;3000000&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;4000000&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;5000000&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;10000000&lt;/p&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;g++-4.9.4&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;48.34ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;80.53ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;114.97ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.72us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;22.79us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;354.20us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.24ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.89ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;2.52ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;3.19ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;6.55ms&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;g++-5.4.0&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;47.16ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;77.70ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;113.66ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.72us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;22.71us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;363.86us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.24ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.89ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;2.52ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;3.19ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;6.56ms&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;g++-6.3.0&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;46.39ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;77.67ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;116.28ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.74us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;23.39us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;452.44us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.45ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;2.26ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;2.87ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;3.49ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;7.52ms&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;g++-7.1.0&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;49.70ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;80.40ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;115.77ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.71us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;22.46us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;355.16us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.21ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.85ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;2.49ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;3.14ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;6.47ms&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;clang++-3.9.1&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;46.13ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;78.01ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;114.70ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.66us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;22.82us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;359.42us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.24ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.88ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;2.53ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;3.16ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;6.50ms&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;clang++-4.0.1&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;45.59ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;74.90ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;111.29ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.57us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;22.47us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;351.31us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.23ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.85ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;2.49ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;3.12ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;6.45ms&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;zapcc++-1.0&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;45.11ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;75.04ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;111.28ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.59us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;22.46us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;357.32us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.25ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.89ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;2.53ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;3.15ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;6.47ms&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;If we look at the optimized version, the differences are even slower. Again, the
clang-based compilers are producing the fastest executables, but are closely
followed by gcc, except for gcc-6.3 in which we can still see the same
regression as before.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="logistic-sigmoid"&gt;
&lt;h3&gt;Logistic Sigmoid&lt;/h3&gt;
&lt;p&gt;The next test is to check the performance of the sigmoid operation. In that
case, the evaluator of the library will try to use parallelization and
vectorization to compute it. Let's see how the different compilers fare:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;&lt;th class="head"&gt;&lt;p&gt;sigmoid&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;10&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;100&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;1000&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;10000&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;100000&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;1000000&lt;/p&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;g++-4.9.4&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;8.16us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;5.23us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;6.33us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;29.56us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;259.72us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;2.78ms&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;g++-5.4.0&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;7.07us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;5.08us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;6.39us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;29.44us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;266.27us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;2.96ms&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;g++-6.3.0&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;7.13us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;5.32us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;6.45us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;28.99us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;261.81us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;2.86ms&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;g++-7.1.0&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;7.03us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;5.09us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;6.24us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;28.61us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;252.78us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;2.71ms&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;clang++-3.9.1&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;7.30us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;5.25us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;6.57us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;30.24us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;256.75us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.99ms&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;clang++-4.0.1&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;7.47us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;5.14us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;5.77us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;26.03us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;235.87us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.81ms&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;zapcc++-1.0&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;7.51us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;5.26us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;6.48us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;28.86us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;258.31us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.95ms&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Interestingly, we can see that gcc-7.1 is the fastest for small vectors while
clang-4.0 is the best for producing code for larger vectors. However, except for
the biggest vector size, the difference is not really significantly. Apparently,
there is a regression in zapcc (or clang-5.0) since it's slower than clang-4.0
at the same level as clang-3.9.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="y-alpha-x-y-axpy"&gt;
&lt;h3&gt;y = alpha * x + y (axpy)&lt;/h3&gt;
&lt;p&gt;The third benchmark is the well-known axpy (y = alpha * x + y). This is entirely
resolved by expressions templates in the library, no specific algorithm is used.
Let's see the results:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;&lt;th class="head"&gt;&lt;p&gt;saxpy&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;10&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;100&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;1000&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;10000&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;100000&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;1000000&lt;/p&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;g++-4.9.4&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;38.1ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;61.6ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;374ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;3.65us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;40.8us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;518us&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;g++-5.4.0&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;35.0ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;58.1ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;383ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;3.87us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;43.2us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;479us&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;g++-6.3.0&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;34.3ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;59.4ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;371ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;3.57us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;40.4us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;452us&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;g++-7.1.0&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;34.8ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;59.7ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;399ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;3.78us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;43.1us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;547us&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;clang++-3.9.1&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;32.3ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;53.8ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;297ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;3.21us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;38.3us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;466us&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;clang++-4.0.1&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;32.4ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;59.8ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;296ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;3.31us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;38.2us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;475us&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;zapcc++-1.0&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;32.0ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;54.0ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;333ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;3.32us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;38.7us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;447us&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Even on the biggest vector, this is a very fast operation, once vectorized and
parallelized. At this speed, some of the differences observed may not be highly
significant. Again clang-based versions are the fastest versions on this code,
but by a small margin.  There also seems to be a slight regression in gcc-7.1,
but again quite small.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="matrix-matrix-multiplication-gemm"&gt;
&lt;h3&gt;Matrix Matrix multiplication (GEMM)&lt;/h3&gt;
&lt;p&gt;The next benchmark is testing the performance of a Matrix-Matrix Multiplication,
an operation known as GEMM in the BLAS nomenclature. In that case, we test both
the naive and the optimized vectorized implementation. To save some horizontal
space, I've split the tables in two.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;&lt;th class="head"&gt;&lt;p&gt;sgemm (std)&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;10&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;20&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;40&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;60&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;80&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;100&lt;/p&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;g++-4.9.4&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;7.04us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;50.15us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;356.42us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.18ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;3.41ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;5.56ms&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;g++-5.4.0&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;8.14us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;74.77us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;513.64us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.72ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;4.05ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;7.92ms&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;g++-6.3.0&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;8.03us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;64.78us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;504.41us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.69ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;4.02ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;7.87ms&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;g++-7.1.0&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;7.95us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;65.00us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;508.84us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.69ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;4.02ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;7.84ms&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;clang++-3.9.1&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;3.58us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;28.59us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;222.36us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;0.73ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.77us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;3.41ms&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;clang++-4.0.1&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;4.00us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;25.47us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;190.56us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;0.61ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.45us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;2.80ms&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;zapcc++-1.0&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;4.00us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;25.38us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;189.98us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;0.60ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.43us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;2.81ms&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;&lt;th class="head"&gt;&lt;p&gt;sgemm (std)&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;200&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;300&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;400&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;500&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;600&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;700&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;800&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;900&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;1000&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;1200&lt;/p&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;g++-4.9.4&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;44.16ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;148.88ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;455.81ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;687.96ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.47s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.98s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;2.81s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;4.00s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;5.91s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;9.52s&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;g++-5.4.0&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;63.17ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;213.01ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;504.83ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;984.90ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.70s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;2.70s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;4.03s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;5.74s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;7.87s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;14.905&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;g++-6.3.0&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;64.04ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;212.12ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;502.95ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;981.74ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.69s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;2.69s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;4.13s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;5.85s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;8.10s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;14.08s&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;g++-7.1.0&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;62.57ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;210.72ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;499.68ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;974.94ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.68s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;2.67s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;3.99s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;5.68s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;7.85s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;13.49s&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;clang++-3.9.1&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;27.48ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;90.85ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;219.34ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;419.53ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;0.72s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.18s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.90s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;2.44s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;3.36s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;5.84s&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;clang++-4.0.1&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;22.01ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;73.90ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;175.02ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;340.70ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;0.58s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;0.93s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.40s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.98s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;2.79s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;4.69s&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;zapcc++-1.0&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;22.33ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;75.80ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;181.27ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;359.13ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;0.63s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.02s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.52s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;2.24s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;3.21s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;5.62s&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;This time, the differences between the different compilers are very significant.
The clang compilers are leading the way by a large margin here, with clang-4.0
being the fastest of them (by another nice margin). Indeed, clang-4.0.1 is
producing code that is, on average, about twice faster than the code generated
by the best GCC compiler. Very interestingly as well, we can see a huge
regression starting from GCC-5.4 and that is still here in GCC-7.1. Indeed, the
best GCC version, in the tested versions, is again GCC-4.9.4. Clang is really
doing an excellent job of compiling the GEMM code.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;&lt;th class="head"&gt;&lt;p&gt;sgemm (vec)&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;10&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;20&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;40&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;60&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;80&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;100&lt;/p&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;g++-4.9.4&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;264.27ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;0.95us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;3.28us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;14.77us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;23.50us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;60.37us&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;g++-5.4.0&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;271.41ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;0.99us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;3.31us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;14.811us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;24.116us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;61.00us&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;g++-6.3.0&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;279.72ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.02us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;3.27us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;15.39us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;24.29us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;61.99us&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;g++-7.1.0&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;273.74ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;0.96us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;3.81us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;15.55us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;31.35us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;71.11us&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;clang++-3.9.1&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;296.67ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.34us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;4.18us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;19.93us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;33.15us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;82.60us&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;clang++-4.0.1&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;322.68ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.38us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;4.17us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;20.19us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;34.17us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;83.64us&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;zapcc++-1.0&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;307.49ns&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.41us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;4.10us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;19.72us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;33.72us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;84.80us&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;&lt;th class="head"&gt;&lt;p&gt;sgemm (vec)&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;200&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;300&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;400&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;500&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;600&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;700&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;800&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;900&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;1000&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;1200&lt;/p&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;g++-4.9.4&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;369.52us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.62ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;2.91ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;7.17ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;11.74ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;22.91ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;34.82ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;51.67ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;64.36ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;111.15ms&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;g++-5.4.0&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;387.54us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.60ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;2.97ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;7.36ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;12.11ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;24.37ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;35.37ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;52.27ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;65.72ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;112.74ms&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;g++-6.3.0&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;384.43us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.74ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;3.12ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;7.16ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;12.44ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;24.15ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;34.87ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;52.59ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;70.074ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;119.22ms&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;g++-7.1.0&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;458.05us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.81ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;3.44ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;7.86ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;13.43ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;24.70ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;36.54ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;53.47ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;66.87ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;117.25ms&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;clang++-3.9.1&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;494.52us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.96ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;4.80ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;8.88ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;18.20ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;29.37ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;41.24ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;60.72ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;72.28ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;123.75ms&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;clang++-4.0.1&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;511.24us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;2.04ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;4.11ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;9.46ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;15.34ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;27.23ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;38.27ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;58.14ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;72.78ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;128.60ms&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;zapcc++-1.0&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;492.28us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;2.03ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;3.90ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;9.00ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;14.31ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;25.72ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;37.09ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;55.79ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;67.88ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;119.92ms&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;As for the optimized version, it seems that the two families are reversed.
Indeed, GCC is doing a better job than clang here, and although the margin is
not as big as before, it's still significant. We can still observe a small
regression in GCC versions because the 4.9 version is again the fastest. As for
clang versions, it seems that clang-5.0 (used in zapcc) has had some performance
improvements for this case.&lt;/p&gt;
&lt;p&gt;For this case of matrix-matrix multiplication, it's very impressive that the
differences in the non-optimized code are so significant. And it's also
impressive that each family of compilers has its own strength, clang being
seemingly much better at handling unoptimized code while GCC is better at
handling vectorized code.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="convolution-2d"&gt;
&lt;h3&gt;Convolution (2D)&lt;/h3&gt;
&lt;p&gt;The last benchmark that I considered is the case of the valid convolution on 2D
images. The code is quite similar to the GEMM code but more complicated to
optimized due to cache locality.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;&lt;th class="head"&gt;&lt;p&gt;sconv2_valid (std)&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;100x50&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;105x50&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;110x55&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;115x55&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;120x60&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;125x60&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;130x65&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;135x65&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;140x70&lt;/p&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;g++-4.9.4&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;27.93ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;33.68ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;40.62ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;48.23ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;57.27ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;67.02ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;78.45ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;92.53ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;105.08ms&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;g++-5.4.0&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;37.60ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;44.94ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;54.24ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;64.45ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;76.63ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;89.75ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;105.08ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;121.66ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;140.95ms&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;g++-6.3.0&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;37.10ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;44.99ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;54.34ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;64.54ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;76.54ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;89.87ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;105.35ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;121.94ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;141.20ms&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;g++-7.1.0&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;37.55ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;45.08ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;54.39ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;64.48ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;76.51ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;92.02ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;106.16ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;125.67ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;143.57ms&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;clang++-3.9.1&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;15.42ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;18.59ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;22.21ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;26.40ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;31.03ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;36.26ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;42.35ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;48.87ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;56.29ms&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;clang++-4.0.1&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;15.48ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;18.67ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;22.34ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;26.50ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;31.27ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;36.58ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;42.61ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;49.33ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;56.80ms&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;zapcc++-1.0&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;15.29ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;18.37ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;22.00ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;26.10ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;30.75ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;35.95ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;41.85ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;48.42ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;55.74ms&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;In that case, we can observe the same as for the GEMM. The clang-based versions
are much producing significantly faster code than the GCC versions. Moreover, we
can also observe the same large regression starting from GCC-5.4.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;&lt;th class="head"&gt;&lt;p&gt;sconv2_valid (vec)&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;100x50&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;105x50&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;110x55&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;115x55&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;120x60&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;125x60&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;130x65&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;135x65&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;140x70&lt;/p&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;g++-4.9.4&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;878.32us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.07ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.20ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.68ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;2.04ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;2.06ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;2.54ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;3.20ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;4.14ms&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;g++-5.4.0&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;853.73us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.03ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.15ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.36ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.76ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;2.05ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;2.44ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;2.91ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;3.13ms&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;g++-6.3.0&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;847.95us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.02ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.14ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.35ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.74ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.98ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;2.43ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;2.90ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;3.12ms&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;g++-7.1.0&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;795.82us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;0.93ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.05ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.24ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.60ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.77ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;2.20ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;2.69ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;2.81ms&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;clang++-3.9.1&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;782.46us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;0.93ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.05ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.26ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.60ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.84ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;2.21ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;2.65ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;2.84ms&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;clang++-4.0.1&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;767.58us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;0.92ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.04ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.25ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.59ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.83ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;2.20ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;2.62ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;2.83ms&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;zapcc++-1.0&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;782.49us&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;0.94ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.06ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.27ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.62ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.83ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;2.24ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;2.65ms&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;2.85ms&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;This time, clang manages to produce excellent results. Indeed, all the produced
executables are significantly faster than the versions produced by GCC, except
for GCC-7.1 which is producing similar results. The other versions of GCC are
falling behind it seems. It seems that it was only for the GEMM that clang was
having a lot of troubles handling the optimized code.&lt;/p&gt;
&lt;/section&gt;
&lt;/section&gt;
&lt;section id="conclusion"&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Clang seems to have recently done a lot of optimizations regarding compilation
time. Indeed, clang-4.0.1 is much faster for compilation than clang-3.9.
Although GCC-7.1 is faster than GCC-6.3, all the GCC versions are slower than
GCC-4.9.4 which is the fastest at compiling code with optimizations. GCC-7.1 is
the fastest GCC version for compiling code in debug mode.&lt;/p&gt;
&lt;p&gt;In some cases, there is almost no difference between different compilers in the
generated code. However, in more  complex algorithms such as the matrix-matrix
multiplication or the two-dimensional convolution, the differences can be quite
significant. In my tests, Clang have shown to be much better at compiling
unoptimized code. However, and especially in the GEMM case, it seems to be worse
than GCC at handling hand-optimized. I will investigate that case and try to
tailor the code so that clang is having a better time with it.&lt;/p&gt;
&lt;p&gt;For me, it's really weird that the GCC regression, apparently starting from
GCC-5.4, has still not been fixed in GCC 7.1. I was thinking of dropping support
for GCC-4.9 in order to go full C++14 support, but now I may have to reconsider
my position. However, seeing that GCC is generally the best at handling
optimized code (especially for GEMM), I may be able to do the transition, since
the optimized code will be used in most cases.&lt;/p&gt;
&lt;p&gt;As for zapcc, although it is still the fastest compiler in debug mode, with the
new speed of clang-4.0.1, its margin is quite small. Moreover, on optimized
build, it's not as fast as GCC. If you use clang and can have access to zapcc,
it's still quite a good option to save some time.&lt;/p&gt;
&lt;p&gt;Overall, I have been quite pleased by clang-4.0.1 and GCC-7.1, the most recent
versions I have been testing. It seems that they did quite some good work.
I will definitely run some more tests with them and try to adapt the code. I'm
still considering whether I will drop support for some older compilers.&lt;/p&gt;
&lt;p&gt;I hope this comparison was interesting :) My next post will probably be about
the difference in performance between my machine learning framework and other
frameworks to train neural networks.&lt;/p&gt;
&lt;/section&gt;</description><category>C++</category><category>C++11</category><category>C++14</category><category>clang</category><category>Compilers</category><category>etl</category><category>gcc</category><category>Performance</category><category>projects</category><guid>https://baptiste-wicht.com/posts/2017/08/compiler-benchmark-gcc-clang-cpp-library-etl.html</guid><pubDate>Mon, 07 Aug 2017 07:16:21 GMT</pubDate></item><item><title>Expression Templates Library (ETL) 1.1</title><link>https://baptiste-wicht.com/posts/2017/08/expression-templates-library-etl-11.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;img alt="ETL Logo" class="align-center" src="https://baptiste-wicht.com/images/logo.png"&gt;
&lt;p&gt;It took me longer than I thought, but I'm glad to announce the release of the
version 1.1 of my Expression Templates Library (ETL) project. This is a major
new release with many improvements and new features. It's been almost one month
since the last, and first, release (1.0) was released. I should have done some
minor releases in the mean time, but at least now the library is in a good shape
for major version.&lt;/p&gt;
&lt;p&gt;It may be interesting to note that my machine learning framework (DLL), based on
the ETL library, has shown to be faster than all the tested popular frameworks
(Tensorflow, Keras, Caffee, Torch, DeepLearning4J) for training various neural
networks on CPU. I'll post more details on another post on the coming weeks, but
that shows that special attention to performance has been done in this library
and that it is well adapted to machine learning.&lt;/p&gt;
&lt;p&gt;For those of you that don't follow my blog, ETL is a library providing
Expression Templates for computations on matrix and vector. For instance, if you
have three matrices A, B and C you could write C++ code like this:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code cpp"&gt;&lt;a id="rest_code_9614b43d714842e69344d44f0004b7fa-1" name="rest_code_9614b43d714842e69344d44f0004b7fa-1" href="https://baptiste-wicht.com/posts/2017/08/expression-templates-library-etl-11.html#rest_code_9614b43d714842e69344d44f0004b7fa-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;2.0&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;B&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Or given vectors b, v, h and a matrix W, you could write code like this:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code cpp"&gt;&lt;a id="rest_code_7f89506573b34280927e5efc1712cb34-1" name="rest_code_7f89506573b34280927e5efc1712cb34-1" href="https://baptiste-wicht.com/posts/2017/08/expression-templates-library-etl-11.html#rest_code_7f89506573b34280927e5efc1712cb34-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;h&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;sigmoid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;W&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The goal of such library is two-fold. First, this makes the expression more
readable and as close to math as possible. And then, it allows the library to
compute the expressions as fast as possible.  In the first case, the framework
will compute the sum using a vectorized algorithm and then compute the overall
expression using yet again vectorized code. The expression can also be computed
in parallel if the matrices are big enough. In the second case, the
vector-matrix multiplication will be computed first using either hand-code
optimized vectorized or a BLAS routine (depending on configuration options).
Then, all the expression will be executed using vectorized code.&lt;/p&gt;
&lt;section id="features"&gt;
&lt;h2&gt;Features&lt;/h2&gt;
&lt;p&gt;Many new features have been integrated into the library.&lt;/p&gt;
&lt;p&gt;The support for machine learning operations has been improved. There are now
specific helpers for machine learning in the etl::ml namespace which have names
that are standard to machine learning. A real transposed convolution has been
implemented with support for padding and stride. Batched outer product and
batched bias averaging are also now supported. The activation function support
has also been improved and the derivatives have been reviewed. The pooling
operators have also been improved with stride and padding support. Unrelated to
machine learning, 2D and 3D pooling can also be done in higher dimensional
matrix now.&lt;/p&gt;
&lt;p&gt;New functions are also available for matrices and vectors. The support for
square root has been improved with cubic root and inverse root. Support has also
been added for floor and ceil. Moreover, comparison operators are now available
as well as global functions such as approx_equals.&lt;/p&gt;
&lt;p&gt;New reductions have also been added with support for absolute sum and mean
(asum/asum) and for min_index and max_index, which returns the index of the
minimum element, respectively the maximum. Finally, argmax can now be used to
get the max index in each sub dimensions of a matrix. argmax on a vector is
equivalent to max_index.&lt;/p&gt;
&lt;p&gt;Support for shuffling has also been added. By default, shuffling a vector means
shuffling all elements and shuffling a matrix means shuffling by shuffling the
sub matrices (only the first dimension is shuffled), but shuffling a matrix as
a vector is also possible. Shuffle of two vectors or two matrices in parallel,
is also possible. In that case, the same permutation is applied to both
containers. As a side note, all operations using random generation are also
available with an addition parameter for the random generator, which can help to
improve reproducibility or simply tune the random generator.&lt;/p&gt;
&lt;p&gt;I've also included support for adapters matrices. There are adapters for
hermitian matrices, symmetric matrices and lower and upper triangular matrices.
For now, the framework does not take advantage of this information, this will be
done later, but the framework guarantee the different constrain on the content.&lt;/p&gt;
&lt;p&gt;There are also a few new more minor features. Maybe not so minor, matrices can
now be sliced into sub matrices. With that a matrix can be divided into several
sub matrices and modifying the sub matrices will modify the source matrix. The
sub matrices are available in 2D, 3D and 4D for now. There are also some other
ways of slicing matrix and vectors. It is possible to obtain a slice of its
memory or obtain a slice of its first dimension. Another new feature is that it
is now possible compute the cross product of vectors now. Matrices can be
decomposed into their Q/R decomposition rather than only their PALU
decomposition. Special support has been integrated for matrix and vectors of
booleans. In that case, they support logical operators such as and, not and or.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="performance"&gt;
&lt;h2&gt;Performance&lt;/h2&gt;
&lt;p&gt;I've always considered the performance of this library to be a feature itself.
I consider the library to be quite fast, especially its convolution support,
even though there is still room for improvement. Therefore, many improvements
have been made to the performance of the library since the last release. As said
before, this library was used in a machine learning framework which then proved
faster than most popular neural network frameworks on CPU. I'll present here
the most important new improvements to performance, in no real particular order,
every bit being important in my opinion.&lt;/p&gt;
&lt;p&gt;First, several operations have been optimized to be faster.&lt;/p&gt;
&lt;p&gt;Multiplication of matrices or matrices and vectors are now much faster if one of
the matrix is transposed. Instead of performing the slow transposition,
different kernels are used in order to maximize performance without doing any
transposition, although sometimes transposition is performed when it is faster.
This leads to very significant improvements, up to 10 times faster in the best
case. This is performed for vectorized kernels and also for BLAS and CUBLAS
calls. These new kernels are also directly used when matrices of different
storage order are used. For instance, multiplying a column major matrix with
a row major matrix and storing the result in a column major matrix is now much
more efficient than before. Moreover, the performance of the transpose operation
itself is also much faster than before.&lt;/p&gt;
&lt;p&gt;A lot of machine learning operations have also been highly optimized. All the
pooling and upsample operators are now parallelized and the most used kernel
(2x2 pooling) is now more optimized. 4D convolution kernels (for machine
learning) have been greatly improved. There are now very specialized vectorized
kernels for classic kernel configurations (for instance 3x3 or 5x5) and the
selection of implementations is now smarter than before. The support of padding
is now much better than before for small amount of padding. Moreover, for small
kernels the full convolution can now be evaluated using the valid convolution
kernels directly with some padding, for much faster overall performance. The
exponential operation is now vectorized which allows operations such as sigmoid
or softmax to be much faster.&lt;/p&gt;
&lt;p&gt;Matrices and vector are automatically using aligned memory. This means that
vectorized code can use aligned operations, which may be slightly faster.
Moreover, matrices and vectors are now padded to a multiple of the vector size.
This allows to remove the final non-vectorized remainder loop from the
vectorized code. This is only done for the end of matrices, when they are
accessed in flat way. Contrary to some frameworks, inner dimensions of the
matrix are not padded.  Finally, accesses to 3D and 4D matrices is now much
faster than before.&lt;/p&gt;
&lt;p&gt;Then, the parallelization feature of ETL has been completely reworked. Before,
there was a thread pool for each algorithm that was parallelized. Now, there is
a global thread engine with one thread pool. Since parallelization is not nested
in ETL, this improves performance slightly by greatly diminishing the number of
threads that are created throughout an application. Another big difference in
parallel dispatching is that now it can detect good split based on alignment so
that each split are aligned. This then allows the vectorization process to use
aligned stores and loads instead of unaligned ones which may be faster on some
processors.&lt;/p&gt;
&lt;p&gt;Vectorization has also been greatly improved in ETL. Integer operations are now
automatically vectorized on processors that support this. Before, only floating
points operations were vectorized. The automatic vectorizer now is able to use
non-temporal stores for very large operations. A non-temporal store bypasses the
cache, thus gaining some time. Since very large matrices do not fit in cache
anyway and the cache would end up being overwritten anyway, this is a net gain.
Moreover, the alignment detection in the automatic vectorizer has also been
improved. Support for Fused-Multiply-Add (FMA) operations has also been
integrated in the algorithms that can make use of it (multiplications and
convolutions). The matrix-matrix multiplications and vector-matrix
multiplications now have highly optimized vectorized kernels. They also have
versions for column-major matrices now.  I plan to reintegrate a version of the
GEMM based on BLIS in the future but with more optimizations and support for all
precisions and integers, For my version is still slower than the simple
vectorized version. The sum and the dot product operations now also have
specialized vectorized implementations. The min and max operations are now
automatically-vectorized. Several others algorithms have also their own
vectorized implementations.&lt;/p&gt;
&lt;p&gt;Last, but not least, the GPU support has also been almost completely reworked.
Now, several operations can be chained without any copies between GPU and CPU.
Several new operations have also been added with support to GPU (convolutions,
pooling, sigmoid, ReLU, ...). Moreover, to complement operations that are not
available in any of the supported NVIDIA libraries, I've created a simple
library that can be used to add a few more GPU operations.  Nevertheless a lot
of operations are still missing and only algorithms are available not
expressions (such as c = a + b * 1.0) that are entirely computed on CPU. I have
plans to improve that further, probably for version 1.2. The different contexts
necessary for NVIDIA library can now be cached (using an option from ETL),
leading to much faster code. Only the main handle can be cached so far, I plan
to try to cache all the descriptors, but I don't know yet when that will be
ready. Finally, an option is also available to reuse GPU memory instead of
directly releasing it to CUDA. This is using a custom memory pool and can save
some time. Since this needs to be cleaned (by a call to etl::exit() or using
ETL_PROLOGUE), this is only activated on demand.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="other-changes"&gt;
&lt;h2&gt;Other changes&lt;/h2&gt;
&lt;p&gt;There also have been a lot of refactorings in the code of the library. A lot of
expressions now have less overhead and are specialized for performance.
Moreover, temporary expressions have been totally reworked to be more simple and
maintainable and easier to optimize in the future. It's also probably easier to
add new expressions to the framework now, although that could be even more
simple. There are also less duplicated code now in the different expressions.
Especially, now there are now more SSE and AVX variants in the code. All the
optimized algorithms are now using the vectorization system of the library.&lt;/p&gt;
&lt;p&gt;I also tried my best to reduce the compilation time, based on the unit tests.
This is still not great but better than before. For user code, the next version
should be much faster to compile since I plan to disable forced selection of
implementations by default and only enable it on demand.&lt;/p&gt;
&lt;p&gt;Finally, there also was quite a few bug fixes. Most of them have been found by
the use of the library in the Deep Learning Library (DLL) project. Some were
very small edge cases. For instance, the transposition algorithm was not working
on GPU on rectangular column major matrices. There also was a slight bug in the
Q/R decomposition and in the pooling of 4D matrices.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="what-s-next"&gt;
&lt;h2&gt;What's next ?&lt;/h2&gt;
&lt;p&gt;Next time, I may do some minor release, but I don't yet have a complete plan.
For the next major release (1.2 probably), here is what is planned:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;Review the system for selection of algorithms to reduce compilation time&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Review the GPU system to allow more complete support for standard operators&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Switch to C++17: there are many improvements that could be done to the code with C++17 features&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Add support for convolution on mixed types (float/double)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;More tests for sparse matrix&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;More algorithms support for sparse matrix&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Reduce the compilation time of the library in general&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Reduce the compilation and execution time of the unit tests&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These are pretty big changes, especially the first two, so maybe it'll be split
into several releases. It will really depend on the time I have. As for C++17,
I really want to try it and I have a lot of points that could profit from the
switch, but that will means setting GCC 7.1 and Clang 3.9 as minimum
requirement, which may not be reasonable for every user.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="download-etl"&gt;
&lt;h2&gt;Download ETL&lt;/h2&gt;
&lt;p&gt;You can download ETL &lt;a class="reference external" href="https://github.com/wichtounet/etl"&gt;on Github&lt;/a&gt;. If you
only interested in the 1.1 version, you can look at the
&lt;a class="reference external" href="https://github.com/wichtounet/etl/releases"&gt;Releases pages&lt;/a&gt; or clone the tag
1.1. There are several branches:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;master&lt;/em&gt; Is the eternal development branch, may not always be stable&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;stable&lt;/em&gt; Is a branch always pointing to the last tag, no development here&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For the future release, there always will tags pointing to the corresponding
commits. I'm not following the git flow way, I'd rather try to have a more
linear history with one eternal development branch, rather than an useless
develop branch or a load of other branches for releases.&lt;/p&gt;
&lt;p&gt;The documentation is a bit sparse. There are a few examples and the Wiki, but
there still is work to be done. If you have questions on how to use or configure
the library, please don't hesitate.&lt;/p&gt;
&lt;p&gt;Don't hesitate to comment this post if you have any comment on this library or
any question. You can also open an Issue on Github if you have a problem using
this library or propose a Pull Request if you have any contribution you'd like
to make to the library.&lt;/p&gt;
&lt;p&gt;Hope this may be useful to some of you :)&lt;/p&gt;
&lt;/section&gt;</description><category>C++</category><category>C++14</category><category>C++17</category><category>Compilers</category><category>dll</category><category>etl</category><category>GPU</category><category>Performance</category><category>projects</category><guid>https://baptiste-wicht.com/posts/2017/08/expression-templates-library-etl-11.html</guid><pubDate>Fri, 04 Aug 2017 13:13:03 GMT</pubDate></item><item><title>Update on Deep Learning Library (DLL): Dropout, Batch Normalization, Adaptive Learning Rates, ...</title><link>https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;p&gt;It's been a while since I've posted something on this, especially since I had
one month vacation. This year I've been able to integrate a great number of
changes into my Deep Learning Library (DLL) project. It has seen a lot of
refactorings and a lot of new features making it look like a real neural network
library now. In this post, I'll try to outline the last new features and changes
of the library.&lt;/p&gt;
&lt;p&gt;For those that don't know, DLL is a library for neural network training, written
in C++ and for C++. You can train Fully-Connected Neural Networks and
Convolutional Neural Networks. The focus of the framework is on speed and easy
use in C++.&lt;/p&gt;
&lt;p&gt;As for my ETL project and again thanks to my thesis supervisor, the project now
has a logo:&lt;/p&gt;
&lt;img alt="DLL Logo" class="align-center" src="https://baptiste-wicht.com/images/dll_logo.png"&gt;
&lt;section id="adaptive-learning-rates"&gt;
&lt;h2&gt;Adaptive Learning Rates&lt;/h2&gt;
&lt;p&gt;Before, the framework only supported simple SGD and Momentum updates for the
different parameters of the network. Moreover, it was not very well extendable.
Therefore, I reviewed the system to be able to configure an optimizer for each
network to train. Once that was done, the first thing I did was to add support
for Nesterov Accelerated Gradients (NAG) as a third optimizer. After this,
I realized it was then easy to integrate support for more advanced optimizers
including support for adaptive learning rates. This means that the learning rate
will be adapted for each parameter depending on what the network is learning.
Some of the optimizers even don't need any learning rate. So far, I've
implemented support for the following optimizers: Adagrad, RMSProp, Adam (with
and without bias correction), Adamax (Adam with infinite norm), Nadam (Adam with
Nesterov momentum) and Adadelta (no more learning rate). The user can now choose
the optimizer of its choice, for instance NADAM, as a parameter of the network:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code c++"&gt;&lt;a id="rest_code_9945ce42209d4e48837ea2c499c9003b-1" name="rest_code_9945ce42209d4e48837ea2c499c9003b-1" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_9945ce42209d4e48837ea2c499c9003b-1"&gt;&lt;/a&gt;&lt;span class="c1"&gt;// Use a Nadam optimizer&lt;/span&gt;
&lt;a id="rest_code_9945ce42209d4e48837ea2c499c9003b-2" name="rest_code_9945ce42209d4e48837ea2c499c9003b-2" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_9945ce42209d4e48837ea2c499c9003b-2"&gt;&lt;/a&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;updater&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;updater_type&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;NADAM&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Another improvement in the same domain is that the learning rate can also be
decayed over time automatically by the optimizer.&lt;/p&gt;
&lt;p&gt;If you want more information on the different optimizers, you can have a look at
this very good article:
&lt;a class="reference external" href="http://ruder.io/optimizing-gradient-descent/"&gt;An overview of gradient descent optimization algorithms&lt;/a&gt;
from Sebastian Ruder.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="better-loss-support"&gt;
&lt;h2&gt;Better loss support&lt;/h2&gt;
&lt;p&gt;Before, DLL was automatically using Categorical Cross Entropy Loss, but it was
not possible to change it and it was not even possible to see the loss over
time. Now, the current value of the loss is displayed after each epoch of
training and the loss used for training is now configurable. So far, only three
different losses are supported, but it it not difficult to add new loss to the
system. The three losses supported are: Categorical Cross Entropy Loss, Binary
Cross Entropy Loss and Mean Squared Error Loss.&lt;/p&gt;
&lt;p&gt;Again, each network can specify the loss to use:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code C++"&gt;&lt;a id="rest_code_c2cea0020cb64b03b7d217d78a8c2c83-1" name="rest_code_c2cea0020cb64b03b7d217d78a8c2c83-1" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_c2cea0020cb64b03b7d217d78a8c2c83-1"&gt;&lt;/a&gt;&lt;span class="c1"&gt;// Use a Binary Cross Entropy Loss&lt;/span&gt;
&lt;a id="rest_code_c2cea0020cb64b03b7d217d78a8c2c83-2" name="rest_code_c2cea0020cb64b03b7d217d78a8c2c83-2" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_c2cea0020cb64b03b7d217d78a8c2c83-2"&gt;&lt;/a&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;loss_function&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;BINARY_CROSS_ENTROPY&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/section&gt;
&lt;section id="dropout"&gt;
&lt;h2&gt;Dropout&lt;/h2&gt;
&lt;p&gt;Dropout is a relatively new technique for neural network training. This is
especially made to reduce overfitting since a large number of sub networks will
be trained and it should prevent co-adaptation between different neurons. This
technique is relatively simple. Indeed, it simply randomly sets to zero some of
the input neurons of layers. At each batch, a new mask will be used and this
should lead to a large number of sub networks being trained.&lt;/p&gt;
&lt;p&gt;Here is example of a MLP with Dropout (p=0.5):&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code C++"&gt;&lt;a id="rest_code_dea1f9e78c7b477a9811deebbb1fa54d-1" name="rest_code_dea1f9e78c7b477a9811deebbb1fa54d-1" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_dea1f9e78c7b477a9811deebbb1fa54d-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;using&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;network_t&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dyn_dbn_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;
&lt;a id="rest_code_dea1f9e78c7b477a9811deebbb1fa54d-2" name="rest_code_dea1f9e78c7b477a9811deebbb1fa54d-2" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_dea1f9e78c7b477a9811deebbb1fa54d-2"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dbn_layers&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;
&lt;a id="rest_code_dea1f9e78c7b477a9811deebbb1fa54d-3" name="rest_code_dea1f9e78c7b477a9811deebbb1fa54d-3" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_dea1f9e78c7b477a9811deebbb1fa54d-3"&gt;&lt;/a&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dense_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;28&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;28&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;500&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;layer_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a id="rest_code_dea1f9e78c7b477a9811deebbb1fa54d-4" name="rest_code_dea1f9e78c7b477a9811deebbb1fa54d-4" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_dea1f9e78c7b477a9811deebbb1fa54d-4"&gt;&lt;/a&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dropout_layer_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;layer_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a id="rest_code_dea1f9e78c7b477a9811deebbb1fa54d-5" name="rest_code_dea1f9e78c7b477a9811deebbb1fa54d-5" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_dea1f9e78c7b477a9811deebbb1fa54d-5"&gt;&lt;/a&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dense_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;500&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;250&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;layer_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a id="rest_code_dea1f9e78c7b477a9811deebbb1fa54d-6" name="rest_code_dea1f9e78c7b477a9811deebbb1fa54d-6" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_dea1f9e78c7b477a9811deebbb1fa54d-6"&gt;&lt;/a&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dropout_layer_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;layer_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a id="rest_code_dea1f9e78c7b477a9811deebbb1fa54d-7" name="rest_code_dea1f9e78c7b477a9811deebbb1fa54d-7" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_dea1f9e78c7b477a9811deebbb1fa54d-7"&gt;&lt;/a&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dense_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;250&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;activation&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;function&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;SOFTMAX&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;layer_t&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a id="rest_code_dea1f9e78c7b477a9811deebbb1fa54d-8" name="rest_code_dea1f9e78c7b477a9811deebbb1fa54d-8" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_dea1f9e78c7b477a9811deebbb1fa54d-8"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;updater&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;updater_type&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;MOMENTUM&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="c1"&gt;// Momentum&lt;/span&gt;
&lt;a id="rest_code_dea1f9e78c7b477a9811deebbb1fa54d-9" name="rest_code_dea1f9e78c7b477a9811deebbb1fa54d-9" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_dea1f9e78c7b477a9811deebbb1fa54d-9"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt;                          &lt;/span&gt;&lt;span class="c1"&gt;// The mini-batch size&lt;/span&gt;
&lt;a id="rest_code_dea1f9e78c7b477a9811deebbb1fa54d-10" name="rest_code_dea1f9e78c7b477a9811deebbb1fa54d-10" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_dea1f9e78c7b477a9811deebbb1fa54d-10"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;shuffle&lt;/span&gt;&lt;span class="w"&gt;                                  &lt;/span&gt;&lt;span class="c1"&gt;// Shuffle before each epoch&lt;/span&gt;
&lt;a id="rest_code_dea1f9e78c7b477a9811deebbb1fa54d-11" name="rest_code_dea1f9e78c7b477a9811deebbb1fa54d-11" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_dea1f9e78c7b477a9811deebbb1fa54d-11"&gt;&lt;/a&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;dbn_t&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/section&gt;
&lt;section id="batch-normalization"&gt;
&lt;h2&gt;Batch Normalization&lt;/h2&gt;
&lt;p&gt;Batch Normalization is another new technique for training neural networks. This
technique will ensure that each of the layer will receive inputs that look
kind of similar. This is a very large advantage since then you reduce the
different in impact of hyper parameters on different layers. Google reported
much faster training with this technique by getting rid of Dropout and by
increasing the learning rate of training.&lt;/p&gt;
&lt;p&gt;Here is an example of using Batch Normalization in a CNN:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code C++"&gt;&lt;a id="rest_code_7270b31219ba4443943c1a381222499f-1" name="rest_code_7270b31219ba4443943c1a381222499f-1" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_7270b31219ba4443943c1a381222499f-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;using&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;network_t&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dyn_dbn_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;
&lt;a id="rest_code_7270b31219ba4443943c1a381222499f-2" name="rest_code_7270b31219ba4443943c1a381222499f-2" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_7270b31219ba4443943c1a381222499f-2"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dbn_layers&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;
&lt;a id="rest_code_7270b31219ba4443943c1a381222499f-3" name="rest_code_7270b31219ba4443943c1a381222499f-3" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_7270b31219ba4443943c1a381222499f-3"&gt;&lt;/a&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;conv_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;28&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;28&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;layer_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a id="rest_code_7270b31219ba4443943c1a381222499f-4" name="rest_code_7270b31219ba4443943c1a381222499f-4" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_7270b31219ba4443943c1a381222499f-4"&gt;&lt;/a&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;batch_normalization_layer_4d_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;24&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;24&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;layer_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a id="rest_code_7270b31219ba4443943c1a381222499f-5" name="rest_code_7270b31219ba4443943c1a381222499f-5" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_7270b31219ba4443943c1a381222499f-5"&gt;&lt;/a&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;mp_layer_2d_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;24&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;24&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;layer_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a id="rest_code_7270b31219ba4443943c1a381222499f-6" name="rest_code_7270b31219ba4443943c1a381222499f-6" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_7270b31219ba4443943c1a381222499f-6"&gt;&lt;/a&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;conv_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;layer_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a id="rest_code_7270b31219ba4443943c1a381222499f-7" name="rest_code_7270b31219ba4443943c1a381222499f-7" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_7270b31219ba4443943c1a381222499f-7"&gt;&lt;/a&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;batch_normalization_layer_4d_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;layer_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a id="rest_code_7270b31219ba4443943c1a381222499f-8" name="rest_code_7270b31219ba4443943c1a381222499f-8" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_7270b31219ba4443943c1a381222499f-8"&gt;&lt;/a&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;mp_layer_2d_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;layer_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a id="rest_code_7270b31219ba4443943c1a381222499f-9" name="rest_code_7270b31219ba4443943c1a381222499f-9" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_7270b31219ba4443943c1a381222499f-9"&gt;&lt;/a&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dense_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;150&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;layer_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a id="rest_code_7270b31219ba4443943c1a381222499f-10" name="rest_code_7270b31219ba4443943c1a381222499f-10" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_7270b31219ba4443943c1a381222499f-10"&gt;&lt;/a&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;batch_normalization_layer_2d_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;150&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;layer_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a id="rest_code_7270b31219ba4443943c1a381222499f-11" name="rest_code_7270b31219ba4443943c1a381222499f-11" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_7270b31219ba4443943c1a381222499f-11"&gt;&lt;/a&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dense_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;150&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;activation&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;function&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;SOFTMAX&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;layer_t&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a id="rest_code_7270b31219ba4443943c1a381222499f-12" name="rest_code_7270b31219ba4443943c1a381222499f-12" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_7270b31219ba4443943c1a381222499f-12"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;updater&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;updater_type&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;ADADELTA&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="c1"&gt;// Adadelta&lt;/span&gt;
&lt;a id="rest_code_7270b31219ba4443943c1a381222499f-13" name="rest_code_7270b31219ba4443943c1a381222499f-13" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_7270b31219ba4443943c1a381222499f-13"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt;                          &lt;/span&gt;&lt;span class="c1"&gt;// The mini-batch size&lt;/span&gt;
&lt;a id="rest_code_7270b31219ba4443943c1a381222499f-14" name="rest_code_7270b31219ba4443943c1a381222499f-14" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_7270b31219ba4443943c1a381222499f-14"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;shuffle&lt;/span&gt;&lt;span class="w"&gt;                                  &lt;/span&gt;&lt;span class="c1"&gt;// Shuffle the dataset before each epoch&lt;/span&gt;
&lt;a id="rest_code_7270b31219ba4443943c1a381222499f-15" name="rest_code_7270b31219ba4443943c1a381222499f-15" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_7270b31219ba4443943c1a381222499f-15"&gt;&lt;/a&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;dbn_t&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;You may notice that the layer is set as 4D so should only be used after
convolutional layer (or after the input). If you want to use it after
fully-connected layers, you can use the 2D version that works the same way.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="better-dataset-support"&gt;
&lt;h2&gt;Better dataset support&lt;/h2&gt;
&lt;p&gt;At the beginning, I designed DLL so that the user could directly pass data for
training in the form of STL Containers such as the std::vector. This is good in
some cases, but in some cases, the user does not know how to read the data , or
does not want to be bothered with it. Therefore, several data sets reader are
now available. Moreover, the entire system has been reworked to use generators
for data. A generator is simply a concept that has some data to produce. The
advantage of this new system is data augmentation is now supported every where
and much more efficiently than before. It is now possible to perform random
cropping and mirroring of images for instance. Moreover, the data augmentation
can be done in a secondary thread so as to be sure that there is always enough
data available for the training.&lt;/p&gt;
&lt;p&gt;The library now has a powerful dataset reader for both MNIST and CIFAR-10 and
the reader for ImageNet is almost ready. The project has already been used and
tested with these three datasets now. Moreover, the support for directly passing
STL containers has been maintained. In this case, a generator is simply created
around the data provided in the container and the generator is then passed to
the system for training.&lt;/p&gt;
&lt;p&gt;Here for instance is how to read MNIST data and scale (divide) all pixel values
by 255:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code c++"&gt;&lt;a id="rest_code_721b91c3b7304c0caa1c7ddec53a497b-1" name="rest_code_721b91c3b7304c0caa1c7ddec53a497b-1" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_721b91c3b7304c0caa1c7ddec53a497b-1"&gt;&lt;/a&gt;&lt;span class="c1"&gt;// Load the dataset&lt;/span&gt;
&lt;a id="rest_code_721b91c3b7304c0caa1c7ddec53a497b-2" name="rest_code_721b91c3b7304c0caa1c7ddec53a497b-2" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_721b91c3b7304c0caa1c7ddec53a497b-2"&gt;&lt;/a&gt;&lt;span class="k"&gt;auto&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;make_mnist_dataset&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;{},&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;scale_pre&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;255&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;{});&lt;/span&gt;
&lt;a id="rest_code_721b91c3b7304c0caa1c7ddec53a497b-3" name="rest_code_721b91c3b7304c0caa1c7ddec53a497b-3" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_721b91c3b7304c0caa1c7ddec53a497b-3"&gt;&lt;/a&gt;&lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;display&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;a id="rest_code_721b91c3b7304c0caa1c7ddec53a497b-4" name="rest_code_721b91c3b7304c0caa1c7ddec53a497b-4" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_721b91c3b7304c0caa1c7ddec53a497b-4"&gt;&lt;/a&gt;
&lt;a id="rest_code_721b91c3b7304c0caa1c7ddec53a497b-5" name="rest_code_721b91c3b7304c0caa1c7ddec53a497b-5" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_721b91c3b7304c0caa1c7ddec53a497b-5"&gt;&lt;/a&gt;&lt;span class="c1"&gt;// Train the network&lt;/span&gt;
&lt;a id="rest_code_721b91c3b7304c0caa1c7ddec53a497b-6" name="rest_code_721b91c3b7304c0caa1c7ddec53a497b-6" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_721b91c3b7304c0caa1c7ddec53a497b-6"&gt;&lt;/a&gt;&lt;span class="n"&gt;net&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;fine_tune&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;25&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a id="rest_code_721b91c3b7304c0caa1c7ddec53a497b-7" name="rest_code_721b91c3b7304c0caa1c7ddec53a497b-7" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_721b91c3b7304c0caa1c7ddec53a497b-7"&gt;&lt;/a&gt;
&lt;a id="rest_code_721b91c3b7304c0caa1c7ddec53a497b-8" name="rest_code_721b91c3b7304c0caa1c7ddec53a497b-8" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_721b91c3b7304c0caa1c7ddec53a497b-8"&gt;&lt;/a&gt;&lt;span class="c1"&gt;// Test the network&lt;/span&gt;
&lt;a id="rest_code_721b91c3b7304c0caa1c7ddec53a497b-9" name="rest_code_721b91c3b7304c0caa1c7ddec53a497b-9" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_721b91c3b7304c0caa1c7ddec53a497b-9"&gt;&lt;/a&gt;&lt;span class="n"&gt;net&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;evaluate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;test&lt;/span&gt;&lt;span class="p"&gt;());&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/section&gt;
&lt;section id="much-faster-performance"&gt;
&lt;h2&gt;Much faster performance&lt;/h2&gt;
&lt;p&gt;I've spent quite a lot of time improving the performance of the framework. I've
focused on every part of training in order to make training of neural networks
as fast as possible. I've also made a comparison of the framework against
several popular machine learning framework (Caffe, TensorFlow, Keras, Torch and
DeepLearning4J). For instance, here are the results on a small CNN experiment on
MNIST with all the different frameworks in CPU mode and in GPU mode:&lt;/p&gt;
&lt;img alt="DLL Comparison Against other frameworks" class="align-center" src="https://baptiste-wicht.com/images/dll_comparison.png"&gt;
&lt;p&gt;As you can see, DLL is by far the fastest framework on CPU. On GPU, there is
still some work to be done, but this is already ongoing (although a lot of work
remains). This is confirmed on each of the four experiments performed on MNIST,
CIFAR-10 and ImageNet, although the margin is smaller for larger networks (still
about 40% faster than TensorFlow and Keras which are the fastest framework after
DLL on CPU on my tests).&lt;/p&gt;
&lt;p&gt;Overall, DLL is between 2 and 4 times faster than before and is always the
fastest framework for neural network training when training is performed on CPU.&lt;/p&gt;
&lt;p&gt;I proposed a talk about these optimizations and performance for Meeting C++ this
year, but it has unfortunately not been accepted. We also have submitted
a publication about the framework to a conference later this year.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="examples"&gt;
&lt;h2&gt;Examples&lt;/h2&gt;
&lt;p&gt;The project now has a few examples (available &lt;a class="reference external" href="https://github.com/wichtounet/dll/tree/master/examples/src"&gt;here&lt;/a&gt;), well-designed and I try to update them with the latest updates of the framework.&lt;/p&gt;
&lt;p&gt;For instance, here is the CNN example for MNIST (without includes):&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code c++"&gt;&lt;a id="rest_code_71373914d4714c60a72ccca1f141d583-1" name="rest_code_71373914d4714c60a72ccca1f141d583-1" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_71373914d4714c60a72ccca1f141d583-1"&gt;&lt;/a&gt;&lt;span class="kt"&gt;int&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="cm"&gt;/*argc*/&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;char&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="cm"&gt;/*argv*/&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;[])&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;a id="rest_code_71373914d4714c60a72ccca1f141d583-2" name="rest_code_71373914d4714c60a72ccca1f141d583-2" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_71373914d4714c60a72ccca1f141d583-2"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="c1"&gt;// Load the dataset&lt;/span&gt;
&lt;a id="rest_code_71373914d4714c60a72ccca1f141d583-3" name="rest_code_71373914d4714c60a72ccca1f141d583-3" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_71373914d4714c60a72ccca1f141d583-3"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;auto&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;make_mnist_dataset&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;{},&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;scale_pre&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;255&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;{});&lt;/span&gt;
&lt;a id="rest_code_71373914d4714c60a72ccca1f141d583-4" name="rest_code_71373914d4714c60a72ccca1f141d583-4" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_71373914d4714c60a72ccca1f141d583-4"&gt;&lt;/a&gt;
&lt;a id="rest_code_71373914d4714c60a72ccca1f141d583-5" name="rest_code_71373914d4714c60a72ccca1f141d583-5" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_71373914d4714c60a72ccca1f141d583-5"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="c1"&gt;// Build the network&lt;/span&gt;
&lt;a id="rest_code_71373914d4714c60a72ccca1f141d583-6" name="rest_code_71373914d4714c60a72ccca1f141d583-6" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_71373914d4714c60a72ccca1f141d583-6"&gt;&lt;/a&gt;
&lt;a id="rest_code_71373914d4714c60a72ccca1f141d583-7" name="rest_code_71373914d4714c60a72ccca1f141d583-7" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_71373914d4714c60a72ccca1f141d583-7"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;using&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;network_t&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dyn_dbn_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;
&lt;a id="rest_code_71373914d4714c60a72ccca1f141d583-8" name="rest_code_71373914d4714c60a72ccca1f141d583-8" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_71373914d4714c60a72ccca1f141d583-8"&gt;&lt;/a&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dbn_layers&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;
&lt;a id="rest_code_71373914d4714c60a72ccca1f141d583-9" name="rest_code_71373914d4714c60a72ccca1f141d583-9" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_71373914d4714c60a72ccca1f141d583-9"&gt;&lt;/a&gt;&lt;span class="w"&gt;            &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;conv_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;28&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;28&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;layer_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a id="rest_code_71373914d4714c60a72ccca1f141d583-10" name="rest_code_71373914d4714c60a72ccca1f141d583-10" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_71373914d4714c60a72ccca1f141d583-10"&gt;&lt;/a&gt;&lt;span class="w"&gt;            &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;mp_layer_2d_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;24&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;24&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;layer_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a id="rest_code_71373914d4714c60a72ccca1f141d583-11" name="rest_code_71373914d4714c60a72ccca1f141d583-11" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_71373914d4714c60a72ccca1f141d583-11"&gt;&lt;/a&gt;&lt;span class="w"&gt;            &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;conv_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;layer_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a id="rest_code_71373914d4714c60a72ccca1f141d583-12" name="rest_code_71373914d4714c60a72ccca1f141d583-12" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_71373914d4714c60a72ccca1f141d583-12"&gt;&lt;/a&gt;&lt;span class="w"&gt;            &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;mp_layer_2d_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;layer_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a id="rest_code_71373914d4714c60a72ccca1f141d583-13" name="rest_code_71373914d4714c60a72ccca1f141d583-13" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_71373914d4714c60a72ccca1f141d583-13"&gt;&lt;/a&gt;&lt;span class="w"&gt;            &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dense_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;150&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;layer_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a id="rest_code_71373914d4714c60a72ccca1f141d583-14" name="rest_code_71373914d4714c60a72ccca1f141d583-14" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_71373914d4714c60a72ccca1f141d583-14"&gt;&lt;/a&gt;&lt;span class="w"&gt;            &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dense_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;150&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;activation&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;function&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;SOFTMAX&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;layer_t&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a id="rest_code_71373914d4714c60a72ccca1f141d583-15" name="rest_code_71373914d4714c60a72ccca1f141d583-15" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_71373914d4714c60a72ccca1f141d583-15"&gt;&lt;/a&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;updater&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;updater_type&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;MOMENTUM&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="c1"&gt;// Momentum&lt;/span&gt;
&lt;a id="rest_code_71373914d4714c60a72ccca1f141d583-16" name="rest_code_71373914d4714c60a72ccca1f141d583-16" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_71373914d4714c60a72ccca1f141d583-16"&gt;&lt;/a&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt;                          &lt;/span&gt;&lt;span class="c1"&gt;// The mini-batch size&lt;/span&gt;
&lt;a id="rest_code_71373914d4714c60a72ccca1f141d583-17" name="rest_code_71373914d4714c60a72ccca1f141d583-17" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_71373914d4714c60a72ccca1f141d583-17"&gt;&lt;/a&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;shuffle&lt;/span&gt;&lt;span class="w"&gt;                                  &lt;/span&gt;&lt;span class="c1"&gt;// Shuffle the dataset before each epoch&lt;/span&gt;
&lt;a id="rest_code_71373914d4714c60a72ccca1f141d583-18" name="rest_code_71373914d4714c60a72ccca1f141d583-18" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_71373914d4714c60a72ccca1f141d583-18"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;dbn_t&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a id="rest_code_71373914d4714c60a72ccca1f141d583-19" name="rest_code_71373914d4714c60a72ccca1f141d583-19" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_71373914d4714c60a72ccca1f141d583-19"&gt;&lt;/a&gt;
&lt;a id="rest_code_71373914d4714c60a72ccca1f141d583-20" name="rest_code_71373914d4714c60a72ccca1f141d583-20" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_71373914d4714c60a72ccca1f141d583-20"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;auto&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;net&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;make_unique&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;network_t&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;a id="rest_code_71373914d4714c60a72ccca1f141d583-21" name="rest_code_71373914d4714c60a72ccca1f141d583-21" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_71373914d4714c60a72ccca1f141d583-21"&gt;&lt;/a&gt;
&lt;a id="rest_code_71373914d4714c60a72ccca1f141d583-22" name="rest_code_71373914d4714c60a72ccca1f141d583-22" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_71373914d4714c60a72ccca1f141d583-22"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;net&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;learning_rate&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a id="rest_code_71373914d4714c60a72ccca1f141d583-23" name="rest_code_71373914d4714c60a72ccca1f141d583-23" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_71373914d4714c60a72ccca1f141d583-23"&gt;&lt;/a&gt;
&lt;a id="rest_code_71373914d4714c60a72ccca1f141d583-24" name="rest_code_71373914d4714c60a72ccca1f141d583-24" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_71373914d4714c60a72ccca1f141d583-24"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="c1"&gt;// Display the network and dataset&lt;/span&gt;
&lt;a id="rest_code_71373914d4714c60a72ccca1f141d583-25" name="rest_code_71373914d4714c60a72ccca1f141d583-25" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_71373914d4714c60a72ccca1f141d583-25"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;net&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;display&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;a id="rest_code_71373914d4714c60a72ccca1f141d583-26" name="rest_code_71373914d4714c60a72ccca1f141d583-26" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_71373914d4714c60a72ccca1f141d583-26"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;display&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;a id="rest_code_71373914d4714c60a72ccca1f141d583-27" name="rest_code_71373914d4714c60a72ccca1f141d583-27" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_71373914d4714c60a72ccca1f141d583-27"&gt;&lt;/a&gt;
&lt;a id="rest_code_71373914d4714c60a72ccca1f141d583-28" name="rest_code_71373914d4714c60a72ccca1f141d583-28" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_71373914d4714c60a72ccca1f141d583-28"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="c1"&gt;// Train the network&lt;/span&gt;
&lt;a id="rest_code_71373914d4714c60a72ccca1f141d583-29" name="rest_code_71373914d4714c60a72ccca1f141d583-29" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_71373914d4714c60a72ccca1f141d583-29"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;net&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;fine_tune&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;25&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a id="rest_code_71373914d4714c60a72ccca1f141d583-30" name="rest_code_71373914d4714c60a72ccca1f141d583-30" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_71373914d4714c60a72ccca1f141d583-30"&gt;&lt;/a&gt;
&lt;a id="rest_code_71373914d4714c60a72ccca1f141d583-31" name="rest_code_71373914d4714c60a72ccca1f141d583-31" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_71373914d4714c60a72ccca1f141d583-31"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="c1"&gt;// Test the network on test set&lt;/span&gt;
&lt;a id="rest_code_71373914d4714c60a72ccca1f141d583-32" name="rest_code_71373914d4714c60a72ccca1f141d583-32" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_71373914d4714c60a72ccca1f141d583-32"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;net&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;evaluate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;test&lt;/span&gt;&lt;span class="p"&gt;());&lt;/span&gt;
&lt;a id="rest_code_71373914d4714c60a72ccca1f141d583-33" name="rest_code_71373914d4714c60a72ccca1f141d583-33" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_71373914d4714c60a72ccca1f141d583-33"&gt;&lt;/a&gt;
&lt;a id="rest_code_71373914d4714c60a72ccca1f141d583-34" name="rest_code_71373914d4714c60a72ccca1f141d583-34" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_71373914d4714c60a72ccca1f141d583-34"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;return&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a id="rest_code_71373914d4714c60a72ccca1f141d583-35" name="rest_code_71373914d4714c60a72ccca1f141d583-35" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_71373914d4714c60a72ccca1f141d583-35"&gt;&lt;/a&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/section&gt;
&lt;section id="reproducible-results"&gt;
&lt;h2&gt;Reproducible results&lt;/h2&gt;
&lt;p&gt;And last, but maybe not least, I've finally united all the random number
generation code. This means that DLL can now set a global seed and that two
training of the same network and data with the same seed will now produce
exactly the same result.&lt;/p&gt;
&lt;p&gt;The usage is extremely simple:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code c++"&gt;&lt;a id="rest_code_e99a807734844b18a1a64e7a9f130069-1" name="rest_code_e99a807734844b18a1a64e7a9f130069-1" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html#rest_code_e99a807734844b18a1a64e7a9f130069-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;set_seed&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;42&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/section&gt;
&lt;section id="conclusion"&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;After all these changes, I truly feel that the library is now in a much better
state and could be useful in several projects. I hope that this will be useful
to some more people. Moreover, as you can see by the performance results, the
framework is now extremely efficient at training neural networks on CPU.&lt;/p&gt;
&lt;p&gt;If you want more information, you can consult the
&lt;a class="reference external" href="https://github.com/wichtounet/dll"&gt;dll Github Repository&lt;/a&gt;. You can also add
a comment to this post. If you find any problem on the project or have specific
question or request, don't hesitate to open an issue on Github.&lt;/p&gt;
&lt;/section&gt;</description><category>Deep Learning</category><category>dll</category><category>etl</category><category>Machine Learning</category><category>publications</category><category>thesis</category><guid>https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html</guid><pubDate>Sun, 16 Jul 2017 13:41:51 GMT</pubDate></item><item><title>Update on Expression Templates Library (ETL)</title><link>https://baptiste-wicht.com/posts/2017/05/update-on-expression-templates-library-etl.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;p&gt;It's been a while since I've &lt;a class="reference external" href="https://baptiste-wicht.com/posts/2016/09/expression-templates-library-etl-10.html"&gt;released the version 1.0 of ETL&lt;/a&gt;. There is some work to do before I release the next version, but I wanted to give you a quick update on what has been going on for ETL in the last months. There has been a lot of changes in the library and the next version will be a major update when I'm done with some refactorings and improvements.&lt;/p&gt;
&lt;p&gt;Thanks to my thesis supervisor, the project now has a logo:&lt;/p&gt;
&lt;img alt="ETL Logo" class="align-center" src="https://baptiste-wicht.com/images/logo.png"&gt;
&lt;p&gt;There are quite a few new features, although probably nothing really major. The
support for square root has been improved with cubic root and inverse root.
Vectors can now be transformed using floor and ceil. Cross product of vector has
been implemented as well. Batched outer product and batched bias averaging (for
machine learning) are now supported. Reductions have also been improved with
absolute sum and mean (asum/asum) support and min_index and max_index. argmax
can now be used to get the max index in each sub dimensions. Matrix can now be
decomposed into their Q/R decomposition rather than only their PALU
decomposition. The matrices can now be sliced by getting only a sub part of the
matrix. The pooling operators  have also been improved with stride and padding
support. Matrices and vectors can also be shuffled. Moreover, a few adapters
are now available for hermitian matrices, symmetric matrices and lower and upper
matrices. So far the support for these adapters is not huge, but they are
guaranteed to validate their constraints.&lt;/p&gt;
&lt;p&gt;Several operations have been optimized for speed. All the pooling and upsample
operators are now parallelized and the most used kernel (2x2 pooling) is now
more optimized. 4D convolution kernels (for machine learning) have been greatly
improved. There are now very specialized vectorized kernels for classic kernel
configurations (for instance 3x3 or 5x5) and the selection of implementations is
now smarter than before. The support of padding now much better than before for
small amount of padding. Moreover, for small kernels the full convolution can
now be evaluated using the valid convolution kernels directly with some padding,
for much faster overall performance. Matrix-matrix multiplication with
transposed matrices is now much faster when using BLAS kernels. Indeed, the
transposition is not performed but handled inside the kernels. Moreover, the
performance of the transposition itself is also much faster. Finally, accesses
to 3D and 4D matrices is now much faster than before.&lt;/p&gt;
&lt;p&gt;The parallelization feature of ETL has been completely reworked. Before, there
was a thread pool for each algorithm that was parallelized. Now, there is
a global thread engine with one thread pool. Since parallelization is not nested
in ETL, this improves performance slightly by greatly diminishing the number of
threads that are created throughout an application.&lt;/p&gt;
&lt;p&gt;Vectorization has also been greatly improved in ETL. Integer operations are now
automatically vectorized on processors that support this. The automatic
vectorizer now is able to use non-temporal stores for very large operations.
A non-temporal store bypasses the cache, thus gaining some time. Since very
large matrices do not fit in cache, this is a net gain. Moreover, the alignment
detection in the automatic vectorizer has also been improved. Support for
Fused-Multiply-Add (FMA) operations has also been integrated in the algorithms
that can make use of it. The matrix-matrix multiplications and vector-matrix
multiplications now have optimized vectorized kernels. They also have versions
for column-major matrices now. The old egblas version of the gemm, based on BLIS
kernels, has been removed since it was only supporting double-precision and was
not faster than the new vectorized algorithm. I plan to reintegrate a version of
the GEMM based on BLIS in the future but with more optimizations and support for
all precisions and integers. The sum and the dot product now also have
specialized vectorized implementations. The min and max operations are now
automatically-vectorized.&lt;/p&gt;
&lt;p&gt;The GPU has also been almost completely reworked. Now, operations can be chained
without any copies between GPU and CPU. Several new operations have also been
added with support to GPU. Moreover, to complement operations that are not
available in any of the supported NVIDIA libraries, I've created a simple
library that can be used to add a few more GPU operations. Nevertheless a lot of
operations are still missing and only algorithms are available not expressions
(such as c = a + b * 1.0) that are entirely computed on CPU. I have plans to
improve that further, but probably not before the version 1.2.&lt;/p&gt;
&lt;p&gt;There also have been a lot of refactorings in the code of the library. A lot of
expressions now have less overhead and are specialized for performance.
Moreover, temporary expressions are currently being reworked in order to be more
simple and maintainable and easier to optimize in the future.&lt;/p&gt;
&lt;p&gt;Finally, there also was quite a few bug fixes. Most of them have been found by
the use of the library in the Deep Learning Library (DLL) project.&lt;/p&gt;</description><category>C++</category><category>C++14</category><category>etl</category><category>GPU</category><category>Performance</category><category>projects</category><guid>https://baptiste-wicht.com/posts/2017/05/update-on-expression-templates-library-etl.html</guid><pubDate>Sat, 06 May 2017 19:31:48 GMT</pubDate></item><item><title>Partial type erasing in Deep Learning Library (DLL) to improve compilation time</title><link>https://baptiste-wicht.com/posts/2017/03/partial-type-erasing-deep-learning-library-dll-improve-compilation-time.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;p&gt;In a previous post, I compared the &lt;a class="reference external" href="https://baptiste-wicht.com/posts/2017/03/disappointing-zapcc-performance-on-deep-learning-library-dll.html"&gt;compilation time on my Deep Learning Library (DLL) project with different compilers&lt;/a&gt;. I realized that the compilation times were quickly going unreasonable for this library, especially for compiling the unit cases which clearly hurts the development of the library. Indeed, you want to be able to run the unit tests reasonably quickly after you integrated new changes.&lt;/p&gt;
&lt;section id="reduce-the-compilation-time"&gt;
&lt;h2&gt;Reduce the compilation time&lt;/h2&gt;
&lt;p&gt;The first thing I did was to split the compilation in three executables: one for
the unit tests, one for the various performance tests and one for the various other
miscellaneous tests. With this, it is much faster to compile only the unit test
cases.&lt;/p&gt;
&lt;p&gt;But this can be improved significantly more. In DLL a network is a variadic
template containing the list of layers, in order. In DLL, there are two main
different ways of declaring a neural networks. In the first version, the fast
version, the layers directly know their sizes:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code cpp"&gt;&lt;a id="rest_code_debfc4dc28a943b9ad05570ea2d6e275-1" name="rest_code_debfc4dc28a943b9ad05570ea2d6e275-1" href="https://baptiste-wicht.com/posts/2017/03/partial-type-erasing-deep-learning-library-dll-improve-compilation-time.html#rest_code_debfc4dc28a943b9ad05570ea2d6e275-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;using&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;network_t&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;
&lt;a id="rest_code_debfc4dc28a943b9ad05570ea2d6e275-2" name="rest_code_debfc4dc28a943b9ad05570ea2d6e275-2" href="https://baptiste-wicht.com/posts/2017/03/partial-type-erasing-deep-learning-library-dll-improve-compilation-time.html#rest_code_debfc4dc28a943b9ad05570ea2d6e275-2"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dbn_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;
&lt;a id="rest_code_debfc4dc28a943b9ad05570ea2d6e275-3" name="rest_code_debfc4dc28a943b9ad05570ea2d6e275-3" href="https://baptiste-wicht.com/posts/2017/03/partial-type-erasing-deep-learning-library-dll-improve-compilation-time.html#rest_code_debfc4dc28a943b9ad05570ea2d6e275-3"&gt;&lt;/a&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dbn_layers&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;
&lt;a id="rest_code_debfc4dc28a943b9ad05570ea2d6e275-4" name="rest_code_debfc4dc28a943b9ad05570ea2d6e275-4" href="https://baptiste-wicht.com/posts/2017/03/partial-type-erasing-deep-learning-library-dll-improve-compilation-time.html#rest_code_debfc4dc28a943b9ad05570ea2d6e275-4"&gt;&lt;/a&gt;&lt;span class="w"&gt;            &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;rbm_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;28&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;28&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;500&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;momentum&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;64&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;layer_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a id="rest_code_debfc4dc28a943b9ad05570ea2d6e275-5" name="rest_code_debfc4dc28a943b9ad05570ea2d6e275-5" href="https://baptiste-wicht.com/posts/2017/03/partial-type-erasing-deep-learning-library-dll-improve-compilation-time.html#rest_code_debfc4dc28a943b9ad05570ea2d6e275-5"&gt;&lt;/a&gt;&lt;span class="w"&gt;            &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;rbm_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;500&lt;/span&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;400&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;momentum&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;64&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;layer_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a id="rest_code_debfc4dc28a943b9ad05570ea2d6e275-6" name="rest_code_debfc4dc28a943b9ad05570ea2d6e275-6" href="https://baptiste-wicht.com/posts/2017/03/partial-type-erasing-deep-learning-library-dll-improve-compilation-time.html#rest_code_debfc4dc28a943b9ad05570ea2d6e275-6"&gt;&lt;/a&gt;&lt;span class="w"&gt;            &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;rbm_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;400&lt;/span&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;momentum&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;64&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;hidden&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;unit_type&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;SOFTMAX&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;layer_t&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a id="rest_code_debfc4dc28a943b9ad05570ea2d6e275-7" name="rest_code_debfc4dc28a943b9ad05570ea2d6e275-7" href="https://baptiste-wicht.com/posts/2017/03/partial-type-erasing-deep-learning-library-dll-improve-compilation-time.html#rest_code_debfc4dc28a943b9ad05570ea2d6e275-7"&gt;&lt;/a&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;trainer&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;sgd_trainer&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;64&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;dbn_t&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a id="rest_code_debfc4dc28a943b9ad05570ea2d6e275-8" name="rest_code_debfc4dc28a943b9ad05570ea2d6e275-8" href="https://baptiste-wicht.com/posts/2017/03/partial-type-erasing-deep-learning-library-dll-improve-compilation-time.html#rest_code_debfc4dc28a943b9ad05570ea2d6e275-8"&gt;&lt;/a&gt;
&lt;a id="rest_code_debfc4dc28a943b9ad05570ea2d6e275-9" name="rest_code_debfc4dc28a943b9ad05570ea2d6e275-9" href="https://baptiste-wicht.com/posts/2017/03/partial-type-erasing-deep-learning-library-dll-improve-compilation-time.html#rest_code_debfc4dc28a943b9ad05570ea2d6e275-9"&gt;&lt;/a&gt;&lt;span class="k"&gt;auto&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;network&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;make_unique&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;network_t&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;a id="rest_code_debfc4dc28a943b9ad05570ea2d6e275-10" name="rest_code_debfc4dc28a943b9ad05570ea2d6e275-10" href="https://baptiste-wicht.com/posts/2017/03/partial-type-erasing-deep-learning-library-dll-improve-compilation-time.html#rest_code_debfc4dc28a943b9ad05570ea2d6e275-10"&gt;&lt;/a&gt;&lt;span class="n"&gt;network&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;pretrain&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;training_images&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a id="rest_code_debfc4dc28a943b9ad05570ea2d6e275-11" name="rest_code_debfc4dc28a943b9ad05570ea2d6e275-11" href="https://baptiste-wicht.com/posts/2017/03/partial-type-erasing-deep-learning-library-dll-improve-compilation-time.html#rest_code_debfc4dc28a943b9ad05570ea2d6e275-11"&gt;&lt;/a&gt;&lt;span class="n"&gt;network&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;fine_tune&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;training_images&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;training_labels&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In my opinion, this is the best way to use DLL. This is the fastest and the
clearest. Moreover, the dimensions of the network can be validated at compile
time, which is always better than at runtime. However, the dimensions of the
network cannot be changed at runtime.  For this, there is a different version,
the dynamic version:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code cpp"&gt;&lt;a id="rest_code_78760e19181b41eeae65163b96ccb7e8-1" name="rest_code_78760e19181b41eeae65163b96ccb7e8-1" href="https://baptiste-wicht.com/posts/2017/03/partial-type-erasing-deep-learning-library-dll-improve-compilation-time.html#rest_code_78760e19181b41eeae65163b96ccb7e8-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;using&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;network_t&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;
&lt;a id="rest_code_78760e19181b41eeae65163b96ccb7e8-2" name="rest_code_78760e19181b41eeae65163b96ccb7e8-2" href="https://baptiste-wicht.com/posts/2017/03/partial-type-erasing-deep-learning-library-dll-improve-compilation-time.html#rest_code_78760e19181b41eeae65163b96ccb7e8-2"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dbn_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;
&lt;a id="rest_code_78760e19181b41eeae65163b96ccb7e8-3" name="rest_code_78760e19181b41eeae65163b96ccb7e8-3" href="https://baptiste-wicht.com/posts/2017/03/partial-type-erasing-deep-learning-library-dll-improve-compilation-time.html#rest_code_78760e19181b41eeae65163b96ccb7e8-3"&gt;&lt;/a&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dbn_layers&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;
&lt;a id="rest_code_78760e19181b41eeae65163b96ccb7e8-4" name="rest_code_78760e19181b41eeae65163b96ccb7e8-4" href="https://baptiste-wicht.com/posts/2017/03/partial-type-erasing-deep-learning-library-dll-improve-compilation-time.html#rest_code_78760e19181b41eeae65163b96ccb7e8-4"&gt;&lt;/a&gt;&lt;span class="w"&gt;            &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dyn_rbm_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;momentum&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;layer_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a id="rest_code_78760e19181b41eeae65163b96ccb7e8-5" name="rest_code_78760e19181b41eeae65163b96ccb7e8-5" href="https://baptiste-wicht.com/posts/2017/03/partial-type-erasing-deep-learning-library-dll-improve-compilation-time.html#rest_code_78760e19181b41eeae65163b96ccb7e8-5"&gt;&lt;/a&gt;&lt;span class="w"&gt;            &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dyn_rbm_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;momentum&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;layer_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a id="rest_code_78760e19181b41eeae65163b96ccb7e8-6" name="rest_code_78760e19181b41eeae65163b96ccb7e8-6" href="https://baptiste-wicht.com/posts/2017/03/partial-type-erasing-deep-learning-library-dll-improve-compilation-time.html#rest_code_78760e19181b41eeae65163b96ccb7e8-6"&gt;&lt;/a&gt;&lt;span class="w"&gt;            &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dyn_rbm_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;momentum&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;hidden&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;unit_type&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;SOFTMAX&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;layer_t&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a id="rest_code_78760e19181b41eeae65163b96ccb7e8-7" name="rest_code_78760e19181b41eeae65163b96ccb7e8-7" href="https://baptiste-wicht.com/posts/2017/03/partial-type-erasing-deep-learning-library-dll-improve-compilation-time.html#rest_code_78760e19181b41eeae65163b96ccb7e8-7"&gt;&lt;/a&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;64&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;trainer&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;sgd_trainer&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;dbn_t&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a id="rest_code_78760e19181b41eeae65163b96ccb7e8-8" name="rest_code_78760e19181b41eeae65163b96ccb7e8-8" href="https://baptiste-wicht.com/posts/2017/03/partial-type-erasing-deep-learning-library-dll-improve-compilation-time.html#rest_code_78760e19181b41eeae65163b96ccb7e8-8"&gt;&lt;/a&gt;
&lt;a id="rest_code_78760e19181b41eeae65163b96ccb7e8-9" name="rest_code_78760e19181b41eeae65163b96ccb7e8-9" href="https://baptiste-wicht.com/posts/2017/03/partial-type-erasing-deep-learning-library-dll-improve-compilation-time.html#rest_code_78760e19181b41eeae65163b96ccb7e8-9"&gt;&lt;/a&gt;&lt;span class="k"&gt;auto&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;network&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;make_unique&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;network_t&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;a id="rest_code_78760e19181b41eeae65163b96ccb7e8-10" name="rest_code_78760e19181b41eeae65163b96ccb7e8-10" href="https://baptiste-wicht.com/posts/2017/03/partial-type-erasing-deep-learning-library-dll-improve-compilation-time.html#rest_code_78760e19181b41eeae65163b96ccb7e8-10"&gt;&lt;/a&gt;
&lt;a id="rest_code_78760e19181b41eeae65163b96ccb7e8-11" name="rest_code_78760e19181b41eeae65163b96ccb7e8-11" href="https://baptiste-wicht.com/posts/2017/03/partial-type-erasing-deep-learning-library-dll-improve-compilation-time.html#rest_code_78760e19181b41eeae65163b96ccb7e8-11"&gt;&lt;/a&gt;&lt;span class="n"&gt;network&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;layer_get&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;().&lt;/span&gt;&lt;span class="n"&gt;init_layer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;28&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;28&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;500&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a id="rest_code_78760e19181b41eeae65163b96ccb7e8-12" name="rest_code_78760e19181b41eeae65163b96ccb7e8-12" href="https://baptiste-wicht.com/posts/2017/03/partial-type-erasing-deep-learning-library-dll-improve-compilation-time.html#rest_code_78760e19181b41eeae65163b96ccb7e8-12"&gt;&lt;/a&gt;&lt;span class="n"&gt;network&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;layer_get&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;().&lt;/span&gt;&lt;span class="n"&gt;init_layer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;500&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;400&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a id="rest_code_78760e19181b41eeae65163b96ccb7e8-13" name="rest_code_78760e19181b41eeae65163b96ccb7e8-13" href="https://baptiste-wicht.com/posts/2017/03/partial-type-erasing-deep-learning-library-dll-improve-compilation-time.html#rest_code_78760e19181b41eeae65163b96ccb7e8-13"&gt;&lt;/a&gt;&lt;span class="n"&gt;network&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;layer_get&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;().&lt;/span&gt;&lt;span class="n"&gt;init_layer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;400&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a id="rest_code_78760e19181b41eeae65163b96ccb7e8-14" name="rest_code_78760e19181b41eeae65163b96ccb7e8-14" href="https://baptiste-wicht.com/posts/2017/03/partial-type-erasing-deep-learning-library-dll-improve-compilation-time.html#rest_code_78760e19181b41eeae65163b96ccb7e8-14"&gt;&lt;/a&gt;&lt;span class="n"&gt;network&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;layer_get&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;().&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;64&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a id="rest_code_78760e19181b41eeae65163b96ccb7e8-15" name="rest_code_78760e19181b41eeae65163b96ccb7e8-15" href="https://baptiste-wicht.com/posts/2017/03/partial-type-erasing-deep-learning-library-dll-improve-compilation-time.html#rest_code_78760e19181b41eeae65163b96ccb7e8-15"&gt;&lt;/a&gt;&lt;span class="n"&gt;network&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;layer_get&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;().&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;64&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a id="rest_code_78760e19181b41eeae65163b96ccb7e8-16" name="rest_code_78760e19181b41eeae65163b96ccb7e8-16" href="https://baptiste-wicht.com/posts/2017/03/partial-type-erasing-deep-learning-library-dll-improve-compilation-time.html#rest_code_78760e19181b41eeae65163b96ccb7e8-16"&gt;&lt;/a&gt;&lt;span class="n"&gt;network&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;layer_get&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;().&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;64&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a id="rest_code_78760e19181b41eeae65163b96ccb7e8-17" name="rest_code_78760e19181b41eeae65163b96ccb7e8-17" href="https://baptiste-wicht.com/posts/2017/03/partial-type-erasing-deep-learning-library-dll-improve-compilation-time.html#rest_code_78760e19181b41eeae65163b96ccb7e8-17"&gt;&lt;/a&gt;
&lt;a id="rest_code_78760e19181b41eeae65163b96ccb7e8-18" name="rest_code_78760e19181b41eeae65163b96ccb7e8-18" href="https://baptiste-wicht.com/posts/2017/03/partial-type-erasing-deep-learning-library-dll-improve-compilation-time.html#rest_code_78760e19181b41eeae65163b96ccb7e8-18"&gt;&lt;/a&gt;&lt;span class="n"&gt;network&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;pretrain&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;training_images&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a id="rest_code_78760e19181b41eeae65163b96ccb7e8-19" name="rest_code_78760e19181b41eeae65163b96ccb7e8-19" href="https://baptiste-wicht.com/posts/2017/03/partial-type-erasing-deep-learning-library-dll-improve-compilation-time.html#rest_code_78760e19181b41eeae65163b96ccb7e8-19"&gt;&lt;/a&gt;&lt;span class="n"&gt;network&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;fine_tune&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;training_images&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;training_labels&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This is a bit more verbose, but the configuration can be changed at runtime with
this system. Moreover, this is also faster to compile. On the other hand, there
is some performance slowdown.&lt;/p&gt;
&lt;p&gt;There is also a third version that is a hybrid of the first version:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code cpp"&gt;&lt;a id="rest_code_e36a1fc53ca546308cf2596a6d6dd97c-1" name="rest_code_e36a1fc53ca546308cf2596a6d6dd97c-1" href="https://baptiste-wicht.com/posts/2017/03/partial-type-erasing-deep-learning-library-dll-improve-compilation-time.html#rest_code_e36a1fc53ca546308cf2596a6d6dd97c-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;using&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;network_t&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;
&lt;a id="rest_code_e36a1fc53ca546308cf2596a6d6dd97c-2" name="rest_code_e36a1fc53ca546308cf2596a6d6dd97c-2" href="https://baptiste-wicht.com/posts/2017/03/partial-type-erasing-deep-learning-library-dll-improve-compilation-time.html#rest_code_e36a1fc53ca546308cf2596a6d6dd97c-2"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dyn_dbn_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;
&lt;a id="rest_code_e36a1fc53ca546308cf2596a6d6dd97c-3" name="rest_code_e36a1fc53ca546308cf2596a6d6dd97c-3" href="https://baptiste-wicht.com/posts/2017/03/partial-type-erasing-deep-learning-library-dll-improve-compilation-time.html#rest_code_e36a1fc53ca546308cf2596a6d6dd97c-3"&gt;&lt;/a&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dbn_layers&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;
&lt;a id="rest_code_e36a1fc53ca546308cf2596a6d6dd97c-4" name="rest_code_e36a1fc53ca546308cf2596a6d6dd97c-4" href="https://baptiste-wicht.com/posts/2017/03/partial-type-erasing-deep-learning-library-dll-improve-compilation-time.html#rest_code_e36a1fc53ca546308cf2596a6d6dd97c-4"&gt;&lt;/a&gt;&lt;span class="w"&gt;            &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;rbm_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;28&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;28&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;500&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;momentum&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;64&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;layer_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a id="rest_code_e36a1fc53ca546308cf2596a6d6dd97c-5" name="rest_code_e36a1fc53ca546308cf2596a6d6dd97c-5" href="https://baptiste-wicht.com/posts/2017/03/partial-type-erasing-deep-learning-library-dll-improve-compilation-time.html#rest_code_e36a1fc53ca546308cf2596a6d6dd97c-5"&gt;&lt;/a&gt;&lt;span class="w"&gt;            &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;rbm_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;500&lt;/span&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;400&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;momentum&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;64&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;layer_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a id="rest_code_e36a1fc53ca546308cf2596a6d6dd97c-6" name="rest_code_e36a1fc53ca546308cf2596a6d6dd97c-6" href="https://baptiste-wicht.com/posts/2017/03/partial-type-erasing-deep-learning-library-dll-improve-compilation-time.html#rest_code_e36a1fc53ca546308cf2596a6d6dd97c-6"&gt;&lt;/a&gt;&lt;span class="w"&gt;            &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;rbm_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;400&lt;/span&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;momentum&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;64&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;hidden&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;unit_type&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;SOFTMAX&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;layer_t&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a id="rest_code_e36a1fc53ca546308cf2596a6d6dd97c-7" name="rest_code_e36a1fc53ca546308cf2596a6d6dd97c-7" href="https://baptiste-wicht.com/posts/2017/03/partial-type-erasing-deep-learning-library-dll-improve-compilation-time.html#rest_code_e36a1fc53ca546308cf2596a6d6dd97c-7"&gt;&lt;/a&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;trainer&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;sgd_trainer&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;64&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;dbn_t&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a id="rest_code_e36a1fc53ca546308cf2596a6d6dd97c-8" name="rest_code_e36a1fc53ca546308cf2596a6d6dd97c-8" href="https://baptiste-wicht.com/posts/2017/03/partial-type-erasing-deep-learning-library-dll-improve-compilation-time.html#rest_code_e36a1fc53ca546308cf2596a6d6dd97c-8"&gt;&lt;/a&gt;
&lt;a id="rest_code_e36a1fc53ca546308cf2596a6d6dd97c-9" name="rest_code_e36a1fc53ca546308cf2596a6d6dd97c-9" href="https://baptiste-wicht.com/posts/2017/03/partial-type-erasing-deep-learning-library-dll-improve-compilation-time.html#rest_code_e36a1fc53ca546308cf2596a6d6dd97c-9"&gt;&lt;/a&gt;&lt;span class="k"&gt;auto&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;network&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;make_unique&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;network_t&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;a id="rest_code_e36a1fc53ca546308cf2596a6d6dd97c-10" name="rest_code_e36a1fc53ca546308cf2596a6d6dd97c-10" href="https://baptiste-wicht.com/posts/2017/03/partial-type-erasing-deep-learning-library-dll-improve-compilation-time.html#rest_code_e36a1fc53ca546308cf2596a6d6dd97c-10"&gt;&lt;/a&gt;&lt;span class="n"&gt;network&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;pretrain&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;training_images&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a id="rest_code_e36a1fc53ca546308cf2596a6d6dd97c-11" name="rest_code_e36a1fc53ca546308cf2596a6d6dd97c-11" href="https://baptiste-wicht.com/posts/2017/03/partial-type-erasing-deep-learning-library-dll-improve-compilation-time.html#rest_code_e36a1fc53ca546308cf2596a6d6dd97c-11"&gt;&lt;/a&gt;&lt;span class="n"&gt;network&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;fine_tune&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;training_images&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;training_labels&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Only one line was changed compared to the first version, &lt;code&gt;dbn_desc&lt;/code&gt;
becomes &lt;code&gt;dyn_dbn_desc&lt;/code&gt;. What this changes is that all the layers are
automatically transformed into their dynamic versions and all the parameters are
propagated at runtime. This is a form a type erasing since the sizes will not be
propagated at compilation time. But this is simple since the types are simply
transformed from one type to another directly. Behind the scene, it's the
dynamic version using the front-end of the fast version. This is almost as fast
to compile as the dynamic version, but the code is much better. It executes the
same as the dynamic version.&lt;/p&gt;
&lt;p&gt;If we compare the compilation time of the three versions when compiling a single
network and 5 different networks with different architectures, we get the
following results (with clang):&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;&lt;th class="head"&gt;&lt;p&gt;Model&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;Time [s]&lt;/p&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;1 Fast&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;30&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;1 Dynamic&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;16.6&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;1 Hybrid&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;16.6&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;5 Fast&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;114&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;5 Dynamic&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;16.6&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;5 Hybrid&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;21.9&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Even with one single network, the compilation time is reduced by 44%. When five
different networks are compilation, time is reduced by 85%. This can be
explained easily. Indeed, for the hybrid and dynamic versions, the layers will
have the same type and therefore a lot of template instantiations will only be
done once instead of five times. This makes a lot of difference since almost
everything is template inside the library.&lt;/p&gt;
&lt;p&gt;Unfortunately, this also has an impact on the runtime of the network:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;&lt;th class="head"&gt;&lt;p&gt;Model&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;Pretrain [s]&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;Train [s]&lt;/p&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;Fast&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;195&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;114&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;Dynamic&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;203&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;123&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;Hybrid&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;204&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;122&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;On average, for dense models, the slowdown is between 4% and 8%. For
convolutional models, it is between 10% and 25%. I will definitely work on
trying to make the dynamic and especially the hybrid version faster in the
future, most on the work should be on the matrix library (ETL) that is used.&lt;/p&gt;
&lt;p&gt;Since for test cases, a 20% increase in runtime is not really a problem, tests
being fast already, I decided to add an option to DLL so that everything can be
compiled by default in hybrid model. By using a compilation flag, all the
&lt;code&gt;dbn_desc&lt;/code&gt; are becoming &lt;code&gt;dyn_dbn_desc&lt;/code&gt; and therefore each used
network is becoming a hybrid network. Without a single change in the code, the
compilation time of the entire library can be significantly improved, as seen in
the next section.  This can also be used in user code to improve compilation
time during debugging and experiments and can be turned off for the final
training.&lt;/p&gt;
&lt;p&gt;On my Continuous Integration system, I will build the system in both
configurations. This is not really an issue, since my personal machine at home
is more powerful than what I have available here.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="results"&gt;
&lt;h2&gt;Results&lt;/h2&gt;
&lt;p&gt;On a first experiment, I measured the difference before and after this change on
the three executables of the library, with gcc:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;&lt;th class="head"&gt;&lt;p&gt;Model&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;Unit [s]&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;Perf [s]&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;Misc [s]&lt;/p&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;Before&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1029&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;192&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;937&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;After&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;617&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;143&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;619&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;Speedup&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;40.03%&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;25.52%&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;33.93%&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;It is clear that the speedups are very significant! The compilation is between
25% and 40% faster with the new option. Overall, this is a speedup of 36%!
I also noticed that the compilation takes significantly less memory than before.
Therefore, I decided to rerun the compiler benchmark on the library. In the
previous experiment, zapcc was taking so much memory that it was impossible to
use more than one thread. Let's see how it is faring now. The time to compile
the full unit tests is computed for each compiler. Let's start in debug mode:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;&lt;th class="head"&gt;&lt;p&gt;Debug&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;-j1&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;-j2&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;-j3&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;-j4&lt;/p&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;clang-3.9&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;527&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;268&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;182&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;150&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;gcc-4.9.3&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;591&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;303&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;211&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;176&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;gcc-5.3.0&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;588&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;302&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;209&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;175&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;zapcc-1.0&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;&lt;strong&gt;375&lt;/strong&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;&lt;strong&gt;187&lt;/strong&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;&lt;strong&gt;126&lt;/strong&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;&lt;strong&gt;121&lt;/strong&gt;&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;This time, zapcc is able to scale to four threads without problems. Moreover, it
is always the fastest compiler, by a significant margin, in this configuration.
It is followed by clang and then by gcc for which both versions are about the
same speed.&lt;/p&gt;
&lt;p&gt;If we compile again in release mode:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;&lt;th class="head"&gt;&lt;p&gt;Release&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;-j1&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;-j2&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;-j3&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;-j4&lt;/p&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;clang-3.9&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1201&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;615&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;421&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;356&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;gcc-4.9.3&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1041&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;541&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;385&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;321&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;gcc-5.3.0&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1114&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;579&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;412&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;348&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;zapcc-1.0&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;&lt;strong&gt;897&lt;/strong&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;&lt;strong&gt;457&lt;/strong&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;&lt;strong&gt;306&lt;/strong&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;&lt;em&gt;306&lt;/em&gt;&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The difference in compilation time is very large, it's twice slower to compile
with all optimizations enabled. It also takes significantly more memory. Indeed,
zapcc was not able to compile with 4 threads. Nevertheless, even the results
with three threads are better than the other compilers using four threads. zapcc
is clearly the winner again on this test, followed by gcc4-9 which is faster
than gcc-5.3 which is itself faster than clang. It seems that while clang is
better at frontend than gcc, it is slower for optimizations. Note that this may
also be an indication that clang performs more optimizations than gcc and may
not be slower.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="conclusion"&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;By using some form of type erasing to simplify the templates types at compile
time, I was able to reduce the overall compilation time of my Deep Learning
Library (DLL) by 36%. Moreover, this can be done by switching a simple
compilation flag. This also very significantly reduce the memory used during the
compilation, allowing zapcc to to compile with up to three threads, compared
with only one before. This makes zapcc the fastest compiler again on this
benchmark. Overall, this will make debugging much easier on this library and
will save me a lot of time.&lt;/p&gt;
&lt;p&gt;In the future, I plan to try to improve compilation time even more. I have a few
ideas, especially in ETL that should significantly improve the compilation time
but that will require a lot of time to implement, so that will likely have to
wait a while. In the coming days, I plan to work on the performance of DLL,
especially for stochastic gradient descent.&lt;/p&gt;
&lt;p&gt;If you want more information on DLL, you can check out the
&lt;a class="reference external" href="https://github.com/wichtounet/dll"&gt;dll Github repository&lt;/a&gt;.&lt;/p&gt;
&lt;/section&gt;</description><category>C++</category><category>C++11</category><category>clang</category><category>Compilers</category><category>dll</category><category>etl</category><category>gcc</category><category>zapcc</category><guid>https://baptiste-wicht.com/posts/2017/03/partial-type-erasing-deep-learning-library-dll-improve-compilation-time.html</guid><pubDate>Wed, 15 Mar 2017 06:43:44 GMT</pubDate></item><item><title>Release of zapcc 1.0 - Fast C++ compiler</title><link>https://baptiste-wicht.com/posts/2017/03/release-zapcc-10-fast-cpp-compiler.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;p&gt;If you remember, I recently wrote about &lt;a class="reference external" href="http://baptiste-wicht.com/posts/2016/12/zapcc-cpp-compilation-speed-against-gcc-54-and-clang-39.html"&gt;zapcc C++ compilation speed against gcc 5.4 and clang 3.9&lt;/a&gt; in which I was comparing the beta version of zapcc against gcc and clang.&lt;/p&gt;
&lt;p&gt;I just been informed that zapcc was just released in version 1.0. I though it
was a good occasion to test it again. It will be compared against gcc-4.9,
gcc-5.3 and clang-3.9. This version is based on the trunk of clang-5.0.&lt;/p&gt;
&lt;p&gt;Again, I will use my Expression Template Library (&lt;a class="reference external" href="https://github.com/wichtounet/etl/"&gt;ETL&lt;/a&gt;) project. This is a purely header-only
library with lots of templates. I'm going to compile the full test cases. This
is a perfect example for long compilation times.&lt;/p&gt;
&lt;p&gt;The current tests are made on the last version of the library and with slightly
different parameters for compilation, therefore the absolute times are not
comparable, but the speedups should be comparable.&lt;/p&gt;
&lt;p&gt;Just like last time, I have configured zapcc to let is use 2Go RAM per caching
server, which is the maximum allowed. Moreover, I killed the servers before each
tests.&lt;/p&gt;
&lt;section id="debug-results"&gt;
&lt;h2&gt;Debug results&lt;/h2&gt;
&lt;p&gt;Let's start with a debug build, with no optimizations enabled. Every build will
use four threads. This is the equivalent of doing make -j4 debug/bin/etl_test
without the link step.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;&lt;th class="head"&gt;&lt;p&gt;Compiler&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;g++-4.9.3&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;190.09s&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;g++-5.3.0&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;200.92s&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;clang++-3.9&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;313.85&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;zapcc++&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;81.25&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;Speedup VS Clang&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;3.86&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;Speedup VS GCC-5.3&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;2.47&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;Speedup VS GCC-4.9&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;2.33&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The speedups are even more impressive than last time! zapcc is &lt;strong&gt;almost four
times fast than clang-3.9&lt;/strong&gt; and around &lt;strong&gt;2.5 times faster than GCC-5.3&lt;/strong&gt;.
Interestingly, we can see that gcc-5.3 is slighly slower than GCC-4.9.&lt;/p&gt;
&lt;p&gt;It seems that they have the compiler even faster!&lt;/p&gt;
&lt;/section&gt;
&lt;section id="release-results"&gt;
&lt;h2&gt;Release results&lt;/h2&gt;
&lt;p&gt;Let's look now how the results are looking with optimizations enabled. Again,
every build will use four threads. This is the equivalent of doing make -j4
release_debug/bin/etl_test without the link step.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;&lt;th class="head"&gt;&lt;p&gt;Compiler&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;g++-4.9.3&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;252.99&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;g++-5.3.0&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;264.96&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;clang++-3.9&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;361.65&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;zapcc++&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;237.96&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;Speedup VS Clang&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.51&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;Speedup VS GCC-5.3&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.11&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;Speedup VS GCC-4.9&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.06&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;We can see that this time the speedups are not as interesting as they were.
Very interestingly, it's the compiler that suffers the more from the
optimization overhead. Indeed, zapcc is three times slower in release mode than
it was in debug mode. Nevertheless, it still manages to beat the three other
compilers, by about 10% for Gcc and 50% than clang, which is already
interesting.&lt;/p&gt;
&lt;section id="conclusion"&gt;
&lt;h3&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;To conclude, we have observed that zapcc is always faster than the three
compilers tested in this experiment. Moreover, in debug mode, the speedups are
very significant, it was almost 4 times faster than clang and around 2.5 faster
than gcc.&lt;/p&gt;
&lt;p&gt;I haven't seen any problem with the tool, it's like clang and it should generate
code of the same performance, but just compile it much faster. One problem
I have with zapcc is that it is not based on an already released version of
clang but on the trunk. That means it is hard to be compare with the exact same
version of clang and it is also a risk of running into clang bugs.&lt;/p&gt;
&lt;p&gt;Although the prices have not been published yet, it is indicated on the website
that zapcc is free for non-commercial entities. Which is really great.&lt;/p&gt;
&lt;p&gt;If you want more information, you can go to the
&lt;a class="reference external" href="https://www.zapcc.com/"&gt;official website of zapcc&lt;/a&gt;&lt;/p&gt;
&lt;/section&gt;
&lt;/section&gt;</description><category>C++</category><category>clang</category><category>Compilers</category><category>etl</category><category>gcc</category><category>projects</category><category>zapcc</category><guid>https://baptiste-wicht.com/posts/2017/03/release-zapcc-10-fast-cpp-compiler.html</guid><pubDate>Thu, 02 Mar 2017 13:50:04 GMT</pubDate></item><item><title>Publication: CPU Performance Optimizations for RBM and CRBM</title><link>https://baptiste-wicht.com/posts/2017/02/publication-cpu-performance-optimizations-rbm-crbm.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;p&gt;Recently, we have published a paper about performance optimizations that may
interest you.&lt;/p&gt;
&lt;p&gt;The paper is &lt;a class="reference external" href="https://www.researchgate.net/publication/307908790_On_CPU_Performance_Optimization_of_Restricted_Boltzmann_Machine_and_Convolutional_RBM"&gt;On CPU Performance Optimizations for Restricted Boltzmann Machine and Convolutional RBM&lt;/a&gt;, published in the Proceedings of the Artificial Neural Networks and Pattern Recognition workshop (ANNPR-2016). I've presented this paper in Germany, at Ulm.&lt;/p&gt;
&lt;p&gt;Although most of the performance research going on is focused on GPU, there are
still of research laboratories that are only equipped with CPU and it remains
important to be as fast as possible on CPU. Moreover, this is something
I really like.&lt;/p&gt;
&lt;p&gt;For this publication, I have tried to make my Restricted Boltzmann Machine (RBM)
and Convolutional RBM (CRBM) implementations in my DLL library as fast as
possible.&lt;/p&gt;
&lt;p&gt;The first part of the article is about Restricted Boltzmann Machine (RBM) which
are a form of dense Artificial Neural Network (ANN). Their training is very
similar to that of the ANN with Gradient Descent. Four different network
configurations are being tested.&lt;/p&gt;
&lt;p&gt;First, mini-batch training is shown to be much faster than online training, even
when online training is performed in parallel. Once mini-batch training is used,
BLAS operations are used in order to get as much performance as possible on the
different operations, mainly the Matrix Matrix Multiplication with the use of
the GEMM operation from the Intel Math Kernel Library (MKL). Moreover, the
parallel version of the MKL is also used to get even more performance. When all
these optimizations are performed, speedups of 11 to 30 are obtained compared to
the online training, depending on the network configurations. This final version
is able  to perform one epoch of Contrastive Divergence in 4 to 15 seconds
depending on the network, for 60000 images.&lt;/p&gt;
&lt;p&gt;The second part of the article is about Convolutional Restricted Boltzmann
Machine (CRBM). This is almost the equivalent of a Convolutional Neural Network
(CNN). Again four different networks are evaluated.&lt;/p&gt;
&lt;p&gt;The main problem with CRBM is that there are no standard implementations of the
convolution operation that is really fast. Therefore, it is not possible to
simply use a BLAS library to make the computation as fast as possible. The first
optimization that was tried is to vectorize the convolutions. With this, the
speedups have been between 1.1 and 1.9 times faster. I'm not really satisfied
with these results since in fact per convolution the speedups are much better.
Moreover, I have since been able to obtain better speedups but the deadline was
too short to include them in this paper. I'll try to talk about these
improvements in more details on this blog. What is more interesting to to
parallellize the different convolutions since they are mostly independent. This
can bring a speedup of the amount of cores available on the machine. Since
convolutions are extremely memory hungry, virtual cores with Hyper Threading
generally does not help. An interesting optimization is to use a Matrix
Multiplication to compute several valid convolutions at once.  This can give an
additional speedup between 1.6 and 2.2 compared to the vectorized version. While
it is possible to use the FFT to reduce the full convolution as well, in our
experiment the images were not big enough for this to be interesting. The final
speedups are about 10 times faster with these optimizations.&lt;/p&gt;
&lt;p&gt;We have obtained pretty good and I'm happy we have been published. However, I'm
not very satisfied with these results since I've been able to get even faster
since this and when compared with other frameworks, DLL is actually quite
competitive. I'll try to publish something new in the future.&lt;/p&gt;
&lt;p&gt;If you want more information, you can have a look at the paper. If you want to
look at the code, you can have a look at my projects:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;&lt;a class="reference external" href="https://github.com/wichtounet/etl"&gt;Expression Templates Library (ETL)&lt;/a&gt;: For
the Matrix Multiplication and Convolutions&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a class="reference external" href="https://github.com/wichtounet/dll"&gt;Deep Learning Library (DLL)&lt;/a&gt;: For the RBM
and CRBM implementations&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Don't hesitate to ask any questions if you want more information :)&lt;/p&gt;</description><category>C++</category><category>CPU</category><category>crbm</category><category>dbn</category><category>Deep Learning</category><category>dll</category><category>etl</category><category>Intel</category><category>Performances</category><category>publications</category><category>rbm</category><category>thesis</category><guid>https://baptiste-wicht.com/posts/2017/02/publication-cpu-performance-optimizations-rbm-crbm.html</guid><pubDate>Tue, 07 Feb 2017 16:33:33 GMT</pubDate></item><item><title>zapcc C++ compilation speed against gcc 5.4 and clang 3.9</title><link>https://baptiste-wicht.com/posts/2016/12/zapcc-cpp-compilation-speed-against-gcc-54-and-clang-39.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;p&gt;A week ago, I compared the &lt;a class="reference external" href="http://baptiste-wicht.com/posts/2016/11/zapcc-a-faster-cpp-compiler.html"&gt;compilation time performance of zapcc against gcc-4.9.3 and clang-3.7&lt;/a&gt;. On debug builds, zapcc was about 2 times faster than gcc and 3 times faster than clang. In this post, I'm going to try some more recent compilers, namely gcc 5.4 and clang 3.9 on the same project. If you want more information on zapcc, read the previous posts, this post will concentrate on results.&lt;/p&gt;
&lt;p&gt;Again, I use my Expression Template Library
(&lt;a class="reference external" href="https://github.com/wichtounet/etl/"&gt;ETL&lt;/a&gt;). This is a purely header-only
library with lots of templates. I'm going to compile the full test cases.&lt;/p&gt;
&lt;p&gt;The results of the two articles are not directly comparable, since they were
obtained on two different computers. The one on which the present results are
done has a less powerful and only 16Go of RAM compared to the 32Go of RAM of my
build machine. Also take into account that that the present results were
obtained on a Desktop machine, there can be some perturbations from background
tasks.&lt;/p&gt;
&lt;p&gt;Just like on the previous results, it does not help using more threads than
physical cores, therefore, the results were only computed on up to 4 cores on
this machine.&lt;/p&gt;
&lt;p&gt;The link time is not taken into account on the results.&lt;/p&gt;
&lt;section id="debug-build"&gt;
&lt;h2&gt;Debug build&lt;/h2&gt;
&lt;p&gt;Let's start with the result of the debug build.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;&lt;th class="head"&gt;&lt;p&gt;Compiler&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;-j1&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;-j2&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;-j4&lt;/p&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;g++-5.4.0&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;469s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;230s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;130s&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;clang++-3.9&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;710s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;371s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;218s&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;zapcc++&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;214s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;112s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;66s&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;Speedup VS Clang&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;3.31&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;3.31&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;3.3&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;Speedup VS GCC&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;2.19&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;2.05&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.96&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The results are almost the same as the previous test. zapcc is 3.3 times faster
to compile than Clang and around 2 times faster than GCC. It seems that GCC 5.4
is a bit faster than GCC 4.9.3 while clang 3.9 is a bit slower than clang 3.7,
but nothing terribly significant.&lt;/p&gt;
&lt;p&gt;Overall, for debug builds, zapcc can bring a very significant improvement to
your compile times.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="release-build"&gt;
&lt;h2&gt;Release build&lt;/h2&gt;
&lt;p&gt;Let's see what is the status of Release builds. Since the results are comparable
between the numbers of threads, the results here are just for one thread.&lt;/p&gt;
&lt;p&gt;This is more time consuming since a lot of optimizations are enabled and more
features from ETL are enabled as well.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;&lt;th class="head"&gt;&lt;p&gt;Compiler&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;-j1&lt;/p&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;g++-5.4.0&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;782s&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;clang++-3.9&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;960s&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;zapcc++&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;640s&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;Speedup VS Clang&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.5&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;Speedup VS GCC&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.22&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;On a release build, the speedups are much less interesting. Nevertheless, they
are still significant. zapcc is still 1.2 times faster than gcc and 1.5 times
faster than clang. Then speedup against clang 3.9 is significantly higher than
it was on my experiment with clang 3.7, it's possible that clang 3.9 is slower
or simply has new optimization passes.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="conclusion"&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;The previous conclusion still holds with modern version of compilers: zapcc is
much faster than other compilers on Debug builds of template heavy code. More
than 3 times faster than clang-3.9 and about 2 times faster than gcc-5.4. Since
it's based on clang, there should not be any issue compiling projects that
already compile with a recent clang. Even though the speedups are less
interesting on a release build, it is still significantly, especially compared
against clang.&lt;/p&gt;
&lt;p&gt;I'm really interested in finding out what will be the pricing for zapcc once
out of the beta or if they will be able to get even faster!&lt;/p&gt;
&lt;p&gt;For the comparison with gcc 4.9.3 and clang 3.7, you can have a look at
&lt;a class="reference external" href="http://baptiste-wicht.com/posts/2016/11/zapcc-a-faster-cpp-compiler.html"&gt;this article&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you want more information about zapcc, you can go to the
&lt;a class="reference external" href="https://www.zapcc.com/"&gt;official website of zapcc&lt;/a&gt;&lt;/p&gt;
&lt;/section&gt;</description><category>C++</category><category>clang</category><category>Compilers</category><category>etl</category><category>gcc</category><category>meta</category><category>projects</category><guid>https://baptiste-wicht.com/posts/2016/12/zapcc-cpp-compilation-speed-against-gcc-54-and-clang-39.html</guid><pubDate>Mon, 05 Dec 2016 17:46:09 GMT</pubDate></item><item><title>zapcc - a faster C++ compiler</title><link>https://baptiste-wicht.com/posts/2016/11/zapcc-a-faster-cpp-compiler.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;p&gt;Update: For a comparison against more modern compiler versions, you can read: &lt;a class="reference external" href="http://baptiste-wicht.com/posts/2016/12/zapcc-cpp-compilation-speed-against-gcc-54-and-clang-39.html"&gt;zapcc C++ compilation speed against gcc 5.4 and clang 3.9&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I just joined the private beta program of zapcc. Zapcc is a c++ compiler, based
on Clang which aims at being much faster than other C++ compilers. How they are
doing this is using a caching server that saves some of the compiler structures,
which should speed up compilation a lot. The private beta is free, but once the
compiler is ready, it will be a commercial compiler.&lt;/p&gt;
&lt;p&gt;Every C++ developer knows that compilation time can quickly be an issue when
programs are getting very big and especially when working with template-heavy
code.&lt;/p&gt;
&lt;p&gt;To benchmark this new compiler, I use my Expression Template Library
(&lt;a class="reference external" href="https://github.com/wichtounet/etl/"&gt;ETL&lt;/a&gt;). This is a purely header-only
library with lots of templates. There are lots of test cases which is what I'm
going to compile. I'm going to compare against Clang-3.7 and gcc-4.9.3.&lt;/p&gt;
&lt;p&gt;I have configured zapcc to let is use 2Go RAM per caching server, which is the
maximum allowed. Moreover, I killed the servers before each tests.&lt;/p&gt;
&lt;section id="debug-build"&gt;
&lt;h2&gt;Debug build&lt;/h2&gt;
&lt;p&gt;Let's start with a debug build. In that configuration, there is no optimization
going on and several of the features of the library (GPU, BLAS, ...) are
disabled. This is the fastest way to compile ETL. I gathered this result on
a 4 core, 8 threads, Intel processor, with an SSD.&lt;/p&gt;
&lt;p&gt;The following table presents the results with different number of threads and
the difference of zapcc compared to the other compilers:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;&lt;th class="head"&gt;&lt;p&gt;Compiler&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;-j1&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;-j2&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;-j4&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;-j6&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;-j8&lt;/p&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;g++-4.9.3&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;350s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;185s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;104s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;94s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;91s&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;clang++-3.7&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;513s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;271s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;153s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;145s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;138s&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;zapcc++&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;158s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;87s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;47s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;44s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;42s&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;Speedup VS Clang&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;3.24&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;3.103&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;3.25&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;3.29&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;3.28&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;Speedup VS GCC&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;2.21&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;2.12&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;2.21&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;2.13&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;2.16&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The result is pretty clear! zapcc is around &lt;strong&gt;three times faster than Clang&lt;/strong&gt; and around
&lt;strong&gt;two times faster than GCC&lt;/strong&gt;. This is pretty impressive!&lt;/p&gt;
&lt;p&gt;For those that think than Clang is always faster than GCC, keep in mind that
this is not the case for template-heavy code such as this library. In all my
tests, Clang has always been slower and much memory hungrier than GCC on
template-heavy C++ code. And sometimes the difference is very significant.&lt;/p&gt;
&lt;p&gt;Interestingly, we can also see that going past the physical cores is not really
interesting on this computer. On some computer, the speedups are interesting,
but not on this one. Always benchmark!&lt;/p&gt;
&lt;/section&gt;
&lt;section id="release-build"&gt;
&lt;h2&gt;Release build&lt;/h2&gt;
&lt;p&gt;We have seen the results on a debug build, let's now compare on something a bit
more timely, a release build with all options of ETL enabled (GPU, BLAS, ...),
which should make it significantly longer to compile.&lt;/p&gt;
&lt;p&gt;Again, the table:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;&lt;th class="head"&gt;&lt;p&gt;Compiler&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;-j1&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;-j2&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;-j4&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;-j6&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;-j8&lt;/p&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;g++-4.9.3&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;628s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;336s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;197s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;189s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;184s&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;clang++-3.7&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;663s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;388s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;215s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;212s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;205s&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;zapcc++&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;515s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;281s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;173s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;168s&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;158s&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;Speedup VS Clang&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.28&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.38&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.24&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.26&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.29&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;Speedup VS GCC&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.21&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.30&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.13&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.12&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;1.16&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;This time, we can see that the difference is much lower. Zapcc is &lt;strong&gt;between 1.2
and 1.4 times faster than Clang&lt;/strong&gt; and &lt;strong&gt;between 1.1 and 1.3 times faster than
GCC&lt;/strong&gt;. This shows that most of the speedups from zapcc are in the front end of
the compiler. This is not a lot but still significant over long builds,
especially if you have few threads where the absolute difference would be
higher.&lt;/p&gt;
&lt;p&gt;We can also observe that Clang is now almost on par with GCC which shows that
optimization is faster in Clang while front and backend is faster in gcc.&lt;/p&gt;
&lt;p&gt;You also have to keep in mind that zapcc memory usage is higher than Clang
because of all the caching. Moreover, the server are still up in between
compilations, so this memory usage stays between builds, which may not be what
you want.&lt;/p&gt;
&lt;p&gt;As for runtime, I have not seen any significant difference in performance
between the clang version and the zapcc. According to the official benchmarks
and documentation, there should not be any difference in that between zapcc and
the version of clang on which zapcc is based.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="incremental-build"&gt;
&lt;h2&gt;Incremental build&lt;/h2&gt;
&lt;p&gt;Normally, zapcc should shine at incremental building, but I was unable to show
any speedup when changing a single without killing the zapcc servers. Maybe
I did something wrong in my usage of zapcc.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="conclusion"&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;In conclusion, we can see that zapcc is always faster than both GCC and Clang,
on my template-heavy library. Moreover, on debug builds, it is much faster than
any of the two compilers, being more than 2 times faster than GCC and more than
3 times faster than clang. This is really great. Moreover, I have not seen any
issue with the tool so far, it can seamlessly replace Clang without problem.&lt;/p&gt;
&lt;p&gt;It's a bit weird that you cannot allocate more than 2Go to the zapcc servers.&lt;/p&gt;
&lt;p&gt;For a program, that's really impressive. I hope that they are continuing the
good work and especially that this motivates other compilers to improve the
speed of compilation (especially of templates).&lt;/p&gt;
&lt;p&gt;If you want more information, you can go to the
&lt;a class="reference external" href="https://www.zapcc.com/"&gt;official website of zapcc&lt;/a&gt;&lt;/p&gt;
&lt;/section&gt;</description><category>C++</category><category>clang</category><category>Compilers</category><category>etl</category><category>gcc</category><category>projects</category><category>zapcc</category><guid>https://baptiste-wicht.com/posts/2016/11/zapcc-a-faster-cpp-compiler.html</guid><pubDate>Sat, 26 Nov 2016 12:17:50 GMT</pubDate></item><item><title>Blazing fast unit test compilation with doctest 1.1</title><link>https://baptiste-wicht.com/posts/2016/09/blazing-fast-unit-test-compilation-with-doctest-11.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;p&gt;You may remember &lt;a class="reference external" href="http://baptiste-wicht.com/posts/2016/06/reduce-compilation-time-by-another-16-with-catch.html"&gt;my quest for faster compilation times&lt;/a&gt;. I had made several changes to the Catch test framework macros in order to save some compilation at the expense of my test code looking a bit less nice:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code cpp"&gt;&lt;a id="rest_code_2cb655aa7b1545fb8d1b6ed76d6b2256-1" name="rest_code_2cb655aa7b1545fb8d1b6ed76d6b2256-1" href="https://baptiste-wicht.com/posts/2016/09/blazing-fast-unit-test-compilation-with-doctest-11.html#rest_code_2cb655aa7b1545fb8d1b6ed76d6b2256-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;REQUIRE&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="c1"&gt;//Before&lt;/span&gt;
&lt;a id="rest_code_2cb655aa7b1545fb8d1b6ed76d6b2256-2" name="rest_code_2cb655aa7b1545fb8d1b6ed76d6b2256-2" href="https://baptiste-wicht.com/posts/2016/09/blazing-fast-unit-test-compilation-with-doctest-11.html#rest_code_2cb655aa7b1545fb8d1b6ed76d6b2256-2"&gt;&lt;/a&gt;&lt;span class="n"&gt;REQUIRE_EQUALS&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="c1"&gt;//After&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The first line is a little bit better, but using several optimizations, I was
able to dramatically change the compilation time of the test cases of ETL. In
the end, I don't think that the difference between the two lines justifies the
high overhead in compilation times.&lt;/p&gt;
&lt;section id="doctest"&gt;
&lt;h2&gt;doctest&lt;/h2&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/onqtam/doctest"&gt;doctest&lt;/a&gt; is a framework quite similar to
Catch but that claims to be much lighter. I tested doctest 1.0 early on, but at
this point it was actually slower than Catch and especially slower than my
versions of the macro.&lt;/p&gt;
&lt;p&gt;Today, doctest 1.1 was released with promises of being even lighter than before
and providing several new ways of speeding up compilation. If you want the
results directly, you can take a look at the next section.&lt;/p&gt;
&lt;p&gt;First of all, this new version improved the basic macros to make expression
decomposition faster. When you use the standard REQUIRE macro, the expression is
composed by using several template techniques and operator overloading. This is
really slow to compile. By removing the need for this decomposition, the fast
Catch macros are much faster to compile.&lt;/p&gt;
&lt;p&gt;Moreover, doctest 1.1 also introduces CHECK_EQ that does not any expression
decomposition. This is close to what I did in my macros expect that it is
directly integrated into the framework and preserves all its features. It is
also possible to bypass the expression checking code by using FAST_CHECK_EQ
macro. In that case, the exceptions are not captured. Finally, a new
configuration option is introduced (DOCTEST_CONFIG_SUPER_FAST_ASSERTS) that
removes some features related to automatic debugger breaks. Since I don't use
the debugger features and I don't need to capture exception everywhere (it's
sufficient for me that the test fails completely if an exception is thrown), I'm
more than eager to use these new features.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="results"&gt;
&lt;h2&gt;Results&lt;/h2&gt;
&lt;p&gt;For evaluation, I have compiled the complete test suite of ETL, with 1 thread,
using gcc 4.9.3 with various different options, starting from Catch to doctest
1.1 with all compilation time features. Here are the results, in seconds:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;&lt;th class="head"&gt;&lt;p&gt;Version&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;Time&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;VS Catch&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;VS Fast Catch&lt;/p&gt;&lt;/th&gt;
&lt;th class="head"&gt;&lt;p&gt;VS doctest 1.0&lt;/p&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;Catch&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;724.22&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;Fast Catch&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;464.52&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;-36%&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;doctest 1.0&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;871.54&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;+20%&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;+87%&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;doctest 1.1&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;614.67&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;-16%&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;+32%&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;-30%&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;REQUIRE_EQ&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;493.97&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;-32%&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;+6%&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;-43%&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;FAST_REQUIRE_EQ&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;439.09&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;-39%&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;-6%&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;-50%&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;p&gt;SUPER_FAST_ASSERTS&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;411.11&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;-43%&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;-12%&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;-53%&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;As you can see, doctest 1.1 is much faster to compile than doctest 1.0! This is
really great news. Moreover, it is already 16% faster than Catch. When all the
features are used, doctest is 12% faster than my stripped down versions of Catch
macros (and 43% faster than Catch standard macros). This is really cool! It
means that I don't have to do any change in the code (no need to strip macros
myself) and I can gain a lot of compilation time compared to the bare Catch
framework.&lt;/p&gt;
&lt;p&gt;I really think the author of doctest did a great job with the new version.
Although this was not of as much interest for me, there are also a lot of
other changes in the new version. You can consult the
&lt;a class="reference external" href="https://github.com/onqtam/doctest/blob/master/CHANGELOG.md"&gt;changelog&lt;/a&gt; if you want more information.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="conclusion"&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Overall, doctest 1.1 is much faster to compile than doctest 1.0. Moreover, it
offers very fast macros for test assertions that are much faster to compile
than Catch versions and even faster than the versions I created myself to reduce
compilation time. I really thing this is a great advance for doctest. When
compiling with all the optimizations, doctest 1.1 saves me 50 seconds in
compilation time compared to the fast version of Catch macro and more than
5 minutes compared to the standard version of Catch macros.&lt;/p&gt;
&lt;p&gt;I'll probably start using doctest on my development machine. For now, I'll keep
Catch as well since I need it to generate the unit test reports in XML format
for Sonarqube. Once this feature appears in doctest, I'll probably drop Catch
from ETL and DLL&lt;/p&gt;
&lt;p&gt;If you need blazing fast compilation times for your unit tests, doctest 1.1 is
probably the way to go.&lt;/p&gt;
&lt;/section&gt;</description><category>C++</category><category>Catch</category><category>Compilers</category><category>doctest</category><category>etl</category><category>gcc</category><category>Performances</category><category>Tests</category><category>time</category><guid>https://baptiste-wicht.com/posts/2016/09/blazing-fast-unit-test-compilation-with-doctest-11.html</guid><pubDate>Wed, 21 Sep 2016 19:45:13 GMT</pubDate></item><item><title>Expression Templates Library (ETL) 1.0</title><link>https://baptiste-wicht.com/posts/2016/09/expression-templates-library-etl-10.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;p&gt;I've just released the first official version of my Expression Templates Library
(ETL for short): The version 1.0.&lt;/p&gt;
&lt;p&gt;Until now, I was using a simple rolling release model, but I think it's now time
to switch to some basic versioning. The project is now at a stable state.&lt;/p&gt;
&lt;p&gt;ETL 1.0 has the following main features:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;Smart Expression Templates&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Matrix and vector (runtime-sized and compile-time-sized)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Simple element-wise operations&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Reductions (sum, mean, max, ...)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Unary operations (sigmoid, log, exp, abs, ...)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Matrix multiplication&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Convolution (1D and 2D and higher variations)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Max Pooling&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Fast Fourrier Transform&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Use of SSE/AVX to speed up operations&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Use of BLAS/MKL/CUBLAS/CUFFT/CUDNN libraries to speed up operations&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Symmetric matrix adapter (experimental)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Sparse matrix (experimental)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;section id="examples"&gt;
&lt;h2&gt;Examples&lt;/h2&gt;
&lt;p&gt;Here is an example of expressions in ETL:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code cpp"&gt;&lt;a id="rest_code_1fee889f51f9475e97341f2018796999-1" name="rest_code_1fee889f51f9475e97341f2018796999-1" href="https://baptiste-wicht.com/posts/2016/09/expression-templates-library-etl-10.html#rest_code_1fee889f51f9475e97341f2018796999-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;etl&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;fast_matrix&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="mf"&gt;1.1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;2.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;5.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;1.1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;2.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;5.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="p"&gt;};&lt;/span&gt;
&lt;a id="rest_code_1fee889f51f9475e97341f2018796999-2" name="rest_code_1fee889f51f9475e97341f2018796999-2" href="https://baptiste-wicht.com/posts/2016/09/expression-templates-library-etl-10.html#rest_code_1fee889f51f9475e97341f2018796999-2"&gt;&lt;/a&gt;&lt;span class="n"&gt;etl&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;fast_matrix&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="mf"&gt;2.5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;-3.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;4.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;2.5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;-3.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;4.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="p"&gt;};&lt;/span&gt;
&lt;a id="rest_code_1fee889f51f9475e97341f2018796999-3" name="rest_code_1fee889f51f9475e97341f2018796999-3" href="https://baptiste-wicht.com/posts/2016/09/expression-templates-library-etl-10.html#rest_code_1fee889f51f9475e97341f2018796999-3"&gt;&lt;/a&gt;&lt;span class="n"&gt;etl&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;fast_matrix&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="mf"&gt;2.2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;3.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;3.5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;2.2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;3.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;3.5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="p"&gt;};&lt;/span&gt;
&lt;a id="rest_code_1fee889f51f9475e97341f2018796999-4" name="rest_code_1fee889f51f9475e97341f2018796999-4" href="https://baptiste-wicht.com/posts/2016/09/expression-templates-library-etl-10.html#rest_code_1fee889f51f9475e97341f2018796999-4"&gt;&lt;/a&gt;
&lt;a id="rest_code_1fee889f51f9475e97341f2018796999-5" name="rest_code_1fee889f51f9475e97341f2018796999-5" href="https://baptiste-wicht.com/posts/2016/09/expression-templates-library-etl-10.html#rest_code_1fee889f51f9475e97341f2018796999-5"&gt;&lt;/a&gt;&lt;span class="n"&gt;etl&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;fast_matrix&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;2.5&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;log&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;abs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;1.5&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;scale&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;sign&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;2.111&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;log&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Or another I'm using in my neural networks library:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code cpp"&gt;&lt;a id="rest_code_0b32f39c77e7404fb30f13137d098051-1" name="rest_code_0b32f39c77e7404fb30f13137d098051-1" href="https://baptiste-wicht.com/posts/2016/09/expression-templates-library-etl-10.html#rest_code_0b32f39c77e7404fb30f13137d098051-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;h&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;etl&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;sigmoid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In that case, the vector-matrix multiplication will be executed using a BLAS
kernel (if ETL is configured correclty) and the assignment, the sigmoid and the
addition will be automatically vectorized to use either AVX or SSE depending
on the machine.&lt;/p&gt;
&lt;p&gt;Or with a convolutional layer and a ReLU activation function:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code cpp"&gt;&lt;a id="rest_code_667a8655607d41219240007f23058ddc-1" name="rest_code_667a8655607d41219240007f23058ddc-1" href="https://baptiste-wicht.com/posts/2016/09/expression-templates-library-etl-10.html#rest_code_667a8655607d41219240007f23058ddc-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;etl&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;K&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;NH1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;NH2&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;h_a&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;etl&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;conv_4d_valid_flipped&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;etl&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;NC&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;NV1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;NV2&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;v_a&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a id="rest_code_667a8655607d41219240007f23058ddc-2" name="rest_code_667a8655607d41219240007f23058ddc-2" href="https://baptiste-wicht.com/posts/2016/09/expression-templates-library-etl-10.html#rest_code_667a8655607d41219240007f23058ddc-2"&gt;&lt;/a&gt;&lt;span class="n"&gt;h&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;b_rep&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;h_a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;0.0&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This will automatically be computed either with NVIDIA CUDNN (if available) or
with optimized SSE/AVX kernels.&lt;/p&gt;
&lt;p&gt;For more information, you can take a look at the &lt;a class="reference external" href="https://github.com/wichtounet/etl/wiki"&gt;Reference&lt;/a&gt; on the wiki.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="next-version"&gt;
&lt;h2&gt;Next version&lt;/h2&gt;
&lt;p&gt;For the next version, I'll focus on several things:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;Improve matrix-matrix multiplication kernels when BLAS is not available. There
is a lot of room for improvement here&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Complete support for symmetric matrices (currently experimental)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Maybe some new adapters such as Hermitian matrices&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;GPU improvements for some operations that can be done entirely on GPU&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;New convolution performanceimprovements&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Perhaps more complete parallel support for some implementations&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Drop some compiler support to use full C++14 support&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/section&gt;
&lt;section id="download-etl"&gt;
&lt;h2&gt;Download ETL&lt;/h2&gt;
&lt;p&gt;You can download ETL &lt;a class="reference external" href="https://github.com/wichtounet/etl"&gt;on Github&lt;/a&gt;. If you
only interested in the 1.0 version, you can look at the
&lt;a class="reference external" href="https://github.com/wichtounet/etl/releases"&gt;Releases pages&lt;/a&gt; or clone the tag
1.0. There are several branches:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;master&lt;/em&gt; Is the eternal development branch, may not always be stable&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;stable&lt;/em&gt; Is a branch always pointing to the last tag, no development here&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For the future release, there always will tags pointing to the corresponding
commits. I'm not following the git flow way, I'd rather try to have a more
linear history with one eternal development branch, rather than an useless
develop branch or a load of other branches for releases.&lt;/p&gt;
&lt;p&gt;Don't hesitate to comment this post if you have any comment on this library or
any question. You can also open an Issue on Github if you have a problem using
this library or propose a Pull Request if you have any contribution you'd like
to make to the library.&lt;/p&gt;
&lt;p&gt;Hope this may be useful to some of you :)&lt;/p&gt;
&lt;/section&gt;</description><category>C++</category><category>C++14</category><category>Compilers</category><category>etl</category><category>projects</category><guid>https://baptiste-wicht.com/posts/2016/09/expression-templates-library-etl-10.html</guid><pubDate>Fri, 02 Sep 2016 14:12:38 GMT</pubDate></item><item><title>Improve DLL and ETL Compile Time further</title><link>https://baptiste-wicht.com/posts/2016/01/improve-dll-and-etl-compile-time-further.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;p&gt;For a while, the compilation time of my matrix/vector computation library (ETL), based on Expression Templates has become more and more problematic. I've already worked on this problem &lt;a class="reference external" href="http://baptiste-wicht.com/posts/2015/06/how-i-improved-a-bit-compile-time-of-etl.html"&gt;here&lt;/a&gt; and &lt;a class="reference external" href="http://baptiste-wicht.com/posts/2015/06/improve-etl-compile-time-with-precompiled-headers.html"&gt;there&lt;/a&gt;, using some general techniques (pragmas, precompiled headers, header removals and so on). On this post, I'll talk about two major improvements I have been able to do directly in the code.&lt;/p&gt;
&lt;section id="use-of-static-if"&gt;
&lt;h2&gt;Use of static_if&lt;/h2&gt;
&lt;p&gt;Remember &lt;a class="reference external" href="http://baptiste-wicht.com/posts/2015/07/simulate-static_if-with-c11c14.html"&gt;static_if&lt;/a&gt; ? I was able to use it to really reduce the compile time of DLL.&lt;/p&gt;
&lt;p&gt;I wrote a script to time each test case of the DLL project to find the test cases that took the longest to compile. Once I found the best candidate, I isolated the functions that took the longest to compile. It was quite tedious and I did it by hand, primarily by commenting parts of the code and going deeper and deeper in the code. I was quite suprised to find that a single function call (template function of course ;) ) was responsible for 60% of the compilation time of my candidate test case. The function was instantiating a whole bunch of expression templates (to compute the free energy of several models). The function itself was not really optimizable, but what was really interesting is that this function was only used in some very rare cases and that these cases were known at compile-time :) This was a perfect case to use a static_if. And once the call was inside the static_if, the test case was indeed about 60% faster. &lt;strong&gt;This reduced the overall compilation time of DLL by about 30%&lt;/strong&gt;!&lt;/p&gt;
&lt;p&gt;This could also of course also have been achieved by using two functions, one with the call, one empty and selected by SFINAE (Substitution Failure Is Not An Error). I prefer the statif_if version since this really shows the intent and hides SFINAE behind nicer syntax.&lt;/p&gt;
&lt;p&gt;I was also able to use static_if at other places in the DLL code to avoid instantiating some templates, but the improvements were much less dramatic (about 1% of the total compilation time). I was very lucky to find a single function that accounted for so much compile time. After some more tests, I concluded that much of the compilation time of DLL was spent compiling the Expression Templates from my ETL library so I decided to delve into ETL code directly.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="removal-of-std-async"&gt;
&lt;h2&gt;Removal of std::async&lt;/h2&gt;
&lt;p&gt;The second improvement was very surprising. I was working on improving the compilation of ETL and found out that the sum and average reductions of matrices were dramatically slow, about an order of magnitude slower than standard operations on matrices. In parallel (but the two facts are linked), I also found out another weird fact when splitting a file into 10 parts (the file was comprised of 10 test cases). Compiling the 10 parts separarely (and sequentially, not multiple threads) was about 40% faster than compiling the complete file. There was no swapping so it was not a memory issue. This is not expected. Generally, it is faster to compile a big file than to compile its parts separately. The advantage of smaller files is that you can compile them in parallel and that incremental builds are faster (only compile a small part).&lt;/p&gt;
&lt;p&gt;By elimination, I found out that most of the time was spent inside the function that was dispatching in parallel the work for accumulating the sum of a matrix. Here is the function:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code cpp"&gt;&lt;a id="rest_code_81ad6613abd64e46934bd6d539691bae-1" name="rest_code_81ad6613abd64e46934bd6d539691bae-1" href="https://baptiste-wicht.com/posts/2016/01/improve-dll-and-etl-compile-time-further.html#rest_code_81ad6613abd64e46934bd6d539691bae-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nc"&gt;T&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nc"&gt;Functor&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nc"&gt;AccFunctor&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a id="rest_code_81ad6613abd64e46934bd6d539691bae-2" name="rest_code_81ad6613abd64e46934bd6d539691bae-2" href="https://baptiste-wicht.com/posts/2016/01/improve-dll-and-etl-compile-time-further.html#rest_code_81ad6613abd64e46934bd6d539691bae-2"&gt;&lt;/a&gt;&lt;span class="kr"&gt;inline&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;void&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dispatch_1d_acc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;bool&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Functor&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;functor&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;AccFunctor&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;acc_functor&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;first&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;last&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
&lt;a id="rest_code_81ad6613abd64e46934bd6d539691bae-3" name="rest_code_81ad6613abd64e46934bd6d539691bae-3" href="https://baptiste-wicht.com/posts/2016/01/improve-dll-and-etl-compile-time-further.html#rest_code_81ad6613abd64e46934bd6d539691bae-3"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
&lt;a id="rest_code_81ad6613abd64e46934bd6d539691bae-4" name="rest_code_81ad6613abd64e46934bd6d539691bae-4" href="https://baptiste-wicht.com/posts/2016/01/improve-dll-and-etl-compile-time-further.html#rest_code_81ad6613abd64e46934bd6d539691bae-4"&gt;&lt;/a&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;vector&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;future&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;futures&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;threads&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a id="rest_code_81ad6613abd64e46934bd6d539691bae-5" name="rest_code_81ad6613abd64e46934bd6d539691bae-5" href="https://baptiste-wicht.com/posts/2016/01/improve-dll-and-etl-compile-time-further.html#rest_code_81ad6613abd64e46934bd6d539691bae-5"&gt;&lt;/a&gt;
&lt;a id="rest_code_81ad6613abd64e46934bd6d539691bae-6" name="rest_code_81ad6613abd64e46934bd6d539691bae-6" href="https://baptiste-wicht.com/posts/2016/01/improve-dll-and-etl-compile-time-further.html#rest_code_81ad6613abd64e46934bd6d539691bae-6"&gt;&lt;/a&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="k"&gt;auto&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;last&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;first&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a id="rest_code_81ad6613abd64e46934bd6d539691bae-7" name="rest_code_81ad6613abd64e46934bd6d539691bae-7" href="https://baptiste-wicht.com/posts/2016/01/improve-dll-and-etl-compile-time-further.html#rest_code_81ad6613abd64e46934bd6d539691bae-7"&gt;&lt;/a&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="k"&gt;auto&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;batch&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;threads&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a id="rest_code_81ad6613abd64e46934bd6d539691bae-8" name="rest_code_81ad6613abd64e46934bd6d539691bae-8" href="https://baptiste-wicht.com/posts/2016/01/improve-dll-and-etl-compile-time-further.html#rest_code_81ad6613abd64e46934bd6d539691bae-8"&gt;&lt;/a&gt;
&lt;a id="rest_code_81ad6613abd64e46934bd6d539691bae-9" name="rest_code_81ad6613abd64e46934bd6d539691bae-9" href="https://baptiste-wicht.com/posts/2016/01/improve-dll-and-etl-compile-time-further.html#rest_code_81ad6613abd64e46934bd6d539691bae-9"&gt;&lt;/a&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;threads&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
&lt;a id="rest_code_81ad6613abd64e46934bd6d539691bae-10" name="rest_code_81ad6613abd64e46934bd6d539691bae-10" href="https://baptiste-wicht.com/posts/2016/01/improve-dll-and-etl-compile-time-further.html#rest_code_81ad6613abd64e46934bd6d539691bae-10"&gt;&lt;/a&gt;&lt;span class="w"&gt;            &lt;/span&gt;&lt;span class="n"&gt;futures&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;async&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;launch&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;async&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;functor&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;first&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;batch&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;first&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;batch&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a id="rest_code_81ad6613abd64e46934bd6d539691bae-11" name="rest_code_81ad6613abd64e46934bd6d539691bae-11" href="https://baptiste-wicht.com/posts/2016/01/improve-dll-and-etl-compile-time-further.html#rest_code_81ad6613abd64e46934bd6d539691bae-11"&gt;&lt;/a&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;a id="rest_code_81ad6613abd64e46934bd6d539691bae-12" name="rest_code_81ad6613abd64e46934bd6d539691bae-12" href="https://baptiste-wicht.com/posts/2016/01/improve-dll-and-etl-compile-time-further.html#rest_code_81ad6613abd64e46934bd6d539691bae-12"&gt;&lt;/a&gt;
&lt;a id="rest_code_81ad6613abd64e46934bd6d539691bae-13" name="rest_code_81ad6613abd64e46934bd6d539691bae-13" href="https://baptiste-wicht.com/posts/2016/01/improve-dll-and-etl-compile-time-further.html#rest_code_81ad6613abd64e46934bd6d539691bae-13"&gt;&lt;/a&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;acc_functor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;functor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;first&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;threads&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;batch&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;last&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;
&lt;a id="rest_code_81ad6613abd64e46934bd6d539691bae-14" name="rest_code_81ad6613abd64e46934bd6d539691bae-14" href="https://baptiste-wicht.com/posts/2016/01/improve-dll-and-etl-compile-time-further.html#rest_code_81ad6613abd64e46934bd6d539691bae-14"&gt;&lt;/a&gt;
&lt;a id="rest_code_81ad6613abd64e46934bd6d539691bae-15" name="rest_code_81ad6613abd64e46934bd6d539691bae-15" href="https://baptiste-wicht.com/posts/2016/01/improve-dll-and-etl-compile-time-further.html#rest_code_81ad6613abd64e46934bd6d539691bae-15"&gt;&lt;/a&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;auto&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;fut&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;futures&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
&lt;a id="rest_code_81ad6613abd64e46934bd6d539691bae-16" name="rest_code_81ad6613abd64e46934bd6d539691bae-16" href="https://baptiste-wicht.com/posts/2016/01/improve-dll-and-etl-compile-time-further.html#rest_code_81ad6613abd64e46934bd6d539691bae-16"&gt;&lt;/a&gt;&lt;span class="w"&gt;            &lt;/span&gt;&lt;span class="n"&gt;acc_functor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fut&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;());&lt;/span&gt;
&lt;a id="rest_code_81ad6613abd64e46934bd6d539691bae-17" name="rest_code_81ad6613abd64e46934bd6d539691bae-17" href="https://baptiste-wicht.com/posts/2016/01/improve-dll-and-etl-compile-time-further.html#rest_code_81ad6613abd64e46934bd6d539691bae-17"&gt;&lt;/a&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;a id="rest_code_81ad6613abd64e46934bd6d539691bae-18" name="rest_code_81ad6613abd64e46934bd6d539691bae-18" href="https://baptiste-wicht.com/posts/2016/01/improve-dll-and-etl-compile-time-further.html#rest_code_81ad6613abd64e46934bd6d539691bae-18"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;a id="rest_code_81ad6613abd64e46934bd6d539691bae-19" name="rest_code_81ad6613abd64e46934bd6d539691bae-19" href="https://baptiste-wicht.com/posts/2016/01/improve-dll-and-etl-compile-time-further.html#rest_code_81ad6613abd64e46934bd6d539691bae-19"&gt;&lt;/a&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;acc_functor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;functor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;first&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;last&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;
&lt;a id="rest_code_81ad6613abd64e46934bd6d539691bae-20" name="rest_code_81ad6613abd64e46934bd6d539691bae-20" href="https://baptiste-wicht.com/posts/2016/01/improve-dll-and-etl-compile-time-further.html#rest_code_81ad6613abd64e46934bd6d539691bae-20"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;a id="rest_code_81ad6613abd64e46934bd6d539691bae-21" name="rest_code_81ad6613abd64e46934bd6d539691bae-21" href="https://baptiste-wicht.com/posts/2016/01/improve-dll-and-etl-compile-time-further.html#rest_code_81ad6613abd64e46934bd6d539691bae-21"&gt;&lt;/a&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;There isn't anything really fancy about this function. This takes one functor that will be done in parallel and one function for accumulation.  It dispatches all the work in batch and then accumulates the results. I tried several things to optimize the compilation time of this function, but nothing worked. The line that was consuming all the time was the std::async line. This function was using std::async because the thread pool that I'm generally using does not support returning values from parallel functors. I decided to use a workaround and use my thread pool and I came out with this version:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code cpp"&gt;&lt;a id="rest_code_b37008f623424063ab1d09c30e4b6e7e-1" name="rest_code_b37008f623424063ab1d09c30e4b6e7e-1" href="https://baptiste-wicht.com/posts/2016/01/improve-dll-and-etl-compile-time-further.html#rest_code_b37008f623424063ab1d09c30e4b6e7e-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nc"&gt;T&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nc"&gt;Functor&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nc"&gt;AccFunctor&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a id="rest_code_b37008f623424063ab1d09c30e4b6e7e-2" name="rest_code_b37008f623424063ab1d09c30e4b6e7e-2" href="https://baptiste-wicht.com/posts/2016/01/improve-dll-and-etl-compile-time-further.html#rest_code_b37008f623424063ab1d09c30e4b6e7e-2"&gt;&lt;/a&gt;&lt;span class="kr"&gt;inline&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;void&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dispatch_1d_acc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;bool&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Functor&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;functor&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;AccFunctor&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;acc_functor&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;first&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;last&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
&lt;a id="rest_code_b37008f623424063ab1d09c30e4b6e7e-3" name="rest_code_b37008f623424063ab1d09c30e4b6e7e-3" href="https://baptiste-wicht.com/posts/2016/01/improve-dll-and-etl-compile-time-further.html#rest_code_b37008f623424063ab1d09c30e4b6e7e-3"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
&lt;a id="rest_code_b37008f623424063ab1d09c30e4b6e7e-4" name="rest_code_b37008f623424063ab1d09c30e4b6e7e-4" href="https://baptiste-wicht.com/posts/2016/01/improve-dll-and-etl-compile-time-further.html#rest_code_b37008f623424063ab1d09c30e4b6e7e-4"&gt;&lt;/a&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;vector&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;futures&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;threads&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a id="rest_code_b37008f623424063ab1d09c30e4b6e7e-5" name="rest_code_b37008f623424063ab1d09c30e4b6e7e-5" href="https://baptiste-wicht.com/posts/2016/01/improve-dll-and-etl-compile-time-further.html#rest_code_b37008f623424063ab1d09c30e4b6e7e-5"&gt;&lt;/a&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;cpp&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;default_thread_pool&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;pool&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;threads&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a id="rest_code_b37008f623424063ab1d09c30e4b6e7e-6" name="rest_code_b37008f623424063ab1d09c30e4b6e7e-6" href="https://baptiste-wicht.com/posts/2016/01/improve-dll-and-etl-compile-time-further.html#rest_code_b37008f623424063ab1d09c30e4b6e7e-6"&gt;&lt;/a&gt;
&lt;a id="rest_code_b37008f623424063ab1d09c30e4b6e7e-7" name="rest_code_b37008f623424063ab1d09c30e4b6e7e-7" href="https://baptiste-wicht.com/posts/2016/01/improve-dll-and-etl-compile-time-further.html#rest_code_b37008f623424063ab1d09c30e4b6e7e-7"&gt;&lt;/a&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="k"&gt;auto&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;last&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;first&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a id="rest_code_b37008f623424063ab1d09c30e4b6e7e-8" name="rest_code_b37008f623424063ab1d09c30e4b6e7e-8" href="https://baptiste-wicht.com/posts/2016/01/improve-dll-and-etl-compile-time-further.html#rest_code_b37008f623424063ab1d09c30e4b6e7e-8"&gt;&lt;/a&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="k"&gt;auto&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;batch&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;threads&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a id="rest_code_b37008f623424063ab1d09c30e4b6e7e-9" name="rest_code_b37008f623424063ab1d09c30e4b6e7e-9" href="https://baptiste-wicht.com/posts/2016/01/improve-dll-and-etl-compile-time-further.html#rest_code_b37008f623424063ab1d09c30e4b6e7e-9"&gt;&lt;/a&gt;
&lt;a id="rest_code_b37008f623424063ab1d09c30e4b6e7e-10" name="rest_code_b37008f623424063ab1d09c30e4b6e7e-10" href="https://baptiste-wicht.com/posts/2016/01/improve-dll-and-etl-compile-time-further.html#rest_code_b37008f623424063ab1d09c30e4b6e7e-10"&gt;&lt;/a&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="k"&gt;auto&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;sub_functor&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;futures&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;functor&lt;/span&gt;&lt;span class="p"&gt;](&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;first&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;last&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
&lt;a id="rest_code_b37008f623424063ab1d09c30e4b6e7e-11" name="rest_code_b37008f623424063ab1d09c30e4b6e7e-11" href="https://baptiste-wicht.com/posts/2016/01/improve-dll-and-etl-compile-time-further.html#rest_code_b37008f623424063ab1d09c30e4b6e7e-11"&gt;&lt;/a&gt;&lt;span class="w"&gt;            &lt;/span&gt;&lt;span class="n"&gt;futures&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;functor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;first&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;last&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a id="rest_code_b37008f623424063ab1d09c30e4b6e7e-12" name="rest_code_b37008f623424063ab1d09c30e4b6e7e-12" href="https://baptiste-wicht.com/posts/2016/01/improve-dll-and-etl-compile-time-further.html#rest_code_b37008f623424063ab1d09c30e4b6e7e-12"&gt;&lt;/a&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="p"&gt;};&lt;/span&gt;
&lt;a id="rest_code_b37008f623424063ab1d09c30e4b6e7e-13" name="rest_code_b37008f623424063ab1d09c30e4b6e7e-13" href="https://baptiste-wicht.com/posts/2016/01/improve-dll-and-etl-compile-time-further.html#rest_code_b37008f623424063ab1d09c30e4b6e7e-13"&gt;&lt;/a&gt;
&lt;a id="rest_code_b37008f623424063ab1d09c30e4b6e7e-14" name="rest_code_b37008f623424063ab1d09c30e4b6e7e-14" href="https://baptiste-wicht.com/posts/2016/01/improve-dll-and-etl-compile-time-further.html#rest_code_b37008f623424063ab1d09c30e4b6e7e-14"&gt;&lt;/a&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;threads&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
&lt;a id="rest_code_b37008f623424063ab1d09c30e4b6e7e-15" name="rest_code_b37008f623424063ab1d09c30e4b6e7e-15" href="https://baptiste-wicht.com/posts/2016/01/improve-dll-and-etl-compile-time-further.html#rest_code_b37008f623424063ab1d09c30e4b6e7e-15"&gt;&lt;/a&gt;&lt;span class="w"&gt;            &lt;/span&gt;&lt;span class="n"&gt;pool&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;do_task&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sub_functor&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;first&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;batch&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;first&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;batch&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a id="rest_code_b37008f623424063ab1d09c30e4b6e7e-16" name="rest_code_b37008f623424063ab1d09c30e4b6e7e-16" href="https://baptiste-wicht.com/posts/2016/01/improve-dll-and-etl-compile-time-further.html#rest_code_b37008f623424063ab1d09c30e4b6e7e-16"&gt;&lt;/a&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;a id="rest_code_b37008f623424063ab1d09c30e4b6e7e-17" name="rest_code_b37008f623424063ab1d09c30e4b6e7e-17" href="https://baptiste-wicht.com/posts/2016/01/improve-dll-and-etl-compile-time-further.html#rest_code_b37008f623424063ab1d09c30e4b6e7e-17"&gt;&lt;/a&gt;
&lt;a id="rest_code_b37008f623424063ab1d09c30e4b6e7e-18" name="rest_code_b37008f623424063ab1d09c30e4b6e7e-18" href="https://baptiste-wicht.com/posts/2016/01/improve-dll-and-etl-compile-time-further.html#rest_code_b37008f623424063ab1d09c30e4b6e7e-18"&gt;&lt;/a&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;acc_functor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;functor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;first&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;threads&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;batch&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;last&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;
&lt;a id="rest_code_b37008f623424063ab1d09c30e4b6e7e-19" name="rest_code_b37008f623424063ab1d09c30e4b6e7e-19" href="https://baptiste-wicht.com/posts/2016/01/improve-dll-and-etl-compile-time-further.html#rest_code_b37008f623424063ab1d09c30e4b6e7e-19"&gt;&lt;/a&gt;
&lt;a id="rest_code_b37008f623424063ab1d09c30e4b6e7e-20" name="rest_code_b37008f623424063ab1d09c30e4b6e7e-20" href="https://baptiste-wicht.com/posts/2016/01/improve-dll-and-etl-compile-time-further.html#rest_code_b37008f623424063ab1d09c30e4b6e7e-20"&gt;&lt;/a&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;pool&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;wait&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;a id="rest_code_b37008f623424063ab1d09c30e4b6e7e-21" name="rest_code_b37008f623424063ab1d09c30e4b6e7e-21" href="https://baptiste-wicht.com/posts/2016/01/improve-dll-and-etl-compile-time-further.html#rest_code_b37008f623424063ab1d09c30e4b6e7e-21"&gt;&lt;/a&gt;
&lt;a id="rest_code_b37008f623424063ab1d09c30e4b6e7e-22" name="rest_code_b37008f623424063ab1d09c30e4b6e7e-22" href="https://baptiste-wicht.com/posts/2016/01/improve-dll-and-etl-compile-time-further.html#rest_code_b37008f623424063ab1d09c30e4b6e7e-22"&gt;&lt;/a&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;auto&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;fut&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;futures&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
&lt;a id="rest_code_b37008f623424063ab1d09c30e4b6e7e-23" name="rest_code_b37008f623424063ab1d09c30e4b6e7e-23" href="https://baptiste-wicht.com/posts/2016/01/improve-dll-and-etl-compile-time-further.html#rest_code_b37008f623424063ab1d09c30e4b6e7e-23"&gt;&lt;/a&gt;&lt;span class="w"&gt;            &lt;/span&gt;&lt;span class="n"&gt;acc_functor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fut&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a id="rest_code_b37008f623424063ab1d09c30e4b6e7e-24" name="rest_code_b37008f623424063ab1d09c30e4b6e7e-24" href="https://baptiste-wicht.com/posts/2016/01/improve-dll-and-etl-compile-time-further.html#rest_code_b37008f623424063ab1d09c30e4b6e7e-24"&gt;&lt;/a&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;a id="rest_code_b37008f623424063ab1d09c30e4b6e7e-25" name="rest_code_b37008f623424063ab1d09c30e4b6e7e-25" href="https://baptiste-wicht.com/posts/2016/01/improve-dll-and-etl-compile-time-further.html#rest_code_b37008f623424063ab1d09c30e4b6e7e-25"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;a id="rest_code_b37008f623424063ab1d09c30e4b6e7e-26" name="rest_code_b37008f623424063ab1d09c30e4b6e7e-26" href="https://baptiste-wicht.com/posts/2016/01/improve-dll-and-etl-compile-time-further.html#rest_code_b37008f623424063ab1d09c30e4b6e7e-26"&gt;&lt;/a&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;acc_functor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;functor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;first&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;last&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;
&lt;a id="rest_code_b37008f623424063ab1d09c30e4b6e7e-27" name="rest_code_b37008f623424063ab1d09c30e4b6e7e-27" href="https://baptiste-wicht.com/posts/2016/01/improve-dll-and-etl-compile-time-further.html#rest_code_b37008f623424063ab1d09c30e4b6e7e-27"&gt;&lt;/a&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;a id="rest_code_b37008f623424063ab1d09c30e4b6e7e-28" name="rest_code_b37008f623424063ab1d09c30e4b6e7e-28" href="https://baptiste-wicht.com/posts/2016/01/improve-dll-and-etl-compile-time-further.html#rest_code_b37008f623424063ab1d09c30e4b6e7e-28"&gt;&lt;/a&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;I simply preallocate space for all the threads and create a new functor calling the input functor and saving its result inside the vector. It is less nice, but it works well. And it compiles MUCH faster. This &lt;strong&gt;reduced the compilation time&lt;/strong&gt; of my biggest test case &lt;strong&gt;by a factor of 8&lt;/strong&gt; (from 344 seconds to 44 seconds). This is really crazy. It also fixed the problem where splitting the test case was faster than big file (it is now twice faster to compile the big files than compiling all the small files separately). &lt;strong&gt;This reduced the total compilation time of dll by about 400%&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;As of now, I still have no idea why this makes such a big difference. I have looked at the std::async code, but I haven't found a valid reason for this slowdown. If someone has any idea, I'd be very glad to discuss in the comments below.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="improving-the-template-instantiation-tree"&gt;
&lt;h2&gt;Improving the template instantiation tree&lt;/h2&gt;
&lt;p&gt;I recently discovered the templight tool that is a profiler for templates (pretty cool). After some time, I was able to build it and use it on ETL. For now, I haven't been able to reduce compile time a lot, but I have been able to reduce the template instantiation tree a lot seeing that some instantiations were completely useless and I optimized the code to remove them.&lt;/p&gt;
&lt;p&gt;I won't be go into much details here because I plan to write a post on this subject in the coming days.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="conclusion"&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;In conclusion, I would say that it is pretty hard to improve the compile time of complex C++ programs once you have gone through all the standard methods. However, I was very happy to found that &lt;strong&gt;two optimizations in the source code reduced the overall compilation of DLL by almost 500%&lt;/strong&gt;. I will continue working on this, but for now, the compilation time is much more reasonable.&lt;/p&gt;
&lt;p&gt;I hope the two main facts in this article were interesting. If you have similar experience, comments or ideas for further improvements, I'd be glad to discuss them with you in the comments :)&lt;/p&gt;
&lt;/section&gt;</description><category>C++</category><category>Compilers</category><category>dll</category><category>etl</category><category>gcc</category><category>Performances</category><guid>https://baptiste-wicht.com/posts/2016/01/improve-dll-and-etl-compile-time-further.html</guid><pubDate>Fri, 29 Jan 2016 16:02:34 GMT</pubDate></item><item><title>Improve ETL compile-time with Precompiled Headers</title><link>https://baptiste-wicht.com/posts/2015/06/improve-etl-compile-time-with-precompiled-headers.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;p&gt;Very recently, I started trying to improve the compile-time of the ETL test suite. While not critical, it is always better to have tests that compile as fast as possible. In a &lt;a class="reference external" href="http://baptiste-wicht.com/posts/2015/06/how-i-improved-a-bit-compile-time-of-etl.html"&gt;previous post&lt;/a&gt;, I was able to improve the time a bit by improve the makefile, using pragra once and avoiding &lt;cite&gt;&amp;lt;iostream&amp;gt;&lt;/cite&gt; headers. With these techniques, I reduced the compile-time from 87.5 to 84.1, which is not bad, but not as good as I would have expected.&lt;/p&gt;
&lt;p&gt;In the previous, I had not tried to use Precompiled Headers (PCH) to improve the compile time, so I thought it would be a good time to do it.&lt;/p&gt;
&lt;section id="precompiled-headers"&gt;
&lt;h2&gt;Precompiled Headers&lt;/h2&gt;
&lt;p&gt;Precompiled Headers are an option of the compiler, where one header gets compiled. Normally, you only compile source files into object files, but you can also compile headers, although it is not the same thing. When a compiler compiles a header, it can do a lot of preprocessing (macros, includes, AST, symbols) and then store all the results into a precompiled header file. Once you compile the source files, the compiler will try to use the precompiled header file instead of the real header file. Of course, this can breaks the C++ standard since with that a header can not have different behaviour based on macros for instance. For these reasons (and probably implementation reasons as well), precompiled headers are really limited.&lt;/p&gt;
&lt;p&gt;If we take the case of G++, G++ will consider the precompiled header file instead of the standard header only if (for a complete list, take a look at the GCC docs):&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;The same compilation flags are the same between the two compilations&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The same compiler binary is used for the compilations&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Only one precompiled header can be used in each compilation&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The same macros must be defined&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The include of the header must be before every possible C/C++ token&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If all these conditions are met and you try to &lt;cite&gt;#include "header.hpp&lt;/cite&gt; and there is a header.hpp.gch (the precompiled file) available in the search path, then the precompiled header will be taken instead of the standard one.&lt;/p&gt;
&lt;p&gt;With clang, it is a bit different because the precompiled header cannot be included automatically, but has to be included explicitely in the source code, meaning you have to modify your code for this technique to work. This is a bad thing in my opinion, you never should have to modify your code to profit from a compiler feature. This is why I haven't used and don't plan to use precompiled headers with clang.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="how-to"&gt;
&lt;h2&gt;How-to&lt;/h2&gt;
&lt;p&gt;Once you know all the conditions for a precompiled header to be automatically included, it is quite straightforward to use them.&lt;/p&gt;
&lt;p&gt;To generate a PCH file is easy:&lt;/p&gt;
&lt;pre class="literal-block"&gt;g++ options header.hpp&lt;/pre&gt;
&lt;p&gt;This will generate header.hpp.gch. When you compile your source file using header.hpp, you don't have anything to do, you just have to compile it as usually and if all the conditions are met, the PCH file will be used instead of the other header.&lt;/p&gt;
&lt;/section&gt;
&lt;section id="results-and-conclusion"&gt;
&lt;h2&gt;Results and conclusion&lt;/h2&gt;
&lt;p&gt;I added precompiled header support into my &lt;a class="reference external" href="https://github.com/wichtounet/make-utils"&gt;make-utils&lt;/a&gt; collection of Makefile utilities and tested it on ETL. I have precompiled a header that itself included Catch and ETL. Almost all test files are including this header. With this change, I went from 84 seconds to 78seconds. Headers are taking 1.5seconds to be precompiled. This is a nice result I think. If your application is not as template-heavy as mine or if you have more source files, you should expect better improvements.&lt;/p&gt;
&lt;p&gt;To conclude, even if precompiled headers are a sound way to reduce compile-time, they are really limited to some cases. I'm not a fan of the feature overally. It is not portable between compilers and not standard. Anyway, if you are really in need of saving some time, you should not hesitate too much ;)&lt;/p&gt;
&lt;/section&gt;</description><category>C++</category><category>Compilers</category><category>etl</category><category>gcc</category><category>Performances</category><guid>https://baptiste-wicht.com/posts/2015/06/improve-etl-compile-time-with-precompiled-headers.html</guid><pubDate>Sat, 20 Jun 2015 13:08:31 GMT</pubDate></item></channel></rss>