<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Blog blog("Baptiste Wicht"); (Posts about C++11)</title><link>http://baptiste-wicht.com/</link><description></description><atom:link type="application/rss+xml" rel="self" href="http://baptiste-wicht.com/categories/c%2B%2B11.xml"></atom:link><language>en</language><lastBuildDate>Tue, 17 Oct 2017 18:58:42 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>C++11 Performance tip: Update on when to use std::pow ?</title><link>http://baptiste-wicht.com/posts/2017/09/cpp11-performance-tip-update-when-to-use-std-pow.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;div&gt;&lt;p&gt;A few days ago, I published a post comparing the
&lt;a class="reference external" href="https://baptiste-wicht.com/posts/2017/09/cpp11-performance-tip-when-to-use-std-pow.html"&gt;performance of std::pow against direct multiplications&lt;/a&gt;. When not compiling with -ffast-math, direct multiplication was significantly faster than &lt;code&gt;std::pow&lt;/code&gt;, around two orders of magnitude faster when comparing &lt;code&gt;x * x * x&lt;/code&gt; and &lt;code&gt;code:std::pow(x, 3)&lt;/code&gt;.
One comment that I've got was to test for which &lt;code&gt;n&lt;/code&gt; is
&lt;code&gt;code:std::pow(x, n)&lt;/code&gt; becoming faster than multiplying in a loop. Since
std::pow is using a special algorithm to perform the computation rather than be
simply loop-based multiplications, there may be a point after which it's more interesting to use the
algorithm rather than a loop. So I decided to do the tests. You can also find
the result in the original article, which I've updated.&lt;/p&gt;
&lt;p&gt;First, our pow function:&lt;/p&gt;
&lt;pre class="code c++"&gt;&lt;a name="rest_code_52b382b39caf497cb43a418034153a77-1"&gt;&lt;/a&gt;&lt;span class="kt"&gt;double&lt;/span&gt; &lt;span class="nf"&gt;my_pow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;double&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
&lt;a name="rest_code_52b382b39caf497cb43a418034153a77-2"&gt;&lt;/a&gt;    &lt;span class="kt"&gt;double&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_52b382b39caf497cb43a418034153a77-3"&gt;&lt;/a&gt;
&lt;a name="rest_code_52b382b39caf497cb43a418034153a77-4"&gt;&lt;/a&gt;    &lt;span class="k"&gt;while&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
&lt;a name="rest_code_52b382b39caf497cb43a418034153a77-5"&gt;&lt;/a&gt;        &lt;span class="n"&gt;r&lt;/span&gt; &lt;span class="o"&gt;*=&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_52b382b39caf497cb43a418034153a77-6"&gt;&lt;/a&gt;        &lt;span class="o"&gt;--&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_52b382b39caf497cb43a418034153a77-7"&gt;&lt;/a&gt;    &lt;span class="p"&gt;}&lt;/span&gt;
&lt;a name="rest_code_52b382b39caf497cb43a418034153a77-8"&gt;&lt;/a&gt;
&lt;a name="rest_code_52b382b39caf497cb43a418034153a77-9"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_52b382b39caf497cb43a418034153a77-10"&gt;&lt;/a&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;And now, let's see the performance. I've compiled my benchmark with GCC 4.9.3
and running on my old Sandy Bridge processor. Here are the results for 1000
calls to each functions:&lt;/p&gt;
&lt;div id="graph_std_pow_my_pow_1" style="width: 700px; height: 400px;"&gt;&lt;/div&gt;&lt;p&gt;We can see that between &lt;code&gt;n=100&lt;/code&gt; and &lt;code&gt;n=110&lt;/code&gt;, &lt;code&gt;std::pow(x, n)&lt;/code&gt;
starts to be faster than &lt;code&gt;my_pow(x, n)&lt;/code&gt;. At this point, you should only
use &lt;code&gt;std::pow(x, n)&lt;/code&gt;.  Interestingly too, the time for &lt;code&gt;std::pow(x,
n)&lt;/code&gt; is decreasing. Let's see how is the performance with higher range of
&lt;code&gt;n&lt;/code&gt;:&lt;/p&gt;
&lt;div id="graph_std_pow_my_pow_2" style="width: 700px; height: 400px;"&gt;&lt;/div&gt;&lt;p&gt;We can see that the pow function time still remains stable while our loop-based
pow function still increases linearly. At &lt;code&gt;n=1000&lt;/code&gt;, &lt;code&gt;std::pow&lt;/code&gt; is
one order of magnitude faster than &lt;code&gt;my_pow&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Overall, if you do not care much about extreme accuracy, you may consider using
you own pow function for small-ish (integer) &lt;code&gt;n&lt;/code&gt; values. After
&lt;code&gt;n=100&lt;/code&gt;, it becomes more interesting to use &lt;code&gt;std::pow&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;If you want more results on the subject, you take a look at the
&lt;a class="reference external" href="https://baptiste-wicht.com/posts/2017/09/cpp11-performance-tip-when-to-use-std-pow.html"&gt;original article&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you are interested in the code of this benchmark, it's available online:
&lt;a class="reference external" href="https://github.com/wichtounet/articles/blob/master/src/bench_pow_my_pow.cpp"&gt;bench_pow_my_pow.cpp&lt;/a&gt;&lt;/p&gt;
&lt;script type="text/javascript" src="https://www.google.com/jsapi"&gt;&lt;/script&gt;
&lt;script type="text/javascript"&gt;google.load('visualization', '1.0', {'packages':['corechart']});&lt;/script&gt;
&lt;script type="text/javascript"&gt;
function draw_graph_pow_my_pow_1(){
var data = google.visualization.arrayToDataTable([
['n', 'my_pow(x, n)', 'std::pow(x, n)'],
['10',   2,     127],
['20',   17,     123],
['30',   26,     127],
['40',   36,     123],
['50',   43,     123],
['60',   55,     123],
['70',   72,     123],
['80',   85,     123],
['90',   102,    126],
['100',  114,    125],
['110',  131,    115],
['120',  144,    111],
['130',  165,    111],
['140',  173,    108],
['150',  189,    107],
['160',  202,    112],
['170',  219,    106],
['180',  232,    105],
['190',  249,    108],
['200',  261,    105],
]);
var graph = new google.visualization.LineChart(document.getElementById('graph_std_pow_my_pow_1'));
var options = {curveType: "function",title: "std::pow(x, 2) (float)",animation: {duration:1200, easing:"in"},width: 700, height: 400,hAxis: {title:"Number of elements", slantedText:true},vAxis: {viewWindow: {min:0}, title:"us"}};
graph.draw(data, options);
}
function draw_graph_pow_my_pow_2(){
var data = google.visualization.arrayToDataTable([
['n', 'my_pow(x, n)', 'std::pow(x, n)'],
['100',  114,    125],
['200',  261,    105],
['300',  410,    104],
['400',  558,    104],
['500',  708,    104],
['600',  855,    104],
['700',  1002,   104],
['800',  1148,   104],
['900',  1300,   104],
['1000', 1442,   104],
]);
var graph = new google.visualization.LineChart(document.getElementById('graph_std_pow_my_pow_2'));
var options = {curveType: "function",title: "std::pow(x, 2) (float)",animation: {duration:1200, easing:"in"},width: 700, height: 400,hAxis: {title:"Number of elements", slantedText:true},vAxis: {viewWindow: {min:0}, title:"us"}};
graph.draw(data, options);
}
function draw_all(){
draw_graph_pow_my_pow_1();
draw_graph_pow_my_pow_2();
}
google.setOnLoadCallback(draw_all);
&lt;/script&gt;&lt;/div&gt;</description><category>Benchmark</category><category>C++</category><category>C++11</category><category>Performances</category><category>Tip</category><guid>http://baptiste-wicht.com/posts/2017/09/cpp11-performance-tip-update-when-to-use-std-pow.html</guid><pubDate>Fri, 22 Sep 2017 09:21:07 GMT</pubDate></item><item><title>C++11 Performance tip: When to use std::pow ?</title><link>http://baptiste-wicht.com/posts/2017/09/cpp11-performance-tip-when-to-use-std-pow.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;div&gt;&lt;p&gt;Update: I've added a new section for larger values of &lt;code&gt;n&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Recently, I've been wondering about the performance of &lt;code&gt;std::pow(x, n)&lt;/code&gt;.
I'm talking here about the case when &lt;code&gt;n&lt;/code&gt; is an integer. In the case when
&lt;code&gt;n&lt;/code&gt; is not an integer, I believe, you should always use &lt;code&gt;std::pow&lt;/code&gt;
or use another specialized library.&lt;/p&gt;
&lt;p&gt;In case when n is an integer, you can actually replace it with the direct
equivalent (for instance &lt;code&gt;std::pow(x, 3) = x * x x&lt;/code&gt;). If n is very large,
you'd rather write a loop of course ;) In practice, we generally use powers of
two and three much more often than power of 29, although that could happen. Of
course, it especially make sense to wonder about this if the pow is used inside
a loop. If you only use it once outside a loop, that won't be any difference on
the overall performance.&lt;/p&gt;
&lt;p&gt;Since I'm mostly interested in single precision performance (neural networks are
only about single precision), the first benchmarks will be using &lt;code&gt;float&lt;/code&gt;.&lt;/p&gt;
&lt;p class="more"&gt;&lt;a href="http://baptiste-wicht.com/posts/2017/09/cpp11-performance-tip-when-to-use-std-pow.html"&gt;Read moreâ€¦&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;</description><category>Benchmark</category><category>C++</category><category>C++11</category><category>Performances</category><category>Tip</category><guid>http://baptiste-wicht.com/posts/2017/09/cpp11-performance-tip-when-to-use-std-pow.html</guid><pubDate>Mon, 18 Sep 2017 05:50:44 GMT</pubDate></item><item><title>C++11 Concurrency Tutorial - Part 5: Futures</title><link>http://baptiste-wicht.com/posts/2017/09/cpp11-concurrency-tutorial-futures.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;div&gt;&lt;p&gt;I've been recently reminded that a long time ago I was doing a series of
tutorial on C++11 Concurrency. For some reason, I haven't continued these
tutorials.  The next post in the series was supposed to be about Futures, so I'm
finally going to do it :)&lt;/p&gt;
&lt;p&gt;Here are the links to the current posts of the C++11 Concurrency Tutorial:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="https://baptiste-wicht.com/posts/2012/03/cpp11-concurrency-part1-start-threads.html"&gt;Part 1: Start Threads&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://baptiste-wicht.com/posts/2012/03/cp11-concurrency-tutorial-part-2-protect-shared-data.html"&gt;Part 2: Protect Shared Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://baptiste-wicht.com/posts/2012/04/c11-concurrency-tutorial-advanced-locking-and-condition-variables.html"&gt;Part 3: Advanced Locking and condition variables&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://baptiste-wicht.com/posts/2012/07/c11-concurrency-tutorial-part-4-atomic-type.html"&gt;Part 4: Atomic Types&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In this post, we are going to talk about futures, more precisely
&lt;code&gt;std::future&amp;lt;T&amp;gt;&lt;/code&gt;. What is a future ? It's a very nice and simple mechanism
to work with asynchronous tasks. It also has the advantage of decoupling you
from the threads themselves, you can do multithreading without using
&lt;code&gt;std::thread&lt;/code&gt;. The future itself is a structure pointing to a result that
will be computed in the future. How to create a future ? The simplest way is to
use &lt;code&gt;std::async&lt;/code&gt; that will create an asynchronous task and return
a &lt;code&gt;std::future&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Let's start with the simplest of the examples:&lt;/p&gt;
&lt;pre class="code c++"&gt;&lt;a name="rest_code_a0b782c0e9794ea7a06f3cd7b84dc744-1"&gt;&lt;/a&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;&amp;lt;thread&amp;gt;&lt;/span&gt;&lt;span class="cp"&gt;&lt;/span&gt;
&lt;a name="rest_code_a0b782c0e9794ea7a06f3cd7b84dc744-2"&gt;&lt;/a&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;&amp;lt;future&amp;gt;&lt;/span&gt;&lt;span class="cp"&gt;&lt;/span&gt;
&lt;a name="rest_code_a0b782c0e9794ea7a06f3cd7b84dc744-3"&gt;&lt;/a&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;&amp;lt;iostream&amp;gt;&lt;/span&gt;&lt;span class="cp"&gt;&lt;/span&gt;
&lt;a name="rest_code_a0b782c0e9794ea7a06f3cd7b84dc744-4"&gt;&lt;/a&gt;
&lt;a name="rest_code_a0b782c0e9794ea7a06f3cd7b84dc744-5"&gt;&lt;/a&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;(){&lt;/span&gt;
&lt;a name="rest_code_a0b782c0e9794ea7a06f3cd7b84dc744-6"&gt;&lt;/a&gt;    &lt;span class="k"&gt;auto&lt;/span&gt; &lt;span class="n"&gt;future&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;async&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;launch&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;async&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[](){&lt;/span&gt;
&lt;a name="rest_code_a0b782c0e9794ea7a06f3cd7b84dc744-7"&gt;&lt;/a&gt;        &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;cout&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class="s"&gt;"I'm a thread"&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;endl&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_a0b782c0e9794ea7a06f3cd7b84dc744-8"&gt;&lt;/a&gt;    &lt;span class="p"&gt;});&lt;/span&gt;
&lt;a name="rest_code_a0b782c0e9794ea7a06f3cd7b84dc744-9"&gt;&lt;/a&gt;
&lt;a name="rest_code_a0b782c0e9794ea7a06f3cd7b84dc744-10"&gt;&lt;/a&gt;    &lt;span class="n"&gt;future&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;a name="rest_code_a0b782c0e9794ea7a06f3cd7b84dc744-11"&gt;&lt;/a&gt;
&lt;a name="rest_code_a0b782c0e9794ea7a06f3cd7b84dc744-12"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_a0b782c0e9794ea7a06f3cd7b84dc744-13"&gt;&lt;/a&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;Nothing really special here. &lt;code&gt;std::async&lt;/code&gt; will execute the task that we
give it (here a lambda) and return a &lt;code&gt;std::future&lt;/code&gt;. Once you use the
&lt;code&gt;get()&lt;/code&gt; function on a future, it will wait until the result is available
and return this result to you once it is. The &lt;code&gt;get()&lt;/code&gt; function is then
blocking. Since the lambda, is a void lambda, the returned future is of type
&lt;code&gt;std::future&amp;lt;void&amp;gt;&lt;/code&gt; and &lt;code&gt;get()&lt;/code&gt; returns &lt;code&gt;void&lt;/code&gt; as well. It is
very important to know that you cannot call &lt;code&gt;get&lt;/code&gt; several times on the
same future. Once the result is consumed, you cannot consume it again! If you
want to use the result several times, you need to store it yourself after you
called &lt;code&gt;get()&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Let's see with something that returns a value and actually takes some time
before returning it:&lt;/p&gt;
&lt;pre class="code c++"&gt;&lt;a name="rest_code_cda8edd43d0a4b09aaeb6f3081573610-1"&gt;&lt;/a&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;&amp;lt;thread&amp;gt;&lt;/span&gt;&lt;span class="cp"&gt;&lt;/span&gt;
&lt;a name="rest_code_cda8edd43d0a4b09aaeb6f3081573610-2"&gt;&lt;/a&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;&amp;lt;future&amp;gt;&lt;/span&gt;&lt;span class="cp"&gt;&lt;/span&gt;
&lt;a name="rest_code_cda8edd43d0a4b09aaeb6f3081573610-3"&gt;&lt;/a&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;&amp;lt;iostream&amp;gt;&lt;/span&gt;&lt;span class="cp"&gt;&lt;/span&gt;
&lt;a name="rest_code_cda8edd43d0a4b09aaeb6f3081573610-4"&gt;&lt;/a&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;&amp;lt;chrono&amp;gt;&lt;/span&gt;&lt;span class="cp"&gt;&lt;/span&gt;
&lt;a name="rest_code_cda8edd43d0a4b09aaeb6f3081573610-5"&gt;&lt;/a&gt;
&lt;a name="rest_code_cda8edd43d0a4b09aaeb6f3081573610-6"&gt;&lt;/a&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;(){&lt;/span&gt;
&lt;a name="rest_code_cda8edd43d0a4b09aaeb6f3081573610-7"&gt;&lt;/a&gt;    &lt;span class="k"&gt;auto&lt;/span&gt; &lt;span class="n"&gt;future&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;async&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;launch&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;async&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[](){&lt;/span&gt;
&lt;a name="rest_code_cda8edd43d0a4b09aaeb6f3081573610-8"&gt;&lt;/a&gt;        &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;this_thread&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;sleep_for&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;chrono&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;seconds&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;
&lt;a name="rest_code_cda8edd43d0a4b09aaeb6f3081573610-9"&gt;&lt;/a&gt;        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;42&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_cda8edd43d0a4b09aaeb6f3081573610-10"&gt;&lt;/a&gt;    &lt;span class="p"&gt;});&lt;/span&gt;
&lt;a name="rest_code_cda8edd43d0a4b09aaeb6f3081573610-11"&gt;&lt;/a&gt;
&lt;a name="rest_code_cda8edd43d0a4b09aaeb6f3081573610-12"&gt;&lt;/a&gt;    &lt;span class="c1"&gt;// Do something else ?&lt;/span&gt;
&lt;a name="rest_code_cda8edd43d0a4b09aaeb6f3081573610-13"&gt;&lt;/a&gt;
&lt;a name="rest_code_cda8edd43d0a4b09aaeb6f3081573610-14"&gt;&lt;/a&gt;    &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;cout&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;future&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;endl&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_cda8edd43d0a4b09aaeb6f3081573610-15"&gt;&lt;/a&gt;
&lt;a name="rest_code_cda8edd43d0a4b09aaeb6f3081573610-16"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_cda8edd43d0a4b09aaeb6f3081573610-17"&gt;&lt;/a&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;This time, the future will be of the time &lt;code&gt;std::future&amp;lt;int&amp;gt;&lt;/code&gt; and thus
&lt;code&gt;get()&lt;/code&gt; will also return an &lt;code&gt;int&lt;/code&gt;. &lt;code&gt;std::async&lt;/code&gt; will again
launch a task in an asynchronous way and &lt;code&gt;future.get()&lt;/code&gt; will wait for the
answer. What is interesting, is that you can do something else before the call
to future.&lt;/p&gt;
&lt;p&gt;But &lt;code&gt;get()&lt;/code&gt; is not the only interesting function in &lt;code&gt;std::future&lt;/code&gt;.
You also have &lt;code&gt;wait()&lt;/code&gt; which is almost the same as &lt;code&gt;get()&lt;/code&gt; but does
not consume the result. For instance, you can wait for several futures and then
consume their result together. But, more interesting are the
&lt;code&gt;wait_for(duration)&lt;/code&gt; and &lt;code&gt;wait_until(timepoint)&lt;/code&gt; functions. The
first one wait for the result at most the given time and then returns and the
second one wait for the result at most until the given time point. I think that
&lt;code&gt;wait_for&lt;/code&gt; is more useful in practices, so let's discuss it further.
Finally, an interesting function is &lt;code&gt;bool valid()&lt;/code&gt;. When you use
&lt;code&gt;get()&lt;/code&gt; on the future, it will consume the result, making &lt;code&gt;valid()
returns :code:`false&lt;/code&gt;. So, if you intend to check multiple times for a future,
you should use &lt;code&gt;valid()&lt;/code&gt; first.&lt;/p&gt;
&lt;p&gt;One possible scenario would be if you have several asynchronous tasks, which is
a common scenario. You can imagine that you want to process the results as fast
as possible, so you want to ask the futures for their result several times. If
no result is available, maybe you want to do something else. Here is a possible
implementation:&lt;/p&gt;
&lt;pre class="code c++"&gt;&lt;a name="rest_code_58242deea52649409e8e4766a5be6a65-1"&gt;&lt;/a&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;&amp;lt;thread&amp;gt;&lt;/span&gt;&lt;span class="cp"&gt;&lt;/span&gt;
&lt;a name="rest_code_58242deea52649409e8e4766a5be6a65-2"&gt;&lt;/a&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;&amp;lt;future&amp;gt;&lt;/span&gt;&lt;span class="cp"&gt;&lt;/span&gt;
&lt;a name="rest_code_58242deea52649409e8e4766a5be6a65-3"&gt;&lt;/a&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;&amp;lt;iostream&amp;gt;&lt;/span&gt;&lt;span class="cp"&gt;&lt;/span&gt;
&lt;a name="rest_code_58242deea52649409e8e4766a5be6a65-4"&gt;&lt;/a&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;&amp;lt;chrono&amp;gt;&lt;/span&gt;&lt;span class="cp"&gt;&lt;/span&gt;
&lt;a name="rest_code_58242deea52649409e8e4766a5be6a65-5"&gt;&lt;/a&gt;
&lt;a name="rest_code_58242deea52649409e8e4766a5be6a65-6"&gt;&lt;/a&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;(){&lt;/span&gt;
&lt;a name="rest_code_58242deea52649409e8e4766a5be6a65-7"&gt;&lt;/a&gt;    &lt;span class="k"&gt;auto&lt;/span&gt; &lt;span class="n"&gt;f1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;async&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;launch&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;async&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[](){&lt;/span&gt;
&lt;a name="rest_code_58242deea52649409e8e4766a5be6a65-8"&gt;&lt;/a&gt;        &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;this_thread&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;sleep_for&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;chrono&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;seconds&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;
&lt;a name="rest_code_58242deea52649409e8e4766a5be6a65-9"&gt;&lt;/a&gt;        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;42&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_58242deea52649409e8e4766a5be6a65-10"&gt;&lt;/a&gt;    &lt;span class="p"&gt;});&lt;/span&gt;
&lt;a name="rest_code_58242deea52649409e8e4766a5be6a65-11"&gt;&lt;/a&gt;
&lt;a name="rest_code_58242deea52649409e8e4766a5be6a65-12"&gt;&lt;/a&gt;    &lt;span class="k"&gt;auto&lt;/span&gt; &lt;span class="n"&gt;f2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;async&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;launch&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;async&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[](){&lt;/span&gt;
&lt;a name="rest_code_58242deea52649409e8e4766a5be6a65-13"&gt;&lt;/a&gt;        &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;this_thread&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;sleep_for&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;chrono&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;seconds&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;
&lt;a name="rest_code_58242deea52649409e8e4766a5be6a65-14"&gt;&lt;/a&gt;        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;13&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_58242deea52649409e8e4766a5be6a65-15"&gt;&lt;/a&gt;    &lt;span class="p"&gt;});&lt;/span&gt;
&lt;a name="rest_code_58242deea52649409e8e4766a5be6a65-16"&gt;&lt;/a&gt;
&lt;a name="rest_code_58242deea52649409e8e4766a5be6a65-17"&gt;&lt;/a&gt;    &lt;span class="k"&gt;auto&lt;/span&gt; &lt;span class="n"&gt;f3&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;async&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;launch&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;async&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[](){&lt;/span&gt;
&lt;a name="rest_code_58242deea52649409e8e4766a5be6a65-18"&gt;&lt;/a&gt;        &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;this_thread&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;sleep_for&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;chrono&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;seconds&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;
&lt;a name="rest_code_58242deea52649409e8e4766a5be6a65-19"&gt;&lt;/a&gt;        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;666&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_58242deea52649409e8e4766a5be6a65-20"&gt;&lt;/a&gt;    &lt;span class="p"&gt;});&lt;/span&gt;
&lt;a name="rest_code_58242deea52649409e8e4766a5be6a65-21"&gt;&lt;/a&gt;
&lt;a name="rest_code_58242deea52649409e8e4766a5be6a65-22"&gt;&lt;/a&gt;    &lt;span class="k"&gt;auto&lt;/span&gt; &lt;span class="n"&gt;timeout&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;chrono&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;milliseconds&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a name="rest_code_58242deea52649409e8e4766a5be6a65-23"&gt;&lt;/a&gt;
&lt;a name="rest_code_58242deea52649409e8e4766a5be6a65-24"&gt;&lt;/a&gt;    &lt;span class="k"&gt;while&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f1&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;valid&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;||&lt;/span&gt; &lt;span class="n"&gt;f2&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;valid&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;||&lt;/span&gt; &lt;span class="n"&gt;f3&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;valid&lt;/span&gt;&lt;span class="p"&gt;()){&lt;/span&gt;
&lt;a name="rest_code_58242deea52649409e8e4766a5be6a65-25"&gt;&lt;/a&gt;        &lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f1&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;valid&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;f1&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;wait_for&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;timeout&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;future_status&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;ready&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
&lt;a name="rest_code_58242deea52649409e8e4766a5be6a65-26"&gt;&lt;/a&gt;            &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;cout&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class="s"&gt;"Task1 is done! "&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;f1&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;endl&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_58242deea52649409e8e4766a5be6a65-27"&gt;&lt;/a&gt;        &lt;span class="p"&gt;}&lt;/span&gt;
&lt;a name="rest_code_58242deea52649409e8e4766a5be6a65-28"&gt;&lt;/a&gt;
&lt;a name="rest_code_58242deea52649409e8e4766a5be6a65-29"&gt;&lt;/a&gt;        &lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f2&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;valid&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;f2&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;wait_for&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;timeout&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;future_status&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;ready&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
&lt;a name="rest_code_58242deea52649409e8e4766a5be6a65-30"&gt;&lt;/a&gt;            &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;cout&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class="s"&gt;"Task2 is done! "&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;f2&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;endl&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_58242deea52649409e8e4766a5be6a65-31"&gt;&lt;/a&gt;        &lt;span class="p"&gt;}&lt;/span&gt;
&lt;a name="rest_code_58242deea52649409e8e4766a5be6a65-32"&gt;&lt;/a&gt;
&lt;a name="rest_code_58242deea52649409e8e4766a5be6a65-33"&gt;&lt;/a&gt;        &lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f3&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;valid&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;f3&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;wait_for&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;timeout&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;future_status&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;ready&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
&lt;a name="rest_code_58242deea52649409e8e4766a5be6a65-34"&gt;&lt;/a&gt;            &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;cout&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class="s"&gt;"Task3 is done! "&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;f3&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;endl&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_58242deea52649409e8e4766a5be6a65-35"&gt;&lt;/a&gt;        &lt;span class="p"&gt;}&lt;/span&gt;
&lt;a name="rest_code_58242deea52649409e8e4766a5be6a65-36"&gt;&lt;/a&gt;
&lt;a name="rest_code_58242deea52649409e8e4766a5be6a65-37"&gt;&lt;/a&gt;        &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;cout&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class="s"&gt;"I'm doing my own work!"&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;endl&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_58242deea52649409e8e4766a5be6a65-38"&gt;&lt;/a&gt;        &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;this_thread&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;sleep_for&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;chrono&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;seconds&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;
&lt;a name="rest_code_58242deea52649409e8e4766a5be6a65-39"&gt;&lt;/a&gt;        &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;cout&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class="s"&gt;"I'm done with my own work!"&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;endl&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_58242deea52649409e8e4766a5be6a65-40"&gt;&lt;/a&gt;    &lt;span class="p"&gt;}&lt;/span&gt;
&lt;a name="rest_code_58242deea52649409e8e4766a5be6a65-41"&gt;&lt;/a&gt;
&lt;a name="rest_code_58242deea52649409e8e4766a5be6a65-42"&gt;&lt;/a&gt;    &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;cout&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class="s"&gt;"Everything is done, let's go back to the tutorial"&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;endl&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_58242deea52649409e8e4766a5be6a65-43"&gt;&lt;/a&gt;
&lt;a name="rest_code_58242deea52649409e8e4766a5be6a65-44"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_58242deea52649409e8e4766a5be6a65-45"&gt;&lt;/a&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;The three tasks are started asynchronously with &lt;code&gt;std::async&lt;/code&gt; and the
resulting &lt;code&gt;std::future&lt;/code&gt; are stored. Then, as long as one of the tasks is
not complete, we query each three task and try to process its result. If no
result is available, we simply do something else. This example is important to
understand, it covers pretty much every concept of the futures.&lt;/p&gt;
&lt;p&gt;One interesting thing that remains is that you can pass parameters to your task
via &lt;code&gt;std::async&lt;/code&gt;. Indeed, all the extra parameters that you pass to
&lt;code&gt;std::async&lt;/code&gt; will be passed to the task itself. Here is an example of
spawning tasks in a loop with different parameters:&lt;/p&gt;
&lt;pre class="code c++"&gt;&lt;a name="rest_code_3b2147c682c04d7fa38a4eb06490bff7-1"&gt;&lt;/a&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;&amp;lt;thread&amp;gt;&lt;/span&gt;&lt;span class="cp"&gt;&lt;/span&gt;
&lt;a name="rest_code_3b2147c682c04d7fa38a4eb06490bff7-2"&gt;&lt;/a&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;&amp;lt;future&amp;gt;&lt;/span&gt;&lt;span class="cp"&gt;&lt;/span&gt;
&lt;a name="rest_code_3b2147c682c04d7fa38a4eb06490bff7-3"&gt;&lt;/a&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;&amp;lt;iostream&amp;gt;&lt;/span&gt;&lt;span class="cp"&gt;&lt;/span&gt;
&lt;a name="rest_code_3b2147c682c04d7fa38a4eb06490bff7-4"&gt;&lt;/a&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;&amp;lt;chrono&amp;gt;&lt;/span&gt;&lt;span class="cp"&gt;&lt;/span&gt;
&lt;a name="rest_code_3b2147c682c04d7fa38a4eb06490bff7-5"&gt;&lt;/a&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;&amp;lt;vector&amp;gt;&lt;/span&gt;&lt;span class="cp"&gt;&lt;/span&gt;
&lt;a name="rest_code_3b2147c682c04d7fa38a4eb06490bff7-6"&gt;&lt;/a&gt;
&lt;a name="rest_code_3b2147c682c04d7fa38a4eb06490bff7-7"&gt;&lt;/a&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;(){&lt;/span&gt;
&lt;a name="rest_code_3b2147c682c04d7fa38a4eb06490bff7-8"&gt;&lt;/a&gt;    &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;vector&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;future&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;futures&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_3b2147c682c04d7fa38a4eb06490bff7-9"&gt;&lt;/a&gt;
&lt;a name="rest_code_3b2147c682c04d7fa38a4eb06490bff7-10"&gt;&lt;/a&gt;    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;a name="rest_code_3b2147c682c04d7fa38a4eb06490bff7-11"&gt;&lt;/a&gt;        &lt;span class="n"&gt;futures&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;emplace_back&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;async&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;launch&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;async&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[](&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;param&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
&lt;a name="rest_code_3b2147c682c04d7fa38a4eb06490bff7-12"&gt;&lt;/a&gt;            &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;this_thread&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;sleep_for&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;chrono&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;seconds&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;param&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;
&lt;a name="rest_code_3b2147c682c04d7fa38a4eb06490bff7-13"&gt;&lt;/a&gt;            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;param&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_3b2147c682c04d7fa38a4eb06490bff7-14"&gt;&lt;/a&gt;        &lt;span class="p"&gt;},&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;
&lt;a name="rest_code_3b2147c682c04d7fa38a4eb06490bff7-15"&gt;&lt;/a&gt;    &lt;span class="p"&gt;}&lt;/span&gt;
&lt;a name="rest_code_3b2147c682c04d7fa38a4eb06490bff7-16"&gt;&lt;/a&gt;
&lt;a name="rest_code_3b2147c682c04d7fa38a4eb06490bff7-17"&gt;&lt;/a&gt;    &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;cout&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class="s"&gt;"Start querying"&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;endl&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_3b2147c682c04d7fa38a4eb06490bff7-18"&gt;&lt;/a&gt;
&lt;a name="rest_code_3b2147c682c04d7fa38a4eb06490bff7-19"&gt;&lt;/a&gt;    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;auto&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="nl"&gt;future&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;futures&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;a name="rest_code_3b2147c682c04d7fa38a4eb06490bff7-20"&gt;&lt;/a&gt;      &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;cout&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;future&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;endl&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_3b2147c682c04d7fa38a4eb06490bff7-21"&gt;&lt;/a&gt;    &lt;span class="p"&gt;}&lt;/span&gt;
&lt;a name="rest_code_3b2147c682c04d7fa38a4eb06490bff7-22"&gt;&lt;/a&gt;
&lt;a name="rest_code_3b2147c682c04d7fa38a4eb06490bff7-23"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_3b2147c682c04d7fa38a4eb06490bff7-24"&gt;&lt;/a&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;Pretty practical :) All The created &lt;code&gt;std::future&amp;lt;size_t&amp;gt;&lt;/code&gt; are stored in
a &lt;code&gt;std::vector&lt;/code&gt; and then are all queried for their result.&lt;/p&gt;
&lt;p&gt;Overall, I think &lt;code&gt;std::future&lt;/code&gt; and &lt;code&gt;std::async&lt;/code&gt; are great tool that
can simplify your asynchronous code a lot. They allow you to make pretty
advanced stuff while keeping the complexity of the code to a minimum.&lt;/p&gt;
&lt;p&gt;I hope this long-due post is going to be interesting to some of you :)
The code for this post is available &lt;a class="reference external" href="https://github.com/wichtounet/articles/tree/master/src/threads/part5"&gt;on Github&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I do not yet know if there will be a next installment in the series. I've
covered pretty much everything that is available in C++11 for concurrency. I may
cover the parallel algorithms of C++17 in a following post. If you have any
suggestion for the next post, don't hesitate to post a comment or contact me
directly by email.&lt;/p&gt;&lt;/div&gt;</description><category>C++</category><category>C++11</category><category>C++11 Concurrency Tutorial</category><category>Concurrency</category><category>Performances</category><guid>http://baptiste-wicht.com/posts/2017/09/cpp11-concurrency-tutorial-futures.html</guid><pubDate>Tue, 12 Sep 2017 13:05:08 GMT</pubDate></item><item><title>Compiler benchmark GCC and Clang on C++ library (ETL)</title><link>http://baptiste-wicht.com/posts/2017/08/compiler-benchmark-gcc-clang-cpp-library-etl.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;div&gt;&lt;p&gt;It's been a while since I've done a benchmark of different compilers on C++
code. Since I've recently
&lt;a class="reference external" href="https://baptiste-wicht.com/posts/2017/08/expression-templates-library-etl-11.html"&gt;released the version 1.1 of my ETL project&lt;/a&gt;
(an optimized matrix/vector computation library with expression templates), I've
decided to use it as the base of my benchmark. It's a C++14 library with a lot
of templates. I'm going to compile the full test suite (124 test cases). This is
done directly on the last release (1.1) code. I'm going to compile once in debug
mode and once in release_debug (release plus debug symbols and assertions) and
record the times for each compiler. The tests were compiled with support for
every option in ETL to account to maximal compilation time. Each compilation was
made using four threads (make -j4). I'm also going to test a few of the
benchmarks to see the difference in runtime performance between the code
generated by each compiler. The benchmark will be compiled in release mode and
its compilation time recorded as well.&lt;/p&gt;
&lt;p&gt;I'm going to test the following compilers:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;GCC-4.9.4&lt;/li&gt;
&lt;li&gt;GCC-5.4.0&lt;/li&gt;
&lt;li&gt;GCC-6.3.0&lt;/li&gt;
&lt;li&gt;GCC-7.1.0&lt;/li&gt;
&lt;li&gt;clang-3.9.1&lt;/li&gt;
&lt;li&gt;clang-4.0.1&lt;/li&gt;
&lt;li&gt;zapcc-1.0 (commercial, based on clang-5.0 trunk)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;All have been installed directly using Portage (Gentoo package manager) except
for clang-4.0.1 that has been installed from sources and zapcc since it does not
have a Gentoo package. Since clang package on Gentoo does not support
multislotting, I had to install one version from source and the other from the
package manager. This is also the reason I'm testing less versions of clang,
simply less practical.&lt;/p&gt;
&lt;p&gt;For the purpose of these tests, the exact same options have been used throughout
all the compilers. Normally, I use different options for clang than for GCC
(mainly more aggressive vectorization options on clang). This may not lead to
the best performance for each compiler, but allows for comparison between the
results with defaults optimization level. Here are the main options used:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;In debug mode: -g&lt;/li&gt;
&lt;li&gt;In release_debug mode: -g -O2&lt;/li&gt;
&lt;li&gt;In release mode: -g -O3 -DNDEBUG -fomit-frame-pointer&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In each case, a lot of warnings are enabled and the ETL options are the same.&lt;/p&gt;
&lt;p&gt;All the results have been gathered on a Gentoo machine running on Intel Core
i7-2600 (Sandy Bridge...) @3.4GHz with 4 cores and 8 threads, 12Go of RAM and
a SSD. I do my best to isolate as much as possible the benchmark from
perturbations and that my benchmark code is quite sound, it may well be that
some results are not totally accurate. Moreover, some of the benchmarks are
using multithreading, which may add some noise and unpredictability. When I was
not sure about the results, I ran the benchmarks several time to confirm them
and overall I'm confident of the results.&lt;/p&gt;
&lt;div class="section" id="compilation-time"&gt;
&lt;h2&gt;Compilation Time&lt;/h2&gt;
&lt;p&gt;Let's start with the results of the performance of the compilers themselves:&lt;/p&gt;
&lt;table border="1" class="docutils"&gt;
&lt;colgroup&gt;
&lt;col width="31%"&gt;
&lt;col width="15%"&gt;
&lt;col width="31%"&gt;
&lt;col width="23%"&gt;
&lt;/colgroup&gt;
&lt;thead valign="bottom"&gt;
&lt;tr&gt;&lt;th class="head"&gt;Compiler&lt;/th&gt;
&lt;th class="head"&gt;Debug&lt;/th&gt;
&lt;th class="head"&gt;Release_Debug&lt;/th&gt;
&lt;th class="head"&gt;Benchmark&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td&gt;g++-4.9.4&lt;/td&gt;
&lt;td&gt;402s&lt;/td&gt;
&lt;td&gt;616s&lt;/td&gt;
&lt;td&gt;100s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;g++-5.4.0&lt;/td&gt;
&lt;td&gt;403s&lt;/td&gt;
&lt;td&gt;642s&lt;/td&gt;
&lt;td&gt;95s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;g++-6.3.0&lt;/td&gt;
&lt;td&gt;399s&lt;/td&gt;
&lt;td&gt;683s&lt;/td&gt;
&lt;td&gt;102s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;g++-7.1.0&lt;/td&gt;
&lt;td&gt;371s&lt;/td&gt;
&lt;td&gt;650s&lt;/td&gt;
&lt;td&gt;105s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;clang++-3.9.1&lt;/td&gt;
&lt;td&gt;380s&lt;/td&gt;
&lt;td&gt;807s&lt;/td&gt;
&lt;td&gt;106s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;clang++-4.0.1&lt;/td&gt;
&lt;td&gt;260s&lt;/td&gt;
&lt;td&gt;718s&lt;/td&gt;
&lt;td&gt;92s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;zapcc++-1.0&lt;/td&gt;
&lt;td&gt;221s&lt;/td&gt;
&lt;td&gt;649s&lt;/td&gt;
&lt;td&gt;108s&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Note: For Release_Debug and Benchmark, I only use three threads with zapcc,
because 12Go of RAM is not enough memory for four threads.&lt;/p&gt;
&lt;p&gt;There are some very significant differences between the different compilers.
Overall, clang-4.0.1 is by far the fastest free compiler for Debug mode. When
the tests are compiled with optimizations however, clang is falling behind.
It's quite impressive how clang-4.0.1 manages to be so much faster than
clang-3.9.1 both in debug mode and release mode. Really great work by the clang
team here! With these optimizations, clang-4.0.1 is almost on par with gcc-7.1
in release mode.  For GCC, it seems that the cost of optimization has been going
up quite significantly. However, GCC 7.1 seems to have made optimization faster
and standard compilation much faster as well. If we take into account zapcc,
it's the fastest compiler on debug mode, but it's slower than several gcc
versions on release mode.&lt;/p&gt;
&lt;p&gt;Overall, I'm quite impressed by the performance of clang-4.0.1 which seems
really fast! I'll definitely make more tests with this new version of the
compiler in the near future. It's also good to see that g++-7.1 also did make
the build faster than gcc-6.3. However, the fastest gcc version for optimization
is still gcc-4.9.4 which is already an old branch with low C++ standard support.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="runtime-performance"&gt;
&lt;h2&gt;Runtime Performance&lt;/h2&gt;
&lt;p&gt;Let's now take a look at the quality of the generated code. For some of the
benchmarks, I've included two versions of the algorithm. &lt;em&gt;std&lt;/em&gt; is the most
simple algorithm (the naive one) and &lt;em&gt;vec&lt;/em&gt; is the hand-crafted vectorized and
optimized implementation. All the tests were done on single-precision floating
points.&lt;/p&gt;
&lt;div class="section" id="dot-product"&gt;
&lt;h3&gt;Dot product&lt;/h3&gt;
&lt;p&gt;The first benchmark that is run is to compute the dot product between two
vectors. Let's look first at the naive version:&lt;/p&gt;
&lt;table border="1" class="docutils"&gt;
&lt;colgroup&gt;
&lt;col width="13%"&gt;
&lt;col width="8%"&gt;
&lt;col width="8%"&gt;
&lt;col width="8%"&gt;
&lt;col width="7%"&gt;
&lt;col width="8%"&gt;
&lt;col width="8%"&gt;
&lt;col width="8%"&gt;
&lt;col width="8%"&gt;
&lt;col width="8%"&gt;
&lt;col width="8%"&gt;
&lt;col width="8%"&gt;
&lt;/colgroup&gt;
&lt;thead valign="bottom"&gt;
&lt;tr&gt;&lt;th class="head"&gt;dot (std)&lt;/th&gt;
&lt;th class="head"&gt;100&lt;/th&gt;
&lt;th class="head"&gt;500&lt;/th&gt;
&lt;th class="head"&gt;1000&lt;/th&gt;
&lt;th class="head"&gt;10000&lt;/th&gt;
&lt;th class="head"&gt;100000&lt;/th&gt;
&lt;th class="head"&gt;1000000&lt;/th&gt;
&lt;th class="head"&gt;2000000&lt;/th&gt;
&lt;th class="head"&gt;3000000&lt;/th&gt;
&lt;th class="head"&gt;4000000&lt;/th&gt;
&lt;th class="head"&gt;5000000&lt;/th&gt;
&lt;th class="head"&gt;10000000&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td&gt;g++-4.9.4&lt;/td&gt;
&lt;td&gt;64.96ns&lt;/td&gt;
&lt;td&gt;97.12ns&lt;/td&gt;
&lt;td&gt;126.07ns&lt;/td&gt;
&lt;td&gt;1.89us&lt;/td&gt;
&lt;td&gt;25.91us&lt;/td&gt;
&lt;td&gt;326.49us&lt;/td&gt;
&lt;td&gt;1.24ms&lt;/td&gt;
&lt;td&gt;1.92ms&lt;/td&gt;
&lt;td&gt;2.55ms&lt;/td&gt;
&lt;td&gt;3.22ms&lt;/td&gt;
&lt;td&gt;6.36ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;g++-5.4.0&lt;/td&gt;
&lt;td&gt;72.96ns&lt;/td&gt;
&lt;td&gt;101.62ns&lt;/td&gt;
&lt;td&gt;127.89ns&lt;/td&gt;
&lt;td&gt;1.90us&lt;/td&gt;
&lt;td&gt;23.39us&lt;/td&gt;
&lt;td&gt;357.63us&lt;/td&gt;
&lt;td&gt;1.23ms&lt;/td&gt;
&lt;td&gt;1.91ms&lt;/td&gt;
&lt;td&gt;2.57ms&lt;/td&gt;
&lt;td&gt;3.20ms&lt;/td&gt;
&lt;td&gt;6.32ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;g++-6.3.0&lt;/td&gt;
&lt;td&gt;73.31ns&lt;/td&gt;
&lt;td&gt;102.88ns&lt;/td&gt;
&lt;td&gt;130.16ns&lt;/td&gt;
&lt;td&gt;1.89us&lt;/td&gt;
&lt;td&gt;24.314us&lt;/td&gt;
&lt;td&gt;339.13us&lt;/td&gt;
&lt;td&gt;1.47ms&lt;/td&gt;
&lt;td&gt;2.16ms&lt;/td&gt;
&lt;td&gt;2.95ms&lt;/td&gt;
&lt;td&gt;3.70ms&lt;/td&gt;
&lt;td&gt;6.69ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;g++-7.1.0&lt;/td&gt;
&lt;td&gt;70.20ns&lt;/td&gt;
&lt;td&gt;104.09ns&lt;/td&gt;
&lt;td&gt;130.98ns&lt;/td&gt;
&lt;td&gt;1.90us&lt;/td&gt;
&lt;td&gt;23.96us&lt;/td&gt;
&lt;td&gt;281.47us&lt;/td&gt;
&lt;td&gt;1.24ms&lt;/td&gt;
&lt;td&gt;1.93ms&lt;/td&gt;
&lt;td&gt;2.58ms&lt;/td&gt;
&lt;td&gt;3.19ms&lt;/td&gt;
&lt;td&gt;6.33ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;clang++-3.9.1&lt;/td&gt;
&lt;td&gt;64.69ns&lt;/td&gt;
&lt;td&gt;98.69ns&lt;/td&gt;
&lt;td&gt;128.60ns&lt;/td&gt;
&lt;td&gt;1.89us&lt;/td&gt;
&lt;td&gt;23.33us&lt;/td&gt;
&lt;td&gt;272.71us&lt;/td&gt;
&lt;td&gt;1.24ms&lt;/td&gt;
&lt;td&gt;1.91ms&lt;/td&gt;
&lt;td&gt;2.56ms&lt;/td&gt;
&lt;td&gt;3.19ms&lt;/td&gt;
&lt;td&gt;6.37ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;clang++-4.0.1&lt;/td&gt;
&lt;td&gt;60.31ns&lt;/td&gt;
&lt;td&gt;96.34ns&lt;/td&gt;
&lt;td&gt;128.90ns&lt;/td&gt;
&lt;td&gt;1.89us&lt;/td&gt;
&lt;td&gt;22.87us&lt;/td&gt;
&lt;td&gt;270.21us&lt;/td&gt;
&lt;td&gt;1.23ms&lt;/td&gt;
&lt;td&gt;1.91ms&lt;/td&gt;
&lt;td&gt;2.55ms&lt;/td&gt;
&lt;td&gt;3.18ms&lt;/td&gt;
&lt;td&gt;6.35ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;zapcc++-1.0&lt;/td&gt;
&lt;td&gt;61.14ns&lt;/td&gt;
&lt;td&gt;96.92ns&lt;/td&gt;
&lt;td&gt;125.95ns&lt;/td&gt;
&lt;td&gt;1.89us&lt;/td&gt;
&lt;td&gt;23.84us&lt;/td&gt;
&lt;td&gt;285.80us&lt;/td&gt;
&lt;td&gt;1.24ms&lt;/td&gt;
&lt;td&gt;1.92ms&lt;/td&gt;
&lt;td&gt;2.55ms&lt;/td&gt;
&lt;td&gt;3.16ms&lt;/td&gt;
&lt;td&gt;6.34ms&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The differences are not very significant between the different compilers. The
clang-based compilers seem to be the compilers producing the fastest code.
Interestingly, there seem to have been a big regression in gcc-6.3 for large
containers, but that has been fixed in gcc-7.1.&lt;/p&gt;
&lt;table border="1" class="docutils"&gt;
&lt;colgroup&gt;
&lt;col width="13%"&gt;
&lt;col width="8%"&gt;
&lt;col width="8%"&gt;
&lt;col width="9%"&gt;
&lt;col width="7%"&gt;
&lt;col width="8%"&gt;
&lt;col width="9%"&gt;
&lt;col width="8%"&gt;
&lt;col width="8%"&gt;
&lt;col width="8%"&gt;
&lt;col width="8%"&gt;
&lt;col width="9%"&gt;
&lt;/colgroup&gt;
&lt;thead valign="bottom"&gt;
&lt;tr&gt;&lt;th class="head"&gt;dot (vec)&lt;/th&gt;
&lt;th class="head"&gt;100&lt;/th&gt;
&lt;th class="head"&gt;500&lt;/th&gt;
&lt;th class="head"&gt;1000&lt;/th&gt;
&lt;th class="head"&gt;10000&lt;/th&gt;
&lt;th class="head"&gt;100000&lt;/th&gt;
&lt;th class="head"&gt;1000000&lt;/th&gt;
&lt;th class="head"&gt;2000000&lt;/th&gt;
&lt;th class="head"&gt;3000000&lt;/th&gt;
&lt;th class="head"&gt;4000000&lt;/th&gt;
&lt;th class="head"&gt;5000000&lt;/th&gt;
&lt;th class="head"&gt;10000000&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td&gt;g++-4.9.4&lt;/td&gt;
&lt;td&gt;48.34ns&lt;/td&gt;
&lt;td&gt;80.53ns&lt;/td&gt;
&lt;td&gt;114.97ns&lt;/td&gt;
&lt;td&gt;1.72us&lt;/td&gt;
&lt;td&gt;22.79us&lt;/td&gt;
&lt;td&gt;354.20us&lt;/td&gt;
&lt;td&gt;1.24ms&lt;/td&gt;
&lt;td&gt;1.89ms&lt;/td&gt;
&lt;td&gt;2.52ms&lt;/td&gt;
&lt;td&gt;3.19ms&lt;/td&gt;
&lt;td&gt;6.55ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;g++-5.4.0&lt;/td&gt;
&lt;td&gt;47.16ns&lt;/td&gt;
&lt;td&gt;77.70ns&lt;/td&gt;
&lt;td&gt;113.66ns&lt;/td&gt;
&lt;td&gt;1.72us&lt;/td&gt;
&lt;td&gt;22.71us&lt;/td&gt;
&lt;td&gt;363.86us&lt;/td&gt;
&lt;td&gt;1.24ms&lt;/td&gt;
&lt;td&gt;1.89ms&lt;/td&gt;
&lt;td&gt;2.52ms&lt;/td&gt;
&lt;td&gt;3.19ms&lt;/td&gt;
&lt;td&gt;6.56ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;g++-6.3.0&lt;/td&gt;
&lt;td&gt;46.39ns&lt;/td&gt;
&lt;td&gt;77.67ns&lt;/td&gt;
&lt;td&gt;116.28ns&lt;/td&gt;
&lt;td&gt;1.74us&lt;/td&gt;
&lt;td&gt;23.39us&lt;/td&gt;
&lt;td&gt;452.44us&lt;/td&gt;
&lt;td&gt;1.45ms&lt;/td&gt;
&lt;td&gt;2.26ms&lt;/td&gt;
&lt;td&gt;2.87ms&lt;/td&gt;
&lt;td&gt;3.49ms&lt;/td&gt;
&lt;td&gt;7.52ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;g++-7.1.0&lt;/td&gt;
&lt;td&gt;49.70ns&lt;/td&gt;
&lt;td&gt;80.40ns&lt;/td&gt;
&lt;td&gt;115.77ns&lt;/td&gt;
&lt;td&gt;1.71us&lt;/td&gt;
&lt;td&gt;22.46us&lt;/td&gt;
&lt;td&gt;355.16us&lt;/td&gt;
&lt;td&gt;1.21ms&lt;/td&gt;
&lt;td&gt;1.85ms&lt;/td&gt;
&lt;td&gt;2.49ms&lt;/td&gt;
&lt;td&gt;3.14ms&lt;/td&gt;
&lt;td&gt;6.47ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;clang++-3.9.1&lt;/td&gt;
&lt;td&gt;46.13ns&lt;/td&gt;
&lt;td&gt;78.01ns&lt;/td&gt;
&lt;td&gt;114.70ns&lt;/td&gt;
&lt;td&gt;1.66us&lt;/td&gt;
&lt;td&gt;22.82us&lt;/td&gt;
&lt;td&gt;359.42us&lt;/td&gt;
&lt;td&gt;1.24ms&lt;/td&gt;
&lt;td&gt;1.88ms&lt;/td&gt;
&lt;td&gt;2.53ms&lt;/td&gt;
&lt;td&gt;3.16ms&lt;/td&gt;
&lt;td&gt;6.50ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;clang++-4.0.1&lt;/td&gt;
&lt;td&gt;45.59ns&lt;/td&gt;
&lt;td&gt;74.90ns&lt;/td&gt;
&lt;td&gt;111.29ns&lt;/td&gt;
&lt;td&gt;1.57us&lt;/td&gt;
&lt;td&gt;22.47us&lt;/td&gt;
&lt;td&gt;351.31us&lt;/td&gt;
&lt;td&gt;1.23ms&lt;/td&gt;
&lt;td&gt;1.85ms&lt;/td&gt;
&lt;td&gt;2.49ms&lt;/td&gt;
&lt;td&gt;3.12ms&lt;/td&gt;
&lt;td&gt;6.45ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;zapcc++-1.0&lt;/td&gt;
&lt;td&gt;45.11ns&lt;/td&gt;
&lt;td&gt;75.04ns&lt;/td&gt;
&lt;td&gt;111.28ns&lt;/td&gt;
&lt;td&gt;1.59us&lt;/td&gt;
&lt;td&gt;22.46us&lt;/td&gt;
&lt;td&gt;357.32us&lt;/td&gt;
&lt;td&gt;1.25ms&lt;/td&gt;
&lt;td&gt;1.89ms&lt;/td&gt;
&lt;td&gt;2.53ms&lt;/td&gt;
&lt;td&gt;3.15ms&lt;/td&gt;
&lt;td&gt;6.47ms&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;If we look at the optimized version, the differences are even slower. Again, the
clang-based compilers are producing the fastest executables, but are closely
followed by gcc, except for gcc-6.3 in which we can still see the same
regression as before.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="logistic-sigmoid"&gt;
&lt;h3&gt;Logistic Sigmoid&lt;/h3&gt;
&lt;p&gt;The next test is to check the performance of the sigmoid operation. In that
case, the evaluator of the library will try to use parallelization and
vectorization to compute it. Let's see how the different compilers fare:&lt;/p&gt;
&lt;table border="1" class="docutils"&gt;
&lt;colgroup&gt;
&lt;col width="22%"&gt;
&lt;col width="12%"&gt;
&lt;col width="12%"&gt;
&lt;col width="12%"&gt;
&lt;col width="13%"&gt;
&lt;col width="15%"&gt;
&lt;col width="13%"&gt;
&lt;/colgroup&gt;
&lt;thead valign="bottom"&gt;
&lt;tr&gt;&lt;th class="head"&gt;sigmoid&lt;/th&gt;
&lt;th class="head"&gt;10&lt;/th&gt;
&lt;th class="head"&gt;100&lt;/th&gt;
&lt;th class="head"&gt;1000&lt;/th&gt;
&lt;th class="head"&gt;10000&lt;/th&gt;
&lt;th class="head"&gt;100000&lt;/th&gt;
&lt;th class="head"&gt;1000000&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td&gt;g++-4.9.4&lt;/td&gt;
&lt;td&gt;8.16us&lt;/td&gt;
&lt;td&gt;5.23us&lt;/td&gt;
&lt;td&gt;6.33us&lt;/td&gt;
&lt;td&gt;29.56us&lt;/td&gt;
&lt;td&gt;259.72us&lt;/td&gt;
&lt;td&gt;2.78ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;g++-5.4.0&lt;/td&gt;
&lt;td&gt;7.07us&lt;/td&gt;
&lt;td&gt;5.08us&lt;/td&gt;
&lt;td&gt;6.39us&lt;/td&gt;
&lt;td&gt;29.44us&lt;/td&gt;
&lt;td&gt;266.27us&lt;/td&gt;
&lt;td&gt;2.96ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;g++-6.3.0&lt;/td&gt;
&lt;td&gt;7.13us&lt;/td&gt;
&lt;td&gt;5.32us&lt;/td&gt;
&lt;td&gt;6.45us&lt;/td&gt;
&lt;td&gt;28.99us&lt;/td&gt;
&lt;td&gt;261.81us&lt;/td&gt;
&lt;td&gt;2.86ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;g++-7.1.0&lt;/td&gt;
&lt;td&gt;7.03us&lt;/td&gt;
&lt;td&gt;5.09us&lt;/td&gt;
&lt;td&gt;6.24us&lt;/td&gt;
&lt;td&gt;28.61us&lt;/td&gt;
&lt;td&gt;252.78us&lt;/td&gt;
&lt;td&gt;2.71ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;clang++-3.9.1&lt;/td&gt;
&lt;td&gt;7.30us&lt;/td&gt;
&lt;td&gt;5.25us&lt;/td&gt;
&lt;td&gt;6.57us&lt;/td&gt;
&lt;td&gt;30.24us&lt;/td&gt;
&lt;td&gt;256.75us&lt;/td&gt;
&lt;td&gt;1.99ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;clang++-4.0.1&lt;/td&gt;
&lt;td&gt;7.47us&lt;/td&gt;
&lt;td&gt;5.14us&lt;/td&gt;
&lt;td&gt;5.77us&lt;/td&gt;
&lt;td&gt;26.03us&lt;/td&gt;
&lt;td&gt;235.87us&lt;/td&gt;
&lt;td&gt;1.81ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;zapcc++-1.0&lt;/td&gt;
&lt;td&gt;7.51us&lt;/td&gt;
&lt;td&gt;5.26us&lt;/td&gt;
&lt;td&gt;6.48us&lt;/td&gt;
&lt;td&gt;28.86us&lt;/td&gt;
&lt;td&gt;258.31us&lt;/td&gt;
&lt;td&gt;1.95ms&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Interestingly, we can see that gcc-7.1 is the fastest for small vectors while
clang-4.0 is the best for producing code for larger vectors. However, except for
the biggest vector size, the difference is not really significantly. Apparently,
there is a regression in zapcc (or clang-5.0) since it's slower than clang-4.0
at the same level as clang-3.9.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="y-alpha-x-y-axpy"&gt;
&lt;h3&gt;y = alpha * x + y (axpy)&lt;/h3&gt;
&lt;p&gt;The third benchmark is the well-known axpy (y = alpha * x + y). This is entirely
resolved by expressions templates in the library, no specific algorithm is used.
Let's see the results:&lt;/p&gt;
&lt;table border="1" class="docutils"&gt;
&lt;colgroup&gt;
&lt;col width="24%"&gt;
&lt;col width="13%"&gt;
&lt;col width="13%"&gt;
&lt;col width="11%"&gt;
&lt;col width="13%"&gt;
&lt;col width="13%"&gt;
&lt;col width="14%"&gt;
&lt;/colgroup&gt;
&lt;thead valign="bottom"&gt;
&lt;tr&gt;&lt;th class="head"&gt;saxpy&lt;/th&gt;
&lt;th class="head"&gt;10&lt;/th&gt;
&lt;th class="head"&gt;100&lt;/th&gt;
&lt;th class="head"&gt;1000&lt;/th&gt;
&lt;th class="head"&gt;10000&lt;/th&gt;
&lt;th class="head"&gt;100000&lt;/th&gt;
&lt;th class="head"&gt;1000000&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td&gt;g++-4.9.4&lt;/td&gt;
&lt;td&gt;38.1ns&lt;/td&gt;
&lt;td&gt;61.6ns&lt;/td&gt;
&lt;td&gt;374ns&lt;/td&gt;
&lt;td&gt;3.65us&lt;/td&gt;
&lt;td&gt;40.8us&lt;/td&gt;
&lt;td&gt;518us&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;g++-5.4.0&lt;/td&gt;
&lt;td&gt;35.0ns&lt;/td&gt;
&lt;td&gt;58.1ns&lt;/td&gt;
&lt;td&gt;383ns&lt;/td&gt;
&lt;td&gt;3.87us&lt;/td&gt;
&lt;td&gt;43.2us&lt;/td&gt;
&lt;td&gt;479us&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;g++-6.3.0&lt;/td&gt;
&lt;td&gt;34.3ns&lt;/td&gt;
&lt;td&gt;59.4ns&lt;/td&gt;
&lt;td&gt;371ns&lt;/td&gt;
&lt;td&gt;3.57us&lt;/td&gt;
&lt;td&gt;40.4us&lt;/td&gt;
&lt;td&gt;452us&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;g++-7.1.0&lt;/td&gt;
&lt;td&gt;34.8ns&lt;/td&gt;
&lt;td&gt;59.7ns&lt;/td&gt;
&lt;td&gt;399ns&lt;/td&gt;
&lt;td&gt;3.78us&lt;/td&gt;
&lt;td&gt;43.1us&lt;/td&gt;
&lt;td&gt;547us&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;clang++-3.9.1&lt;/td&gt;
&lt;td&gt;32.3ns&lt;/td&gt;
&lt;td&gt;53.8ns&lt;/td&gt;
&lt;td&gt;297ns&lt;/td&gt;
&lt;td&gt;3.21us&lt;/td&gt;
&lt;td&gt;38.3us&lt;/td&gt;
&lt;td&gt;466us&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;clang++-4.0.1&lt;/td&gt;
&lt;td&gt;32.4ns&lt;/td&gt;
&lt;td&gt;59.8ns&lt;/td&gt;
&lt;td&gt;296ns&lt;/td&gt;
&lt;td&gt;3.31us&lt;/td&gt;
&lt;td&gt;38.2us&lt;/td&gt;
&lt;td&gt;475us&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;zapcc++-1.0&lt;/td&gt;
&lt;td&gt;32.0ns&lt;/td&gt;
&lt;td&gt;54.0ns&lt;/td&gt;
&lt;td&gt;333ns&lt;/td&gt;
&lt;td&gt;3.32us&lt;/td&gt;
&lt;td&gt;38.7us&lt;/td&gt;
&lt;td&gt;447us&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Even on the biggest vector, this is a very fast operation, once vectorized and
parallelized. At this speed, some of the differences observed may not be highly
significant. Again clang-based versions are the fastest versions on this code,
but by a small margin.  There also seems to be a slight regression in gcc-7.1,
but again quite small.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="matrix-matrix-multiplication-gemm"&gt;
&lt;h3&gt;Matrix Matrix multiplication (GEMM)&lt;/h3&gt;
&lt;p&gt;The next benchmark is testing the performance of a Matrix-Matrix Multiplication,
an operation known as GEMM in the BLAS nomenclature. In that case, we test both
the naive and the optimized vectorized implementation. To save some horizontal
space, I've split the tables in two.&lt;/p&gt;
&lt;table border="1" class="docutils"&gt;
&lt;colgroup&gt;
&lt;col width="23%"&gt;
&lt;col width="12%"&gt;
&lt;col width="14%"&gt;
&lt;col width="15%"&gt;
&lt;col width="12%"&gt;
&lt;col width="12%"&gt;
&lt;col width="12%"&gt;
&lt;/colgroup&gt;
&lt;thead valign="bottom"&gt;
&lt;tr&gt;&lt;th class="head"&gt;sgemm (std)&lt;/th&gt;
&lt;th class="head"&gt;10&lt;/th&gt;
&lt;th class="head"&gt;20&lt;/th&gt;
&lt;th class="head"&gt;40&lt;/th&gt;
&lt;th class="head"&gt;60&lt;/th&gt;
&lt;th class="head"&gt;80&lt;/th&gt;
&lt;th class="head"&gt;100&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td&gt;g++-4.9.4&lt;/td&gt;
&lt;td&gt;7.04us&lt;/td&gt;
&lt;td&gt;50.15us&lt;/td&gt;
&lt;td&gt;356.42us&lt;/td&gt;
&lt;td&gt;1.18ms&lt;/td&gt;
&lt;td&gt;3.41ms&lt;/td&gt;
&lt;td&gt;5.56ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;g++-5.4.0&lt;/td&gt;
&lt;td&gt;8.14us&lt;/td&gt;
&lt;td&gt;74.77us&lt;/td&gt;
&lt;td&gt;513.64us&lt;/td&gt;
&lt;td&gt;1.72ms&lt;/td&gt;
&lt;td&gt;4.05ms&lt;/td&gt;
&lt;td&gt;7.92ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;g++-6.3.0&lt;/td&gt;
&lt;td&gt;8.03us&lt;/td&gt;
&lt;td&gt;64.78us&lt;/td&gt;
&lt;td&gt;504.41us&lt;/td&gt;
&lt;td&gt;1.69ms&lt;/td&gt;
&lt;td&gt;4.02ms&lt;/td&gt;
&lt;td&gt;7.87ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;g++-7.1.0&lt;/td&gt;
&lt;td&gt;7.95us&lt;/td&gt;
&lt;td&gt;65.00us&lt;/td&gt;
&lt;td&gt;508.84us&lt;/td&gt;
&lt;td&gt;1.69ms&lt;/td&gt;
&lt;td&gt;4.02ms&lt;/td&gt;
&lt;td&gt;7.84ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;clang++-3.9.1&lt;/td&gt;
&lt;td&gt;3.58us&lt;/td&gt;
&lt;td&gt;28.59us&lt;/td&gt;
&lt;td&gt;222.36us&lt;/td&gt;
&lt;td&gt;0.73ms&lt;/td&gt;
&lt;td&gt;1.77us&lt;/td&gt;
&lt;td&gt;3.41ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;clang++-4.0.1&lt;/td&gt;
&lt;td&gt;4.00us&lt;/td&gt;
&lt;td&gt;25.47us&lt;/td&gt;
&lt;td&gt;190.56us&lt;/td&gt;
&lt;td&gt;0.61ms&lt;/td&gt;
&lt;td&gt;1.45us&lt;/td&gt;
&lt;td&gt;2.80ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;zapcc++-1.0&lt;/td&gt;
&lt;td&gt;4.00us&lt;/td&gt;
&lt;td&gt;25.38us&lt;/td&gt;
&lt;td&gt;189.98us&lt;/td&gt;
&lt;td&gt;0.60ms&lt;/td&gt;
&lt;td&gt;1.43us&lt;/td&gt;
&lt;td&gt;2.81ms&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table border="1" class="docutils"&gt;
&lt;colgroup&gt;
&lt;col width="15%"&gt;
&lt;col width="9%"&gt;
&lt;col width="10%"&gt;
&lt;col width="10%"&gt;
&lt;col width="10%"&gt;
&lt;col width="7%"&gt;
&lt;col width="7%"&gt;
&lt;col width="7%"&gt;
&lt;col width="7%"&gt;
&lt;col width="7%"&gt;
&lt;col width="8%"&gt;
&lt;/colgroup&gt;
&lt;thead valign="bottom"&gt;
&lt;tr&gt;&lt;th class="head"&gt;sgemm (std)&lt;/th&gt;
&lt;th class="head"&gt;200&lt;/th&gt;
&lt;th class="head"&gt;300&lt;/th&gt;
&lt;th class="head"&gt;400&lt;/th&gt;
&lt;th class="head"&gt;500&lt;/th&gt;
&lt;th class="head"&gt;600&lt;/th&gt;
&lt;th class="head"&gt;700&lt;/th&gt;
&lt;th class="head"&gt;800&lt;/th&gt;
&lt;th class="head"&gt;900&lt;/th&gt;
&lt;th class="head"&gt;1000&lt;/th&gt;
&lt;th class="head"&gt;1200&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td&gt;g++-4.9.4&lt;/td&gt;
&lt;td&gt;44.16ms&lt;/td&gt;
&lt;td&gt;148.88ms&lt;/td&gt;
&lt;td&gt;455.81ms&lt;/td&gt;
&lt;td&gt;687.96ms&lt;/td&gt;
&lt;td&gt;1.47s&lt;/td&gt;
&lt;td&gt;1.98s&lt;/td&gt;
&lt;td&gt;2.81s&lt;/td&gt;
&lt;td&gt;4.00s&lt;/td&gt;
&lt;td&gt;5.91s&lt;/td&gt;
&lt;td&gt;9.52s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;g++-5.4.0&lt;/td&gt;
&lt;td&gt;63.17ms&lt;/td&gt;
&lt;td&gt;213.01ms&lt;/td&gt;
&lt;td&gt;504.83ms&lt;/td&gt;
&lt;td&gt;984.90ms&lt;/td&gt;
&lt;td&gt;1.70s&lt;/td&gt;
&lt;td&gt;2.70s&lt;/td&gt;
&lt;td&gt;4.03s&lt;/td&gt;
&lt;td&gt;5.74s&lt;/td&gt;
&lt;td&gt;7.87s&lt;/td&gt;
&lt;td&gt;14.905&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;g++-6.3.0&lt;/td&gt;
&lt;td&gt;64.04ms&lt;/td&gt;
&lt;td&gt;212.12ms&lt;/td&gt;
&lt;td&gt;502.95ms&lt;/td&gt;
&lt;td&gt;981.74ms&lt;/td&gt;
&lt;td&gt;1.69s&lt;/td&gt;
&lt;td&gt;2.69s&lt;/td&gt;
&lt;td&gt;4.13s&lt;/td&gt;
&lt;td&gt;5.85s&lt;/td&gt;
&lt;td&gt;8.10s&lt;/td&gt;
&lt;td&gt;14.08s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;g++-7.1.0&lt;/td&gt;
&lt;td&gt;62.57ms&lt;/td&gt;
&lt;td&gt;210.72ms&lt;/td&gt;
&lt;td&gt;499.68ms&lt;/td&gt;
&lt;td&gt;974.94ms&lt;/td&gt;
&lt;td&gt;1.68s&lt;/td&gt;
&lt;td&gt;2.67s&lt;/td&gt;
&lt;td&gt;3.99s&lt;/td&gt;
&lt;td&gt;5.68s&lt;/td&gt;
&lt;td&gt;7.85s&lt;/td&gt;
&lt;td&gt;13.49s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;clang++-3.9.1&lt;/td&gt;
&lt;td&gt;27.48ms&lt;/td&gt;
&lt;td&gt;90.85ms&lt;/td&gt;
&lt;td&gt;219.34ms&lt;/td&gt;
&lt;td&gt;419.53ms&lt;/td&gt;
&lt;td&gt;0.72s&lt;/td&gt;
&lt;td&gt;1.18s&lt;/td&gt;
&lt;td&gt;1.90s&lt;/td&gt;
&lt;td&gt;2.44s&lt;/td&gt;
&lt;td&gt;3.36s&lt;/td&gt;
&lt;td&gt;5.84s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;clang++-4.0.1&lt;/td&gt;
&lt;td&gt;22.01ms&lt;/td&gt;
&lt;td&gt;73.90ms&lt;/td&gt;
&lt;td&gt;175.02ms&lt;/td&gt;
&lt;td&gt;340.70ms&lt;/td&gt;
&lt;td&gt;0.58s&lt;/td&gt;
&lt;td&gt;0.93s&lt;/td&gt;
&lt;td&gt;1.40s&lt;/td&gt;
&lt;td&gt;1.98s&lt;/td&gt;
&lt;td&gt;2.79s&lt;/td&gt;
&lt;td&gt;4.69s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;zapcc++-1.0&lt;/td&gt;
&lt;td&gt;22.33ms&lt;/td&gt;
&lt;td&gt;75.80ms&lt;/td&gt;
&lt;td&gt;181.27ms&lt;/td&gt;
&lt;td&gt;359.13ms&lt;/td&gt;
&lt;td&gt;0.63s&lt;/td&gt;
&lt;td&gt;1.02s&lt;/td&gt;
&lt;td&gt;1.52s&lt;/td&gt;
&lt;td&gt;2.24s&lt;/td&gt;
&lt;td&gt;3.21s&lt;/td&gt;
&lt;td&gt;5.62s&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;This time, the differences between the different compilers are very significant.
The clang compilers are leading the way by a large margin here, with clang-4.0
being the fastest of them (by another nice margin). Indeed, clang-4.0.1 is
producing code that is, on average, about twice faster than the code generated
by the best GCC compiler. Very interestingly as well, we can see a huge
regression starting from GCC-5.4 and that is still here in GCC-7.1. Indeed, the
best GCC version, in the tested versions, is again GCC-4.9.4. Clang is really
doing an excellent job of compiling the GEMM code.&lt;/p&gt;
&lt;table border="1" class="docutils"&gt;
&lt;colgroup&gt;
&lt;col width="21%"&gt;
&lt;col width="14%"&gt;
&lt;col width="11%"&gt;
&lt;col width="11%"&gt;
&lt;col width="14%"&gt;
&lt;col width="14%"&gt;
&lt;col width="13%"&gt;
&lt;/colgroup&gt;
&lt;thead valign="bottom"&gt;
&lt;tr&gt;&lt;th class="head"&gt;sgemm (vec)&lt;/th&gt;
&lt;th class="head"&gt;10&lt;/th&gt;
&lt;th class="head"&gt;20&lt;/th&gt;
&lt;th class="head"&gt;40&lt;/th&gt;
&lt;th class="head"&gt;60&lt;/th&gt;
&lt;th class="head"&gt;80&lt;/th&gt;
&lt;th class="head"&gt;100&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td&gt;g++-4.9.4&lt;/td&gt;
&lt;td&gt;264.27ns&lt;/td&gt;
&lt;td&gt;0.95us&lt;/td&gt;
&lt;td&gt;3.28us&lt;/td&gt;
&lt;td&gt;14.77us&lt;/td&gt;
&lt;td&gt;23.50us&lt;/td&gt;
&lt;td&gt;60.37us&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;g++-5.4.0&lt;/td&gt;
&lt;td&gt;271.41ns&lt;/td&gt;
&lt;td&gt;0.99us&lt;/td&gt;
&lt;td&gt;3.31us&lt;/td&gt;
&lt;td&gt;14.811us&lt;/td&gt;
&lt;td&gt;24.116us&lt;/td&gt;
&lt;td&gt;61.00us&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;g++-6.3.0&lt;/td&gt;
&lt;td&gt;279.72ns&lt;/td&gt;
&lt;td&gt;1.02us&lt;/td&gt;
&lt;td&gt;3.27us&lt;/td&gt;
&lt;td&gt;15.39us&lt;/td&gt;
&lt;td&gt;24.29us&lt;/td&gt;
&lt;td&gt;61.99us&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;g++-7.1.0&lt;/td&gt;
&lt;td&gt;273.74ns&lt;/td&gt;
&lt;td&gt;0.96us&lt;/td&gt;
&lt;td&gt;3.81us&lt;/td&gt;
&lt;td&gt;15.55us&lt;/td&gt;
&lt;td&gt;31.35us&lt;/td&gt;
&lt;td&gt;71.11us&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;clang++-3.9.1&lt;/td&gt;
&lt;td&gt;296.67ns&lt;/td&gt;
&lt;td&gt;1.34us&lt;/td&gt;
&lt;td&gt;4.18us&lt;/td&gt;
&lt;td&gt;19.93us&lt;/td&gt;
&lt;td&gt;33.15us&lt;/td&gt;
&lt;td&gt;82.60us&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;clang++-4.0.1&lt;/td&gt;
&lt;td&gt;322.68ns&lt;/td&gt;
&lt;td&gt;1.38us&lt;/td&gt;
&lt;td&gt;4.17us&lt;/td&gt;
&lt;td&gt;20.19us&lt;/td&gt;
&lt;td&gt;34.17us&lt;/td&gt;
&lt;td&gt;83.64us&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;zapcc++-1.0&lt;/td&gt;
&lt;td&gt;307.49ns&lt;/td&gt;
&lt;td&gt;1.41us&lt;/td&gt;
&lt;td&gt;4.10us&lt;/td&gt;
&lt;td&gt;19.72us&lt;/td&gt;
&lt;td&gt;33.72us&lt;/td&gt;
&lt;td&gt;84.80us&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table border="1" class="docutils"&gt;
&lt;colgroup&gt;
&lt;col width="14%"&gt;
&lt;col width="10%"&gt;
&lt;col width="8%"&gt;
&lt;col width="8%"&gt;
&lt;col width="8%"&gt;
&lt;col width="9%"&gt;
&lt;col width="9%"&gt;
&lt;col width="9%"&gt;
&lt;col width="9%"&gt;
&lt;col width="10%"&gt;
&lt;col width="10%"&gt;
&lt;/colgroup&gt;
&lt;thead valign="bottom"&gt;
&lt;tr&gt;&lt;th class="head"&gt;sgemm (vec)&lt;/th&gt;
&lt;th class="head"&gt;200&lt;/th&gt;
&lt;th class="head"&gt;300&lt;/th&gt;
&lt;th class="head"&gt;400&lt;/th&gt;
&lt;th class="head"&gt;500&lt;/th&gt;
&lt;th class="head"&gt;600&lt;/th&gt;
&lt;th class="head"&gt;700&lt;/th&gt;
&lt;th class="head"&gt;800&lt;/th&gt;
&lt;th class="head"&gt;900&lt;/th&gt;
&lt;th class="head"&gt;1000&lt;/th&gt;
&lt;th class="head"&gt;1200&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td&gt;g++-4.9.4&lt;/td&gt;
&lt;td&gt;369.52us&lt;/td&gt;
&lt;td&gt;1.62ms&lt;/td&gt;
&lt;td&gt;2.91ms&lt;/td&gt;
&lt;td&gt;7.17ms&lt;/td&gt;
&lt;td&gt;11.74ms&lt;/td&gt;
&lt;td&gt;22.91ms&lt;/td&gt;
&lt;td&gt;34.82ms&lt;/td&gt;
&lt;td&gt;51.67ms&lt;/td&gt;
&lt;td&gt;64.36ms&lt;/td&gt;
&lt;td&gt;111.15ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;g++-5.4.0&lt;/td&gt;
&lt;td&gt;387.54us&lt;/td&gt;
&lt;td&gt;1.60ms&lt;/td&gt;
&lt;td&gt;2.97ms&lt;/td&gt;
&lt;td&gt;7.36ms&lt;/td&gt;
&lt;td&gt;12.11ms&lt;/td&gt;
&lt;td&gt;24.37ms&lt;/td&gt;
&lt;td&gt;35.37ms&lt;/td&gt;
&lt;td&gt;52.27ms&lt;/td&gt;
&lt;td&gt;65.72ms&lt;/td&gt;
&lt;td&gt;112.74ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;g++-6.3.0&lt;/td&gt;
&lt;td&gt;384.43us&lt;/td&gt;
&lt;td&gt;1.74ms&lt;/td&gt;
&lt;td&gt;3.12ms&lt;/td&gt;
&lt;td&gt;7.16ms&lt;/td&gt;
&lt;td&gt;12.44ms&lt;/td&gt;
&lt;td&gt;24.15ms&lt;/td&gt;
&lt;td&gt;34.87ms&lt;/td&gt;
&lt;td&gt;52.59ms&lt;/td&gt;
&lt;td&gt;70.074ms&lt;/td&gt;
&lt;td&gt;119.22ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;g++-7.1.0&lt;/td&gt;
&lt;td&gt;458.05us&lt;/td&gt;
&lt;td&gt;1.81ms&lt;/td&gt;
&lt;td&gt;3.44ms&lt;/td&gt;
&lt;td&gt;7.86ms&lt;/td&gt;
&lt;td&gt;13.43ms&lt;/td&gt;
&lt;td&gt;24.70ms&lt;/td&gt;
&lt;td&gt;36.54ms&lt;/td&gt;
&lt;td&gt;53.47ms&lt;/td&gt;
&lt;td&gt;66.87ms&lt;/td&gt;
&lt;td&gt;117.25ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;clang++-3.9.1&lt;/td&gt;
&lt;td&gt;494.52us&lt;/td&gt;
&lt;td&gt;1.96ms&lt;/td&gt;
&lt;td&gt;4.80ms&lt;/td&gt;
&lt;td&gt;8.88ms&lt;/td&gt;
&lt;td&gt;18.20ms&lt;/td&gt;
&lt;td&gt;29.37ms&lt;/td&gt;
&lt;td&gt;41.24ms&lt;/td&gt;
&lt;td&gt;60.72ms&lt;/td&gt;
&lt;td&gt;72.28ms&lt;/td&gt;
&lt;td&gt;123.75ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;clang++-4.0.1&lt;/td&gt;
&lt;td&gt;511.24us&lt;/td&gt;
&lt;td&gt;2.04ms&lt;/td&gt;
&lt;td&gt;4.11ms&lt;/td&gt;
&lt;td&gt;9.46ms&lt;/td&gt;
&lt;td&gt;15.34ms&lt;/td&gt;
&lt;td&gt;27.23ms&lt;/td&gt;
&lt;td&gt;38.27ms&lt;/td&gt;
&lt;td&gt;58.14ms&lt;/td&gt;
&lt;td&gt;72.78ms&lt;/td&gt;
&lt;td&gt;128.60ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;zapcc++-1.0&lt;/td&gt;
&lt;td&gt;492.28us&lt;/td&gt;
&lt;td&gt;2.03ms&lt;/td&gt;
&lt;td&gt;3.90ms&lt;/td&gt;
&lt;td&gt;9.00ms&lt;/td&gt;
&lt;td&gt;14.31ms&lt;/td&gt;
&lt;td&gt;25.72ms&lt;/td&gt;
&lt;td&gt;37.09ms&lt;/td&gt;
&lt;td&gt;55.79ms&lt;/td&gt;
&lt;td&gt;67.88ms&lt;/td&gt;
&lt;td&gt;119.92ms&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;As for the optimized version, it seems that the two families are reversed.
Indeed, GCC is doing a better job than clang here, and although the margin is
not as big as before, it's still significant. We can still observe a small
regression in GCC versions because the 4.9 version is again the fastest. As for
clang versions, it seems that clang-5.0 (used in zapcc) has had some performance
improvements for this case.&lt;/p&gt;
&lt;p&gt;For this case of matrix-matrix multiplication, it's very impressive that the
differences in the non-optimized code are so significant. And it's also
impressive that each family of compilers has its own strength, clang being
seemingly much better at handling unoptimized code while GCC is better at
handling vectorized code.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="convolution-2d"&gt;
&lt;h3&gt;Convolution (2D)&lt;/h3&gt;
&lt;p&gt;The last benchmark that I considered is the case of the valid convolution on 2D
images. The code is quite similar to the GEMM code but more complicated to
optimized due to cache locality.&lt;/p&gt;
&lt;table border="1" class="docutils"&gt;
&lt;colgroup&gt;
&lt;col width="19%"&gt;
&lt;col width="9%"&gt;
&lt;col width="9%"&gt;
&lt;col width="9%"&gt;
&lt;col width="9%"&gt;
&lt;col width="9%"&gt;
&lt;col width="9%"&gt;
&lt;col width="10%"&gt;
&lt;col width="10%"&gt;
&lt;col width="10%"&gt;
&lt;/colgroup&gt;
&lt;thead valign="bottom"&gt;
&lt;tr&gt;&lt;th class="head"&gt;sconv2_valid (std)&lt;/th&gt;
&lt;th class="head"&gt;100x50&lt;/th&gt;
&lt;th class="head"&gt;105x50&lt;/th&gt;
&lt;th class="head"&gt;110x55&lt;/th&gt;
&lt;th class="head"&gt;115x55&lt;/th&gt;
&lt;th class="head"&gt;120x60&lt;/th&gt;
&lt;th class="head"&gt;125x60&lt;/th&gt;
&lt;th class="head"&gt;130x65&lt;/th&gt;
&lt;th class="head"&gt;135x65&lt;/th&gt;
&lt;th class="head"&gt;140x70&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td&gt;g++-4.9.4&lt;/td&gt;
&lt;td&gt;27.93ms&lt;/td&gt;
&lt;td&gt;33.68ms&lt;/td&gt;
&lt;td&gt;40.62ms&lt;/td&gt;
&lt;td&gt;48.23ms&lt;/td&gt;
&lt;td&gt;57.27ms&lt;/td&gt;
&lt;td&gt;67.02ms&lt;/td&gt;
&lt;td&gt;78.45ms&lt;/td&gt;
&lt;td&gt;92.53ms&lt;/td&gt;
&lt;td&gt;105.08ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;g++-5.4.0&lt;/td&gt;
&lt;td&gt;37.60ms&lt;/td&gt;
&lt;td&gt;44.94ms&lt;/td&gt;
&lt;td&gt;54.24ms&lt;/td&gt;
&lt;td&gt;64.45ms&lt;/td&gt;
&lt;td&gt;76.63ms&lt;/td&gt;
&lt;td&gt;89.75ms&lt;/td&gt;
&lt;td&gt;105.08ms&lt;/td&gt;
&lt;td&gt;121.66ms&lt;/td&gt;
&lt;td&gt;140.95ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;g++-6.3.0&lt;/td&gt;
&lt;td&gt;37.10ms&lt;/td&gt;
&lt;td&gt;44.99ms&lt;/td&gt;
&lt;td&gt;54.34ms&lt;/td&gt;
&lt;td&gt;64.54ms&lt;/td&gt;
&lt;td&gt;76.54ms&lt;/td&gt;
&lt;td&gt;89.87ms&lt;/td&gt;
&lt;td&gt;105.35ms&lt;/td&gt;
&lt;td&gt;121.94ms&lt;/td&gt;
&lt;td&gt;141.20ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;g++-7.1.0&lt;/td&gt;
&lt;td&gt;37.55ms&lt;/td&gt;
&lt;td&gt;45.08ms&lt;/td&gt;
&lt;td&gt;54.39ms&lt;/td&gt;
&lt;td&gt;64.48ms&lt;/td&gt;
&lt;td&gt;76.51ms&lt;/td&gt;
&lt;td&gt;92.02ms&lt;/td&gt;
&lt;td&gt;106.16ms&lt;/td&gt;
&lt;td&gt;125.67ms&lt;/td&gt;
&lt;td&gt;143.57ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;clang++-3.9.1&lt;/td&gt;
&lt;td&gt;15.42ms&lt;/td&gt;
&lt;td&gt;18.59ms&lt;/td&gt;
&lt;td&gt;22.21ms&lt;/td&gt;
&lt;td&gt;26.40ms&lt;/td&gt;
&lt;td&gt;31.03ms&lt;/td&gt;
&lt;td&gt;36.26ms&lt;/td&gt;
&lt;td&gt;42.35ms&lt;/td&gt;
&lt;td&gt;48.87ms&lt;/td&gt;
&lt;td&gt;56.29ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;clang++-4.0.1&lt;/td&gt;
&lt;td&gt;15.48ms&lt;/td&gt;
&lt;td&gt;18.67ms&lt;/td&gt;
&lt;td&gt;22.34ms&lt;/td&gt;
&lt;td&gt;26.50ms&lt;/td&gt;
&lt;td&gt;31.27ms&lt;/td&gt;
&lt;td&gt;36.58ms&lt;/td&gt;
&lt;td&gt;42.61ms&lt;/td&gt;
&lt;td&gt;49.33ms&lt;/td&gt;
&lt;td&gt;56.80ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;zapcc++-1.0&lt;/td&gt;
&lt;td&gt;15.29ms&lt;/td&gt;
&lt;td&gt;18.37ms&lt;/td&gt;
&lt;td&gt;22.00ms&lt;/td&gt;
&lt;td&gt;26.10ms&lt;/td&gt;
&lt;td&gt;30.75ms&lt;/td&gt;
&lt;td&gt;35.95ms&lt;/td&gt;
&lt;td&gt;41.85ms&lt;/td&gt;
&lt;td&gt;48.42ms&lt;/td&gt;
&lt;td&gt;55.74ms&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;In that case, we can observe the same as for the GEMM. The clang-based versions
are much producing significantly faster code than the GCC versions. Moreover, we
can also observe the same large regression starting from GCC-5.4.&lt;/p&gt;
&lt;table border="1" class="docutils"&gt;
&lt;colgroup&gt;
&lt;col width="21%"&gt;
&lt;col width="11%"&gt;
&lt;col width="9%"&gt;
&lt;col width="9%"&gt;
&lt;col width="9%"&gt;
&lt;col width="9%"&gt;
&lt;col width="9%"&gt;
&lt;col width="9%"&gt;
&lt;col width="9%"&gt;
&lt;col width="9%"&gt;
&lt;/colgroup&gt;
&lt;thead valign="bottom"&gt;
&lt;tr&gt;&lt;th class="head"&gt;sconv2_valid (vec)&lt;/th&gt;
&lt;th class="head"&gt;100x50&lt;/th&gt;
&lt;th class="head"&gt;105x50&lt;/th&gt;
&lt;th class="head"&gt;110x55&lt;/th&gt;
&lt;th class="head"&gt;115x55&lt;/th&gt;
&lt;th class="head"&gt;120x60&lt;/th&gt;
&lt;th class="head"&gt;125x60&lt;/th&gt;
&lt;th class="head"&gt;130x65&lt;/th&gt;
&lt;th class="head"&gt;135x65&lt;/th&gt;
&lt;th class="head"&gt;140x70&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td&gt;g++-4.9.4&lt;/td&gt;
&lt;td&gt;878.32us&lt;/td&gt;
&lt;td&gt;1.07ms&lt;/td&gt;
&lt;td&gt;1.20ms&lt;/td&gt;
&lt;td&gt;1.68ms&lt;/td&gt;
&lt;td&gt;2.04ms&lt;/td&gt;
&lt;td&gt;2.06ms&lt;/td&gt;
&lt;td&gt;2.54ms&lt;/td&gt;
&lt;td&gt;3.20ms&lt;/td&gt;
&lt;td&gt;4.14ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;g++-5.4.0&lt;/td&gt;
&lt;td&gt;853.73us&lt;/td&gt;
&lt;td&gt;1.03ms&lt;/td&gt;
&lt;td&gt;1.15ms&lt;/td&gt;
&lt;td&gt;1.36ms&lt;/td&gt;
&lt;td&gt;1.76ms&lt;/td&gt;
&lt;td&gt;2.05ms&lt;/td&gt;
&lt;td&gt;2.44ms&lt;/td&gt;
&lt;td&gt;2.91ms&lt;/td&gt;
&lt;td&gt;3.13ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;g++-6.3.0&lt;/td&gt;
&lt;td&gt;847.95us&lt;/td&gt;
&lt;td&gt;1.02ms&lt;/td&gt;
&lt;td&gt;1.14ms&lt;/td&gt;
&lt;td&gt;1.35ms&lt;/td&gt;
&lt;td&gt;1.74ms&lt;/td&gt;
&lt;td&gt;1.98ms&lt;/td&gt;
&lt;td&gt;2.43ms&lt;/td&gt;
&lt;td&gt;2.90ms&lt;/td&gt;
&lt;td&gt;3.12ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;g++-7.1.0&lt;/td&gt;
&lt;td&gt;795.82us&lt;/td&gt;
&lt;td&gt;0.93ms&lt;/td&gt;
&lt;td&gt;1.05ms&lt;/td&gt;
&lt;td&gt;1.24ms&lt;/td&gt;
&lt;td&gt;1.60ms&lt;/td&gt;
&lt;td&gt;1.77ms&lt;/td&gt;
&lt;td&gt;2.20ms&lt;/td&gt;
&lt;td&gt;2.69ms&lt;/td&gt;
&lt;td&gt;2.81ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;clang++-3.9.1&lt;/td&gt;
&lt;td&gt;782.46us&lt;/td&gt;
&lt;td&gt;0.93ms&lt;/td&gt;
&lt;td&gt;1.05ms&lt;/td&gt;
&lt;td&gt;1.26ms&lt;/td&gt;
&lt;td&gt;1.60ms&lt;/td&gt;
&lt;td&gt;1.84ms&lt;/td&gt;
&lt;td&gt;2.21ms&lt;/td&gt;
&lt;td&gt;2.65ms&lt;/td&gt;
&lt;td&gt;2.84ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;clang++-4.0.1&lt;/td&gt;
&lt;td&gt;767.58us&lt;/td&gt;
&lt;td&gt;0.92ms&lt;/td&gt;
&lt;td&gt;1.04ms&lt;/td&gt;
&lt;td&gt;1.25ms&lt;/td&gt;
&lt;td&gt;1.59ms&lt;/td&gt;
&lt;td&gt;1.83ms&lt;/td&gt;
&lt;td&gt;2.20ms&lt;/td&gt;
&lt;td&gt;2.62ms&lt;/td&gt;
&lt;td&gt;2.83ms&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;zapcc++-1.0&lt;/td&gt;
&lt;td&gt;782.49us&lt;/td&gt;
&lt;td&gt;0.94ms&lt;/td&gt;
&lt;td&gt;1.06ms&lt;/td&gt;
&lt;td&gt;1.27ms&lt;/td&gt;
&lt;td&gt;1.62ms&lt;/td&gt;
&lt;td&gt;1.83ms&lt;/td&gt;
&lt;td&gt;2.24ms&lt;/td&gt;
&lt;td&gt;2.65ms&lt;/td&gt;
&lt;td&gt;2.85ms&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;This time, clang manages to produce excellent results. Indeed, all the produced
executables are significantly faster than the versions produced by GCC, except
for GCC-7.1 which is producing similar results. The other versions of GCC are
falling behind it seems. It seems that it was only for the GEMM that clang was
having a lot of troubles handling the optimized code.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="conclusion"&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Clang seems to have recently done a lot of optimizations regarding compilation
time. Indeed, clang-4.0.1 is much faster for compilation than clang-3.9.
Although GCC-7.1 is faster than GCC-6.3, all the GCC versions are slower than
GCC-4.9.4 which is the fastest at compiling code with optimizations. GCC-7.1 is
the fastest GCC version for compiling code in debug mode.&lt;/p&gt;
&lt;p&gt;In some cases, there is almost no difference between different compilers in the
generated code. However, in more  complex algorithms such as the matrix-matrix
multiplication or the two-dimensional convolution, the differences can be quite
significant. In my tests, Clang have shown to be much better at compiling
unoptimized code. However, and especially in the GEMM case, it seems to be worse
than GCC at handling hand-optimized. I will investigate that case and try to
tailor the code so that clang is having a better time with it.&lt;/p&gt;
&lt;p&gt;For me, it's really weird that the GCC regression, apparently starting from
GCC-5.4, has still not been fixed in GCC 7.1. I was thinking of dropping support
for GCC-4.9 in order to go full C++14 support, but now I may have to reconsider
my position. However, seeing that GCC is generally the best at handling
optimized code (especially for GEMM), I may be able to do the transition, since
the optimized code will be used in most cases.&lt;/p&gt;
&lt;p&gt;As for zapcc, although it is still the fastest compiler in debug mode, with the
new speed of clang-4.0.1, its margin is quite small. Moreover, on optimized
build, it's not as fast as GCC. If you use clang and can have access to zapcc,
it's still quite a good option to save some time.&lt;/p&gt;
&lt;p&gt;Overall, I have been quite pleased by clang-4.0.1 and GCC-7.1, the most recent
versions I have been testing. It seems that they did quite some good work.
I will definitely run some more tests with them and try to adapt the code. I'm
still considering whether I will drop support for some older compilers.&lt;/p&gt;
&lt;p&gt;I hope this comparison was interesting :) My next post will probably be about
the difference in performance between my machine learning framework and other
frameworks to train neural networks.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;</description><category>C++</category><category>C++11</category><category>C++14</category><category>clang</category><category>Compilers</category><category>etl</category><category>gcc</category><category>Performance</category><category>projects</category><guid>http://baptiste-wicht.com/posts/2017/08/compiler-benchmark-gcc-clang-cpp-library-etl.html</guid><pubDate>Mon, 07 Aug 2017 07:16:21 GMT</pubDate></item><item><title>C++ Containers Benchmark: vector/list/deque and plf::colony</title><link>http://baptiste-wicht.com/posts/2017/05/cpp-containers-benchmark-vector-list-deque-plf-colony.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;div&gt;&lt;p&gt;Already more than three years ago, I've written a &lt;a class="reference external" href="https://baptiste-wicht.com/posts/2012/12/cpp-benchmark-vector-list-deque.html"&gt;benchmark of some of the STL containers&lt;/a&gt;,
namely the vector, the list and the deque. Since this article was very popular,
I decided to improve the benchmarks and collect again all the results. There are
now more benchmarks and some problems have been fixed in the benchmark code.
Moreover, I have also added a new container, the plf::colony. Therefore, there
are four containers tested:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;The std::vector: This is a dynamically-resized array of elements. All the
elements are contiguous in memory. If an element is inserted or removed it at
a position other than the end, the following elements will be moved to fill
the gap or to open a gap. Elements can be accessed at random position in
constant time. The array is resized so that it can several more elements, not
resized at each insert operation. This means that insertion at the end of the
container is done in amortized constant time.&lt;/li&gt;
&lt;li&gt;The std::deque: The deque is a container that offer constant time insertion
both at the front and at the back of the collection. In current c++ libraries,
it is implementation as a collection of dynamically allocated fixed-size
array. Not all elements are contiguous, but depending on the size of the data
type, this still has good data locality. Access to a random element is also
done in constant time, but with more overhead than the vector. For insertions
and removal at random positions, the elements are shifted either to the front
or to the back meaning that it is generally faster than the vector, by twice
in average.&lt;/li&gt;
&lt;li&gt;The std::list: This is a doubly-linked list. It supports constant time
insertions at any position of the collection. However, it does not support
constant time random access. The elements are obviously not contiguous, since
they are all allocated in nodes. For small elements, this collection has
a very big memory overhead.&lt;/li&gt;
&lt;li&gt;The plf::colony: This container is a non-standard container which is
unordered, it means that the insertion order will not necessarily be
preserved. It provides strong iterators guarantee, pointers to non-erased
element are not invalidated by insertion or erasure. It is especially tailored
for high-insertion/erasure workloads. Moreover, it is also specially optimized
for non-scalar types, namely structs and classes with relatively large data
size (greater than 128 bits on the official documentation). Its implementation
is more complicated than the other containers. It is also implemented as
a list of memory blocks, but they are of increasingly large sizes. When
elements are erased, there position is not removed, but marked as erased so
that it can be reused for fast insertion later on. This container uses the
same conventions as the standard containers and was proposed for inclusion to
the standard library, which is the main reason why it's included in this
benchmark. If you want more information, you can consult the
&lt;a class="reference external" href="http://plflib.org/colony.htm"&gt;official website&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In the text and results, the namespaces will be omitted. Note that I have only
included sequence containers in my test. These are the most common containers in
practices and these also the containers I'm the most familiar with. I could have
included multiset in this benchmark, but the interface and purpose being
different, I didn't want the benchmark to be confusing.&lt;/p&gt;
&lt;p&gt;All the examples are compiled with g++-4.9.4 (-std=c++11 -march=native -O2) and
run on a Gentoo Linux machine with an Intel Core i7-4770 at 3.4GHz.&lt;/p&gt;
&lt;p&gt;For each graph, the vertical axis represent the amount of time necessary to
perform the operations, so the lower values are the better. The horizontal axis
is always the number of elements of the collection. For some graph, the
logarithmic scale could be clearer, a button is available after each graph to
change the vertical scale to a logarithmic scale.&lt;/p&gt;
&lt;p&gt;The tests are done with several different data types. The trivial data types are
varying in size, they hold an array of longs and the size of the array varies to
change the size of the data type. The non-trivial data type is composed of
a string (just long enough to avoid SSO (Small String Optimization) (even though
I'm using GCC)). The non-trivial data types comes in a second version with
noexcept move operations.  Not all results are presented for each data types if
there are not significant differences between in order to keep this article
relatively short (it's already probably too long :P).&lt;/p&gt;
&lt;p class="more"&gt;&lt;a href="http://baptiste-wicht.com/posts/2017/05/cpp-containers-benchmark-vector-list-deque-plf-colony.html"&gt;Read moreâ€¦&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;</description><category>Benchmarks</category><category>C++</category><category>C++11</category><category>Performances</category><guid>http://baptiste-wicht.com/posts/2017/05/cpp-containers-benchmark-vector-list-deque-plf-colony.html</guid><pubDate>Sun, 21 May 2017 10:46:23 GMT</pubDate></item><item><title>Partial type erasing in Deep Learning Library (DLL) to improve compilation time</title><link>http://baptiste-wicht.com/posts/2017/03/partial-type-erasing-deep-learning-library-dll-improve-compilation-time.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;div&gt;&lt;p&gt;In a previous post, I compared the &lt;a class="reference external" href="https://baptiste-wicht.com/posts/2017/03/disappointing-zapcc-performance-on-deep-learning-library-dll.html"&gt;compilation time on my Deep Learning Library (DLL) project with different compilers&lt;/a&gt;. I realized that the compilation times were quickly going unreasonable for this library, especially for compiling the unit cases which clearly hurts the development of the library. Indeed, you want to be able to run the unit tests reasonably quickly after you integrated new changes.&lt;/p&gt;
&lt;div class="section" id="reduce-the-compilation-time"&gt;
&lt;h2&gt;Reduce the compilation time&lt;/h2&gt;
&lt;p&gt;The first thing I did was to split the compilation in three executables: one for
the unit tests, one for the various performance tests and one for the various other
miscellaneous tests. With this, it is much faster to compile only the unit test
cases.&lt;/p&gt;
&lt;p&gt;But this can be improved significantly more. In DLL a network is a variadic
template containing the list of layers, in order. In DLL, there are two main
different ways of declaring a neural networks. In the first version, the fast
version, the layers directly know their sizes:&lt;/p&gt;
&lt;pre class="code cpp"&gt;&lt;a name="rest_code_f16feeb38686463faeb78f276a61043d-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;using&lt;/span&gt; &lt;span class="n"&gt;network_t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;
&lt;a name="rest_code_f16feeb38686463faeb78f276a61043d-2"&gt;&lt;/a&gt;    &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dbn_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;
&lt;a name="rest_code_f16feeb38686463faeb78f276a61043d-3"&gt;&lt;/a&gt;        &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dbn_layers&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;
&lt;a name="rest_code_f16feeb38686463faeb78f276a61043d-4"&gt;&lt;/a&gt;            &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;rbm_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;28&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;28&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;500&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;momentum&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;64&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;layer_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_f16feeb38686463faeb78f276a61043d-5"&gt;&lt;/a&gt;            &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;rbm_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;500&lt;/span&gt;    &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;400&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;momentum&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;64&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;layer_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_f16feeb38686463faeb78f276a61043d-6"&gt;&lt;/a&gt;            &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;rbm_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;400&lt;/span&gt;    &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;momentum&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;64&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;hidden&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;unit_type&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;SOFTMAX&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;layer_t&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_f16feeb38686463faeb78f276a61043d-7"&gt;&lt;/a&gt;        &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;trainer&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;sgd_trainer&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;64&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;dbn_t&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_f16feeb38686463faeb78f276a61043d-8"&gt;&lt;/a&gt;
&lt;a name="rest_code_f16feeb38686463faeb78f276a61043d-9"&gt;&lt;/a&gt;&lt;span class="k"&gt;auto&lt;/span&gt; &lt;span class="n"&gt;network&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;make_unique&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;network_t&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;a name="rest_code_f16feeb38686463faeb78f276a61043d-10"&gt;&lt;/a&gt;&lt;span class="n"&gt;network&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;pretrain&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;training_images&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a name="rest_code_f16feeb38686463faeb78f276a61043d-11"&gt;&lt;/a&gt;&lt;span class="n"&gt;network&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;fine_tune&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;training_images&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;training_labels&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;In my opinion, this is the best way to use DLL. This is the fastest and the
clearest. Moreover, the dimensions of the network can be validated at compile
time, which is always better than at runtime. However, the dimensions of the
network cannot be changed at runtime.  For this, there is a different version,
the dynamic version:&lt;/p&gt;
&lt;pre class="code cpp"&gt;&lt;a name="rest_code_7dba155d64d04952aa1bff84e2570a48-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;using&lt;/span&gt; &lt;span class="n"&gt;network_t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;
&lt;a name="rest_code_7dba155d64d04952aa1bff84e2570a48-2"&gt;&lt;/a&gt;    &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dbn_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;
&lt;a name="rest_code_7dba155d64d04952aa1bff84e2570a48-3"&gt;&lt;/a&gt;        &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dbn_layers&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;
&lt;a name="rest_code_7dba155d64d04952aa1bff84e2570a48-4"&gt;&lt;/a&gt;            &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dyn_rbm_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;momentum&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;layer_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_7dba155d64d04952aa1bff84e2570a48-5"&gt;&lt;/a&gt;            &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dyn_rbm_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;momentum&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;layer_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_7dba155d64d04952aa1bff84e2570a48-6"&gt;&lt;/a&gt;            &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dyn_rbm_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;momentum&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;hidden&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;unit_type&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;SOFTMAX&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;layer_t&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_7dba155d64d04952aa1bff84e2570a48-7"&gt;&lt;/a&gt;        &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;64&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;trainer&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;sgd_trainer&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;dbn_t&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_7dba155d64d04952aa1bff84e2570a48-8"&gt;&lt;/a&gt;
&lt;a name="rest_code_7dba155d64d04952aa1bff84e2570a48-9"&gt;&lt;/a&gt;&lt;span class="k"&gt;auto&lt;/span&gt; &lt;span class="n"&gt;network&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;make_unique&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;network_t&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;a name="rest_code_7dba155d64d04952aa1bff84e2570a48-10"&gt;&lt;/a&gt;
&lt;a name="rest_code_7dba155d64d04952aa1bff84e2570a48-11"&gt;&lt;/a&gt;&lt;span class="n"&gt;network&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="k"&gt;template&lt;/span&gt; &lt;span class="n"&gt;layer_get&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;().&lt;/span&gt;&lt;span class="n"&gt;init_layer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;28&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;28&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;500&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a name="rest_code_7dba155d64d04952aa1bff84e2570a48-12"&gt;&lt;/a&gt;&lt;span class="n"&gt;network&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="k"&gt;template&lt;/span&gt; &lt;span class="n"&gt;layer_get&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;().&lt;/span&gt;&lt;span class="n"&gt;init_layer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;500&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;400&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a name="rest_code_7dba155d64d04952aa1bff84e2570a48-13"&gt;&lt;/a&gt;&lt;span class="n"&gt;network&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="k"&gt;template&lt;/span&gt; &lt;span class="n"&gt;layer_get&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;().&lt;/span&gt;&lt;span class="n"&gt;init_layer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;400&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a name="rest_code_7dba155d64d04952aa1bff84e2570a48-14"&gt;&lt;/a&gt;&lt;span class="n"&gt;network&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="k"&gt;template&lt;/span&gt; &lt;span class="n"&gt;layer_get&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;().&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;64&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_7dba155d64d04952aa1bff84e2570a48-15"&gt;&lt;/a&gt;&lt;span class="n"&gt;network&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="k"&gt;template&lt;/span&gt; &lt;span class="n"&gt;layer_get&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;().&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;64&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_7dba155d64d04952aa1bff84e2570a48-16"&gt;&lt;/a&gt;&lt;span class="n"&gt;network&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="k"&gt;template&lt;/span&gt; &lt;span class="n"&gt;layer_get&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;().&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;64&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_7dba155d64d04952aa1bff84e2570a48-17"&gt;&lt;/a&gt;
&lt;a name="rest_code_7dba155d64d04952aa1bff84e2570a48-18"&gt;&lt;/a&gt;&lt;span class="n"&gt;network&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;pretrain&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;training_images&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a name="rest_code_7dba155d64d04952aa1bff84e2570a48-19"&gt;&lt;/a&gt;&lt;span class="n"&gt;network&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;fine_tune&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;training_images&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;training_labels&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;This is a bit more verbose, but the configuration can be changed at runtime with
this system. Moreover, this is also faster to compile. On the other hand, there
is some performance slowdown.&lt;/p&gt;
&lt;p&gt;There is also a third version that is a hybrid of the first version:&lt;/p&gt;
&lt;pre class="code cpp"&gt;&lt;a name="rest_code_c95085d4c8b34af3ace718c536a89849-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;using&lt;/span&gt; &lt;span class="n"&gt;network_t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;
&lt;a name="rest_code_c95085d4c8b34af3ace718c536a89849-2"&gt;&lt;/a&gt;    &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dyn_dbn_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;
&lt;a name="rest_code_c95085d4c8b34af3ace718c536a89849-3"&gt;&lt;/a&gt;        &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dbn_layers&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;
&lt;a name="rest_code_c95085d4c8b34af3ace718c536a89849-4"&gt;&lt;/a&gt;            &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;rbm_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;28&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;28&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;500&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;momentum&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;64&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;layer_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_c95085d4c8b34af3ace718c536a89849-5"&gt;&lt;/a&gt;            &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;rbm_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;500&lt;/span&gt;    &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;400&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;momentum&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;64&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;layer_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_c95085d4c8b34af3ace718c536a89849-6"&gt;&lt;/a&gt;            &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;rbm_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;400&lt;/span&gt;    &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;momentum&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;64&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;hidden&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;unit_type&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;SOFTMAX&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;layer_t&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_c95085d4c8b34af3ace718c536a89849-7"&gt;&lt;/a&gt;        &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;trainer&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;sgd_trainer&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;64&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;dbn_t&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_c95085d4c8b34af3ace718c536a89849-8"&gt;&lt;/a&gt;
&lt;a name="rest_code_c95085d4c8b34af3ace718c536a89849-9"&gt;&lt;/a&gt;&lt;span class="k"&gt;auto&lt;/span&gt; &lt;span class="n"&gt;network&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;make_unique&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;network_t&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;a name="rest_code_c95085d4c8b34af3ace718c536a89849-10"&gt;&lt;/a&gt;&lt;span class="n"&gt;network&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;pretrain&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;training_images&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a name="rest_code_c95085d4c8b34af3ace718c536a89849-11"&gt;&lt;/a&gt;&lt;span class="n"&gt;network&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;fine_tune&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;training_images&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;training_labels&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;Only one line was changed compared to the first version, &lt;code&gt;dbn_desc&lt;/code&gt;
becomes &lt;code&gt;dyn_dbn_desc&lt;/code&gt;. What this changes is that all the layers are
automatically transformed into their dynamic versions and all the parameters are
propagated at runtime. This is a form a type erasing since the sizes will not be
propagated at compilation time. But this is simple since the types are simply
transformed from one type to another directly. Behind the scene, it's the
dynamic version using the front-end of the fast version. This is almost as fast
to compile as the dynamic version, but the code is much better. It executes the
same as the dynamic version.&lt;/p&gt;
&lt;p&gt;If we compare the compilation time of the three versions when compiling a single
network and 5 different networks with different architectures, we get the
following results (with clang):&lt;/p&gt;
&lt;table border="1" class="docutils"&gt;
&lt;colgroup&gt;
&lt;col width="52%"&gt;
&lt;col width="48%"&gt;
&lt;/colgroup&gt;
&lt;thead valign="bottom"&gt;
&lt;tr&gt;&lt;th class="head"&gt;Model&lt;/th&gt;
&lt;th class="head"&gt;Time [s]&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td&gt;1 Fast&lt;/td&gt;
&lt;td&gt;30&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;1 Dynamic&lt;/td&gt;
&lt;td&gt;16.6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;1 Hybrid&lt;/td&gt;
&lt;td&gt;16.6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;5 Fast&lt;/td&gt;
&lt;td&gt;114&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;5 Dynamic&lt;/td&gt;
&lt;td&gt;16.6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;5 Hybrid&lt;/td&gt;
&lt;td&gt;21.9&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Even with one single network, the compilation time is reduced by 44%. When five
different networks are compilation, time is reduced by 85%. This can be
explained easily. Indeed, for the hybrid and dynamic versions, the layers will
have the same type and therefore a lot of template instantiations will only be
done once instead of five times. This makes a lot of difference since almost
everything is template inside the library.&lt;/p&gt;
&lt;p&gt;Unfortunately, this also has an impact on the runtime of the network:&lt;/p&gt;
&lt;table border="1" class="docutils"&gt;
&lt;colgroup&gt;
&lt;col width="26%"&gt;
&lt;col width="41%"&gt;
&lt;col width="32%"&gt;
&lt;/colgroup&gt;
&lt;thead valign="bottom"&gt;
&lt;tr&gt;&lt;th class="head"&gt;Model&lt;/th&gt;
&lt;th class="head"&gt;Pretrain [s]&lt;/th&gt;
&lt;th class="head"&gt;Train [s]&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td&gt;Fast&lt;/td&gt;
&lt;td&gt;195&lt;/td&gt;
&lt;td&gt;114&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Dynamic&lt;/td&gt;
&lt;td&gt;203&lt;/td&gt;
&lt;td&gt;123&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Hybrid&lt;/td&gt;
&lt;td&gt;204&lt;/td&gt;
&lt;td&gt;122&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;On average, for dense models, the slowdown is between 4% and 8%. For
convolutional models, it is between 10% and 25%. I will definitely work on
trying to make the dynamic and especially the hybrid version faster in the
future, most on the work should be on the matrix library (ETL) that is used.&lt;/p&gt;
&lt;p&gt;Since for test cases, a 20% increase in runtime is not really a problem, tests
being fast already, I decided to add an option to DLL so that everything can be
compiled by default in hybrid model. By using a compilation flag, all the
&lt;code&gt;dbn_desc&lt;/code&gt; are becoming &lt;code&gt;dyn_dbn_desc&lt;/code&gt; and therefore each used
network is becoming a hybrid network. Without a single change in the code, the
compilation time of the entire library can be significantly improved, as seen in
the next section.  This can also be used in user code to improve compilation
time during debugging and experiments and can be turned off for the final
training.&lt;/p&gt;
&lt;p&gt;On my Continuous Integration system, I will build the system in both
configurations. This is not really an issue, since my personal machine at home
is more powerful than what I have available here.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="results"&gt;
&lt;h2&gt;Results&lt;/h2&gt;
&lt;p&gt;On a first experiment, I measured the difference before and after this change on
the three executables of the library, with gcc:&lt;/p&gt;
&lt;table border="1" class="docutils"&gt;
&lt;colgroup&gt;
&lt;col width="23%"&gt;
&lt;col width="26%"&gt;
&lt;col width="26%"&gt;
&lt;col width="26%"&gt;
&lt;/colgroup&gt;
&lt;thead valign="bottom"&gt;
&lt;tr&gt;&lt;th class="head"&gt;Model&lt;/th&gt;
&lt;th class="head"&gt;Unit [s]&lt;/th&gt;
&lt;th class="head"&gt;Perf [s]&lt;/th&gt;
&lt;th class="head"&gt;Misc [s]&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td&gt;Before&lt;/td&gt;
&lt;td&gt;1029&lt;/td&gt;
&lt;td&gt;192&lt;/td&gt;
&lt;td&gt;937&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;After&lt;/td&gt;
&lt;td&gt;617&lt;/td&gt;
&lt;td&gt;143&lt;/td&gt;
&lt;td&gt;619&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Speedup&lt;/td&gt;
&lt;td&gt;40.03%&lt;/td&gt;
&lt;td&gt;25.52%&lt;/td&gt;
&lt;td&gt;33.93%&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;It is clear that the speedups are very significant! The compilation is between
25% and 40% faster with the new option. Overall, this is a speedup of 36%!
I also noticed that the compilation takes significantly less memory than before.
Therefore, I decided to rerun the compiler benchmark on the library. In the
previous experiment, zapcc was taking so much memory that it was impossible to
use more than one thread. Let's see how it is faring now. The time to compile
the full unit tests is computed for each compiler. Let's start in debug mode:&lt;/p&gt;
&lt;table border="1" class="docutils"&gt;
&lt;colgroup&gt;
&lt;col width="23%"&gt;
&lt;col width="19%"&gt;
&lt;col width="19%"&gt;
&lt;col width="19%"&gt;
&lt;col width="19%"&gt;
&lt;/colgroup&gt;
&lt;thead valign="bottom"&gt;
&lt;tr&gt;&lt;th class="head"&gt;Debug&lt;/th&gt;
&lt;th class="head"&gt;-j1&lt;/th&gt;
&lt;th class="head"&gt;-j2&lt;/th&gt;
&lt;th class="head"&gt;-j3&lt;/th&gt;
&lt;th class="head"&gt;-j4&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td&gt;clang-3.9&lt;/td&gt;
&lt;td&gt;527&lt;/td&gt;
&lt;td&gt;268&lt;/td&gt;
&lt;td&gt;182&lt;/td&gt;
&lt;td&gt;150&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;gcc-4.9.3&lt;/td&gt;
&lt;td&gt;591&lt;/td&gt;
&lt;td&gt;303&lt;/td&gt;
&lt;td&gt;211&lt;/td&gt;
&lt;td&gt;176&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;gcc-5.3.0&lt;/td&gt;
&lt;td&gt;588&lt;/td&gt;
&lt;td&gt;302&lt;/td&gt;
&lt;td&gt;209&lt;/td&gt;
&lt;td&gt;175&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;zapcc-1.0&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;375&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;187&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;126&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;121&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;This time, zapcc is able to scale to four threads without problems. Moreover, it
is always the fastest compiler, by a significant margin, in this configuration.
It is followed by clang and then by gcc for which both versions are about the
same speed.&lt;/p&gt;
&lt;p&gt;If we compile again in release mode:&lt;/p&gt;
&lt;table border="1" class="docutils"&gt;
&lt;colgroup&gt;
&lt;col width="24%"&gt;
&lt;col width="20%"&gt;
&lt;col width="20%"&gt;
&lt;col width="20%"&gt;
&lt;col width="16%"&gt;
&lt;/colgroup&gt;
&lt;thead valign="bottom"&gt;
&lt;tr&gt;&lt;th class="head"&gt;Release&lt;/th&gt;
&lt;th class="head"&gt;-j1&lt;/th&gt;
&lt;th class="head"&gt;-j2&lt;/th&gt;
&lt;th class="head"&gt;-j3&lt;/th&gt;
&lt;th class="head"&gt;-j4&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td&gt;clang-3.9&lt;/td&gt;
&lt;td&gt;1201&lt;/td&gt;
&lt;td&gt;615&lt;/td&gt;
&lt;td&gt;421&lt;/td&gt;
&lt;td&gt;356&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;gcc-4.9.3&lt;/td&gt;
&lt;td&gt;1041&lt;/td&gt;
&lt;td&gt;541&lt;/td&gt;
&lt;td&gt;385&lt;/td&gt;
&lt;td&gt;321&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;gcc-5.3.0&lt;/td&gt;
&lt;td&gt;1114&lt;/td&gt;
&lt;td&gt;579&lt;/td&gt;
&lt;td&gt;412&lt;/td&gt;
&lt;td&gt;348&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;zapcc-1.0&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;897&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;457&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;306&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;em&gt;306&lt;/em&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The difference in compilation time is very large, it's twice slower to compile
with all optimizations enabled. It also takes significantly more memory. Indeed,
zapcc was not able to compile with 4 threads. Nevertheless, even the results
with three threads are better than the other compilers using four threads. zapcc
is clearly the winner again on this test, followed by gcc4-9 which is faster
than gcc-5.3 which is itself faster than clang. It seems that while clang is
better at frontend than gcc, it is slower for optimizations. Note that this may
also be an indication that clang performs more optimizations than gcc and may
not be slower.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="conclusion"&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;By using some form of type erasing to simplify the templates types at compile
time, I was able to reduce the overall compilation time of my Deep Learning
Library (DLL) by 36%. Moreover, this can be done by switching a simple
compilation flag. This also very significantly reduce the memory used during the
compilation, allowing zapcc to to compile with up to three threads, compared
with only one before. This makes zapcc the fastest compiler again on this
benchmark. Overall, this will make debugging much easier on this library and
will save me a lot of time.&lt;/p&gt;
&lt;p&gt;In the future, I plan to try to improve compilation time even more. I have a few
ideas, especially in ETL that should significantly improve the compilation time
but that will require a lot of time to implement, so that will likely have to
wait a while. In the coming days, I plan to work on the performance of DLL,
especially for stochastic gradient descent.&lt;/p&gt;
&lt;p&gt;If you want more information on DLL, you can check out the
&lt;a class="reference external" href="https://github.com/wichtounet/dll"&gt;dll Github repository&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;</description><category>C++</category><category>C++11</category><category>clang</category><category>Compilers</category><category>dll</category><category>etl</category><category>gcc</category><category>zapcc</category><guid>http://baptiste-wicht.com/posts/2017/03/partial-type-erasing-deep-learning-library-dll-improve-compilation-time.html</guid><pubDate>Wed, 15 Mar 2017 06:43:44 GMT</pubDate></item><item><title>PVS-Studio on C++ Library Review</title><link>http://baptiste-wicht.com/posts/2016/12/pvs-studio-on-cpp-library-review.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;div&gt;&lt;p&gt;PVS-Studio is a commercial static analyzer for C, C++ and C#. It works in both
Windows and Linux.&lt;/p&gt;
&lt;p&gt;It has been a long time since I wanted to test it on my projects. I contacted
The PVS-Studio team and they gave me a temporary license so that I can test the
tool and make a review.&lt;/p&gt;
&lt;p&gt;I tried the static analyzer on my Expression Templates Library (ETL) project.
This is a heavily-templated C++ library. I tried it on Linux of course.&lt;/p&gt;
&lt;div class="section" id="usage"&gt;
&lt;h2&gt;Usage&lt;/h2&gt;
&lt;p&gt;The installation is very simple, simply untar an archive and put the executables
in your PATH (or use absolute paths). There are also some deb and rpm packages
for some distributions. You need strace to make the analyzer work, it should be
available on any Linux platform.&lt;/p&gt;
&lt;p&gt;The usage of PVS-Studio on Linux should be straightforward. First, you can use the
analyzer directly with make and it will detect the invocations of the compiler.
For instance, here is the command I used for ETL:&lt;/p&gt;
&lt;pre class="code text"&gt;&lt;a name="rest_code_752c559723d548da94c2bd4eb5ff80c3-1"&gt;&lt;/a&gt;pvs-studio-analyzer trace -- make -j5 debug/bin/etl_test
&lt;/pre&gt;&lt;p&gt;Note that you can use several threads without issues, which is really great.
There does not seem to be any slowdown at this stage, probably only collecting
compiler arguments.&lt;/p&gt;
&lt;p&gt;This first step creates a strace_out file that will be used by the next stage.&lt;/p&gt;
&lt;p&gt;Once, the compilation has been analyzed, you can generate the results with the
analyze function, for which you'll need a license. Here is what I did:&lt;/p&gt;
&lt;pre class="code text"&gt;&lt;a name="rest_code_f580069643b4459c9ad1752698c2a779-1"&gt;&lt;/a&gt;pvs-studio-analyzer analyze -l ~/pvs_studio/PVS-Studio.lic -j5
&lt;/pre&gt;&lt;p&gt;Unfortunately, this didn't work for me:&lt;/p&gt;
&lt;pre class="code text"&gt;&lt;a name="rest_code_60665f89921a4298b44f12553e8ec726-1"&gt;&lt;/a&gt;No compilation units found
&lt;a name="rest_code_60665f89921a4298b44f12553e8ec726-2"&gt;&lt;/a&gt;Analysis finished in 0:00:00.00
&lt;/pre&gt;&lt;p&gt;Apparently, it's not able to use the strace_out it generated itself...&lt;/p&gt;
&lt;p&gt;Another possibility is to use the compilation database from clang to use
PVS-Studio. So I generated my compile_commands.json file again (it was not up to
date...) with &lt;a class="reference external" href="https://github.com/rizsotto/Bear"&gt;Bear&lt;/a&gt;. And then, you only
need to run the analyze step:&lt;/p&gt;
&lt;pre class="code text"&gt;&lt;a name="rest_code_6b00f9eef835477b94c8c676bd66966c-1"&gt;&lt;/a&gt;pvs-studio-analyzer analyze -l ~/pvs_studio/PVS-Studio.lic -j5
&lt;/pre&gt;&lt;p&gt;Make sure you have the same compiler configured than the one used to generate
the compilation database to avoid errors with compiler arguments.&lt;/p&gt;
&lt;p&gt;Unfortunately, this just printed a load of crap on my console:&lt;/p&gt;
&lt;pre class="code text"&gt;&lt;a name="rest_code_321fa4266d3d4657a65379ee2704342f-1"&gt;&lt;/a&gt;(L8Pu(]-'Lo8h&amp;gt;uo(_uv(uo2(-&amp;gt;'2h_u(uo2(uvU2K h&amp;gt;'o8a=}Lkk;x[G^%cuaa8acr[VS%
&lt;a name="rest_code_321fa4266d3d4657a65379ee2704342f-2"&gt;&lt;/a&gt;$ckUaoc8 c'8&amp;gt;_-o-8&amp;gt;U2cu/kau==-8&amp;gt;c-=cU2]Uf=c U2=u%c&amp;amp;kU__-&amp;gt;j}c@uvu2%cJ
&lt;a name="rest_code_321fa4266d3d4657a65379ee2704342f-3"&gt;&lt;/a&gt;(L8Pu(]-'Lo8h&amp;gt;uo(_uv(uo2(-&amp;gt;'2h_u(uo2(uvU2K h&amp;gt;'o8a=}Lkk;JVJ^%cuaa8acr[VS%
&lt;a name="rest_code_321fa4266d3d4657a65379ee2704342f-4"&gt;&lt;/a&gt;$ckUaoc8 c'8&amp;gt;_-o-8&amp;gt;U2cu/kau==-8&amp;gt;c-=cU2]Uf=c U2=u%c&amp;amp;kU__-&amp;gt;j}c@uvu2%cJ
&lt;a name="rest_code_321fa4266d3d4657a65379ee2704342f-5"&gt;&lt;/a&gt;(L8Pu(]-'Lo8h&amp;gt;uo(_uv(uo2(-&amp;gt;'2h_u(uo2(uvU2K h&amp;gt;'o8a=}Lkk;*[G^%cuaa8acr[VS%
&lt;a name="rest_code_321fa4266d3d4657a65379ee2704342f-6"&gt;&lt;/a&gt;$ckUaoc8 c'8&amp;gt;_-o-8&amp;gt;U2cu/kau==-8&amp;gt;c-=cU2]Uf=c U2=u%c&amp;amp;kU__-&amp;gt;j}c@uvu2%cJ
&lt;a name="rest_code_321fa4266d3d4657a65379ee2704342f-7"&gt;&lt;/a&gt;(L8Pu(]-'Lo8h&amp;gt;uo(_uv(uo2(-&amp;gt;'2h_u(uo2(uvU2K h&amp;gt;'o8a=}Lkk;b[b^%cuaa8acr[VS%
&lt;a name="rest_code_321fa4266d3d4657a65379ee2704342f-8"&gt;&lt;/a&gt;$ckUaoc8 c'8&amp;gt;_-o-8&amp;gt;U2cu/kau==-8&amp;gt;c-=cU2]Uf=c U2=u%c&amp;amp;kU__-&amp;gt;j}c@uvu2%cJ
&lt;a name="rest_code_321fa4266d3d4657a65379ee2704342f-9"&gt;&lt;/a&gt;(L8Pu(]-'Lo8h&amp;gt;uo(_uv(uo2(-&amp;gt;'2h_u(uo2(uvU2K h&amp;gt;'o8a=}Lkk;[[x^%cuaa8acr[VS%
&lt;a name="rest_code_321fa4266d3d4657a65379ee2704342f-10"&gt;&lt;/a&gt;$ckUaoc8 c'8&amp;gt;_-o-8&amp;gt;U2cu/kau==-8&amp;gt;c-=cU2]Uf=c U2=u%c&amp;amp;kU__-&amp;gt;j}c@uvu2%cJ
&lt;/pre&gt;&lt;p&gt;Pretty nice, isn't it ?&lt;/p&gt;
&lt;p&gt;Let's try again in a file:&lt;/p&gt;
&lt;pre class="code text"&gt;&lt;a name="rest_code_76c68ac3fa004470bff70317545dddc3-1"&gt;&lt;/a&gt;pvs-studio-analyzer analyze -o results.log -l ~/pvs_studio/PVS-Studio.lic -j5
&lt;/pre&gt;&lt;p&gt;The time is quite reasonable for the analysis, it took much less time than the
compilation time. In total, it took 88 seconds to analyze all the files. It's
much faster than the clang static analyzer.&lt;/p&gt;
&lt;p&gt;This time it worked, but the log file is not readable, you need to convert it
again:&lt;/p&gt;
&lt;pre class="code text"&gt;&lt;a name="rest_code_7fe83609152a4d95bffb4dbf29f1a676-1"&gt;&lt;/a&gt;plog-converter -t errorfile -o errors results.log
&lt;/pre&gt;&lt;p&gt;And finally, you can read the results of the analysis in the errors file.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="results"&gt;
&lt;h2&gt;Results&lt;/h2&gt;
&lt;p&gt;Overall, PVS-Studio found 236 messages in the ETL library, I was expecting more.
I also wish there was an HTML report that include the source code as well as the
error message. I had to lookup at the code for each message (you could integrate
it in vim and then use the quickfix window to do that). There are some
visualization but in things like QtCreator or LibreOffice which I don't have nor
want on my computer.&lt;/p&gt;
&lt;p&gt;Let's look at the results. For each message, I'll include the message from
PVS-Studio and the code if it's relevant.&lt;/p&gt;
&lt;p&gt;The first is about using the comma:&lt;/p&gt;
&lt;pre class="code text"&gt;&lt;a name="rest_code_d1cd556acbc948daa757274fdb086395-1"&gt;&lt;/a&gt;include/etl/traits.hpp:674:1: error: V521 Such expressions using the ',' operator are dangerous. Make sure the expression is correct.
&lt;a name="rest_code_d1cd556acbc948daa757274fdb086395-2"&gt;&lt;/a&gt;include/etl/traits.hpp:674:1: error: V685 Consider inspecting the return statement. The expression contains a comma.
&lt;/pre&gt;&lt;pre class="code cpp"&gt;&lt;a name="rest_code_56f52f0c63de49dab5e4937dde5d3b38-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;E&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_56f52f0c63de49dab5e4937dde5d3b38-2"&gt;&lt;/a&gt;&lt;span class="k"&gt;constexpr&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;dimensions&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="n"&gt;E&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;expr&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;noexcept&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;a name="rest_code_56f52f0c63de49dab5e4937dde5d3b38-3"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;void&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="n"&gt;expr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;etl_traits&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;E&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;dimensions&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;a name="rest_code_56f52f0c63de49dab5e4937dde5d3b38-4"&gt;&lt;/a&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;Here I'm simply using the comma operand to ignore expr to avoid a warning. To
make this compile in C++11, you need to do it in one line otherwise it's not
a constexpr function. It's probably not perfect to use this construct, but there
is no problem here.&lt;/p&gt;
&lt;p&gt;There is a bunch of these, let's filter them, it remains 207 warnings. Let's
jump to the next one:&lt;/p&gt;
&lt;pre class="code text"&gt;&lt;a name="rest_code_d447255158b94c23a01e76d8401783ef-1"&gt;&lt;/a&gt;include/etl/impl/blas/fft.hpp:29:1: error: V501 There are identical sub-expressions to the left and to the right of the '==' operator: (DFTI_SINGLE) == DFTI_SINGLE
&lt;/pre&gt;&lt;pre class="code cpp"&gt;&lt;a name="rest_code_1ffa634a24a04e80be401e49c3cf8bf6-1"&gt;&lt;/a&gt;&lt;span class="kr"&gt;inline&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="nf"&gt;fft_kernel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;complex&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;*&lt;/span&gt; &lt;span class="n"&gt;in&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;complex&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;*&lt;/span&gt; &lt;span class="n"&gt;out&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;a name="rest_code_1ffa634a24a04e80be401e49c3cf8bf6-2"&gt;&lt;/a&gt;    &lt;span class="n"&gt;DFTI_DESCRIPTOR_HANDLE&lt;/span&gt; &lt;span class="n"&gt;descriptor&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_1ffa634a24a04e80be401e49c3cf8bf6-3"&gt;&lt;/a&gt;
&lt;a name="rest_code_1ffa634a24a04e80be401e49c3cf8bf6-4"&gt;&lt;/a&gt;    &lt;span class="kt"&gt;void&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;in_ptr&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;const_cast&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kt"&gt;void&lt;/span&gt;&lt;span class="o"&gt;*&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;static_cast&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt;&lt;span class="o"&gt;*&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;in&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;
&lt;a name="rest_code_1ffa634a24a04e80be401e49c3cf8bf6-5"&gt;&lt;/a&gt;
&lt;a name="rest_code_1ffa634a24a04e80be401e49c3cf8bf6-6"&gt;&lt;/a&gt;    &lt;span class="n"&gt;DftiCreateDescriptor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;descriptor&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;DFTI_SINGLE&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;DFTI_COMPLEX&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="c1"&gt;//Specify size and precision&lt;/span&gt;
&lt;a name="rest_code_1ffa634a24a04e80be401e49c3cf8bf6-7"&gt;&lt;/a&gt;    &lt;span class="n"&gt;DftiSetValue&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;descriptor&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;DFTI_PLACEMENT&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;DFTI_NOT_INPLACE&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;         &lt;span class="c1"&gt;//Out of place FFT&lt;/span&gt;
&lt;a name="rest_code_1ffa634a24a04e80be401e49c3cf8bf6-8"&gt;&lt;/a&gt;    &lt;span class="n"&gt;DftiCommitDescriptor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;descriptor&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;                                   &lt;span class="c1"&gt;//Finalize the descriptor&lt;/span&gt;
&lt;a name="rest_code_1ffa634a24a04e80be401e49c3cf8bf6-9"&gt;&lt;/a&gt;    &lt;span class="n"&gt;DftiComputeForward&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;descriptor&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;in_ptr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;out&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;                        &lt;span class="c1"&gt;//Compute the Forward FFT&lt;/span&gt;
&lt;a name="rest_code_1ffa634a24a04e80be401e49c3cf8bf6-10"&gt;&lt;/a&gt;    &lt;span class="n"&gt;DftiFreeDescriptor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;descriptor&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;                                    &lt;span class="c1"&gt;//Free the descriptor&lt;/span&gt;
&lt;a name="rest_code_1ffa634a24a04e80be401e49c3cf8bf6-11"&gt;&lt;/a&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;Unfortunately, the error is inside the MKL library. Here, I really don't think
it's an issue. There is pack of them. I forgot to exclude non-ETL code from the
results. Once filter from all dependencies, 137 messages remain.&lt;/p&gt;
&lt;pre class="code text"&gt;&lt;a name="rest_code_111dd50645214eea853a6856282af689-1"&gt;&lt;/a&gt;include/etl/eval_functors.hpp:157:1: warning: V560 A part of conditional expression is always false: !padding.
&lt;/pre&gt;&lt;p&gt;This is true, but not an issue since padding is a configuration constant that
enables the use of padding in vector and matrices. There was 27 of these at
different locations and with different configuration variables.&lt;/p&gt;
&lt;pre class="code text"&gt;&lt;a name="rest_code_2fa08654a2444fc3a7666d703e66359d-1"&gt;&lt;/a&gt;include/etl/op/sub_view.hpp:161:1: note: V688 The 'i' function argument possesses the same name as one of the class members, which can result in a confusion.
&lt;/pre&gt;&lt;p&gt;This is again true, but not a bug in this particular case. It is still helpful and
I ended up changing these to avoid confusion. Again, there was a few of these.&lt;/p&gt;
&lt;pre class="code text"&gt;&lt;a name="rest_code_7d8f80daa6c642db8538f20b8bcfab0d-1"&gt;&lt;/a&gt;etl/test/src/conv_multi_multi.cpp:23:1: error: V573 Uninitialized variable 'k' was used. The variable was used to initialize itself.
&lt;/pre&gt;&lt;p&gt;This one is in the test code:&lt;/p&gt;
&lt;pre class="code cpp"&gt;&lt;a name="rest_code_60d95f6168254801a31c9a2a04517769-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;etl&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dim&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;K&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;a name="rest_code_60d95f6168254801a31c9a2a04517769-2"&gt;&lt;/a&gt;    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;etl&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dim&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;I&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;a name="rest_code_60d95f6168254801a31c9a2a04517769-3"&gt;&lt;/a&gt;        &lt;span class="n"&gt;C_ref&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;)(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;conv_2d_valid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;I&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;K&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt; &lt;span class="c1"&gt;// HERE&lt;/span&gt;
&lt;a name="rest_code_60d95f6168254801a31c9a2a04517769-4"&gt;&lt;/a&gt;    &lt;span class="p"&gt;}&lt;/span&gt;
&lt;a name="rest_code_60d95f6168254801a31c9a2a04517769-5"&gt;&lt;/a&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;I don't see any error, k is initialized correctly to zero in the first loop.
This is a &lt;strong&gt;false positive&lt;/strong&gt; for me. There were several of these in different
places. It seems to that the use of the operator() is confusing for PVS-Studio.&lt;/p&gt;
&lt;pre class="code text"&gt;&lt;a name="rest_code_b3dc5441d3e34bdeae62788ed1b8abb9-1"&gt;&lt;/a&gt;include/etl/traits.hpp:703:1: note: V659 Declarations of functions with 'rows' name differ in the 'const' keyword only, but the bodies of these functions have different composition. This is suspicious and can possibly be an error. Check lines: 693, 703.
&lt;/pre&gt;&lt;pre class="code cpp"&gt;&lt;a name="rest_code_7304c0f2a47a47e4ac438da342420d7f-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;E&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cpp_disable_if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;decay_traits&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;E&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;is_fast&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_7304c0f2a47a47e4ac438da342420d7f-2"&gt;&lt;/a&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;rows&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="n"&gt;E&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;expr&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="c1"&gt;//693&lt;/span&gt;
&lt;a name="rest_code_7304c0f2a47a47e4ac438da342420d7f-3"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;etl_traits&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;E&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;dim&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;expr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a name="rest_code_7304c0f2a47a47e4ac438da342420d7f-4"&gt;&lt;/a&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;a name="rest_code_7304c0f2a47a47e4ac438da342420d7f-5"&gt;&lt;/a&gt;
&lt;a name="rest_code_7304c0f2a47a47e4ac438da342420d7f-6"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;E&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cpp_enable_if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;decay_traits&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;E&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;is_fast&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_7304c0f2a47a47e4ac438da342420d7f-7"&gt;&lt;/a&gt;&lt;span class="k"&gt;constexpr&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;rows&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="n"&gt;E&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;expr&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;noexcept&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="c1"&gt;//703&lt;/span&gt;
&lt;a name="rest_code_7304c0f2a47a47e4ac438da342420d7f-8"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;void&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="n"&gt;expr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;etl_traits&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;E&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="k"&gt;template&lt;/span&gt; &lt;span class="n"&gt;dim&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;a name="rest_code_7304c0f2a47a47e4ac438da342420d7f-9"&gt;&lt;/a&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;Unfortunately, this is again a &lt;strong&gt;false positive&lt;/strong&gt; because PVS-Studio failed to
recognized SFINAE and therefore the warning is wrong.&lt;/p&gt;
&lt;pre class="code text"&gt;&lt;a name="rest_code_eb53724f5d234dfa905dafc7af1d94cc-1"&gt;&lt;/a&gt;include/etl/builder/expression_builder.hpp:345:1: note: V524 It is odd that the body of '&amp;gt;&amp;gt;=' function is fully equivalent to the body of '*=' function.
&lt;/pre&gt;&lt;p&gt;This one is interesting indeed. It is true that they are exactly because in ETL
&amp;gt;&amp;gt; is used for scalar element-wise multiplication. This is quite interesting that
PVS-Studio points that out. There was a few of these oddities but all were
normal in the library.&lt;/p&gt;
&lt;pre class="code text"&gt;&lt;a name="rest_code_a1311dfae763417186e8671f1800b60f-1"&gt;&lt;/a&gt;etl/test/src/compare.cpp:23:1: error: V501 There are identical sub-expressions to the left and to the right of the '!=' operator: a != a
&lt;/pre&gt;&lt;p&gt;Again, it is nice that PVS-Studio finds that, but this is done on purpose on the
tests to compare an object to itself. If I remove all the oddities in the test
cases, there are only 17 left in the headers. None of the warnings on the test
case was serious, but there was no more false positives either, so that's great.&lt;/p&gt;
&lt;pre class="code text"&gt;&lt;a name="rest_code_095a52ec6f7f49d0b15f39d99c079ea4-1"&gt;&lt;/a&gt;include/etl/impl/vec/sum.hpp:92:1: error: V591 Non-void function should return a value.
&lt;/pre&gt;&lt;pre class="code cpp"&gt;&lt;a name="rest_code_a0b062010d854e0fba1faada4751e938-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;L&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cpp_disable_if&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;vec_enabled&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;all_vectorizable&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;vector_mode&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;L&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_a0b062010d854e0fba1faada4751e938-2"&gt;&lt;/a&gt;&lt;span class="n"&gt;value_t&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;L&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="n"&gt;L&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;lhs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;first&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;last&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;a name="rest_code_a0b062010d854e0fba1faada4751e938-3"&gt;&lt;/a&gt;    &lt;span class="n"&gt;cpp_unused&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lhs&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a name="rest_code_a0b062010d854e0fba1faada4751e938-4"&gt;&lt;/a&gt;    &lt;span class="n"&gt;cpp_unused&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;first&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a name="rest_code_a0b062010d854e0fba1faada4751e938-5"&gt;&lt;/a&gt;    &lt;span class="n"&gt;cpp_unused&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;last&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a name="rest_code_a0b062010d854e0fba1faada4751e938-6"&gt;&lt;/a&gt;    &lt;span class="n"&gt;cpp_unreachable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"vec::sum called with invalid parameters"&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a name="rest_code_a0b062010d854e0fba1faada4751e938-7"&gt;&lt;/a&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;This one is interesting. It's not a false positive since indeed the function
does not return a value, but there is a __builtin_unreachable() inside the
function and it cannot be called. In my opinion, the static analyzer should be
able to handle that, but this is really a corner case.&lt;/p&gt;
&lt;pre class="code text"&gt;&lt;a name="rest_code_b219d74dbaed49e98ecdd5fe7500fe03-1"&gt;&lt;/a&gt;include/etl/sparse.hpp:148:1: note: V550 An odd precise comparison: a == 0.0. It's probably better to use a comparison with defined precision: fabs(A - B) &amp;lt; Epsilon.
&lt;/pre&gt;&lt;pre class="code cpp"&gt;&lt;a name="rest_code_59bd3ebbaf2c46708a11e8a0c16cd6e2-1"&gt;&lt;/a&gt;&lt;span class="kr"&gt;inline&lt;/span&gt; &lt;span class="kt"&gt;bool&lt;/span&gt; &lt;span class="nf"&gt;is_zero&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;double&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;a name="rest_code_59bd3ebbaf2c46708a11e8a0c16cd6e2-2"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mf"&gt;0.0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_59bd3ebbaf2c46708a11e8a0c16cd6e2-3"&gt;&lt;/a&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;This is not false, but again this is intended because of the comparison to zero
for a sparse matrix. There were 10 of these in the same class.&lt;/p&gt;
&lt;pre class="code text"&gt;&lt;a name="rest_code_c73e32153c654273bcf8e44990c0bd04-1"&gt;&lt;/a&gt;include/etl/impl/blas/fft.hpp:562:1: note: V656 Variables 'a_padded', 'b_padded' are initialized through the call to the same function. It's probably an error or un-optimized code. Consider inspecting the 'etl::size(c)' expression. Check lines: 561, 562.
&lt;/pre&gt;&lt;pre class="code cpp"&gt;&lt;a name="rest_code_04f673f4a3704d26bbcd988b927a6c9e-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;dyn_vector&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;etl&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;complex&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;type&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;a_padded&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;etl&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;
&lt;a name="rest_code_04f673f4a3704d26bbcd988b927a6c9e-2"&gt;&lt;/a&gt;&lt;span class="n"&gt;dyn_vector&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;etl&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;complex&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;type&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;b_padded&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;etl&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;It's indeed constructed with the same size, but for me I don't think it's an
odd pattern. I would not consider that as a warning, especially since it's
a constructor and not a assignment.&lt;/p&gt;
&lt;pre class="code text"&gt;&lt;a name="rest_code_552292314a2a423b8527c0a46569b066-1"&gt;&lt;/a&gt;include/etl/dyn_base.hpp:312:1: warning: V690 The 'dense_dyn_base' class implements a copy constructor, but lacks the '=' operator. It is dangerous to use such a class.
&lt;/pre&gt;&lt;p&gt;This is again a kind of corner case in the library because it's a base class
and the assignment is different between the sub classes and not a real
assignment in the C++ sense.&lt;/p&gt;
&lt;pre class="code text"&gt;&lt;a name="rest_code_30fc09ec90d6491d88e8d60d9b36579b-1"&gt;&lt;/a&gt;include/etl/impl/reduc/conv_multi.hpp:657:1: warning: V711 It is dangerous to create a local variable within a loop with a same name as a variable controlling this loop.
&lt;/pre&gt;&lt;pre class="code cpp"&gt;&lt;a name="rest_code_6b882fcce86f443e9696906ac056a024-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;a name="rest_code_6b882fcce86f443e9696906ac056a024-2"&gt;&lt;/a&gt;    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;K&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;a name="rest_code_6b882fcce86f443e9696906ac056a024-3"&gt;&lt;/a&gt;        &lt;span class="n"&gt;conv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;)(&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;conv_temp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;)(&lt;/span&gt;&lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a name="rest_code_6b882fcce86f443e9696906ac056a024-4"&gt;&lt;/a&gt;    &lt;span class="p"&gt;}&lt;/span&gt;
&lt;a name="rest_code_6b882fcce86f443e9696906ac056a024-5"&gt;&lt;/a&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;This is again a false positive... It really seems that PVS-Studio is not able to
handle the operator().&lt;/p&gt;
&lt;pre class="code text"&gt;&lt;a name="rest_code_6c7ed72cd5a74f9ebe874565aca49a35-1"&gt;&lt;/a&gt;include/etl/impl/pooling.hpp:396:1: error: V501 There are identical sub-expressions to the left and to the right of the '||' operator: P1 || P2 || P1
&lt;/pre&gt;&lt;pre class="code cpp"&gt;&lt;a name="rest_code_167a26b701f8409b9fcd72ea284ad765-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;C1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;C2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;C3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;S1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;S2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;S3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;P1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;P2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;P3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;M&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_167a26b701f8409b9fcd72ea284ad765-2"&gt;&lt;/a&gt;&lt;span class="k"&gt;static&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="n"&gt;apply&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;sub&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;M&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;m&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;a name="rest_code_167a26b701f8409b9fcd72ea284ad765-3"&gt;&lt;/a&gt;    &lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;o1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;etl&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dim&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sub&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;C1&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;P1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;S1&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_167a26b701f8409b9fcd72ea284ad765-4"&gt;&lt;/a&gt;    &lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;o2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;etl&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dim&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sub&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;C2&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;P2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;S2&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_167a26b701f8409b9fcd72ea284ad765-5"&gt;&lt;/a&gt;    &lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;o3&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;etl&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dim&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sub&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;C3&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;P3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;S3&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_167a26b701f8409b9fcd72ea284ad765-6"&gt;&lt;/a&gt;
&lt;a name="rest_code_167a26b701f8409b9fcd72ea284ad765-7"&gt;&lt;/a&gt;    &lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;P1&lt;/span&gt; &lt;span class="o"&gt;||&lt;/span&gt; &lt;span class="n"&gt;P2&lt;/span&gt; &lt;span class="o"&gt;||&lt;/span&gt; &lt;span class="n"&gt;P1&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;Last but not least, this time, it's entirely true and it's in fact a bug in my
code! The condition should be written like this:&lt;/p&gt;
&lt;pre class="code cpp"&gt;&lt;a name="rest_code_be83421ee5314baaaa1c96d426e6e9c0-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;P1&lt;/span&gt; &lt;span class="o"&gt;||&lt;/span&gt; &lt;span class="n"&gt;P2&lt;/span&gt; &lt;span class="o"&gt;||&lt;/span&gt; &lt;span class="n"&gt;P3&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;This is now fixed in the master of ETL.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="conclusion"&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;The installation was pretty easy, but the usage was not as easy as it could
because the first method by analyzing the build system did not work.
Fortunately, the system supports using the Clang compilation database directly
and therefore it was possible to use.&lt;/p&gt;
&lt;p&gt;Overall, it found 236 warnings on my code base (heavily templated library).
Around 50 of them were in some of the extend libraries, but I forgot to filter
them out. The quality of the results is pretty good in my opinion. It was able
to &lt;strong&gt;find a bug&lt;/strong&gt; in my implementation of pooling with padding. Unfortunately,
there was quite a few false positives, due to SFINAE, bad handling of the
operator() and no handling of __builtin_unreachable. The remaining were all
correct, but were not bug considering their usages.&lt;/p&gt;
&lt;p&gt;To conclude, I think it's a great static analyzer that is really fast compared
to other one in the market. There are a few false positives, but it's really not
bad compared to other tools and some of the messages are really great. An HTML
report including the source code would be great as well.&lt;/p&gt;
&lt;p&gt;If you want more information, you can consult
&lt;a class="reference external" href="http://www.viva64.com/en/pvs-studio/"&gt;the official site&lt;/a&gt;. There is even a way
to use it on open-source code for free, but you have to add comments on top of
each of your files.&lt;/p&gt;
&lt;p&gt;I hope it was helpful ;)&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;</description><category>C++</category><category>C++11</category><category>C++14</category><category>Review</category><category>Tools</category><guid>http://baptiste-wicht.com/posts/2016/12/pvs-studio-on-cpp-library-review.html</guid><pubDate>Tue, 20 Dec 2016 08:40:12 GMT</pubDate></item><item><title>Update: Thor, Thesis and Publications</title><link>http://baptiste-wicht.com/posts/2016/08/update-thor-thesis-and-publications.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;div&gt;&lt;p&gt;Since it's been a real while since the last post I've written here, I wanted to
write a short status update.&lt;/p&gt;
&lt;p&gt;I had to serve one month in the army, which does not help at all for
productivity :P Since the update to Boost Spirit X3, I haven't worked on my
eddic compiler again, but I've switched back to my operating system project:
thor. I'm having a lot of fun with it again and it's in much better state than
before.&lt;/p&gt;
&lt;p&gt;We also have been very productive on the publication side, with four new
publications this year in various conferences. I'll update the blog when the
proceedings are published. I'll be going to ICANN 2016 and ANNPR 2016 next week
and probably to ICFHR in October. And of course, I'll go back to Meeting C++ in
November :) As for my thesis, it's finally going great, I've started writing
regularly and it's taking form!&lt;/p&gt;
&lt;div class="section" id="thor"&gt;
&lt;h2&gt;Thor&lt;/h2&gt;
&lt;p&gt;My project Thor Operating System now has much more features than before:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;64bit operating system&lt;/li&gt;
&lt;li&gt;Preemptive Multiprocessing&lt;/li&gt;
&lt;li&gt;Keyboard / Mouse driver&lt;/li&gt;
&lt;li&gt;Full ACPI support with ACPICA&lt;/li&gt;
&lt;li&gt;Read/Write ATA driver&lt;/li&gt;
&lt;li&gt;FAT32 file system support&lt;/li&gt;
&lt;li&gt;HPET/RTC/PIT drivers&lt;/li&gt;
&lt;li&gt;Basic PCI support&lt;/li&gt;
&lt;li&gt;Multi stage booting with FAT32&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Since last time, I've fixed tons of bug in the system. Although there are still
some culprit, it's much more stable than before. They were a lot of bugs in the
scheduler with loads of race conditions. I hope I've working through most of
them now.&lt;/p&gt;
&lt;p&gt;I'm currently working on the network stack. I'm able to receive and send packets
using the Realtek 8139 card. I have working support for Ethernet, IP and ARP.
I'm currently working on adding ICMP support. I've come to realize that the
hardest part is not to develop the code here but to find a way to test it.
Network in Qemu is a huge pain in the ass to configure. And then, you need tools
to generate some packets or at least answer to packets send by the virtual
machine, and it's really bad... Nevertheless, it's pretty fun overall :)&lt;/p&gt;
&lt;p&gt;Aside from this, I'm also working on a window manager. I'll try to post an
update on this.&lt;/p&gt;
&lt;p&gt;You can take a look at the &lt;a class="reference external" href="https://github.com/wichtounet/thor-os"&gt;thor sources&lt;/a&gt; if you're interested.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="future"&gt;
&lt;h2&gt;Future&lt;/h2&gt;
&lt;p&gt;For the time being, I'll focus my effort on the thor project. I also have some
development to do on my home automation system: &lt;a class="reference external" href="https://github.com/wichtounet/asgard-server"&gt;asgard-server&lt;/a&gt; that I plan to finalize and deploy in a useful way this weekend in my apartment. You can also expect some updates on my deep learning library where I've started work to make it more user-friendly (kind of). I'm also still waiting on the first stable version of doctest for a new comparison with Catch.&lt;/p&gt;
&lt;p&gt;I really want to try to publish again some more posts on the blog. I'll
especially try to publish some more updates about Thor.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;</description><category>C++</category><category>C++11</category><category>deep learning</category><category>osdev</category><category>publications</category><category>thesis</category><category>thor</category><guid>http://baptiste-wicht.com/posts/2016/08/update-thor-thesis-and-publications.html</guid><pubDate>Tue, 23 Aug 2016 05:40:13 GMT</pubDate></item><item><title>Simulate static_if with C++11/C++14</title><link>http://baptiste-wicht.com/posts/2015/07/simulate-static_if-with-c11c14.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;div&gt;&lt;p&gt;If you are doing a lot of template metaprogramming and other template magic stuff, you are likely to miss a &lt;code&gt;static_if&lt;/code&gt; in the language. Unfortunately, it didn't make the cut for C++11 and it seems unlikely that it will make it in C++17.&lt;/p&gt;
&lt;div class="section" id="static-if"&gt;
&lt;h2&gt;static_if&lt;/h2&gt;
&lt;p&gt;As its name indicates, &lt;code&gt;static_if&lt;/code&gt; is an if statement but that is done at compile-time. At first, it could seem that the main point is performance, but that is not the case. With recent compilers, if you have an if statement with a compile-time constant, it will never be executed at runtime and only the correct branch will be included in the final executable code. However, even if the compiler knows that a branch will never be executed, it still has to ensure that this branch compiles. This is not the case with &lt;code&gt;static_if&lt;/code&gt;. With &lt;code&gt;static_if&lt;/code&gt;, only the valid branch is compiled, the other can contains invalid code. The most common reason to use a &lt;code&gt;static_if&lt;/code&gt; is inside a template where you perform a test on a template argument and execute code based on this test. &lt;code&gt;static_if&lt;/code&gt; has another advantage on standard if. Since only one branch is instantiated, it may save quite a lot of compile-time.&lt;/p&gt;
&lt;p&gt;Let's say we have to write a template function that, if the template argument is a string, removes the last character of the string argument, otherwise decrement the argument (I know, stupid example, but simple). With &lt;code&gt;static_if&lt;/code&gt;, you can write it like this:&lt;/p&gt;
&lt;pre class="code cpp"&gt;&lt;a name="rest_code_5a56a7671c364fefb2599c1522c67ba9-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_5a56a7671c364fefb2599c1522c67ba9-2"&gt;&lt;/a&gt;&lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="n"&gt;decrement_kindof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
&lt;a name="rest_code_5a56a7671c364fefb2599c1522c67ba9-3"&gt;&lt;/a&gt;    &lt;span class="n"&gt;static_if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;is_same&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;string&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
&lt;a name="rest_code_5a56a7671c364fefb2599c1522c67ba9-4"&gt;&lt;/a&gt;        &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pop_back&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;a name="rest_code_5a56a7671c364fefb2599c1522c67ba9-5"&gt;&lt;/a&gt;    &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;a name="rest_code_5a56a7671c364fefb2599c1522c67ba9-6"&gt;&lt;/a&gt;        &lt;span class="o"&gt;--&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_5a56a7671c364fefb2599c1522c67ba9-7"&gt;&lt;/a&gt;    &lt;span class="p"&gt;}&lt;/span&gt;
&lt;a name="rest_code_5a56a7671c364fefb2599c1522c67ba9-8"&gt;&lt;/a&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;I think it is quite elegant.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="the-problem"&gt;
&lt;h2&gt;The problem&lt;/h2&gt;
&lt;p&gt;Some may think, that we could do the same with C++ standard if statement:&lt;/p&gt;
&lt;pre class="code cpp"&gt;&lt;a name="rest_code_98f9c853ee274235a3776b7d86b5864c-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_98f9c853ee274235a3776b7d86b5864c-2"&gt;&lt;/a&gt;&lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="n"&gt;decrement_kindof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
&lt;a name="rest_code_98f9c853ee274235a3776b7d86b5864c-3"&gt;&lt;/a&gt;    &lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;is_same&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;string&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
&lt;a name="rest_code_98f9c853ee274235a3776b7d86b5864c-4"&gt;&lt;/a&gt;        &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pop_back&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;a name="rest_code_98f9c853ee274235a3776b7d86b5864c-5"&gt;&lt;/a&gt;    &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;a name="rest_code_98f9c853ee274235a3776b7d86b5864c-6"&gt;&lt;/a&gt;        &lt;span class="o"&gt;--&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_98f9c853ee274235a3776b7d86b5864c-7"&gt;&lt;/a&gt;    &lt;span class="p"&gt;}&lt;/span&gt;
&lt;a name="rest_code_98f9c853ee274235a3776b7d86b5864c-8"&gt;&lt;/a&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;However, this won't work. This template cannot be instantiated for &lt;code&gt;std::string&lt;/code&gt; since it doesn't have an operator -- and it cannot be instantiated for int since it doesn't have a &lt;code&gt;pop_back()&lt;/code&gt; function.&lt;/p&gt;
&lt;p&gt;There are two solutions in plain C++: specialization and SFINAE. Let's start with specialization:&lt;/p&gt;
&lt;pre class="code cpp"&gt;&lt;a name="rest_code_c5b6234c9b154d60be6f236996b922b7-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_c5b6234c9b154d60be6f236996b922b7-2"&gt;&lt;/a&gt;&lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="n"&gt;decrement_kindof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
&lt;a name="rest_code_c5b6234c9b154d60be6f236996b922b7-3"&gt;&lt;/a&gt;    &lt;span class="o"&gt;--&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_c5b6234c9b154d60be6f236996b922b7-4"&gt;&lt;/a&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;a name="rest_code_c5b6234c9b154d60be6f236996b922b7-5"&gt;&lt;/a&gt;
&lt;a name="rest_code_c5b6234c9b154d60be6f236996b922b7-6"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_c5b6234c9b154d60be6f236996b922b7-7"&gt;&lt;/a&gt;&lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="n"&gt;decrement_kindof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;string&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
&lt;a name="rest_code_c5b6234c9b154d60be6f236996b922b7-8"&gt;&lt;/a&gt;    &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pop_back&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;a name="rest_code_c5b6234c9b154d60be6f236996b922b7-9"&gt;&lt;/a&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;We do a specialization for &lt;code&gt;std::string&lt;/code&gt; case so that in the general case it uses -- and in the &lt;code&gt;std::string&lt;/code&gt; case, it uses &lt;code&gt;pop_back()&lt;/code&gt;. And the SFINAE version:&lt;/p&gt;
&lt;pre class="code cpp"&gt;&lt;a name="rest_code_e77d606f09c54467ae4dd072e9da2d67-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;enable_if_t&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;!&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;is_same&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;string&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;42&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_e77d606f09c54467ae4dd072e9da2d67-2"&gt;&lt;/a&gt;&lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="n"&gt;decrement_kindof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
&lt;a name="rest_code_e77d606f09c54467ae4dd072e9da2d67-3"&gt;&lt;/a&gt;    &lt;span class="o"&gt;--&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_e77d606f09c54467ae4dd072e9da2d67-4"&gt;&lt;/a&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;a name="rest_code_e77d606f09c54467ae4dd072e9da2d67-5"&gt;&lt;/a&gt;
&lt;a name="rest_code_e77d606f09c54467ae4dd072e9da2d67-6"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;enable_if_t&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;is_same&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;string&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;42&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_e77d606f09c54467ae4dd072e9da2d67-7"&gt;&lt;/a&gt;&lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="n"&gt;decrement_kindof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
&lt;a name="rest_code_e77d606f09c54467ae4dd072e9da2d67-8"&gt;&lt;/a&gt;    &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pop_back&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;a name="rest_code_e77d606f09c54467ae4dd072e9da2d67-9"&gt;&lt;/a&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;The first function is enabled when the type is not a &lt;code&gt;std::string&lt;/code&gt; and the second function is enabled when the type is a &lt;code&gt;std::string&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Both solutions needs two functions to make it work. In this particular case, specialization is easier since the condition states exactly one type. If the condition was more complex for instance testing that a constant inside the type is equals to some value, we could only do it with SFINAE.&lt;/p&gt;
&lt;p&gt;Even if both solutions work, both solutions are more complicated than the static_if version and both solutions are creating more functions than what should be necessary.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="one-solution"&gt;
&lt;h2&gt;One solution&lt;/h2&gt;
&lt;p&gt;There is one way to emulate a kind of &lt;code&gt;static_if&lt;/code&gt; with C++14 generic lambdas. It is kind of using anonymous template function to emulate what we did with the previous solutions but does it behind the scene. Here the code I'm using for this emulation:&lt;/p&gt;
&lt;pre class="code cpp"&gt;&lt;a name="rest_code_2e9dcdfc659046e8aa3c1c15cfcfd338-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;namespace&lt;/span&gt; &lt;span class="n"&gt;static_if_detail&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;a name="rest_code_2e9dcdfc659046e8aa3c1c15cfcfd338-2"&gt;&lt;/a&gt;
&lt;a name="rest_code_2e9dcdfc659046e8aa3c1c15cfcfd338-3"&gt;&lt;/a&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;identity&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;a name="rest_code_2e9dcdfc659046e8aa3c1c15cfcfd338-4"&gt;&lt;/a&gt;    &lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_2e9dcdfc659046e8aa3c1c15cfcfd338-5"&gt;&lt;/a&gt;    &lt;span class="n"&gt;T&lt;/span&gt; &lt;span class="k"&gt;operator&lt;/span&gt;&lt;span class="p"&gt;()(&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;a name="rest_code_2e9dcdfc659046e8aa3c1c15cfcfd338-6"&gt;&lt;/a&gt;        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;forward&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a name="rest_code_2e9dcdfc659046e8aa3c1c15cfcfd338-7"&gt;&lt;/a&gt;    &lt;span class="p"&gt;}&lt;/span&gt;
&lt;a name="rest_code_2e9dcdfc659046e8aa3c1c15cfcfd338-8"&gt;&lt;/a&gt;&lt;span class="p"&gt;};&lt;/span&gt;
&lt;a name="rest_code_2e9dcdfc659046e8aa3c1c15cfcfd338-9"&gt;&lt;/a&gt;
&lt;a name="rest_code_2e9dcdfc659046e8aa3c1c15cfcfd338-10"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kt"&gt;bool&lt;/span&gt; &lt;span class="n"&gt;Cond&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_2e9dcdfc659046e8aa3c1c15cfcfd338-11"&gt;&lt;/a&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;statement&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;a name="rest_code_2e9dcdfc659046e8aa3c1c15cfcfd338-12"&gt;&lt;/a&gt;    &lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;F&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_2e9dcdfc659046e8aa3c1c15cfcfd338-13"&gt;&lt;/a&gt;    &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="n"&gt;then&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="n"&gt;F&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
&lt;a name="rest_code_2e9dcdfc659046e8aa3c1c15cfcfd338-14"&gt;&lt;/a&gt;        &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;identity&lt;/span&gt;&lt;span class="p"&gt;());&lt;/span&gt;
&lt;a name="rest_code_2e9dcdfc659046e8aa3c1c15cfcfd338-15"&gt;&lt;/a&gt;    &lt;span class="p"&gt;}&lt;/span&gt;
&lt;a name="rest_code_2e9dcdfc659046e8aa3c1c15cfcfd338-16"&gt;&lt;/a&gt;
&lt;a name="rest_code_2e9dcdfc659046e8aa3c1c15cfcfd338-17"&gt;&lt;/a&gt;    &lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;F&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_2e9dcdfc659046e8aa3c1c15cfcfd338-18"&gt;&lt;/a&gt;    &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="n"&gt;else_&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="n"&gt;F&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="p"&gt;){}&lt;/span&gt;
&lt;a name="rest_code_2e9dcdfc659046e8aa3c1c15cfcfd338-19"&gt;&lt;/a&gt;&lt;span class="p"&gt;};&lt;/span&gt;
&lt;a name="rest_code_2e9dcdfc659046e8aa3c1c15cfcfd338-20"&gt;&lt;/a&gt;
&lt;a name="rest_code_2e9dcdfc659046e8aa3c1c15cfcfd338-21"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_2e9dcdfc659046e8aa3c1c15cfcfd338-22"&gt;&lt;/a&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;statement&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nb"&gt;false&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;a name="rest_code_2e9dcdfc659046e8aa3c1c15cfcfd338-23"&gt;&lt;/a&gt;    &lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;F&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_2e9dcdfc659046e8aa3c1c15cfcfd338-24"&gt;&lt;/a&gt;    &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="n"&gt;then&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="n"&gt;F&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="p"&gt;){}&lt;/span&gt;
&lt;a name="rest_code_2e9dcdfc659046e8aa3c1c15cfcfd338-25"&gt;&lt;/a&gt;
&lt;a name="rest_code_2e9dcdfc659046e8aa3c1c15cfcfd338-26"&gt;&lt;/a&gt;    &lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;F&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_2e9dcdfc659046e8aa3c1c15cfcfd338-27"&gt;&lt;/a&gt;    &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="n"&gt;else_&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="n"&gt;F&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
&lt;a name="rest_code_2e9dcdfc659046e8aa3c1c15cfcfd338-28"&gt;&lt;/a&gt;        &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;identity&lt;/span&gt;&lt;span class="p"&gt;());&lt;/span&gt;
&lt;a name="rest_code_2e9dcdfc659046e8aa3c1c15cfcfd338-29"&gt;&lt;/a&gt;    &lt;span class="p"&gt;}&lt;/span&gt;
&lt;a name="rest_code_2e9dcdfc659046e8aa3c1c15cfcfd338-30"&gt;&lt;/a&gt;&lt;span class="p"&gt;};&lt;/span&gt;
&lt;a name="rest_code_2e9dcdfc659046e8aa3c1c15cfcfd338-31"&gt;&lt;/a&gt;
&lt;a name="rest_code_2e9dcdfc659046e8aa3c1c15cfcfd338-32"&gt;&lt;/a&gt;&lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="c1"&gt;//end of namespace static_if_detail&lt;/span&gt;
&lt;a name="rest_code_2e9dcdfc659046e8aa3c1c15cfcfd338-33"&gt;&lt;/a&gt;
&lt;a name="rest_code_2e9dcdfc659046e8aa3c1c15cfcfd338-34"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kt"&gt;bool&lt;/span&gt; &lt;span class="n"&gt;Cond&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;F&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_2e9dcdfc659046e8aa3c1c15cfcfd338-35"&gt;&lt;/a&gt;&lt;span class="n"&gt;static_if_detail&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;statement&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;Cond&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;static_if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;F&lt;/span&gt; &lt;span class="k"&gt;const&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
&lt;a name="rest_code_2e9dcdfc659046e8aa3c1c15cfcfd338-36"&gt;&lt;/a&gt;    &lt;span class="n"&gt;static_if_detail&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;statement&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;Cond&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;if_&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_2e9dcdfc659046e8aa3c1c15cfcfd338-37"&gt;&lt;/a&gt;    &lt;span class="n"&gt;if_&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;then&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a name="rest_code_2e9dcdfc659046e8aa3c1c15cfcfd338-38"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;if_&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_2e9dcdfc659046e8aa3c1c15cfcfd338-39"&gt;&lt;/a&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;Note: I got the idea (and most of the code) from the &lt;a class="reference external" href="http://lists.boost.org/Archives/boost/2014/08/216607.php"&gt;Boost Mailing List&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The condition is passed a non-type template parameter and the code for the branch is a passed a generic lambda functor. The &lt;code&gt;static_if&lt;/code&gt; function returns a statement structure. We could avoid returning a struct and directly execute, or not, the functor based on the condition, but using a structure allows for the &lt;code&gt;else_&lt;/code&gt; part which may be practical. The structure &lt;code&gt;statement&lt;/code&gt; is specialized on the condition. If the condition is true, the right part will execute the functor while the false part will not execute anything. The specialization when the condition is false willl do the contrary. A special point here is the use of the identity function. The function is passed to the lambda. The user can then use this function to make non-dependent type dependent. This is necessary if we want to call functions on non-dependent types and these functions may not exist. For instance, you may want to call a function on &lt;code&gt;this&lt;/code&gt;, which is not a dependent type.&lt;/p&gt;
&lt;p&gt;Here is how the code will look using this solution:&lt;/p&gt;
&lt;pre class="code cpp"&gt;&lt;a name="rest_code_b78f161de1874265a482478bd74f0054-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_b78f161de1874265a482478bd74f0054-2"&gt;&lt;/a&gt;&lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="n"&gt;decrement_kindof&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
&lt;a name="rest_code_b78f161de1874265a482478bd74f0054-3"&gt;&lt;/a&gt;    &lt;span class="n"&gt;static_if&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;is_same&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;string&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="p"&gt;](&lt;/span&gt;&lt;span class="k"&gt;auto&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
&lt;a name="rest_code_b78f161de1874265a482478bd74f0054-4"&gt;&lt;/a&gt;        &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="n"&gt;pop_back&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;a name="rest_code_b78f161de1874265a482478bd74f0054-5"&gt;&lt;/a&gt;    &lt;span class="p"&gt;}).&lt;/span&gt;&lt;span class="n"&gt;else_&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="p"&gt;](&lt;/span&gt;&lt;span class="k"&gt;auto&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
&lt;a name="rest_code_b78f161de1874265a482478bd74f0054-6"&gt;&lt;/a&gt;        &lt;span class="o"&gt;--&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a name="rest_code_b78f161de1874265a482478bd74f0054-7"&gt;&lt;/a&gt;    &lt;span class="p"&gt;});&lt;/span&gt;
&lt;a name="rest_code_b78f161de1874265a482478bd74f0054-8"&gt;&lt;/a&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;It is not as elegant as the "real" &lt;code&gt;static_if&lt;/code&gt; version, but it is closer than the other solutions.&lt;/p&gt;
&lt;p&gt;If you don't use the lazy identity function (f), it still works on g++, but not on clang for some reasons.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="conclusion"&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;We saw that there are some solutions to emulate &lt;code&gt;static_if&lt;/code&gt; in C++ that you may use to make the code easier to read. I'm personally using this trick on branches with few lines of code and when I don't have to use the identity function too much, otherwise it is cleaner to use standard SFINAE functions to do the job. When you only have a if and no else, this trick is even better because that is where it saves the more code.&lt;/p&gt;
&lt;p&gt;I hope this can be useful to some of you ;)&lt;/p&gt;
&lt;p&gt;You can find my implementation &lt;a class="reference external" href="https://github.com/wichtounet/cpp_utils/blob/master/static_if.hpp"&gt;on Github&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;</description><category>C++</category><category>C++11</category><category>C++14</category><guid>http://baptiste-wicht.com/posts/2015/07/simulate-static_if-with-c11c14.html</guid><pubDate>Sun, 12 Jul 2015 13:23:34 GMT</pubDate></item><item><title>Named Optional Template parameters to configure a class at compile-time</title><link>http://baptiste-wicht.com/posts/2015/03/named-optional-template-parameters-compile-time.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;div&gt;&lt;p&gt;In this post, I'll describe a technique that can be used to configure a class at compile-time when there are multiple, optional parameters, with default values to this class. I used this technique in my dll project to configure each instance of Restricted Boltzmann Machine.&lt;/p&gt;
&lt;p&gt;The technique presented here will only work with C++11 because of the need for variadic template. This could be emulated without them by fixing a maximum number of parameters, but I won't go into this in this post.&lt;/p&gt;
&lt;div class="section" id="the-problem"&gt;
&lt;h2&gt;The problem&lt;/h2&gt;
&lt;p&gt;For this post, we'll take the case of a single class, let's call it configurable. This class has several parameters:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;A of type int&lt;/li&gt;
&lt;li&gt;B of type char&lt;/li&gt;
&lt;li&gt;C of an enum type&lt;/li&gt;
&lt;li&gt;D of type bool&lt;/li&gt;
&lt;li&gt;E is a type&lt;/li&gt;
&lt;li&gt;F is a template type&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This class could simply be written as such:&lt;/p&gt;
&lt;pre class="code c++"&gt;&lt;a name="rest_code_424e69d5f8e64602ae81688f4ffe65a3-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;enum&lt;/span&gt; &lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;type&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;a name="rest_code_424e69d5f8e64602ae81688f4ffe65a3-2"&gt;&lt;/a&gt;    &lt;span class="n"&gt;AAA&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_424e69d5f8e64602ae81688f4ffe65a3-3"&gt;&lt;/a&gt;    &lt;span class="n"&gt;BBB&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_424e69d5f8e64602ae81688f4ffe65a3-4"&gt;&lt;/a&gt;    &lt;span class="n"&gt;CCC&lt;/span&gt;
&lt;a name="rest_code_424e69d5f8e64602ae81688f4ffe65a3-5"&gt;&lt;/a&gt;&lt;span class="p"&gt;};&lt;/span&gt;
&lt;a name="rest_code_424e69d5f8e64602ae81688f4ffe65a3-6"&gt;&lt;/a&gt;
&lt;a name="rest_code_424e69d5f8e64602ae81688f4ffe65a3-7"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;T_A&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;char&lt;/span&gt; &lt;span class="n"&gt;T_B&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="sc"&gt;'b'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;type&lt;/span&gt; &lt;span class="n"&gt;T_C&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;type&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;BBB&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;bool&lt;/span&gt; &lt;span class="n"&gt;T_D&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;false&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;T_E&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;watcher_1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;T_F&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;trainer_1&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_424e69d5f8e64602ae81688f4ffe65a3-8"&gt;&lt;/a&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;configurable_v1&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;a name="rest_code_424e69d5f8e64602ae81688f4ffe65a3-9"&gt;&lt;/a&gt;    &lt;span class="k"&gt;static&lt;/span&gt; &lt;span class="k"&gt;constexpr&lt;/span&gt; &lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;T_A&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_424e69d5f8e64602ae81688f4ffe65a3-10"&gt;&lt;/a&gt;    &lt;span class="k"&gt;static&lt;/span&gt; &lt;span class="k"&gt;constexpr&lt;/span&gt; &lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="kt"&gt;char&lt;/span&gt; &lt;span class="n"&gt;B&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;T_B&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_424e69d5f8e64602ae81688f4ffe65a3-11"&gt;&lt;/a&gt;    &lt;span class="k"&gt;static&lt;/span&gt; &lt;span class="k"&gt;constexpr&lt;/span&gt; &lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="n"&gt;type&lt;/span&gt; &lt;span class="n"&gt;C&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;T_C&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_424e69d5f8e64602ae81688f4ffe65a3-12"&gt;&lt;/a&gt;    &lt;span class="k"&gt;static&lt;/span&gt; &lt;span class="k"&gt;constexpr&lt;/span&gt; &lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="kt"&gt;bool&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;T_D&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_424e69d5f8e64602ae81688f4ffe65a3-13"&gt;&lt;/a&gt;
&lt;a name="rest_code_424e69d5f8e64602ae81688f4ffe65a3-14"&gt;&lt;/a&gt;    &lt;span class="k"&gt;using&lt;/span&gt; &lt;span class="n"&gt;E&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;T_E&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_424e69d5f8e64602ae81688f4ffe65a3-15"&gt;&lt;/a&gt;
&lt;a name="rest_code_424e69d5f8e64602ae81688f4ffe65a3-16"&gt;&lt;/a&gt;    &lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_424e69d5f8e64602ae81688f4ffe65a3-17"&gt;&lt;/a&gt;    &lt;span class="k"&gt;using&lt;/span&gt; &lt;span class="n"&gt;F&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;T_F&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_424e69d5f8e64602ae81688f4ffe65a3-18"&gt;&lt;/a&gt;
&lt;a name="rest_code_424e69d5f8e64602ae81688f4ffe65a3-19"&gt;&lt;/a&gt;    &lt;span class="c1"&gt;//Something useful&lt;/span&gt;
&lt;a name="rest_code_424e69d5f8e64602ae81688f4ffe65a3-20"&gt;&lt;/a&gt;&lt;span class="p"&gt;};&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;and used simply as well:&lt;/p&gt;
&lt;pre class="code c++"&gt;&lt;a name="rest_code_343564584d2e4f0eb59324ec92d007d7-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;using&lt;/span&gt; &lt;span class="n"&gt;configurable_v1_t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;configurable_v1&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="sc"&gt;'z'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;type&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;CCC&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;true&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;watcher_2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;trainer_2&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;This works well and nothing is wrong with this code. However, if you want all default values but the last one, you have to specify each and every one of the previous template parameters as well. The first disadvantage is that it is verbose and tedious. Secondly, instead of using directly the default values implicitly, you have specified them. This means that if the default values are changed by the library authors or even by you in the configurable_v1 class, either all the usages will be out of sync or you'll have to update them. And again, this is not practical. Moreover, if the author of the configurable_v1 template adds new template parameters before the last, you'll have to update all the instantiation points as well.&lt;/p&gt;
&lt;p&gt;Moreover, here we only have 6 parameters, if you have more, the problem becomes even worse.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="the-solution"&gt;
&lt;h2&gt;The solution&lt;/h2&gt;
&lt;p&gt;What can we do to improve over these problems ? We are going to use variadic template parameters in the configurable class and use simple classes for each possible parameters. This will be done in the configurable_v2 class. At the end you could use the class as such:&lt;/p&gt;
&lt;pre class="code c++"&gt;&lt;a name="rest_code_8844cab7b0f94c289353add46a76da9e-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;using&lt;/span&gt; &lt;span class="n"&gt;configurable_v2_t1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;configurable_v2&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="sc"&gt;'z'&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;type&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;CCC&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;watcher_2&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;trainer_2&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_8844cab7b0f94c289353add46a76da9e-2"&gt;&lt;/a&gt;&lt;span class="k"&gt;using&lt;/span&gt; &lt;span class="n"&gt;configurable_v2_t2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;configurable_v2&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;trainer_2&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;You can note, that on the second line, we only specified the value for the last parameter without specifiyng any other value :) This is also much more flexible since the order of the parameters has absolutely no impact. Here, for the sake of the example, the parameters are badly named, so it is not very clear what this do, but in practice, you can give better names to the parameters and make the types more clear. Here is an example from my dll library:&lt;/p&gt;
&lt;pre class="code c++"&gt;&lt;a name="rest_code_7cbe5b424bed4cfcbc6dea71b08beccf-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;using&lt;/span&gt; &lt;span class="n"&gt;rbm_t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;rbm_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;
&lt;a name="rest_code_7cbe5b424bed4cfcbc6dea71b08beccf-2"&gt;&lt;/a&gt;    &lt;span class="mi"&gt;28&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;28&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_7cbe5b424bed4cfcbc6dea71b08beccf-3"&gt;&lt;/a&gt;   &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;25&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_7cbe5b424bed4cfcbc6dea71b08beccf-4"&gt;&lt;/a&gt;   &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;momentum&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_7cbe5b424bed4cfcbc6dea71b08beccf-5"&gt;&lt;/a&gt;   &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;weight_decay&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_7cbe5b424bed4cfcbc6dea71b08beccf-6"&gt;&lt;/a&gt;   &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;visible&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;unit_type&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;GAUSSIAN&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_7cbe5b424bed4cfcbc6dea71b08beccf-7"&gt;&lt;/a&gt;   &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;shuffle&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_7cbe5b424bed4cfcbc6dea71b08beccf-8"&gt;&lt;/a&gt;   &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;weight_type&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_7cbe5b424bed4cfcbc6dea71b08beccf-9"&gt;&lt;/a&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;rbm_t&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;rbm_desc is class that is configurable with this technique, expect that the first two parameters are mandatory and not named. I personally thinks that this is quite clear, but of course I may be biased ;)&lt;/p&gt;
&lt;p&gt;So let's code!&lt;/p&gt;
&lt;p&gt;The class declaration is quite simple:&lt;/p&gt;
&lt;pre class="code c++"&gt;&lt;a name="rest_code_6504c711ea454b1299fe9741741308a9-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt; &lt;span class="n"&gt;Args&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_6504c711ea454b1299fe9741741308a9-2"&gt;&lt;/a&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;configurable_v2&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;a name="rest_code_6504c711ea454b1299fe9741741308a9-3"&gt;&lt;/a&gt;    &lt;span class="c1"&gt;//Coming&lt;/span&gt;
&lt;a name="rest_code_6504c711ea454b1299fe9741741308a9-4"&gt;&lt;/a&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;We will now have to exact values and types from Args in order to get the 4 values, the type and the template type out of Args.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="extracting-integral-values"&gt;
&lt;h2&gt;Extracting integral values&lt;/h2&gt;
&lt;p&gt;We will start with the parameter &lt;em&gt;a&lt;/em&gt; that holds a value of type int with a default value of 1. Here is one way of writing it:&lt;/p&gt;
&lt;pre class="code c++"&gt;&lt;a name="rest_code_58720e5b92cd4472aa8adbff5bff0171-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;a_id&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_58720e5b92cd4472aa8adbff5bff0171-2"&gt;&lt;/a&gt;
&lt;a name="rest_code_58720e5b92cd4472aa8adbff5bff0171-3"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_58720e5b92cd4472aa8adbff5bff0171-4"&gt;&lt;/a&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="nl"&gt;a&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;integral_constant&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;a name="rest_code_58720e5b92cd4472aa8adbff5bff0171-5"&gt;&lt;/a&gt;    &lt;span class="k"&gt;using&lt;/span&gt; &lt;span class="n"&gt;type_id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;a_id&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_58720e5b92cd4472aa8adbff5bff0171-6"&gt;&lt;/a&gt;&lt;span class="p"&gt;};&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;So, &lt;em&gt;a&lt;/em&gt; is simply an integral constant with another typedef &lt;em&gt;type_id&lt;/em&gt;. Why do we need this id ? Because a is a type template, we cannot use std::is_same to compare it with other types, since its value is part of the type. If we had only int values, we could easily write a traits that indicates if the type is a specialization of a, but since will have several types, this would be a real pain to do and we would need such a traits for each possible type. Here the simple way to go is to add inner identifiers to each types.&lt;/p&gt;
&lt;p&gt;We can now write a struct to extract the int value for a from &lt;em&gt;Args&lt;/em&gt;. &lt;em&gt;Args&lt;/em&gt; is a list of types in the form parameter_name&amp;lt;parameter_value&amp;gt;... . We have to find a specialization of a inside this list. If such a specialization is present, we'll take its integral constant value as the value for a, otherwise, we'll take the default values. Here is what we want to do:&lt;/p&gt;
&lt;pre class="code c++"&gt;&lt;a name="rest_code_a273365c4f11453ab5ef28d9641c2ee5-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt; &lt;span class="n"&gt;Args&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_a273365c4f11453ab5ef28d9641c2ee5-2"&gt;&lt;/a&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;configurable_v2&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;a name="rest_code_a273365c4f11453ab5ef28d9641c2ee5-3"&gt;&lt;/a&gt;    &lt;span class="k"&gt;static&lt;/span&gt; &lt;span class="k"&gt;constexpr&lt;/span&gt; &lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;get_value_int&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Args&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_a273365c4f11453ab5ef28d9641c2ee5-4"&gt;&lt;/a&gt;
&lt;a name="rest_code_a273365c4f11453ab5ef28d9641c2ee5-5"&gt;&lt;/a&gt;    &lt;span class="c1"&gt;//Coming&lt;/span&gt;
&lt;a name="rest_code_a273365c4f11453ab5ef28d9641c2ee5-6"&gt;&lt;/a&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;We specify directly into the class the default values (1) for a and we use the class &lt;em&gt;get_value_int&lt;/em&gt; to get its value from the variadic type list. Here is the implementation:&lt;/p&gt;
&lt;pre class="code c++"&gt;&lt;a name="rest_code_6b85ebe5779f4fba95173bb6134edafa-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;typename&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt; &lt;span class="n"&gt;Args&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_6b85ebe5779f4fba95173bb6134edafa-2"&gt;&lt;/a&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;get_value_int&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_6b85ebe5779f4fba95173bb6134edafa-3"&gt;&lt;/a&gt;
&lt;a name="rest_code_6b85ebe5779f4fba95173bb6134edafa-4"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_6b85ebe5779f4fba95173bb6134edafa-5"&gt;&lt;/a&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;get_value_int&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;integral_constant&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;{};&lt;/span&gt;
&lt;a name="rest_code_6b85ebe5779f4fba95173bb6134edafa-6"&gt;&lt;/a&gt;
&lt;a name="rest_code_6b85ebe5779f4fba95173bb6134edafa-7"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;T2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;typename&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt; &lt;span class="n"&gt;Args&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_6b85ebe5779f4fba95173bb6134edafa-8"&gt;&lt;/a&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;get_value_int&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;T2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Args&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;a name="rest_code_6b85ebe5779f4fba95173bb6134edafa-9"&gt;&lt;/a&gt;    &lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;D2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;T22&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;Enable&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_6b85ebe5779f4fba95173bb6134edafa-10"&gt;&lt;/a&gt;    &lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="nl"&gt;impl&lt;/span&gt;
&lt;a name="rest_code_6b85ebe5779f4fba95173bb6134edafa-11"&gt;&lt;/a&gt;        &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;integral_constant&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;get_value_int&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Args&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;{};&lt;/span&gt;
&lt;a name="rest_code_6b85ebe5779f4fba95173bb6134edafa-12"&gt;&lt;/a&gt;
&lt;a name="rest_code_6b85ebe5779f4fba95173bb6134edafa-13"&gt;&lt;/a&gt;    &lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;D2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;T22&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_6b85ebe5779f4fba95173bb6134edafa-14"&gt;&lt;/a&gt;    &lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;impl&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;D2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;T22&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;enable_if_t&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;is_same&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;D2&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;type_id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;T22&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;type_id&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_6b85ebe5779f4fba95173bb6134edafa-15"&gt;&lt;/a&gt;        &lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;integral_constant&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;T22&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;{};&lt;/span&gt;
&lt;a name="rest_code_6b85ebe5779f4fba95173bb6134edafa-16"&gt;&lt;/a&gt;
&lt;a name="rest_code_6b85ebe5779f4fba95173bb6134edafa-17"&gt;&lt;/a&gt;    &lt;span class="k"&gt;static&lt;/span&gt; &lt;span class="k"&gt;constexpr&lt;/span&gt; &lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;impl&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;T2&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_6b85ebe5779f4fba95173bb6134edafa-18"&gt;&lt;/a&gt;&lt;span class="p"&gt;};&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;If you are not really familiar with Template Metaprogramming (TMP), this may seems very unfamiliar or even barbaric, but I'll try to explain into details what is going on here :)&lt;/p&gt;
&lt;p&gt;&lt;em&gt;get_value_int&lt;/em&gt; is a template that takes a type D, representing the parameter we want to extract and its default, and the list of args. It has a first partial specialization for the case when Args is empty. In which case, its value is simply the value inside D (the default value). The second partial specialization handles the case when there are at least one type (T2) inside the list of args. This separation in two partial specialization is the standard way to works with variadic template parameters. This specialization is more complicated than the first one since it uses an inner class to get the value out of the list. The inner class (impl) takes the parameter type (D2), the type that is present in the list (T22) and a special parameter (Enable) that is used for SFINAE. If you're not familiar with SFINAE (you're probably not reading this article...), it is, put simply, a mean to activate or deactivate a template class or function based on its template parameters. Here, the partial specialization of &lt;em&gt;impl&lt;/em&gt; is enabled if &lt;em&gt;T22&lt;/em&gt; and &lt;em&gt;D2&lt;/em&gt; have the same &lt;em&gt;type_id&lt;/em&gt;, in which case, the value of &lt;em&gt;T22&lt;/em&gt; is taken as the return of &lt;em&gt;impl&lt;/em&gt;. In the basic case, template recursion is used to continue iterating over the list of types. The fact that this has to be done into two template classes is because we cannot add a new template parameter to a partial template specialization even without a name. We cannot either add a simple &lt;em&gt;Enable&lt;/em&gt; parameter to get_value_int, we cannot put before Args since then it would be necessary to give it a value in the code that uses it which is not practical neither a good practice.&lt;/p&gt;
&lt;p&gt;We can now do the same for b that is of type char. Here is the parameter definition for b:&lt;/p&gt;
&lt;pre class="code c++"&gt;&lt;a name="rest_code_aa777b532d954b4e87e6eb917a92be10-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;a_id&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_aa777b532d954b4e87e6eb917a92be10-2"&gt;&lt;/a&gt;
&lt;a name="rest_code_aa777b532d954b4e87e6eb917a92be10-3"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_aa777b532d954b4e87e6eb917a92be10-4"&gt;&lt;/a&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="nl"&gt;a&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;integral_constant&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;a name="rest_code_aa777b532d954b4e87e6eb917a92be10-5"&gt;&lt;/a&gt;    &lt;span class="k"&gt;using&lt;/span&gt; &lt;span class="n"&gt;type_id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;a_id&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_aa777b532d954b4e87e6eb917a92be10-6"&gt;&lt;/a&gt;&lt;span class="p"&gt;};&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;This code is highly similar to the code for a, so we can generalize a bit this with a base class:&lt;/p&gt;
&lt;pre class="code c++"&gt;&lt;a name="rest_code_3f51da93438141dfb2f43518bc2b7ab8-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;a_id&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_3f51da93438141dfb2f43518bc2b7ab8-2"&gt;&lt;/a&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;b_id&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_3f51da93438141dfb2f43518bc2b7ab8-3"&gt;&lt;/a&gt;
&lt;a name="rest_code_3f51da93438141dfb2f43518bc2b7ab8-4"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;ID&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;T&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_3f51da93438141dfb2f43518bc2b7ab8-5"&gt;&lt;/a&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="nl"&gt;value_conf_t&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;integral_constant&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;a name="rest_code_3f51da93438141dfb2f43518bc2b7ab8-6"&gt;&lt;/a&gt;    &lt;span class="k"&gt;using&lt;/span&gt; &lt;span class="n"&gt;type_id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ID&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_3f51da93438141dfb2f43518bc2b7ab8-7"&gt;&lt;/a&gt;&lt;span class="p"&gt;};&lt;/span&gt;
&lt;a name="rest_code_3f51da93438141dfb2f43518bc2b7ab8-8"&gt;&lt;/a&gt;
&lt;a name="rest_code_3f51da93438141dfb2f43518bc2b7ab8-9"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_3f51da93438141dfb2f43518bc2b7ab8-10"&gt;&lt;/a&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="nl"&gt;a&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;value_conf_t&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;a_id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;{};&lt;/span&gt;
&lt;a name="rest_code_3f51da93438141dfb2f43518bc2b7ab8-11"&gt;&lt;/a&gt;
&lt;a name="rest_code_3f51da93438141dfb2f43518bc2b7ab8-12"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kt"&gt;char&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_3f51da93438141dfb2f43518bc2b7ab8-13"&gt;&lt;/a&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="nl"&gt;b&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;value_conf_t&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;b_id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;char&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;{};&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;This make the next  parameters easier to describe and avoids small mistakes.&lt;/p&gt;
&lt;p&gt;Making &lt;em&gt;get_value_char&lt;/em&gt; could be achieved by replacing each &lt;em&gt;int&lt;/em&gt; by &lt;em&gt;char&lt;/em&gt; but this would create a lot of duplicated code. So instead of writing &lt;em&gt;get_value_char&lt;/em&gt;, we will replace &lt;em&gt;get_value_int&lt;/em&gt; with a generic &lt;em&gt;get_value&lt;/em&gt; that is able to extract any integral value type:&lt;/p&gt;
&lt;pre class="code c++"&gt;&lt;a name="rest_code_950a9b9d0a79469a8a77665c552ec52b-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;typename&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt; &lt;span class="n"&gt;Args&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_950a9b9d0a79469a8a77665c552ec52b-2"&gt;&lt;/a&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;get_value&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_950a9b9d0a79469a8a77665c552ec52b-3"&gt;&lt;/a&gt;
&lt;a name="rest_code_950a9b9d0a79469a8a77665c552ec52b-4"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;T2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;typename&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt; &lt;span class="n"&gt;Args&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_950a9b9d0a79469a8a77665c552ec52b-5"&gt;&lt;/a&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;get_value&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;T2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Args&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;a name="rest_code_950a9b9d0a79469a8a77665c552ec52b-6"&gt;&lt;/a&gt;    &lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;D2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;T22&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;Enable&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_950a9b9d0a79469a8a77665c552ec52b-7"&gt;&lt;/a&gt;    &lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="nl"&gt;impl&lt;/span&gt;
&lt;a name="rest_code_950a9b9d0a79469a8a77665c552ec52b-8"&gt;&lt;/a&gt;        &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;integral_constant&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;decltype&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;get_value&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Args&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;{};&lt;/span&gt;
&lt;a name="rest_code_950a9b9d0a79469a8a77665c552ec52b-9"&gt;&lt;/a&gt;
&lt;a name="rest_code_950a9b9d0a79469a8a77665c552ec52b-10"&gt;&lt;/a&gt;    &lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;D2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;T22&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_950a9b9d0a79469a8a77665c552ec52b-11"&gt;&lt;/a&gt;    &lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;impl&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;D2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;T22&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;enable_if_t&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;is_same&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;D2&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;type_id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;T22&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;type_id&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_950a9b9d0a79469a8a77665c552ec52b-12"&gt;&lt;/a&gt;        &lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;integral_constant&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;decltype&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;T22&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;{};&lt;/span&gt;
&lt;a name="rest_code_950a9b9d0a79469a8a77665c552ec52b-13"&gt;&lt;/a&gt;
&lt;a name="rest_code_950a9b9d0a79469a8a77665c552ec52b-14"&gt;&lt;/a&gt;    &lt;span class="k"&gt;static&lt;/span&gt; &lt;span class="k"&gt;constexpr&lt;/span&gt; &lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="k"&gt;auto&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;impl&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;T2&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_950a9b9d0a79469a8a77665c552ec52b-15"&gt;&lt;/a&gt;&lt;span class="p"&gt;};&lt;/span&gt;
&lt;a name="rest_code_950a9b9d0a79469a8a77665c552ec52b-16"&gt;&lt;/a&gt;
&lt;a name="rest_code_950a9b9d0a79469a8a77665c552ec52b-17"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_950a9b9d0a79469a8a77665c552ec52b-18"&gt;&lt;/a&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;get_value&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;integral_constant&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;decltype&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;{};&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;This code is almost the same as get_value_int except that the return type is deduced from the value of the parameters. I used &lt;em&gt;decltype&lt;/em&gt; and &lt;em&gt;auto&lt;/em&gt; to automatically gets the correct types for the values. This is the only thing that changed.&lt;/p&gt;
&lt;p&gt;With that we are ready the parameter c as well:&lt;/p&gt;
&lt;pre class="code c++"&gt;&lt;a name="rest_code_b992aa3901e443da8c516f5e77873262-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt; &lt;span class="n"&gt;Args&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_b992aa3901e443da8c516f5e77873262-2"&gt;&lt;/a&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;configurable_v2&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;a name="rest_code_b992aa3901e443da8c516f5e77873262-3"&gt;&lt;/a&gt;    &lt;span class="k"&gt;static&lt;/span&gt; &lt;span class="k"&gt;constexpr&lt;/span&gt; &lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="k"&gt;auto&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;get_value&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Args&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_b992aa3901e443da8c516f5e77873262-4"&gt;&lt;/a&gt;    &lt;span class="k"&gt;static&lt;/span&gt; &lt;span class="k"&gt;constexpr&lt;/span&gt; &lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="k"&gt;auto&lt;/span&gt; &lt;span class="n"&gt;B&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;get_value&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="sc"&gt;'b'&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Args&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_b992aa3901e443da8c516f5e77873262-5"&gt;&lt;/a&gt;    &lt;span class="k"&gt;static&lt;/span&gt; &lt;span class="k"&gt;constexpr&lt;/span&gt; &lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="k"&gt;auto&lt;/span&gt; &lt;span class="n"&gt;C&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;get_value&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;type&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;BBB&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Args&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_b992aa3901e443da8c516f5e77873262-6"&gt;&lt;/a&gt;
&lt;a name="rest_code_b992aa3901e443da8c516f5e77873262-7"&gt;&lt;/a&gt;    &lt;span class="c1"&gt;//Coming&lt;/span&gt;
&lt;a name="rest_code_b992aa3901e443da8c516f5e77873262-8"&gt;&lt;/a&gt;&lt;span class="p"&gt;};&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class="section" id="extracting-boolean-flags"&gt;
&lt;h2&gt;Extracting boolean flags&lt;/h2&gt;
&lt;p&gt;The parameter d is a bit different since it is a boolean flag that puts directly the value to true. We could simply make a integral boolean value (and this would work), but here I needed a boolean flag for activating a feature deactivated by default.&lt;/p&gt;
&lt;p&gt;Defining the parameter is easy:&lt;/p&gt;
&lt;pre class="code c++"&gt;&lt;a name="rest_code_a59b25b983214368a262465d66b29cb0-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;ID&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_a59b25b983214368a262465d66b29cb0-2"&gt;&lt;/a&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;basic_conf_t&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;a name="rest_code_a59b25b983214368a262465d66b29cb0-3"&gt;&lt;/a&gt;    &lt;span class="k"&gt;using&lt;/span&gt; &lt;span class="n"&gt;type_id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ID&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_a59b25b983214368a262465d66b29cb0-4"&gt;&lt;/a&gt;&lt;span class="p"&gt;};&lt;/span&gt;
&lt;a name="rest_code_a59b25b983214368a262465d66b29cb0-5"&gt;&lt;/a&gt;
&lt;a name="rest_code_a59b25b983214368a262465d66b29cb0-6"&gt;&lt;/a&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;d_id&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_a59b25b983214368a262465d66b29cb0-7"&gt;&lt;/a&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="nl"&gt;d&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;basic_conf_t&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;d_id&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;{};&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;It is similar to the other parameters, except that it has no value. You'll see later in this article why type_id is necessary here.&lt;/p&gt;
&lt;p&gt;To check if the flag is present, we'll write the is_present template:&lt;/p&gt;
&lt;pre class="code c++"&gt;&lt;a name="rest_code_84db5a7813cb4caca57ca4379d6b50ec-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;T1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;typename&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt; &lt;span class="n"&gt;Args&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_84db5a7813cb4caca57ca4379d6b50ec-2"&gt;&lt;/a&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;is_present&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_84db5a7813cb4caca57ca4379d6b50ec-3"&gt;&lt;/a&gt;
&lt;a name="rest_code_84db5a7813cb4caca57ca4379d6b50ec-4"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;T1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;T2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;typename&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt; &lt;span class="n"&gt;Args&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_84db5a7813cb4caca57ca4379d6b50ec-5"&gt;&lt;/a&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;is_present&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;T1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;T2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Args&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;integral_constant&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kt"&gt;bool&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;is_same&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;T1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;T2&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt; &lt;span class="o"&gt;||&lt;/span&gt; &lt;span class="n"&gt;is_present&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;T1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Args&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;{};&lt;/span&gt;
&lt;a name="rest_code_84db5a7813cb4caca57ca4379d6b50ec-6"&gt;&lt;/a&gt;
&lt;a name="rest_code_84db5a7813cb4caca57ca4379d6b50ec-7"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;T1&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_84db5a7813cb4caca57ca4379d6b50ec-8"&gt;&lt;/a&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;is_present&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;T1&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;false_type&lt;/span&gt; &lt;span class="p"&gt;{};&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;This time, the template is much easier. We simply need to iterate through all the types from the variadic template parameter and test if the type is present somewhere. Again, you can see that we used two partial template specialization to handle the different cases.&lt;/p&gt;
&lt;p&gt;With this we can now get the value for D:&lt;/p&gt;
&lt;pre class="code c++"&gt;&lt;a name="rest_code_8d4d84387b9c401d9dc993ca540fa30d-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt; &lt;span class="n"&gt;Args&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_8d4d84387b9c401d9dc993ca540fa30d-2"&gt;&lt;/a&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;configurable_v2&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;a name="rest_code_8d4d84387b9c401d9dc993ca540fa30d-3"&gt;&lt;/a&gt;    &lt;span class="k"&gt;static&lt;/span&gt; &lt;span class="k"&gt;constexpr&lt;/span&gt; &lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="k"&gt;auto&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;get_value&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Args&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_8d4d84387b9c401d9dc993ca540fa30d-4"&gt;&lt;/a&gt;    &lt;span class="k"&gt;static&lt;/span&gt; &lt;span class="k"&gt;constexpr&lt;/span&gt; &lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="k"&gt;auto&lt;/span&gt; &lt;span class="n"&gt;B&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;get_value&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="sc"&gt;'b'&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Args&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_8d4d84387b9c401d9dc993ca540fa30d-5"&gt;&lt;/a&gt;    &lt;span class="k"&gt;static&lt;/span&gt; &lt;span class="k"&gt;constexpr&lt;/span&gt; &lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="k"&gt;auto&lt;/span&gt; &lt;span class="n"&gt;C&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;get_value&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;type&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;BBB&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Args&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_8d4d84387b9c401d9dc993ca540fa30d-6"&gt;&lt;/a&gt;    &lt;span class="k"&gt;static&lt;/span&gt; &lt;span class="k"&gt;constexpr&lt;/span&gt; &lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="k"&gt;auto&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;is_present&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Args&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_8d4d84387b9c401d9dc993ca540fa30d-7"&gt;&lt;/a&gt;
&lt;a name="rest_code_8d4d84387b9c401d9dc993ca540fa30d-8"&gt;&lt;/a&gt;    &lt;span class="c1"&gt;//Coming&lt;/span&gt;
&lt;a name="rest_code_8d4d84387b9c401d9dc993ca540fa30d-9"&gt;&lt;/a&gt;&lt;span class="p"&gt;};&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class="section" id="extracting-types"&gt;
&lt;h2&gt;Extracting types&lt;/h2&gt;
&lt;p&gt;The next parameter does not hold a value, but a type. It won't be an integral constant, but it will define a typedef value with the configured type:&lt;/p&gt;
&lt;pre class="code c++"&gt;&lt;a name="rest_code_5966c8c0298b4db59e6073e3704152b9-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;ID&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_5966c8c0298b4db59e6073e3704152b9-2"&gt;&lt;/a&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;type_conf_t&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;a name="rest_code_5966c8c0298b4db59e6073e3704152b9-3"&gt;&lt;/a&gt;    &lt;span class="k"&gt;using&lt;/span&gt; &lt;span class="n"&gt;type_id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ID&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_5966c8c0298b4db59e6073e3704152b9-4"&gt;&lt;/a&gt;    &lt;span class="k"&gt;using&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_5966c8c0298b4db59e6073e3704152b9-5"&gt;&lt;/a&gt;&lt;span class="p"&gt;};&lt;/span&gt;
&lt;a name="rest_code_5966c8c0298b4db59e6073e3704152b9-6"&gt;&lt;/a&gt;
&lt;a name="rest_code_5966c8c0298b4db59e6073e3704152b9-7"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_5966c8c0298b4db59e6073e3704152b9-8"&gt;&lt;/a&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="nl"&gt;e&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;type_conf_t&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;e_id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;{};&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;You may think that the extracting will be very different, but in fact it very similar. And here it is:&lt;/p&gt;
&lt;pre class="code c++"&gt;&lt;a name="rest_code_3aaadf8e152c4431b8ca49c83bfa5ece-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;typename&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt; &lt;span class="n"&gt;Args&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_3aaadf8e152c4431b8ca49c83bfa5ece-2"&gt;&lt;/a&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;get_type&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_3aaadf8e152c4431b8ca49c83bfa5ece-3"&gt;&lt;/a&gt;
&lt;a name="rest_code_3aaadf8e152c4431b8ca49c83bfa5ece-4"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;T2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;typename&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt; &lt;span class="n"&gt;Args&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_3aaadf8e152c4431b8ca49c83bfa5ece-5"&gt;&lt;/a&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;get_type&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;T2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Args&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;a name="rest_code_3aaadf8e152c4431b8ca49c83bfa5ece-6"&gt;&lt;/a&gt;    &lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;D2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;T22&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;Enable&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_3aaadf8e152c4431b8ca49c83bfa5ece-7"&gt;&lt;/a&gt;    &lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;impl&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;a name="rest_code_3aaadf8e152c4431b8ca49c83bfa5ece-8"&gt;&lt;/a&gt;        &lt;span class="k"&gt;using&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;get_type&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Args&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_3aaadf8e152c4431b8ca49c83bfa5ece-9"&gt;&lt;/a&gt;    &lt;span class="p"&gt;};&lt;/span&gt;
&lt;a name="rest_code_3aaadf8e152c4431b8ca49c83bfa5ece-10"&gt;&lt;/a&gt;
&lt;a name="rest_code_3aaadf8e152c4431b8ca49c83bfa5ece-11"&gt;&lt;/a&gt;    &lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;D2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;T22&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_3aaadf8e152c4431b8ca49c83bfa5ece-12"&gt;&lt;/a&gt;    &lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;impl&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;D2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;T22&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;enable_if_t&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;is_same&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;D2&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;type_id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;T22&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;type_id&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;a name="rest_code_3aaadf8e152c4431b8ca49c83bfa5ece-13"&gt;&lt;/a&gt;        &lt;span class="k"&gt;using&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;T22&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_3aaadf8e152c4431b8ca49c83bfa5ece-14"&gt;&lt;/a&gt;    &lt;span class="p"&gt;};&lt;/span&gt;
&lt;a name="rest_code_3aaadf8e152c4431b8ca49c83bfa5ece-15"&gt;&lt;/a&gt;
&lt;a name="rest_code_3aaadf8e152c4431b8ca49c83bfa5ece-16"&gt;&lt;/a&gt;    &lt;span class="k"&gt;using&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;impl&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;T2&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_3aaadf8e152c4431b8ca49c83bfa5ece-17"&gt;&lt;/a&gt;&lt;span class="p"&gt;};&lt;/span&gt;
&lt;a name="rest_code_3aaadf8e152c4431b8ca49c83bfa5ece-18"&gt;&lt;/a&gt;
&lt;a name="rest_code_3aaadf8e152c4431b8ca49c83bfa5ece-19"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_3aaadf8e152c4431b8ca49c83bfa5ece-20"&gt;&lt;/a&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;get_type&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;a name="rest_code_3aaadf8e152c4431b8ca49c83bfa5ece-21"&gt;&lt;/a&gt;    &lt;span class="k"&gt;using&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_3aaadf8e152c4431b8ca49c83bfa5ece-22"&gt;&lt;/a&gt;&lt;span class="p"&gt;};&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;Every integral constant has been replaced with alias declaration (with &lt;em&gt;using&lt;/em&gt;) and we need to use the &lt;em&gt;typename&lt;/em&gt; disambiguator in from of X::value, but that's it :) We could probably have created an integral_type struct to simplify it a bit further, but I don't think that would change a lot. The code of the class follows the same changes:&lt;/p&gt;
&lt;pre class="code c++"&gt;&lt;a name="rest_code_0be239de2ec7484f83b5a6039ea2f417-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt; &lt;span class="n"&gt;Args&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_0be239de2ec7484f83b5a6039ea2f417-2"&gt;&lt;/a&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;configurable_v2&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;a name="rest_code_0be239de2ec7484f83b5a6039ea2f417-3"&gt;&lt;/a&gt;    &lt;span class="k"&gt;static&lt;/span&gt; &lt;span class="k"&gt;constexpr&lt;/span&gt; &lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="k"&gt;auto&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;get_value&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Args&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_0be239de2ec7484f83b5a6039ea2f417-4"&gt;&lt;/a&gt;    &lt;span class="k"&gt;static&lt;/span&gt; &lt;span class="k"&gt;constexpr&lt;/span&gt; &lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="k"&gt;auto&lt;/span&gt; &lt;span class="n"&gt;B&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;get_value&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="sc"&gt;'b'&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Args&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_0be239de2ec7484f83b5a6039ea2f417-5"&gt;&lt;/a&gt;    &lt;span class="k"&gt;static&lt;/span&gt; &lt;span class="k"&gt;constexpr&lt;/span&gt; &lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="k"&gt;auto&lt;/span&gt; &lt;span class="n"&gt;C&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;get_value&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;type&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;BBB&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Args&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_0be239de2ec7484f83b5a6039ea2f417-6"&gt;&lt;/a&gt;    &lt;span class="k"&gt;static&lt;/span&gt; &lt;span class="k"&gt;constexpr&lt;/span&gt; &lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="k"&gt;auto&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;is_present&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Args&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_0be239de2ec7484f83b5a6039ea2f417-7"&gt;&lt;/a&gt;
&lt;a name="rest_code_0be239de2ec7484f83b5a6039ea2f417-8"&gt;&lt;/a&gt;    &lt;span class="k"&gt;using&lt;/span&gt; &lt;span class="n"&gt;E&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;get_type&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;watcher_1&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Args&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_0be239de2ec7484f83b5a6039ea2f417-9"&gt;&lt;/a&gt;
&lt;a name="rest_code_0be239de2ec7484f83b5a6039ea2f417-10"&gt;&lt;/a&gt;    &lt;span class="c1"&gt;//Coming&lt;/span&gt;
&lt;a name="rest_code_0be239de2ec7484f83b5a6039ea2f417-11"&gt;&lt;/a&gt;&lt;span class="p"&gt;};&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class="section" id="extracting-template-types"&gt;
&lt;h2&gt;Extracting template types&lt;/h2&gt;
&lt;p&gt;The last parameter is not a type but a template, so there are some slight changes necessary to extract them. First, let's take a look at the parameter definition:&lt;/p&gt;
&lt;pre class="code c++"&gt;&lt;a name="rest_code_185f003333dc4d6399e31ca0a02113f9-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;ID&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;T&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_185f003333dc4d6399e31ca0a02113f9-2"&gt;&lt;/a&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;template_type_conf_t&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;a name="rest_code_185f003333dc4d6399e31ca0a02113f9-3"&gt;&lt;/a&gt;    &lt;span class="k"&gt;using&lt;/span&gt; &lt;span class="n"&gt;type_id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ID&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_185f003333dc4d6399e31ca0a02113f9-4"&gt;&lt;/a&gt;
&lt;a name="rest_code_185f003333dc4d6399e31ca0a02113f9-5"&gt;&lt;/a&gt;    &lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_185f003333dc4d6399e31ca0a02113f9-6"&gt;&lt;/a&gt;    &lt;span class="k"&gt;using&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_185f003333dc4d6399e31ca0a02113f9-7"&gt;&lt;/a&gt;&lt;span class="p"&gt;};&lt;/span&gt;
&lt;a name="rest_code_185f003333dc4d6399e31ca0a02113f9-8"&gt;&lt;/a&gt;
&lt;a name="rest_code_185f003333dc4d6399e31ca0a02113f9-9"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;T&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_185f003333dc4d6399e31ca0a02113f9-10"&gt;&lt;/a&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="nl"&gt;f&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;template_type_conf_t&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;f_id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;{};&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;Here instead of taking a simple type, we take a type template with one template parameter. This design has a great limitations. It won't be possible to use it for template that takes more than one template parameter. You have to create an extract template for each possible combination that you want to handle. In my case, I only had the case of a template with one template parameter, but if you have several combination, you'll have to write more code. It is quite simple code, since the adaptations are minor, but it is still tedious. Here is the &lt;em&gt;get_template_type&lt;/em&gt; template:&lt;/p&gt;
&lt;pre class="code c++"&gt;&lt;a name="rest_code_038f8435ee2144909a1f01d220bf078c-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;typename&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt; &lt;span class="n"&gt;Args&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_038f8435ee2144909a1f01d220bf078c-2"&gt;&lt;/a&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;get_template_type&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_038f8435ee2144909a1f01d220bf078c-3"&gt;&lt;/a&gt;
&lt;a name="rest_code_038f8435ee2144909a1f01d220bf078c-4"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;T2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;typename&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt; &lt;span class="n"&gt;Args&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_038f8435ee2144909a1f01d220bf078c-5"&gt;&lt;/a&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;get_template_type&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;T2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Args&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;a name="rest_code_038f8435ee2144909a1f01d220bf078c-6"&gt;&lt;/a&gt;    &lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;D2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;T22&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;Enable&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_038f8435ee2144909a1f01d220bf078c-7"&gt;&lt;/a&gt;    &lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;impl&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;a name="rest_code_038f8435ee2144909a1f01d220bf078c-8"&gt;&lt;/a&gt;        &lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_038f8435ee2144909a1f01d220bf078c-9"&gt;&lt;/a&gt;        &lt;span class="k"&gt;using&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;get_template_type&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Args&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="k"&gt;template&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_038f8435ee2144909a1f01d220bf078c-10"&gt;&lt;/a&gt;    &lt;span class="p"&gt;};&lt;/span&gt;
&lt;a name="rest_code_038f8435ee2144909a1f01d220bf078c-11"&gt;&lt;/a&gt;
&lt;a name="rest_code_038f8435ee2144909a1f01d220bf078c-12"&gt;&lt;/a&gt;    &lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;D2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;T22&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_038f8435ee2144909a1f01d220bf078c-13"&gt;&lt;/a&gt;    &lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;impl&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;D2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;T22&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;enable_if_t&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;is_same&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;D2&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;type_id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;T22&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;type_id&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;a name="rest_code_038f8435ee2144909a1f01d220bf078c-14"&gt;&lt;/a&gt;        &lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_038f8435ee2144909a1f01d220bf078c-15"&gt;&lt;/a&gt;        &lt;span class="k"&gt;using&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;T22&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="k"&gt;template&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_038f8435ee2144909a1f01d220bf078c-16"&gt;&lt;/a&gt;    &lt;span class="p"&gt;};&lt;/span&gt;
&lt;a name="rest_code_038f8435ee2144909a1f01d220bf078c-17"&gt;&lt;/a&gt;
&lt;a name="rest_code_038f8435ee2144909a1f01d220bf078c-18"&gt;&lt;/a&gt;    &lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_038f8435ee2144909a1f01d220bf078c-19"&gt;&lt;/a&gt;    &lt;span class="k"&gt;using&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;impl&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;T2&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="k"&gt;template&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_038f8435ee2144909a1f01d220bf078c-20"&gt;&lt;/a&gt;&lt;span class="p"&gt;};&lt;/span&gt;
&lt;a name="rest_code_038f8435ee2144909a1f01d220bf078c-21"&gt;&lt;/a&gt;
&lt;a name="rest_code_038f8435ee2144909a1f01d220bf078c-22"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_038f8435ee2144909a1f01d220bf078c-23"&gt;&lt;/a&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;get_template_type&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;a name="rest_code_038f8435ee2144909a1f01d220bf078c-24"&gt;&lt;/a&gt;    &lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_038f8435ee2144909a1f01d220bf078c-25"&gt;&lt;/a&gt;    &lt;span class="k"&gt;using&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="k"&gt;template&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_038f8435ee2144909a1f01d220bf078c-26"&gt;&lt;/a&gt;&lt;span class="p"&gt;};&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;Again, there are only few changes. Every previous alias declaration is now a template alias declaration and we have to use &lt;em&gt;template&lt;/em&gt; disambiguator in front of value. We now have the final piece to write the configurable_v2 class:&lt;/p&gt;
&lt;pre class="code c++"&gt;&lt;a name="rest_code_8fa59607b643427daefdfe9cec1b33fc-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt; &lt;span class="n"&gt;Args&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_8fa59607b643427daefdfe9cec1b33fc-2"&gt;&lt;/a&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;configurable_v2&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;a name="rest_code_8fa59607b643427daefdfe9cec1b33fc-3"&gt;&lt;/a&gt;    &lt;span class="k"&gt;static&lt;/span&gt; &lt;span class="k"&gt;constexpr&lt;/span&gt; &lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="k"&gt;auto&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;get_value&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Args&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_8fa59607b643427daefdfe9cec1b33fc-4"&gt;&lt;/a&gt;    &lt;span class="k"&gt;static&lt;/span&gt; &lt;span class="k"&gt;constexpr&lt;/span&gt; &lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="k"&gt;auto&lt;/span&gt; &lt;span class="n"&gt;B&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;get_value&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="sc"&gt;'b'&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Args&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_8fa59607b643427daefdfe9cec1b33fc-5"&gt;&lt;/a&gt;    &lt;span class="k"&gt;static&lt;/span&gt; &lt;span class="k"&gt;constexpr&lt;/span&gt; &lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="k"&gt;auto&lt;/span&gt; &lt;span class="n"&gt;C&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;get_value&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;type&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;BBB&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Args&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_8fa59607b643427daefdfe9cec1b33fc-6"&gt;&lt;/a&gt;    &lt;span class="k"&gt;static&lt;/span&gt; &lt;span class="k"&gt;constexpr&lt;/span&gt; &lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="k"&gt;auto&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;is_present&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Args&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_8fa59607b643427daefdfe9cec1b33fc-7"&gt;&lt;/a&gt;
&lt;a name="rest_code_8fa59607b643427daefdfe9cec1b33fc-8"&gt;&lt;/a&gt;    &lt;span class="k"&gt;using&lt;/span&gt; &lt;span class="n"&gt;E&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;get_type&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;watcher_1&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Args&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_8fa59607b643427daefdfe9cec1b33fc-9"&gt;&lt;/a&gt;
&lt;a name="rest_code_8fa59607b643427daefdfe9cec1b33fc-10"&gt;&lt;/a&gt;    &lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_8fa59607b643427daefdfe9cec1b33fc-11"&gt;&lt;/a&gt;    &lt;span class="k"&gt;using&lt;/span&gt; &lt;span class="n"&gt;F&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;get_template_type&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;trainer_1&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Args&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="k"&gt;template&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_8fa59607b643427daefdfe9cec1b33fc-12"&gt;&lt;/a&gt;&lt;span class="p"&gt;};&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class="section" id="validating-parameter-rules"&gt;
&lt;h2&gt;Validating parameter rules&lt;/h2&gt;
&lt;p&gt;If you have more parameters and several classes that are configured in this manner, the user may use a wrong parameter in the list. In that case, nothing will happen, the parameter will simply be ignored. Sometimes, this behavior is acceptable, but sometimes it is better to make the code invalid. That's what we are going to do here by specifying a list of valid parameters and using static_assert to ensure this condition.&lt;/p&gt;
&lt;p&gt;Here is the assertion:&lt;/p&gt;
&lt;pre class="code c++"&gt;&lt;a name="rest_code_cde4a2cbfa4a40a28a75f8527390b4bc-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt; &lt;span class="n"&gt;Args&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_cde4a2cbfa4a40a28a75f8527390b4bc-2"&gt;&lt;/a&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;configurable_v2&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;a name="rest_code_cde4a2cbfa4a40a28a75f8527390b4bc-3"&gt;&lt;/a&gt;    &lt;span class="k"&gt;static&lt;/span&gt; &lt;span class="k"&gt;constexpr&lt;/span&gt; &lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="k"&gt;auto&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;get_value&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Args&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_cde4a2cbfa4a40a28a75f8527390b4bc-4"&gt;&lt;/a&gt;    &lt;span class="k"&gt;static&lt;/span&gt; &lt;span class="k"&gt;constexpr&lt;/span&gt; &lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="k"&gt;auto&lt;/span&gt; &lt;span class="n"&gt;B&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;get_value&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="sc"&gt;'b'&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Args&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_cde4a2cbfa4a40a28a75f8527390b4bc-5"&gt;&lt;/a&gt;    &lt;span class="k"&gt;static&lt;/span&gt; &lt;span class="k"&gt;constexpr&lt;/span&gt; &lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="k"&gt;auto&lt;/span&gt; &lt;span class="n"&gt;C&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;get_value&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;type&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;BBB&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Args&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_cde4a2cbfa4a40a28a75f8527390b4bc-6"&gt;&lt;/a&gt;    &lt;span class="k"&gt;static&lt;/span&gt; &lt;span class="k"&gt;constexpr&lt;/span&gt; &lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="k"&gt;auto&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;is_present&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Args&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_cde4a2cbfa4a40a28a75f8527390b4bc-7"&gt;&lt;/a&gt;
&lt;a name="rest_code_cde4a2cbfa4a40a28a75f8527390b4bc-8"&gt;&lt;/a&gt;    &lt;span class="k"&gt;using&lt;/span&gt; &lt;span class="n"&gt;E&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;get_type&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;watcher_1&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Args&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_cde4a2cbfa4a40a28a75f8527390b4bc-9"&gt;&lt;/a&gt;
&lt;a name="rest_code_cde4a2cbfa4a40a28a75f8527390b4bc-10"&gt;&lt;/a&gt;    &lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_cde4a2cbfa4a40a28a75f8527390b4bc-11"&gt;&lt;/a&gt;    &lt;span class="k"&gt;using&lt;/span&gt; &lt;span class="n"&gt;F&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;get_template_type&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;trainer_1&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Args&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="k"&gt;template&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_cde4a2cbfa4a40a28a75f8527390b4bc-12"&gt;&lt;/a&gt;
&lt;a name="rest_code_cde4a2cbfa4a40a28a75f8527390b4bc-13"&gt;&lt;/a&gt;    &lt;span class="k"&gt;static_assert&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
&lt;a name="rest_code_cde4a2cbfa4a40a28a75f8527390b4bc-14"&gt;&lt;/a&gt;        &lt;span class="n"&gt;is_valid&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;tmp_list&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;a_id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;b_id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;c_id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d_id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;e_id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;f_id&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Args&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_cde4a2cbfa4a40a28a75f8527390b4bc-15"&gt;&lt;/a&gt;        &lt;span class="s"&gt;"Invalid parameters type"&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a name="rest_code_cde4a2cbfa4a40a28a75f8527390b4bc-16"&gt;&lt;/a&gt;
&lt;a name="rest_code_cde4a2cbfa4a40a28a75f8527390b4bc-17"&gt;&lt;/a&gt;    &lt;span class="c1"&gt;//Something useful&lt;/span&gt;
&lt;a name="rest_code_cde4a2cbfa4a40a28a75f8527390b4bc-18"&gt;&lt;/a&gt;&lt;span class="p"&gt;};&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;Since the is_valid traits needs two variadic list of parameters, we have to encapsulate list of valid types in another structure (&lt;em&gt;tmp_list&lt;/em&gt;) to separate the two sets. Here is the implementation of the validation:&lt;/p&gt;
&lt;pre class="code c++"&gt;&lt;a name="rest_code_5b54aa641e274b65ad060c958abb8d4b-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt; &lt;span class="n"&gt;Valid&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_5b54aa641e274b65ad060c958abb8d4b-2"&gt;&lt;/a&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;tmp_list&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;a name="rest_code_5b54aa641e274b65ad060c958abb8d4b-3"&gt;&lt;/a&gt;    &lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_5b54aa641e274b65ad060c958abb8d4b-4"&gt;&lt;/a&gt;    &lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="nl"&gt;contains&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;integral_constant&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kt"&gt;bool&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;is_present&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;type_id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Valid&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;{};&lt;/span&gt;
&lt;a name="rest_code_5b54aa641e274b65ad060c958abb8d4b-5"&gt;&lt;/a&gt;&lt;span class="p"&gt;};&lt;/span&gt;
&lt;a name="rest_code_5b54aa641e274b65ad060c958abb8d4b-6"&gt;&lt;/a&gt;
&lt;a name="rest_code_5b54aa641e274b65ad060c958abb8d4b-7"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;L&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;typename&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt; &lt;span class="n"&gt;Args&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_5b54aa641e274b65ad060c958abb8d4b-8"&gt;&lt;/a&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;is_valid&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_5b54aa641e274b65ad060c958abb8d4b-9"&gt;&lt;/a&gt;
&lt;a name="rest_code_5b54aa641e274b65ad060c958abb8d4b-10"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;L&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;T1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;typename&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt; &lt;span class="n"&gt;Args&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_5b54aa641e274b65ad060c958abb8d4b-11"&gt;&lt;/a&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;is_valid&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;L&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;T1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Args&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;integral_constant&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kt"&gt;bool&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;L&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="k"&gt;template&lt;/span&gt; &lt;span class="n"&gt;contains&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;T1&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;is_valid&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;L&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Args&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;{};&lt;/span&gt;
&lt;a name="rest_code_5b54aa641e274b65ad060c958abb8d4b-12"&gt;&lt;/a&gt;
&lt;a name="rest_code_5b54aa641e274b65ad060c958abb8d4b-13"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;L&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_5b54aa641e274b65ad060c958abb8d4b-14"&gt;&lt;/a&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;is_valid&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;L&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;true_type&lt;/span&gt; &lt;span class="p"&gt;{};&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;The struct tmp_list has a single inner class (&lt;em&gt;contains&lt;/em&gt;) that test if a given type is present in the list. For this, we reuse the is_present template that we created when extracting boolean flag. The &lt;em&gt;is_valid&lt;/em&gt; template simply test that each parameter is present in the &lt;em&gt;tmp_list&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Validation could also be made so that no parameters could be present twice, but I will put that aside for now.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="conclusion"&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Here it is :)&lt;/p&gt;
&lt;p&gt;We now have a set of template that allow us to configure a class at compile-time with named, optional, template parameters, with default and in any order. I personally thinks that this is a great way to configure a class at compile-time and it is also another proof of the power of C++. If you think that the code is complicated, don't forget that this is only the library code, the client code on contrary is at least as clear as the original version and even has several advantages.&lt;/p&gt;
&lt;p&gt;I hope that this article interested you and that you learned something.&lt;/p&gt;
&lt;p&gt;The code of this article is available on Github: &lt;a class="reference external" href="https://github.com/wichtounet/articles/blob/master/src/named_template_par/configurable.cpp"&gt;https://github.com/wichtounet/articles/blob/master/src/named_template_par/configurable.cpp&lt;/a&gt;
It has been tested on Clang 3.5 and GCC 4.9.1.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;</description><category>C++</category><category>C++11</category><category>C++14</category><category>templates</category><guid>http://baptiste-wicht.com/posts/2015/03/named-optional-template-parameters-compile-time.html</guid><pubDate>Sun, 01 Mar 2015 14:52:41 GMT</pubDate></item><item><title>ETL - C++ library for vector and matrix computations</title><link>http://baptiste-wicht.com/posts/2014/07/etl-cpp-library-for-vector-and-matrix-computations.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;div&gt;&lt;p&gt;When working on Machine Learning algorithms, I was in need of a simple library
to ease working with vectors and matrix. This is the reason why I started
developing ETL (Expression Template Library).&lt;/p&gt;
&lt;p&gt;ETL is a small header only library for C++ that provides vector and matrix
classes with support for Expression Templates to perform very efficient
operations on them.&lt;/p&gt;
&lt;p&gt;The library supports statically sized and dynamically sized vector and matrix
structures with efficient element-wise operations. All the operations are
implemented lazily with Expression Templates, they are only implemented once the
expression is assigned to a concrete structure.&lt;/p&gt;
&lt;div class="section" id="data-structures"&gt;
&lt;h2&gt;Data structures&lt;/h2&gt;
&lt;p&gt;Several structures are available:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;code&gt;fast_vector&amp;lt;T, Rows&amp;gt;&lt;/code&gt;: A vector of size Rows with elements of type T. This must
be used when you know the size of the vector at compile-time.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;dyn_vector&amp;lt;T&amp;gt;&lt;/code&gt;: A vector with element of type T. The size of the vector can be
set at runtime.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;fast_matrix&amp;lt;T, Rows,Columns&amp;gt;&lt;/code&gt;: A matrix of size Rows x Columns with elements of
type T. This must be used when you know the size of the matrix at
compile-time.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;dyn_matrix&amp;lt;T&amp;gt;&lt;/code&gt;: A matrix with element of type T. The size of the matrix can be
set at runtime.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;All the structures are size-invariant, once set they cannot be grown or
shrinked.&lt;/p&gt;
&lt;p&gt;In every operations that involves fast version of the structures, all the sizes
are known at compile-time, this gives the compiler a lot of opportunities for
optimization.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="element-wise-operations"&gt;
&lt;h2&gt;Element-wise operations&lt;/h2&gt;
&lt;p&gt;Classic element-wise operations can be done on vector and matrix as if it was
done on scalars. Matrices and vectors can also be added, subtracted, divided,
...  by scalars.&lt;/p&gt;
&lt;p&gt;Here is an example of what can be done:&lt;/p&gt;
&lt;pre class="code cpp"&gt;&lt;a name="rest_code_3be012be9b5445aab1fdc8edf668f3c6-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;etl&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dyn_vector&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kt"&gt;double&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mf"&gt;2.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mf"&gt;3.0&lt;/span&gt;&lt;span class="p"&gt;});&lt;/span&gt;
&lt;a name="rest_code_3be012be9b5445aab1fdc8edf668f3c6-2"&gt;&lt;/a&gt;&lt;span class="n"&gt;etl&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dyn_vector&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kt"&gt;double&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="mf"&gt;3.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mf"&gt;2.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="p"&gt;});&lt;/span&gt;
&lt;a name="rest_code_3be012be9b5445aab1fdc8edf668f3c6-3"&gt;&lt;/a&gt;
&lt;a name="rest_code_3be012be9b5445aab1fdc8edf668f3c6-4"&gt;&lt;/a&gt;&lt;span class="n"&gt;etl&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dyn_vector&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="kt"&gt;double&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;1.4&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mf"&gt;1.2&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;All the operations are only executed once the expression is evaluated to
construct the dyn_vector. No temporaries are involved. This is as efficient as
if a single for loop was used and each element was computed directly.&lt;/p&gt;
&lt;p&gt;You can easily assign the same value to a structure by using the operator = on
it.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="unary-operators"&gt;
&lt;h2&gt;Unary operators&lt;/h2&gt;
&lt;p&gt;Several unary operators are available. Each operation is performed on every
element of the vector or the matrix.&lt;/p&gt;
&lt;p&gt;Available operators:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;code&gt;log&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;abs&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sign&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;max/min&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sigmoid&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;noise&lt;/code&gt;: Add standard normal noise to each element&lt;/li&gt;
&lt;li&gt;&lt;code&gt;logistic_noise&lt;/code&gt;: Add normal noise of mean zero and variance sigmoid(x) to each
element&lt;/li&gt;
&lt;li&gt;&lt;code&gt;exp&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;softplus&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;bernoulli&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Several transformations are also available:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;code&gt;hflip&lt;/code&gt;: Flip the vector or the matrix horizontally&lt;/li&gt;
&lt;li&gt;&lt;code&gt;vflip&lt;/code&gt;: Flip the vector or the matrix vertically&lt;/li&gt;
&lt;li&gt;&lt;code&gt;fflip&lt;/code&gt;: Flip the vector or the matrix horizontally and vertically. It is the
equivalent of &lt;code&gt;hflip(vflip(x))&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;dim/row/col&lt;/code&gt;: Return a vector representing a sub part of a matrix (a row or a
col)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;reshape&lt;/code&gt;: Interpret a vector as a matrix&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Again, all these operations are performed lazily, they are only executed when the
expression is assigned to something.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="lazy-evaluation"&gt;
&lt;h2&gt;Lazy evaluation&lt;/h2&gt;
&lt;p&gt;All binary and unary operations are applied lazily, only when they are assigned
to a concrete vector or matrix class.&lt;/p&gt;
&lt;p&gt;The expression can be evaluated using the &lt;code&gt;s(x)&lt;/code&gt; function that returns a
concrete class (fast_vector,fast_matrix,dyn_vector,dyn_matrix) based on the
expression.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="reduction"&gt;
&lt;h2&gt;Reduction&lt;/h2&gt;
&lt;p&gt;Several reduction functions are available:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;sum: Return the sum of a vector or matrix&lt;/li&gt;
&lt;li&gt;mean: Return the sum of a vector or matrix&lt;/li&gt;
&lt;li&gt;dot: Return the dot product of two vector or matrices&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="functions"&gt;
&lt;h2&gt;Functions&lt;/h2&gt;
&lt;p&gt;The header &lt;em&gt;convolution.hpp&lt;/em&gt; provides several convolution operations both in 1D
(vector) and 2D (matrix). All the convolution are available in valid, full and
same versions.&lt;/p&gt;
&lt;p&gt;The header &lt;em&gt;mutiplication.hpp&lt;/em&gt; provides the matrix multiplication operation
(&lt;code&gt;mmult&lt;/code&gt;). For now on, only the naive algorithm is available. I'll
probably add support for Strassen algorithm in the near future.&lt;/p&gt;
&lt;p&gt;It is possible to pass an expression rather than an data structure to functions.
You have to keep in mind that expression are lazy, therefore if you pass a + b
to a matrix multiplication, an addition will be run each time an element is
accessed (n^3 times), therefore, it is rarely efficient.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="examples"&gt;
&lt;h2&gt;Examples&lt;/h2&gt;
&lt;p&gt;Here are some examples of these operators (taken from my Machine Learning
Library):&lt;/p&gt;
&lt;pre class="code cpp"&gt;&lt;a name="rest_code_dcce251ffbf343bfbb1a4772d3dc2fe7-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;h_a&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sigmoid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;mmul&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_visible&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;v_a&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;
&lt;a name="rest_code_dcce251ffbf343bfbb1a4772d3dc2fe7-2"&gt;&lt;/a&gt;&lt;span class="n"&gt;h_s&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;bernoulli&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;h_a&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="code cpp"&gt;&lt;a name="rest_code_1c1c0164a2974e0f867c21c4895e3306-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;h_a&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;mmul&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_visible&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;v_a&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="mf"&gt;0.0&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="mf"&gt;6.0&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a name="rest_code_1c1c0164a2974e0f867c21c4895e3306-2"&gt;&lt;/a&gt;&lt;span class="n"&gt;h_s&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ranged_noise&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;h_a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;6.0&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;pre class="code cpp"&gt;&lt;a name="rest_code_77d2f7641197405094ac1f1cf8ea09d8-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;weight&lt;/span&gt; &lt;span class="n"&gt;exp_sum&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;exp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;mmul&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_visible&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;v_a&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;)));&lt;/span&gt;
&lt;a name="rest_code_77d2f7641197405094ac1f1cf8ea09d8-2"&gt;&lt;/a&gt;
&lt;a name="rest_code_77d2f7641197405094ac1f1cf8ea09d8-3"&gt;&lt;/a&gt;&lt;span class="n"&gt;h_a&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;exp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;mmul&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_visible&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;v_a&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;exp_sum&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_77d2f7641197405094ac1f1cf8ea09d8-4"&gt;&lt;/a&gt;
&lt;a name="rest_code_77d2f7641197405094ac1f1cf8ea09d8-5"&gt;&lt;/a&gt;&lt;span class="k"&gt;auto&lt;/span&gt; &lt;span class="n"&gt;max&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;max_element&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;h_a&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;begin&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;h_a&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;end&lt;/span&gt;&lt;span class="p"&gt;());&lt;/span&gt;
&lt;a name="rest_code_77d2f7641197405094ac1f1cf8ea09d8-6"&gt;&lt;/a&gt;
&lt;a name="rest_code_77d2f7641197405094ac1f1cf8ea09d8-7"&gt;&lt;/a&gt;&lt;span class="n"&gt;h_s&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_77d2f7641197405094ac1f1cf8ea09d8-8"&gt;&lt;/a&gt;&lt;span class="n"&gt;h_s&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;distance&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;h_a&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;begin&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;max&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class="section" id="conclusion"&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;This library is available on Github: &lt;a class="reference external" href="https://github.com/wichtounet/etl"&gt;etl&lt;/a&gt;.
It is licensed under MIT license.&lt;/p&gt;
&lt;p&gt;It is header-only, therefore you don't have to build it. However, it uses some
recent C++14 stuff, you'll need a recent version of Clang or G++ to be able to
use it.&lt;/p&gt;
&lt;p&gt;If you find an issue or have an idea to improve it, just post it on Github or
as a comment here and I'll do my best to work on that. If you have any question
on the usage of the library, I'd be glad to answer them.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;</description><category>C++</category><category>C++11</category><category>C++14</category><category>Libraries</category><guid>http://baptiste-wicht.com/posts/2014/07/etl-cpp-library-for-vector-and-matrix-computations.html</guid><pubDate>Fri, 25 Jul 2014 08:46:33 GMT</pubDate></item><item><title>Compile integer Square Roots at compile-time in C++</title><link>http://baptiste-wicht.com/posts/2014/07/compile-integer-square-roots-at-compile-time-in-cpp.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;div&gt;&lt;p&gt;For one of my projects, I needed to evaluate a square root at compile-time.
There are several ways to implement it and some are better than the others.&lt;/p&gt;
&lt;p&gt;In this post, I'll show several versions, both with Template Metaprogramming
(TMP) and constexpr functions.&lt;/p&gt;
&lt;div class="section" id="naive-version"&gt;
&lt;h2&gt;Naive version&lt;/h2&gt;
&lt;p&gt;The easiest way to implement it is to enumerate the integers until we find two
integers that when multiplied are equal to our number. This can easily be
implemented in C++ with class template and partial specialization:&lt;/p&gt;
&lt;pre class="code c++"&gt;&lt;a name="rest_code_97153b5d8949456481589bac0794b38d-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;I&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_97153b5d8949456481589bac0794b38d-2"&gt;&lt;/a&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="nl"&gt;ct_sqrt&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;integral_constant&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;I&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;I&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;?&lt;/span&gt; &lt;span class="n"&gt;ct_sqrt&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;I&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="nl"&gt;value&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;I&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;{};&lt;/span&gt;
&lt;a name="rest_code_97153b5d8949456481589bac0794b38d-3"&gt;&lt;/a&gt;
&lt;a name="rest_code_97153b5d8949456481589bac0794b38d-4"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_97153b5d8949456481589bac0794b38d-5"&gt;&lt;/a&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;ct_sqrt&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;integral_constant&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;{};&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;Really easy, isn't it ? If we test it with 100, it gives 10. But, if we try with
higher values, we are going to run into problem. For instance, when compiled
with 289, here is what clang++ gives me:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
src/sqrt/tmp.cpp:5:64: fatal error: recursive template instantiation exceeded maximum depth of 256
struct ct_sqrt : std::integral_constant&amp;lt;std::size_t, (I*I&amp;lt;N) ? ct_sqrt&amp;lt;N,I+1&amp;gt;::value : I &amp;gt; {};
                                                               ^
src/sqrt/tmp.cpp:5:64: note: in instantiation of template class 'ct_sqrt&amp;lt;289, 257&amp;gt;' requested here
struct ct_sqrt : std::integral_constant&amp;lt;std::size_t, (I*I&amp;lt;N) ? ct_sqrt&amp;lt;N,I+1&amp;gt;::value : I &amp;gt; {};
                                                               ^
src/sqrt/tmp.cpp:5:64: note: in instantiation of template class 'ct_sqrt&amp;lt;289, 256&amp;gt;' requested here
struct ct_sqrt : std::integral_constant&amp;lt;std::size_t, (I*I&amp;lt;N) ? ct_sqrt&amp;lt;N,I+1&amp;gt;::value : I &amp;gt; {};
                                                               ^
src/sqrt/tmp.cpp:5:64: note: in instantiation of template class 'ct_sqrt&amp;lt;289, 255&amp;gt;' requested here
struct ct_sqrt : std::integral_constant&amp;lt;std::size_t, (I*I&amp;lt;N) ? ct_sqrt&amp;lt;N,I+1&amp;gt;::value : I &amp;gt; {};
                                                               ^
src/sqrt/tmp.cpp:5:64: note: in instantiation of template class 'ct_sqrt&amp;lt;289, 254&amp;gt;' requested here
struct ct_sqrt : std::integral_constant&amp;lt;std::size_t, (I*I&amp;lt;N) ? ct_sqrt&amp;lt;N,I+1&amp;gt;::value : I &amp;gt; {};
                                                               ^
src/sqrt/tmp.cpp:5:64: note: in instantiation of template class 'ct_sqrt&amp;lt;289, 253&amp;gt;' requested here
struct ct_sqrt : std::integral_constant&amp;lt;std::size_t, (I*I&amp;lt;N) ? ct_sqrt&amp;lt;N,I+1&amp;gt;::value : I &amp;gt; {};
                                                               ^
src/sqrt/tmp.cpp:5:64: note: (skipping 247 contexts in backtrace; use -ftemplate-backtrace-limit=0 to see all)
src/sqrt/tmp.cpp:5:64: note: in instantiation of template class 'ct_sqrt&amp;lt;289, 5&amp;gt;' requested here
struct ct_sqrt : std::integral_constant&amp;lt;std::size_t, (I*I&amp;lt;N) ? ct_sqrt&amp;lt;N,I+1&amp;gt;::value : I &amp;gt; {};
                                                               ^
src/sqrt/tmp.cpp:5:64: note: in instantiation of template class 'ct_sqrt&amp;lt;289, 4&amp;gt;' requested here
struct ct_sqrt : std::integral_constant&amp;lt;std::size_t, (I*I&amp;lt;N) ? ct_sqrt&amp;lt;N,I+1&amp;gt;::value : I &amp;gt; {};
                                                               ^
src/sqrt/tmp.cpp:5:64: note: in instantiation of template class 'ct_sqrt&amp;lt;289, 3&amp;gt;' requested here
struct ct_sqrt : std::integral_constant&amp;lt;std::size_t, (I*I&amp;lt;N) ? ct_sqrt&amp;lt;N,I+1&amp;gt;::value : I &amp;gt; {};
                                                               ^
src/sqrt/tmp.cpp:5:64: note: in instantiation of template class 'ct_sqrt&amp;lt;289, 2&amp;gt;' requested here
struct ct_sqrt : std::integral_constant&amp;lt;std::size_t, (I*I&amp;lt;N) ? ct_sqrt&amp;lt;N,I+1&amp;gt;::value : I &amp;gt; {};
                                                               ^
src/sqrt/tmp.cpp:11:18: note: in instantiation of template class 'ct_sqrt&amp;lt;289, 1&amp;gt;' requested here
    std::cout &amp;lt;&amp;lt; ct_sqrt&amp;lt;289&amp;gt;::value &amp;lt;&amp;lt; std::endl;
                 ^
src/sqrt/tmp.cpp:5:64: note: use -ftemplate-depth=N to increase recursive template instantiation depth
struct ct_sqrt : std::integral_constant&amp;lt;std::size_t, (I*I&amp;lt;N) ? ct_sqrt&amp;lt;N,I+1&amp;gt;::value : I &amp;gt; {};
                                                               ^
&lt;/pre&gt;
&lt;p&gt;And it is only to compute the square root for 289, not a big number. We could of
course increase the template depth limit (-ftemplate-depth=X), but that would
only get us a bit farther. If you try with g++, you should see that this works,
that is because g++ has a higher template depth limit (900 for 4.8.2 on my
machine) where clang has a default limit of 256. It can be noted too that with
g++ no context is skipped, therefore the error is quite long.&lt;/p&gt;
&lt;p&gt;Now that C++11 gives us constexpr function, we can rewrite it more cleanly:&lt;/p&gt;
&lt;pre class="code c++"&gt;&lt;a name="rest_code_73ead4a22db34c17845d956c61d995ab-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;constexpr&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;ct_sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
&lt;a name="rest_code_73ead4a22db34c17845d956c61d995ab-2"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;?&lt;/span&gt; &lt;span class="nl"&gt;n&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt; &lt;span class="o"&gt;?&lt;/span&gt; &lt;span class="n"&gt;ct_sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a name="rest_code_73ead4a22db34c17845d956c61d995ab-3"&gt;&lt;/a&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;Much nicer :) And it works perfectly with 289. And it works quite well up to a
large number. But it still fails once we git large numbers. For instance, here
is what clang++ gives me with 302500 (550*550):&lt;/p&gt;
&lt;pre class="literal-block"&gt;
src/sqrt/constexpr.cpp:8:36: error: constexpr variable 'result' must be initialized by a constant expression
static constexpr const std::size_t result = ct_sqrt(SQRT_VALUE);
                                   ^        ~~~~~~~~~~~~~~~~~~~
src/sqrt/constexpr.cpp:5:38: note: constexpr evaluation exceeded maximum depth of 512 calls
    return n == i ? n : (i * i &amp;lt; n ? ct_sqrt(n, i + 1) : i);
                                     ^
src/sqrt/constexpr.cpp:5:38: note: in call to 'ct_sqrt(302500, 512)'
src/sqrt/constexpr.cpp:5:38: note: in call to 'ct_sqrt(302500, 511)'
src/sqrt/constexpr.cpp:5:38: note: in call to 'ct_sqrt(302500, 510)'
src/sqrt/constexpr.cpp:5:38: note: in call to 'ct_sqrt(302500, 509)'
src/sqrt/constexpr.cpp:5:38: note: in call to 'ct_sqrt(302500, 508)'
src/sqrt/constexpr.cpp:5:38: note: (skipping 502 calls in backtrace; use -fconstexpr-backtrace-limit=0 to see all)
src/sqrt/constexpr.cpp:5:38: note: in call to 'ct_sqrt(302500, 5)'
src/sqrt/constexpr.cpp:5:38: note: in call to 'ct_sqrt(302500, 4)'
src/sqrt/constexpr.cpp:5:38: note: in call to 'ct_sqrt(302500, 3)'
src/sqrt/constexpr.cpp:5:38: note: in call to 'ct_sqrt(302500, 2)'
src/sqrt/constexpr.cpp:8:45: note: in call to 'ct_sqrt(302500, 1)'
static constexpr const std::size_t result = ct_sqrt(SQRT_VALUE);
                                            ^
&lt;/pre&gt;
&lt;p&gt;Again, we run into the limits of the compiler. And again, the limit can be
change with fconstexpr-backtrace-limit=X. With g++, the result is the same
(without the skipped part, which makes the error horribly long), but the command
to change the depth is -fconstexpr-depth=X.&lt;/p&gt;
&lt;p&gt;So, if we need to compute higher square roots at compile-time, we need a better
version.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="binary-search-version"&gt;
&lt;h2&gt;Binary Search version&lt;/h2&gt;
&lt;p&gt;To find the good square root, you don't need to iterate through all the numbers
from 1 to N, you can perform a binary search to find the numbers to test. I
found a very nice implementation by John Khvatov (&lt;a class="reference external" href="http://jkhvatov.blogspot.ch/2009/11/c-compile-time-square-root-sqrt-using.html"&gt;source&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Here is an adaptation of its code:&lt;/p&gt;
&lt;pre class="code c++"&gt;&lt;a name="rest_code_1603c640487a4c67a9e6761ef958bd99-1"&gt;&lt;/a&gt;&lt;span class="cp"&gt;#define MID(a, b) ((a+b)/2)&lt;/span&gt;
&lt;a name="rest_code_1603c640487a4c67a9e6761ef958bd99-2"&gt;&lt;/a&gt;&lt;span class="cp"&gt;#define POW(a) (a*a)&lt;/span&gt;
&lt;a name="rest_code_1603c640487a4c67a9e6761ef958bd99-3"&gt;&lt;/a&gt;
&lt;a name="rest_code_1603c640487a4c67a9e6761ef958bd99-4"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;res&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;l&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;res&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_1603c640487a4c67a9e6761ef958bd99-5"&gt;&lt;/a&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;ct_sqrt&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_1603c640487a4c67a9e6761ef958bd99-6"&gt;&lt;/a&gt;
&lt;a name="rest_code_1603c640487a4c67a9e6761ef958bd99-7"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;res&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_1603c640487a4c67a9e6761ef958bd99-8"&gt;&lt;/a&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="n"&gt;ct_sqrt&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;res&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;integral_constant&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;{};&lt;/span&gt;
&lt;a name="rest_code_1603c640487a4c67a9e6761ef958bd99-9"&gt;&lt;/a&gt;
&lt;a name="rest_code_1603c640487a4c67a9e6761ef958bd99-10"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;res&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;l&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_1603c640487a4c67a9e6761ef958bd99-11"&gt;&lt;/a&gt;&lt;span class="k"&gt;struct&lt;/span&gt; &lt;span class="nl"&gt;ct_sqrt&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;integral_constant&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ct_sqrt&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;res&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_1603c640487a4c67a9e6761ef958bd99-12"&gt;&lt;/a&gt;        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;POW&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;MID&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;l&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="n"&gt;res&lt;/span&gt; &lt;span class="o"&gt;?&lt;/span&gt; &lt;span class="nl"&gt;l&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;MID&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;l&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
&lt;a name="rest_code_1603c640487a4c67a9e6761ef958bd99-13"&gt;&lt;/a&gt;        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;POW&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;MID&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;l&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="n"&gt;res&lt;/span&gt; &lt;span class="o"&gt;?&lt;/span&gt; &lt;span class="n"&gt;MID&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;l&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;{};&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;With smart binary search, you can reduce A LOT the numbers that needs to be
tested in order to find the answer. It very easily found the answer for 302500.
It can find the square root of almost all integers, until it fails due to
overflows. I think it is really great :)&lt;/p&gt;
&lt;p&gt;Of course, we can also do the constexpr version:&lt;/p&gt;
&lt;pre class="code c++"&gt;&lt;a name="rest_code_bc1b6e28f4cb46248bdec544442edaf6-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;static&lt;/span&gt; &lt;span class="k"&gt;constexpr&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;ct_mid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
&lt;a name="rest_code_bc1b6e28f4cb46248bdec544442edaf6-2"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_bc1b6e28f4cb46248bdec544442edaf6-3"&gt;&lt;/a&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;a name="rest_code_bc1b6e28f4cb46248bdec544442edaf6-4"&gt;&lt;/a&gt;
&lt;a name="rest_code_bc1b6e28f4cb46248bdec544442edaf6-5"&gt;&lt;/a&gt;&lt;span class="k"&gt;static&lt;/span&gt; &lt;span class="k"&gt;constexpr&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;ct_pow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
&lt;a name="rest_code_bc1b6e28f4cb46248bdec544442edaf6-6"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_bc1b6e28f4cb46248bdec544442edaf6-7"&gt;&lt;/a&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;a name="rest_code_bc1b6e28f4cb46248bdec544442edaf6-8"&gt;&lt;/a&gt;
&lt;a name="rest_code_bc1b6e28f4cb46248bdec544442edaf6-9"&gt;&lt;/a&gt;&lt;span class="k"&gt;static&lt;/span&gt; &lt;span class="k"&gt;constexpr&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;ct_sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;res&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;l&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
&lt;a name="rest_code_bc1b6e28f4cb46248bdec544442edaf6-10"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt;
&lt;a name="rest_code_bc1b6e28f4cb46248bdec544442edaf6-11"&gt;&lt;/a&gt;        &lt;span class="n"&gt;l&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt; &lt;span class="o"&gt;?&lt;/span&gt; &lt;span class="nl"&gt;r&lt;/span&gt;
&lt;a name="rest_code_bc1b6e28f4cb46248bdec544442edaf6-12"&gt;&lt;/a&gt;        &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;ct_sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;res&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ct_pow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
&lt;a name="rest_code_bc1b6e28f4cb46248bdec544442edaf6-13"&gt;&lt;/a&gt;            &lt;span class="n"&gt;ct_mid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;l&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="n"&gt;res&lt;/span&gt; &lt;span class="o"&gt;?&lt;/span&gt; &lt;span class="nl"&gt;l&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;ct_mid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;l&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_bc1b6e28f4cb46248bdec544442edaf6-14"&gt;&lt;/a&gt;            &lt;span class="n"&gt;ct_pow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ct_mid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;l&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="n"&gt;res&lt;/span&gt; &lt;span class="o"&gt;?&lt;/span&gt; &lt;span class="n"&gt;ct_mid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;l&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a name="rest_code_bc1b6e28f4cb46248bdec544442edaf6-15"&gt;&lt;/a&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;a name="rest_code_bc1b6e28f4cb46248bdec544442edaf6-16"&gt;&lt;/a&gt;
&lt;a name="rest_code_bc1b6e28f4cb46248bdec544442edaf6-17"&gt;&lt;/a&gt;&lt;span class="k"&gt;static&lt;/span&gt; &lt;span class="k"&gt;constexpr&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;ct_sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;res&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
&lt;a name="rest_code_bc1b6e28f4cb46248bdec544442edaf6-18"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;ct_sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;res&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;res&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a name="rest_code_bc1b6e28f4cb46248bdec544442edaf6-19"&gt;&lt;/a&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;Which is a bit more understandable. It works the same way than the previous one
and is only limited by numeric overflow.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="c-14-fun"&gt;
&lt;h2&gt;C++14 Fun&lt;/h2&gt;
&lt;p&gt;In C++14, the constraints on constexpr functions have been highly relaxed, we
can now use variables, if/then/else statements, loops and so on... in constexpr
functions making them much more readable. Here is the C++14 version of the
previous code:&lt;/p&gt;
&lt;pre class="code c++"&gt;&lt;a name="rest_code_b2866268e52c426f90bc7d1939e2802a-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;static&lt;/span&gt; &lt;span class="k"&gt;constexpr&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;ct_sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;res&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;l&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
&lt;a name="rest_code_b2866268e52c426f90bc7d1939e2802a-2"&gt;&lt;/a&gt;    &lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;l&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
&lt;a name="rest_code_b2866268e52c426f90bc7d1939e2802a-3"&gt;&lt;/a&gt;        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_b2866268e52c426f90bc7d1939e2802a-4"&gt;&lt;/a&gt;    &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;a name="rest_code_b2866268e52c426f90bc7d1939e2802a-5"&gt;&lt;/a&gt;        &lt;span class="k"&gt;const&lt;/span&gt; &lt;span class="k"&gt;auto&lt;/span&gt; &lt;span class="n"&gt;mid&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;l&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_b2866268e52c426f90bc7d1939e2802a-6"&gt;&lt;/a&gt;
&lt;a name="rest_code_b2866268e52c426f90bc7d1939e2802a-7"&gt;&lt;/a&gt;        &lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mid&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;mid&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="n"&gt;res&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
&lt;a name="rest_code_b2866268e52c426f90bc7d1939e2802a-8"&gt;&lt;/a&gt;            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;ct_sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;res&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;l&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mid&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a name="rest_code_b2866268e52c426f90bc7d1939e2802a-9"&gt;&lt;/a&gt;        &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;a name="rest_code_b2866268e52c426f90bc7d1939e2802a-10"&gt;&lt;/a&gt;            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;ct_sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;res&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mid&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a name="rest_code_b2866268e52c426f90bc7d1939e2802a-11"&gt;&lt;/a&gt;        &lt;span class="p"&gt;}&lt;/span&gt;
&lt;a name="rest_code_b2866268e52c426f90bc7d1939e2802a-12"&gt;&lt;/a&gt;    &lt;span class="p"&gt;}&lt;/span&gt;
&lt;a name="rest_code_b2866268e52c426f90bc7d1939e2802a-13"&gt;&lt;/a&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;a name="rest_code_b2866268e52c426f90bc7d1939e2802a-14"&gt;&lt;/a&gt;
&lt;a name="rest_code_b2866268e52c426f90bc7d1939e2802a-15"&gt;&lt;/a&gt;&lt;span class="k"&gt;static&lt;/span&gt; &lt;span class="k"&gt;constexpr&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;ct_sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;res&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
&lt;a name="rest_code_b2866268e52c426f90bc7d1939e2802a-16"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;ct_sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;res&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;res&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a name="rest_code_b2866268e52c426f90bc7d1939e2802a-17"&gt;&lt;/a&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;I think this version is highly superior than the previous version. Don't you
think ?&lt;/p&gt;
&lt;p&gt;It performs exactly the same as the previous. This can only be done in clang for
now, but that will come eventually to gcc too.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="conclusion"&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;As you saw, there are several ways to compute a square root at compile-time in
C++. The constexpr versions are much more readable and generally more scalable
than the template metaprogramming version. Moreover, now, with C++14, we can
write constexpr functions almost as standard function, which makes really great.&lt;/p&gt;
&lt;p&gt;I hope that is is helpful to some of you :)&lt;/p&gt;
&lt;p&gt;All the sources are available on Github: &lt;a class="reference external" href="https://github.com/wichtounet/articles/tree/master/src/sqrt"&gt;https://github.com/wichtounet/articles/tree/master/src/sqrt&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;</description><category>C++</category><category>C++11</category><category>C++14</category><category>clang</category><category>Programming</category><guid>http://baptiste-wicht.com/posts/2014/07/compile-integer-square-roots-at-compile-time-in-cpp.html</guid><pubDate>Wed, 02 Jul 2014 19:05:11 GMT</pubDate></item><item><title>Install and Use CLang Static Analyzer on a CMake project</title><link>http://baptiste-wicht.com/posts/2014/04/install-use-clang-static-analyzer-cmake.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;div&gt;&lt;p&gt;I recently started a bit of work on my compiler (eddic) again. I started by adapting it to build on CLang with libc++. There was some minor adaptions to make it compile, but nothing really fancy. It now compiles and runs fine on LLVM/Clang 3.4 with the last version of libc++. I'm gonna use some features of C++14 in it and I plan to refactor some parts to make it more &lt;em&gt;STL-correct&lt;/em&gt;. I also plan to use only CLang on eddic right now, since C++14 support of GCC is not released right now. &lt;/p&gt;
&lt;p&gt;I decided it was a good time to try again the CLang static analyzer. &lt;/p&gt;
&lt;h3&gt;Installation&lt;/h3&gt;
&lt;p&gt;If, like me, you're using Gentoo, the static analyzer is directly installed with the &lt;em&gt;sys-devel/clang&lt;/em&gt; package, unless you disabled the &lt;em&gt;static-analyzer&lt;/em&gt; USE flag. &lt;/p&gt;
&lt;p&gt;If your distribution does not ship the static analyzer directly with CLang, you'll have to install it manually. To install it from sources, I advise you to follow the &lt;a href="http://clang-analyzer.llvm.org/installation.html"&gt;Official Installations instruction&lt;/a&gt;. &lt;/p&gt;
&lt;h3&gt;Usage&lt;/h3&gt;
&lt;p&gt;The usage of CLang static analyzer can be a bit disturbing at first. Most static analysis tools generally takes the sources directly and do their stuff. But that is not how Clang Static Analyzer works. It works as a kind of monitor in top of building the program, using &lt;em&gt;scan-build&lt;/em&gt;. When you are analyzing a program, you are also building the program. &lt;/p&gt;
&lt;p&gt;For instance, if you are compiling a source file like that: &lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;clang [clang-options] source_file.cpp
&lt;/pre&gt;


&lt;p&gt;you can perform static analysis like that: &lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;scan-build [scan-build-options] clang [clang-options] source_file.cpp
&lt;/pre&gt;


&lt;p&gt;scan-build works by replacing calls to the compiler by calls to &lt;em&gt;ccc-analyzer &lt;/em&gt;. This works generally well, but there are some cases where that things get a bit more complicated. That is the case of CMake where the paths to the compiler are hardcoded in the generated makefiles. &lt;/p&gt;
&lt;p&gt;For that, you have to run &lt;em&gt;cmake&lt;/em&gt; and &lt;em&gt;make&lt;/em&gt; with &lt;em&gt;scan-build&lt;/em&gt;: &lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;export CCC_CC=clang
export CCC_CXX=clang++
scan-build cmake -DCMAKE_CXX_COMPILER=clang++ -DCMAKE_C_COMPILER=clang .
scan-build make
&lt;/pre&gt;


&lt;p&gt;This can take a very long time. On eddic, it is about three times slower than a normal compilation. An important point to note about performance, is that you can run compilations in parallel (-j option of make) and that it is supported by scan-build quite well. &lt;/p&gt;
&lt;p&gt;Once analysis is performed, the found bugs are put into an HTML report. By default, the HTML report is created in &lt;em&gt;/tmp/&lt;/em&gt;, but you can specificy the folder with -o option of scan-build. &lt;/p&gt;
&lt;p&gt;You can enable or disable checker with the -enable-checker and -disable-checker options of scan-build. &lt;/p&gt;
&lt;h3&gt;Results on eddic&lt;/h3&gt;
&lt;p&gt;Several versions of Clang ago, I tried the static analyzer on eddic, but it failed on several source files without producing any results. Moreover, at this time, I don't think there was any nice HTML report at this time. &lt;/p&gt;
&lt;p&gt;I ran it again on eddic with the last versions. Here is a picture of the generated report: &lt;/p&gt;
&lt;p&gt;&lt;img alt="CLang Static Analyzer eddic results" src="http://baptiste-wicht.com/images/eddic_results.png"&gt;&lt;/p&gt;
&lt;p&gt;As you can see, 14 bugs have been found. Unfortunately, none of them is a real bug on my code, but they are not all false positives neither. For instance, here is some unreachable code report: &lt;/p&gt;
&lt;p&gt;&lt;img alt="CLang Static Analyzer eddic bug" src="http://baptiste-wicht.com/images/eddic_results_bug.png"&gt;&lt;/p&gt;
&lt;p&gt;It is indeed an unreachable statement, but it is expected, since it is an assert to ensure that the code is unreachable. But that proves that the analysis works ;) &lt;/p&gt;
&lt;p&gt;Even if it didn't found anything, this time it worked much better than the last time I checked and the HTML results are just really good. &lt;/p&gt;
&lt;p&gt;I hope you found this article interesting. If you happen to have interesting results on your codebase with the CLang static analyzer, I'd be glad to hear about them ;)&lt;/p&gt;&lt;/div&gt;</description><category>C++</category><category>C++11</category><category>C++14</category><category>clang</category><category>eddic</category><category>llvm</category><category>Tools</category><guid>http://baptiste-wicht.com/posts/2014/04/install-use-clang-static-analyzer-cmake.html</guid><pubDate>Wed, 09 Apr 2014 14:39:11 GMT</pubDate></item><item><title>Improving eddic Boost Spirit parser performances</title><link>http://baptiste-wicht.com/posts/2013/06/improving-eddic-boost-spirit-parser-performances.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;div&gt;&lt;p&gt;After the last changes on the data-flow framework, the parsing pass of the eddic compiler became the slowest one. I was sure there was some area of optimizations, so I decided to improve its performances.&lt;/p&gt;
&lt;p&gt;In this post, I will present the different techniques I applied and their results.&lt;/p&gt;
&lt;h4&gt;Static grammar&lt;/h4&gt;

&lt;p&gt;The first optimization that I tried was to make the grammar static, meaning that we can declare it static and it will be constructed only once and will be allocated on the data segment.It is indeed heavy to build the lexer especially but also the grammar. I would like to thank &lt;a title="sehe on github" href="https://github.com/sehe"&gt;sehe&lt;/a&gt; for this optimization, he found it after I posted a question on Stackoverflow.&lt;/p&gt;
&lt;p&gt;The lexer was very easy to make static (only add static keyword :) ), but the parser was a bit more complicated because it needs the lexer iterator to get the current position in the file. This problem has been resolved by saving the iterator into the qi::locals of the rules.&lt;/p&gt;
&lt;p&gt;The result of this optimization are amazing. It saved 33% of the time.&lt;/p&gt;
&lt;h4&gt;Expectation points&lt;/h4&gt;

&lt;p&gt;Expectation points have the interesting point that they disallow backtracking and so can improve performances in some cases. Moreover, they are always interesting because they make the grammar clearer and the error messages much better.&lt;/p&gt;
&lt;p&gt;I tried adding more expectation points to the grammar. Unfortunately, there weren't a lot of them to add. Moreover, it seems that there are some quite weird behavior with them because some times it is impossible to add them (causes compilation failure) and sometimes it just make the code don't work anymore the same way, though I don't understand why.&lt;/p&gt;
&lt;p&gt;Anyway, I have been able to add some to the grammar. These changes improve the performance by a bit more than 1%. It is not a lot, but it is still an improvement. Moreover, I'm quite sure that there are more expectation points that can be added to the code. I will take some time again later to try to add more and to understand them better.&lt;/p&gt;
&lt;h4&gt;Less skips&lt;/h4&gt;

&lt;p&gt;In my grammar, I've a special parser for getting the current position in the file to add "debug information" to the AST. This special parser was skipping over its content, but it has no content, since it is artificial. Removing it improved the performance by about half a percent.&lt;/p&gt;
&lt;h4&gt;Improve Position (debug information)&lt;/h4&gt;

&lt;p&gt;As said before, there is a special parser to get the current position in the file. This information is then stored into an eddic::ast::Position structure. This structure was holding the line number, the column, the file name and the contents of the line. The first two were ints and the last two were std::string. Each time, a copy of the strings were necessary.&lt;/p&gt;
&lt;p&gt;I avoided storing the std::string directly by storing only the number of the line as well as the index of the file. Then, the content of the file is stored in the global context and can be accessed if it is necessary to display the line where the error happened.&lt;/p&gt;
&lt;p&gt;This change gave an increase of 10% of the parsing performance.&lt;/p&gt;
&lt;h4&gt;Auto Rules&lt;/h4&gt;

&lt;p&gt;Rules in Boost Spirit have an overhead due to the cost of the virtual calls that are necessary. In theory, auto rules can improve the efficiency of the rules by removing the cost of virtual calls. Moreover, auto rules should also avoid code bloat when the rules are compiled. The rules can be inlined and better optimized.&lt;/p&gt;
&lt;p&gt;I transformed some rules to auto rules to improve performances. Unfortunately, I found that this did not improve the performances. Moreover, transforming some rules to auto rules made the performance worse. I still did let some of the rules as auto rules. I have to say that I was very disappointed by this result, I was really expecting more from this :(&lt;/p&gt;
&lt;h4&gt;Generated Static Lexer&lt;/h4&gt;

&lt;p&gt;The first time the lexer is used, it has to generate the Deterministic Finite Automaton (DFA) that is used to identify the different tokens. This process takes time. There is way to avoid this by using the static model of Boost Spirit Lex. With that, the code is generated with the complete DFA and then it doesn't have to be initialized again.&lt;/p&gt;
&lt;p&gt;I was not expecting a lot from this because the lexer was already static and so was initialized only once. Indeed, it resulted in less than half a percent improvement.&lt;/p&gt;
&lt;h4&gt;Conclusion&lt;/h4&gt;

&lt;p&gt;Even if I've been able to largely reduce the overhead of the parsing by more than 40%, it still has a big overhead. Indeed, it still represents 36 percent of the whole process of compiling a source file. I think it is still too much.&lt;/p&gt;
&lt;p&gt;Moreover, an interesting fact is that the optimization I would have thought to be very effective (auto rules especially) did not have the expected effect, but making the grammar static, which I would not have thought of, was very effective.&lt;/p&gt;
&lt;p&gt;When profiled, the final version shows that quite some time is spent in destructing the multi_pass, which is quite odd. And it also seems that transforming the string operators to ast::Operator is not very effective, but I do not know how to improve that at this point.&lt;/p&gt;
&lt;p&gt;I won't probably work on that again for the version 1.2.4 of eddic, but I will eventually take some time again for the version 1.3.0 to improve it again.&lt;/p&gt;&lt;/div&gt;</description><category>Benchmarks</category><category>Boost</category><category>C++11</category><category>Compilers</category><category>EDDI</category><category>Performances</category><guid>http://baptiste-wicht.com/posts/2013/06/improving-eddic-boost-spirit-parser-performances.html</guid><pubDate>Mon, 10 Jun 2013 06:16:42 GMT</pubDate></item><item><title>eddic 1.2.2 - Performances, improved optimizations and additions to standard library</title><link>http://baptiste-wicht.com/posts/2013/01/eddic-1-2-2-performances-optimization-library.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;div&gt;&lt;p&gt;These last weeks, I had more work than expected with my Master thesis so it took me longer to finish this new version of eddic. Moreover, I included more stuff than I though in this version. Anyway, I'm happy to announce the version 1.2.2 of eddic.&lt;/p&gt;
&lt;p&gt;It is a minor version regarding the language itself. On the other, there are a lot of changes in the compiler itself.&lt;/p&gt;
&lt;p&gt;For the language:&lt;/p&gt;
&lt;ol&gt;
    &lt;li&gt;Structures are now correclty copy constructed when passed by value&lt;/li&gt;
    &lt;li&gt;When the same header is included several times accross the program, it is not parsed again&lt;/li&gt;
    &lt;li&gt;The vector structure has now functions to insert and remove elements in arbitrary positions&lt;/li&gt;
    &lt;li&gt;The functions to print bools, floats and integers are now written in EDDI directly. Only the functions to print chars and raw string are now written in assembly&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I worked on improving the performances by improving the constant propagation pass that runs less times now and by tuning a bit the data-flow framework, avoiding virtual calls.&lt;/p&gt;
&lt;p&gt;Another improvement is that all the mtac::Statement types have been merged in mtac::Quadruple, this removes one level of indirection and simplifies several passes. Moreover, there are now directly stored inside a vector and not allocated via shared_ptr. This removes another level of indirection.&lt;/p&gt;
&lt;p&gt;Put together, these two optimizations improved the performances of the compiler by about 15%. On the other hand, now that printF and printI are written in EDDI, it takes much longer to compile. I will work on that for the next version too. One way to improve the performances will be to tune the ordering of passes and also to tune the passes themselves so that they do more work at once. I will also try to merge constant propagation and offset constant propagation together. They perform very similar work.&lt;/p&gt;
&lt;p&gt;There are also several improvements in the optimization engine:&lt;/p&gt;
&lt;ul&gt;
    &lt;li&gt;The loop analysis has been fixed to handle loops bigger than one basic block. There was a problem in my implement of &lt;strong&gt;Lengauer and Tarjan&lt;/strong&gt; making that dominators were not computed.&lt;/li&gt;
    &lt;li&gt;The optimization engine now create a call graph of the program. This call graph is used to remove unused functions that are called but not reachable from the main function.&lt;/li&gt;
    &lt;li&gt;A new analysis pass has been added: pure_analysis. This pass test if a function is pure (no write to pointers or global variables) and thus avoid creating a basic block for it&lt;/li&gt;
    &lt;li&gt;The L&lt;strong&gt;oop Invariant Code Motion algorithm&lt;/strong&gt; has been improved to handle more invariants&lt;/li&gt;
    &lt;li&gt;The &lt;strong&gt;Common Subexpression Elimination&lt;/strong&gt; algorithm has been improved to handle more expression&lt;/li&gt;
    &lt;li&gt;The &lt;strong&gt;Induction Variables analysis&lt;/strong&gt; has been reviewed and several bugs have been corrected. It is now a bit complicated.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A big bug has been fixed in the handling of the MEMSET LTAC instruction. This will be completely reviewed in the next version (See Future Work).&lt;/p&gt;
&lt;p&gt;Some analysis starts to become quite complicated. I'm thinking of using SSA in MTAC in order to simplify some of the passes and to easily compute ud-chains. Another thing that I'm thinking is to add a powerful and complete alias analysis that would really improve the efficiency of some passes (offset constant propagation for instance) by making them less conservative.&lt;/p&gt;
&lt;p&gt;I also have removed some memory leaks (will try to remove all of them in the next version). I added a new optimization level: O3. This level enables loop unrolling and complete loop peeling.&lt;/p&gt;
&lt;h4&gt;Future Work&lt;/h4&gt;

&lt;p&gt;The next version of the EDDI compiler (eddic) will be the version 1.2.3. The inliner will be improved to work directly in the call graph in postorder. That should produce better code. I will also try to improve the inlining heuristics. A first basic version of loop unswitching will be added as well. I will add a small local constant propagation pass for globals. I will also continue to work on the performances of the passes to avoid repeating them too much. MEMSET will be completely reviewed. That should produce smaller and faster code. Until now, the sizes of the types bool and chars were the same as int. They will be optimized to take only 1 byte.&lt;/p&gt;
&lt;p&gt;I will also continue the improvements of the data structures by merging all ltac::Statement into ltac::Instruction and storing them directly.&lt;/p&gt;
&lt;p&gt;And there will probably be some bug fixing as well.&lt;/p&gt;
&lt;h4&gt;Download&lt;/h4&gt;

&lt;p&gt;You can find the EDDI Compiler sources on the Github repository: &lt;a title="Github repository of eddic" href="https://github.com/wichtounet/eddic"&gt;https://github.com/wichtounet/eddic&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The version is available in the &lt;em&gt;v1.2.2&lt;/em&gt; tag available in the GitHub or directly in the &lt;em&gt;master&lt;/em&gt; branch.&lt;/p&gt;&lt;/div&gt;</description><category>C++11</category><category>EDDI</category><category>Releases</category><guid>http://baptiste-wicht.com/posts/2013/01/eddic-1-2-2-performances-optimization-library.html</guid><pubDate>Sat, 26 Jan 2013 15:35:42 GMT</pubDate></item><item><title>C++ Benchmark - std::list VS boost::intrusive::list</title><link>http://baptiste-wicht.com/posts/2012/12/cpp-benchmark-std-list-boost-intrusive-list.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;div&gt;&lt;script type="text/javascript" src="https://www.google.com/jsapi"&gt;&lt;/script&gt;

&lt;script type="text/javascript"&gt;google.load('visualization','1',{packages:['corechart']});&lt;/script&gt;

&lt;p&gt;Recently, we saw that the &lt;a title="C++ benchmark â€“ std::vector VS std::list VS std::deque" href="http://www.baptiste-wicht.com/2012/12/cpp-benchmark-vector-list-deque/"&gt;std::list performance was not really good&lt;/a&gt; when it comes to searching it or iterating through it.In this post, we will see an alternative to the std::list: the boost::intrusive::list from the Boost C++ libraries. It is not a well known library but it can be useful in some specific cases. I will focus on how this implementation performs compared to an std::list.&lt;/p&gt;
&lt;p&gt;An intrusive list does not store copies of the object but the objects itself. Because it stores the objects, it is necessary to add information to the object data structure directly to link them together, that is why it is called anÂ intrusiveÂ list. This has a big advantage, the list does not have to allocate any memory at all to insert objects. In a std::list if you insert an object, a node object will be created containing a copy of the object, but not in an intrusive list where only the pointers to the next and to the previous element of the inserted object are updated. Another advantage is that if you have a reference to an object you can directly obtain an iterator to this object in O(1), an operation that would be in O(n) with a std::list. Iteration is faster because it needs less memory accesses.&lt;/p&gt;
&lt;p&gt;On the other hand, an intrusive list has also several drawbacks. First of all, it is intrusive. It means that you have to change the definition of the type that is stored inside the intrusive list. Then, and it be very complicated, it is up to the developer to manage the life time of the objects. It means that it is up to you to allocate and deallocate memory for each objects that you want to put in your collection. For instance, if you store an object into an intrusive list and later delete this object without removing it from the list, you will have broken you list. It is also less safe because the container can be modified from outside simply by modifying the pointers directly inside the objects.&lt;/p&gt;
&lt;p&gt;This article is not a tutorial for Boost intrusive collections, I will just focus on the performance aspect, if you want to learn how to use them, you can consult &lt;a href="http://www.boost.org/doc/libs/1_52_0/doc/html/intrusive.html" title="Boost Intrusive 1.52"&gt;the official documentation&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;A boost::intrusive::list can be configured in three mode:&lt;/p&gt;
&lt;ol&gt;
    &lt;li&gt;Normal mode: No special features&lt;/li&gt;
    &lt;li&gt;Safe mode: The hook is initialized to a default safe state and the container check this state before inserting a value. The state of a removed node is also updated correctly. It can be used to detect programming errors. It implies a small performance overhead. This is the default mode.&lt;/li&gt;
    &lt;li&gt;Auto unlink mode: When an object gets destructed it is automatically removed from the container. This mode has also the properties of the safe mode.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The mode is chosen at constant time by configuring the hook of the data type. In this article, all three mode will be tested. Here are the four types that will be tested:&lt;/p&gt;
&lt;ul&gt;
    &lt;li&gt;list : std::list&lt;/li&gt;
    &lt;li&gt;normal_ilist : boost::intrusive::list in normal mode&lt;/li&gt;
    &lt;li&gt;safe_ilist : boost::intrusive::list in safe mode&lt;/li&gt;
    &lt;li&gt;auto_unlink_ilist : boost::intrusive::list in auto unlink mode&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The data types are varying in size, they hold an array of longs and the size of the array varies to change the size of the data type. In each graph, the size of the data type is indicated. It is the size of the normal data type. The intrusive data types are always 16 bytes bigger than the normal data types.&lt;/p&gt;
&lt;p&gt;In the graphs and in the text,Â &lt;em&gt;n&lt;/em&gt;Â is used to refer to the number of elements of the collection.&lt;/p&gt;
&lt;p&gt;All the tests performed have been performed on an Intel Core i7 Q 820 Â @ 1.73GHz. The code has been compiled in 64 bits with GCC 4.7.2 with the given options:Â &lt;em&gt;-std=c++11 -O2 -fomit-frame-pointer -march=native&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;For each graph, the vertical axis represent the amount of time necessary to perform the operations, so the lower values are the better. The horizontal axis is always the number of elements of the collection. For some graph, the logarithmic scale could be clearer, a button is available after each graph to change the vertical scale to a logarithmic scale.&lt;/p&gt;
&lt;p&gt;So let's see these data structures in practice.&lt;/p&gt;
&lt;!--nextpage--&gt;

&lt;h3&gt;Fill list&lt;/h3&gt;

&lt;p&gt;The first test that is performed is how long does it take to fill each data structure. For the std::list, each value is entered directly. For the intrusive list variations, the data are entered into a vector and then pushed back to the intrusive list.&lt;/p&gt;
&lt;p&gt;So, let's test them:&lt;/p&gt;
&lt;div id="graph_0" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_0" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_0(){var graph=new google.visualization.LineChart(document.getElementById('graph_0'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['100000',265,261,491,2926],['200000',534,498,773,4717],['300000',1874,1841,1901,7201],['400000',2670,2657,2749,9696],['500000',3410,3447,3486,11608],['600000',4044,4095,4050,14024],['700000',4653,4549,4626,16750],['800000',5406,5320,5414,18568],['900000',5995,5926,6160,20880],['1000000',6806,6785,6784,22795],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"fill_back - Normal&amp;lt;8u&amp;gt;",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"us",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_0');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;We can see that filling a list is about thrice slower than an intrusive version. This is quite logical because there are much less memory allocations in the case of the intrusive lists. The differences between the different intrusive versions are not very big. The normal version is the fastest, then the auto unlink and finally the safe version is the slowest.&lt;/p&gt;
&lt;p&gt;If we increase the size of the data type a bit:&lt;/p&gt;
&lt;div id="graph_1" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_1" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_1(){var graph=new google.visualization.LineChart(document.getElementById('graph_1'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['100000',850,894,967,2685],['200000',1760,1671,1747,5742],['300000',3987,3916,3970,8517],['400000',5257,5191,5238,10919],['500000',6561,6813,6661,13614],['600000',7943,8197,7954,15874],['700000',9251,9523,9049,18625],['800000',10463,10865,10417,21114],['900000',11736,11992,11734,23824],['1000000',13137,13423,13055,26555],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"fill_back - Normal&amp;lt;32u&amp;gt;",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"us",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_1');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;The results remains more or less the same, but this time there is less difference between list and intrusive list.&lt;/p&gt;
&lt;div id="graph_2" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_2" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_2(){var graph=new google.visualization.LineChart(document.getElementById('graph_2'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['100000',2131,2109,2923,39337],['200000',3834,3830,5792,90984],['300000',6454,6508,8604,138087],['400000',8499,8926,11614,185607],['500000',11068,10874,14455,230798],['600000',13009,13052,17307,275473],['700000',14965,15008,20593,326638],['800000',17082,17186,23109,372022],['900000',19283,19476,26182,415426],['1000000',21503,21569,29463,463462],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"fill_back - Normal&amp;lt;1024u&amp;gt;",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"us",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_2');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;This time, the results are really different. The intrusive versions are twenty times faster than a standard list. This comes from dynamic allocations of large blocks that is very expensive. In the case of intrusive list, there are no memory allocations, just modifications of pointers, so it it is normal that for big blocks the difference is higher.&lt;/p&gt;
&lt;p&gt;We can see that for push_back operations, the intrusive are clearly faster. For small data types, they can be up to three times faster. The difference can be much higher with very big data types. There are no big differences between the different versions of the intrusive lists. The normal mode is about 10% faster than the safe mode.&lt;/p&gt;
&lt;!--nextpage--&gt;

&lt;h3&gt;Destruction of list&lt;/h3&gt;

&lt;p&gt;The second test is about the time necessary to destruct a collection. For a list, the list is simply allocated on the heap and destructed with delete operator. For an intrusive list, both the vector and the list are allocated on the heap. The time is computed to delete both the vector and the intrusive list.&lt;/p&gt;
&lt;p&gt;Let's take a look at the results:&lt;/p&gt;
&lt;div id="graph_3" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_3" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_3(){var graph=new google.visualization.LineChart(document.getElementById('graph_3'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['100000',298,283,0,2420],['200000',588,585,0,3132],['300000',1196,1217,1,4487],['400000',2180,2350,1,6478],['500000',3169,3098,1,7259],['600000',3975,3957,1,8609],['700000',4569,4798,1,10018],['800000',5189,5311,1,11501],['900000',5927,6022,1,13004],['1000000',6616,6592,1,14423],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"destruction - Normal&amp;lt;8u&amp;gt;",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"us",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_3');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;The impressive result is that the normal mode is almost free. It is normal because the destructor of the objects does not do anything. Neither the list does anything about the state of the object after it has been removed. The other two intrusive versions performs the same and twice faster than a list.&lt;/p&gt;
&lt;p&gt;Let's increase a bit the size:&lt;/p&gt;
&lt;div id="graph_4" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_4" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_4(){var graph=new google.visualization.LineChart(document.getElementById('graph_4'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['100000',515,531,0,1490],['200000',1997,1964,0,3370],['300000',4022,3818,1,5585],['400000',5219,5456,1,7099],['500000',6693,6847,1,9054],['600000',7859,7984,1,11131],['700000',9456,9382,1,12248],['800000',10637,10493,1,14059],['900000',12433,11882,1,15933],['1000000',13646,13098,1,17434],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"destruction - Normal&amp;lt;32u&amp;gt;",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"us",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_4');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;This time, the std::list version is getting closer to the auto unlink and safe versions. The auto unlink version is a bit slower than the safe version. The normal mode is still free.&lt;/p&gt;
&lt;p&gt;Increasing it a bit again:&lt;/p&gt;
&lt;div id="graph_5" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_5" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_5(){var graph=new google.visualization.LineChart(document.getElementById('graph_5'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['100000',4110,4158,1,4388],['200000',8357,8231,1,8949],['300000',12461,11871,1,12417],['400000',16097,16064,1,16249],['500000',19754,19990,1,19181],['600000',23724,24022,1,22019],['700000',28973,28421,2,24928],['800000',32638,32793,1,31896],['900000',37257,36320,1,35455],['1000000',40422,41037,1,39357],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"destruction - Normal&amp;lt;128u&amp;gt;",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"us",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_5');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;We can see that the list is a small bit faster than the other two versions.&lt;/p&gt;
&lt;p&gt;If we push the memory to its limit:&lt;/p&gt;
&lt;div id="graph_6" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_6" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_6(){var graph=new google.visualization.LineChart(document.getElementById('graph_6'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['100000',2582,2689,1,5669],['200000',10506,10450,1,19719],['300000',16490,16429,1,33569],['400000',21521,21702,1,47179],['500000',27188,27217,1,59640],['600000',32507,32470,1,70116],['700000',37288,37344,1,81122],['800000',42825,42611,1,91972],['900000',48004,48315,1,104401],['1000000',53439,53988,1,114482],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"destruction - Normal&amp;lt;1024u&amp;gt;",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"us",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_6');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;This time, the list is again slower. I'm not sure of why this happens, but it is certainly because of the memory allocator that has two allocate too many big blocks, which tends to be more costly than many small.&lt;/p&gt;
&lt;p&gt;For the destruction, the normal mode proved its high strength, being totally free to destroy. The safe and auto unlink modes are proving much more expensive during destruction, but still quite a bit faster than a standard list.&lt;/p&gt;
&lt;p&gt;It is also necessary to keep in mind that the destruction is generally not a common operation and is about 4 times faster than insertion. In practice, neither push_back nor destruction are critical in choosing a data structure.&lt;/p&gt;
&lt;!--nextpage--&gt;

&lt;h3&gt;Linear Search in a list&lt;/h3&gt;

&lt;p&gt;The next operation that will benchmark is the linear search. The container is filled with all the numbers in [0, n] and shuffled. Then, each number in [0, n] is searched in the container with std::find that performs a simple linear search.&lt;/p&gt;
&lt;p&gt;How do the different data structures perform:&lt;/p&gt;
&lt;div id="graph_7" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_7" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_7(){var graph=new google.visualization.LineChart(document.getElementById('graph_7'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['1000',1213,1211,1200,1463],['2000',5715,5561,5931,6992],['3000',12451,11619,11608,14251],['4000',19338,20142,19208,24840],['5000',30147,30889,29863,40523],['6000',42941,44530,43289,59541],['7000',59717,62534,58851,80416],['8000',77519,78889,77188,104198],['9000',99738,99434,100375,135452],['10000',123829,123216,123506,169720],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"linear_search - Normal&amp;lt;8u&amp;gt;",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"us",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_7');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;As expected, the intrusive list versions are faster than the standard list. The margin is about 40%. The intrusive versions have a better locality than the standard list because there is one less indirection.&lt;/p&gt;
&lt;p&gt;Increasing the data type size:&lt;/p&gt;
&lt;div id="graph_8" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_8" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_8(){var graph=new google.visualization.LineChart(document.getElementById('graph_8'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['1000',2901,2862,2940,2757],['2000',14258,14242,14413,18990],['3000',37327,37078,37387,48716],['4000',69310,68935,69152,86224],['5000',109444,110199,108283,134128],['6000',158570,158392,158398,202273],['7000',219949,220489,219070,266387],['8000',285885,289721,283485,342109],['9000',363603,361367,362935,424984],['10000',445068,451009,447940,525289],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"linear_search - Normal&amp;lt;128u&amp;gt;",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"us",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_8');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;The margin has decreased a bit to about 15%. As the data object does not fit in cache we have higher cache misses rate.&lt;/p&gt;
&lt;p&gt;If we increase it to the maximum:&lt;/p&gt;
&lt;div id="graph_9" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_9" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_9(){var graph=new google.visualization.LineChart(document.getElementById('graph_9'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['1000',3517,3818,3487,3570],['2000',19342,18999,18875,22972],['3000',59722,59728,60953,60749],['4000',116755,118256,117172,123127],['5000',194630,195522,192977,204278],['6000',287911,287099,291353,296178],['7000',395506,404527,396043,413398],['8000',519636,527051,527183,549713],['9000',662320,669371,672484,693154],['10000',831052,828032,832995,859092],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"linear_search - Normal&amp;lt;1024u&amp;gt;",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"us",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_9');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;Again, the margin decreased, to 3%.&lt;/p&gt;
&lt;p&gt;For linear searching, the intrusive versions are clearly faster, however, not by a high advantage and this advantage tends to get lower with bigger data types. I would really have expected a more interesting result here. We will see with the next results if it gets better.&lt;/p&gt;
&lt;!--nextpage--&gt;

&lt;h3&gt;Iteration over a list&lt;/h3&gt;

&lt;p&gt;This time, we will test the iteration over a whole collection. The iterate is done with the C++11 foreach loop (taking a reference) and the data is used to increment a counter (to make sure the loop is not optimized away.&lt;/p&gt;
&lt;p&gt;Let's start with our small data type:&lt;/p&gt;
&lt;div id="graph_10" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_10" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_10(){var graph=new google.visualization.LineChart(document.getElementById('graph_10'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['100000',204,202,209,276],['200000',430,404,439,715],['300000',967,956,1086,1969],['400000',1837,1826,1870,2672],['500000',2705,2668,2699,3130],['600000',3176,3110,3217,3815],['700000',3856,3678,3575,4363],['800000',4209,4090,4095,4860],['900000',4778,4334,4433,5511],['1000000',4934,4908,4656,5541],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"iterate - Normal&amp;lt;8u&amp;gt;",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"us",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_10');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;The standard list is indeed slower than the other versions (by about 20%). Which is expected due to their better data locality. However, the results are not very stable (probably too fast, many things can intervene). I was expecting better results.&lt;/p&gt;
&lt;p&gt;Let's go with a higher data type:&lt;/p&gt;
&lt;div id="graph_11" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_11" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_11(){var graph=new google.visualization.LineChart(document.getElementById('graph_11'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['100000',3694,3635,3467,3830],['200000',6779,6766,6430,7070],['300000',9472,9819,9291,10270],['400000',12354,12322,12165,13588],['500000',15188,15270,15079,16725],['600000',18447,18246,17797,19875],['700000',20925,20578,20596,23256],['800000',23539,23780,23421,26451],['900000',26492,26237,25975,29785],['1000000',29757,29482,28681,32752],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"iterate - Normal&amp;lt;128u&amp;gt;",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"us",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_11');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;This time, the results look better, but there are less difference between the standard list and the intrusive versions. The intrusive versions are faster by about 10%.&lt;/p&gt;
&lt;p&gt;If we take a bigger data type:&lt;/p&gt;
&lt;div id="graph_12" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_12" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_12(){var graph=new google.visualization.LineChart(document.getElementById('graph_12'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['100000',2797,2649,2496,5211],['200000',10148,10227,10199,10701],['300000',15379,15544,15458,15189],['400000',20181,20599,20213,20135],['500000',25481,25517,25381,25567],['600000',30407,30408,30326,29938],['700000',35187,35343,35498,34985],['800000',40094,39874,40172,40027],['900000',44875,45329,45314,44964],['1000000',49584,50143,50405,49737],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"iterate - Normal&amp;lt;1024u&amp;gt;",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"us",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_12');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;This time, there is no more difference between the different versions.&lt;/p&gt;
&lt;p&gt;Just like the results for linear search, the intrusive versions are faster but the difference is not huge. For very small data type, there is a gain of about 15 to 20 percent, but on very big data types, there is no more increase in performance. Again, I would have expected better results for the intrusive versions.&lt;/p&gt;
&lt;!--nextpage--&gt;

&lt;h3&gt;Write to elements of the list&lt;/h3&gt;

&lt;p&gt;This test is almost the same as the previous one, but this time each element of the collection is modified by incrementing one of its field.&lt;/p&gt;
&lt;p&gt;Let's see if the results are different this time.&lt;/p&gt;
&lt;div id="graph_13" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_13" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_13(){var graph=new google.visualization.LineChart(document.getElementById('graph_13'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['100000',267,290,263,343],['200000',579,583,548,889],['300000',1111,1142,1114,2151],['400000',2155,2143,2146,3197],['500000',3193,3186,3163,4168],['600000',4016,3991,3978,5179],['700000',4727,4916,4717,6026],['800000',5560,5534,5440,6977],['900000',6125,6157,6064,7693],['1000000',6830,6920,6785,8613],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"write - Normal&amp;lt;8u&amp;gt;",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"us",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_13');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;The results are more stable than before. We can see that the normal mode is leading the results by a bit less than 30%. Just like for iteration, there no real difference between the different modes.&lt;/p&gt;
&lt;p&gt;Let's increase the data size by a bit:&lt;/p&gt;
&lt;div id="graph_14" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_14" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_14(){var graph=new google.visualization.LineChart(document.getElementById('graph_14'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['100000',505,513,530,1069],['200000',1957,1991,2023,3222],['300000',4056,4053,4000,4806],['400000',5572,5493,5587,6408],['500000',6763,6798,6714,8578],['600000',8224,8142,8050,10037],['700000',9520,9622,9568,12272],['800000',10982,11451,10947,13818],['900000',12195,12305,12185,15103],['1000000',14043,13657,13775,17187],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"write - Normal&amp;lt;32u&amp;gt;",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"us",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_14');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;The results are the same, still 30% better for the intrusive version.&lt;/p&gt;
&lt;p&gt;Bigger data type again:&lt;/p&gt;
&lt;div id="graph_15" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_15" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_15(){var graph=new google.visualization.LineChart(document.getElementById('graph_15'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['100000',3263,3415,3172,4444],['200000',9467,9434,9513,8855],['300000',13996,13888,14227,13379],['400000',18181,18458,18255,17684],['500000',22751,23292,22956,22067],['600000',27371,27511,27329,25995],['700000',31236,31389,31404,31164],['800000',35749,35970,36132,35224],['900000',39972,40684,40549,39786],['1000000',45119,45124,44840,43937],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"write - Normal&amp;lt;1024u&amp;gt;",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"us",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_15');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;This time, the intrusive version is not faster anymore than the standard list.&lt;/p&gt;
&lt;p&gt;We have seen that when write is made to the data, intrusive list are better than list. The margin is higher than when doing only iteration.&lt;/p&gt;
&lt;!--nextpage--&gt;

&lt;h3&gt;Reverse the list&lt;/h3&gt;

&lt;p&gt;Let's test something more useful with a reverse operation. The reverse member function is used to reverse all the containers.&lt;/p&gt;
&lt;p&gt;Let's see how they perform:&lt;/p&gt;
&lt;div id="graph_16" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_16" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_16(){var graph=new google.visualization.LineChart(document.getElementById('graph_16'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['100000',366,410,390,372],['200000',761,892,758,867],['300000',1278,1354,1308,2062],['400000',2313,2348,2324,3083],['500000',3265,3297,3300,3994],['600000',4036,4171,4063,4890],['700000',4603,4575,4689,6052],['800000',5344,5241,5321,6682],['900000',6107,5912,6251,7623],['1000000',6725,6626,6663,8548],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"reverse - Normal&amp;lt;8u&amp;gt;",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"us",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_16');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;The intrusive versions are about 25% faster than standard list. Even if reversal does not need to access the values, the pointers of the intrusive lists have a better locality than the one of a list that can be dispersed through memory.&lt;/p&gt;
&lt;div id="graph_17" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_17" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_17(){var graph=new google.visualization.LineChart(document.getElementById('graph_17'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['100000',585,563,601,1057],['200000',1903,1902,2011,3043],['300000',4121,4041,4049,4671],['400000',5291,5352,5275,6504],['500000',6831,6711,6584,8273],['600000',7980,8113,8105,9900],['700000',9366,9216,9426,11612],['800000',10680,10622,10602,13377],['900000',11917,11908,11915,15140],['1000000',13442,13239,13268,16718],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"reverse - Normal&amp;lt;32u&amp;gt;",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"us",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_17');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;The performance improved a bit, to 30% improvement for an intrusive list.&lt;/p&gt;
&lt;p&gt;Let's see if this continue:&lt;/p&gt;
&lt;div id="graph_18" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_18" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_18(){var graph=new google.visualization.LineChart(document.getElementById('graph_18'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['100000',2901,2901,2676,4562],['200000',5889,5942,5613,9059],['300000',8696,8618,8372,13501],['400000',11344,11597,11039,17985],['500000',14431,14123,13954,22546],['600000',17084,16955,16605,27246],['700000',19563,19795,19431,31866],['800000',22806,22428,22092,36645],['900000',25553,25283,25003,41025],['1000000',28049,28174,27590,45780],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"reverse - Normal&amp;lt;128u&amp;gt;",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"us",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_18');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;It did, the intrusive list is more than 40% faster than the standard list !&lt;/p&gt;
&lt;p&gt;What happens a bigger one:&lt;/p&gt;
&lt;div id="graph_19" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_19" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_19(){var graph=new google.visualization.LineChart(document.getElementById('graph_19'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['100000',4723,4823,4585,4373],['200000',11566,11566,11842,8704],['300000',17471,17377,17587,12985],['400000',22778,22867,22866,17452],['500000',28548,28434,28837,21357],['600000',34005,34089,33913,25907],['700000',39189,39235,39284,30398],['800000',45186,44900,44838,34632],['900000',50337,50529,50677,38540],['1000000',56045,56026,56007,42867],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"reverse - Normal&amp;lt;1024u&amp;gt;",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"us",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_19');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;The lines have been interchanged! This time the standard list is about 25% faster than the intrusive versions. This time, the better locality of the intrusive versions is not a gain but a loss.&lt;/p&gt;
&lt;p&gt;It is logical that the margin decrease with very big objects during reversal. Indeed, each element is very close one to another, but the pairs of pointers are separated by the size of the data type. The bigger the data type, the higher distance between the pointers and so the worse spatial locality for the pointers. However, I do not explain why there is this big difference...&lt;/p&gt;
&lt;p&gt;The performance of intrusive list are clearly interesting for reversing collection of small data types. However, it seems that for high data types, the standard list is faster.&lt;/p&gt;
&lt;!--nextpage--&gt;

&lt;h3&gt;Sort the list&lt;/h3&gt;

&lt;p&gt;Let's continue with an even more interesting operation, sorting the list. All the versions are sorted with the sort member function.&lt;/p&gt;
&lt;div id="graph_20" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_20" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_20(){var graph=new google.visualization.LineChart(document.getElementById('graph_20'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['100000',16314,16503,16364,24992],['200000',38251,37599,38206,62834],['300000',63573,63521,63878,112848],['400000',90236,88561,88996,168037],['500000',114442,114456,116137,236389],['600000',167279,165879,166617,324302],['700000',190762,190586,190292,377142],['800000',223884,223900,224622,477313],['900000',255248,252795,253070,540602],['1000000',287262,286842,288404,614163],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"sort - Normal&amp;lt;8u&amp;gt;",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"ms",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_20');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;The intrusive versions are really interesting, being twice faster than a standard list.&lt;/p&gt;
&lt;p&gt;Let's see with a see a higher data type:&lt;/p&gt;
&lt;div id="graph_21" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_21" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_21(){var graph=new google.visualization.LineChart(document.getElementById('graph_21'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['100000',25335,25030,25318,31655],['200000',67224,65937,67185,80637],['300000',118284,116947,119686,139629],['400000',169014,165868,169723,194916],['500000',208261,208245,209291,248475],['600000',294572,287231,294284,339917],['700000',337154,332205,338323,389665],['800000',401654,393743,401249,461721],['900000',440058,434855,440984,506999],['1000000',494861,491360,497710,578176],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"sort - Normal&amp;lt;128u&amp;gt;",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"ms",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_21');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;The difference is decreasing to about 20%.&lt;/p&gt;
&lt;p&gt;Increasing it again:&lt;/p&gt;
&lt;div id="graph_22" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_22" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_22(){var graph=new google.visualization.LineChart(document.getElementById('graph_22'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['100000',31568,33319,32201,40331],['200000',82407,85932,83987,97310],['300000',143651,150155,144553,163818],['400000',202050,209178,203821,232728],['500000',250514,256374,253415,289493],['600000',345760,351034,348564,391229],['700000',397848,402385,402371,454434],['800000',471832,479947,477681,538873],['900000',518542,527961,524002,596696],['1000000',583622,596696,591025,672353],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"sort - Normal&amp;lt;1024u&amp;gt;",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"ms",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_22');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;It decreased again to 18%.&lt;/p&gt;
&lt;p&gt;For sort operations, the intrusive versions are clearly interesting, especially for small data types.&lt;/p&gt;
&lt;!--nextpage--&gt;

&lt;h3&gt;Random insert into the list&lt;/h3&gt;

&lt;p&gt;The last operation that we will test is the random insert. I have to say that this test is not fair. Indeed, in an intrusive list, from an object we can directly get an iterator and insert at a random position. For a standard list, we have to find the iterator by linear search. I think that it is still important because it is one of the advantages of an intrusive container.&lt;/p&gt;
&lt;div id="graph_23" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_23" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_23(){var graph=new google.visualization.LineChart(document.getElementById('graph_23'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_ilist','safe_ilist','normal_ilist','list'],['10000',42,46,41,27729],['20000',49,66,45,48736],['30000',64,66,47,62440],['40000',54,53,48,75253],['50000',59,54,49,88493],['60000',67,49,63,104516],['70000',50,53,50,115514],['80000',55,50,50,128950],['90000',51,51,55,144367],['100000',52,52,76,152721],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"random_insert - Normal&amp;lt;8u&amp;gt;",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"us",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_23');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;It is very clear that the performance are much better but it is logical because we are comparing something in O(1) versus something in O(n).&lt;/p&gt;
&lt;h3&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;In conclusion, intrusive lists are almost always faster than a standard list. However, on my computer and with GCC, the difference is not always very important. It can brings about 20%-30% on some workloads but most likely around 15%. Even if not negligible, it is not a huge improvement. I would have thought that intrusive lists were faster by an higher margin. On some operations like sort, it is clearly more interesting. It has a better data locality than standard list.&lt;/p&gt;
&lt;p&gt;It is also more interesting to fill the collection, because no memory allocation is involved. But of course, you need to take care of memory allocation by yourself, for example in a vector like here or by dynamically allocating the objects one after one. This has also a cost that is not counted in the benchmark.&lt;/p&gt;
&lt;p&gt;If you really have to use a linked list and performance is critical, I advice you to use Boost intrusive list. If performance is not really critical, it is not perhaps not interesting because of the increased complexity.&lt;/p&gt;
&lt;p&gt;There are situations when only intrusive lists can work. If you want the same object to be present in two different list, you can use boost intrusive list with several member hooks, which is not possible with standard list because only a copy is stored, not the object itself. The same is true for objects that are non-copyable, only intrusive list can handle them. And finally, with intrusive lists you can directly get an iterator to an object in O(1) if you have a reference to an object. For a standard list, you have to iterate through the list to find the object. Sometimes, it can be very useful.&lt;/p&gt;
&lt;p&gt;If you are interested, the Boost documentation provides also a &lt;a href="http://www.boost.org/doc/libs/1_52_0/doc/html/intrusive/performance.html" title="Boost Intrusive Performance"&gt;performance benchmark for intrusive list&lt;/a&gt;, but it is very old (GCC 4.1.2). It is interesting to see that the results are better for intrusive lists than on my benchmark. I do not know if it comes from the processor, the memory or from the compiler.&lt;/p&gt;
&lt;p&gt;I hope you found this benchmark interesting. If you have questions, comments, ideas or whatever to say about this benchmark, don't hesitate to comment. I would be glad to answer you :) The same if you find errors in this article. If you have different results, don't hesitate to comment as well.&lt;/p&gt;
&lt;p&gt;The code source of the benchmark is available online: https://github.com/wichtounet/articles/blob/master/src/intrusive_list/bench.cpp&lt;/p&gt;
&lt;script type="text/javascript"&gt;function draw_visualization(){draw_graph_0();draw_graph_1();draw_graph_2();draw_graph_3();draw_graph_4();draw_graph_5();draw_graph_6();draw_graph_7();draw_graph_8();draw_graph_9();draw_graph_10();draw_graph_11();draw_graph_12();draw_graph_13();draw_graph_14();draw_graph_15();draw_graph_16();draw_graph_17();draw_graph_18();draw_graph_19();draw_graph_20();draw_graph_21();draw_graph_22();draw_graph_23();} google.setOnLoadCallback(draw_visualization);&lt;/script&gt;&lt;/div&gt;</description><category>Benchmark</category><category>Boost</category><category>C++</category><category>C++11</category><category>Performances</category><guid>http://baptiste-wicht.com/posts/2012/12/cpp-benchmark-std-list-boost-intrusive-list.html</guid><pubDate>Wed, 12 Dec 2012 07:53:17 GMT</pubDate></item><item><title>C++ benchmark â€“ std::vector VS std::list VS std::deque</title><link>http://baptiste-wicht.com/posts/2012/12/cpp-benchmark-vector-list-deque.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;div&gt;&lt;script type="text/javascript" src="https://www.google.com/jsapi"&gt;&lt;/script&gt;

&lt;script type="text/javascript"&gt;google.load('visualization','1',{packages:['corechart']});&lt;/script&gt;

&lt;p&gt;Last week, I wrote a benchmark comparing the performance of std::vector and std::list on different workloads. This previous article received a lot of comments and several suggestions to improve it. The present article is an improvement over the previous article.&lt;/p&gt;
&lt;p&gt;In this article, I will compare the performance of std::vector, std::list and std::deque on several different workloads and with different data types. In this article, when I talk about a list refers to std::list, a vector refers to std::vector and deque to std::deque.&lt;/p&gt;
&lt;p&gt;It is generally said that a list should be used when random insert and remove will be performed (performed in O(1) versus O(n) for a vector or a deque). If we look only at the complexity, the scale of linear search in both data structures should be equivalent, complexity being in O(n). When random insert/replace operations are performed on a vector or a deque, all the subsequent data needs to be moved and so each element will be copied. That is why the size of the data type is an important factor when comparing those two data structures. Because the size of the data type will play an important role on the cost of copying an element.&lt;/p&gt;
&lt;p&gt;However, in practice, there is a huge difference: the usage of the memory caches. All the data in a vector is contiguous where the std::list allocates separately memory for each element. How does that change the results in practice ? The deque is a data structure aiming at having the advantages of both data structures without their drawbacks, we will see how it perform in practice. Complexity analysis does not take the memory hierarchy into level. I believe that in practice, memory hierarchy usage is as important as complexity analysis.&lt;/p&gt;
&lt;p&gt;Keep in mind that all the tests performed are made on vector, list and deque even if other data structures could be better suited to the given workload.&lt;/p&gt;
&lt;p&gt;In the graphs and in the text, &lt;em&gt;n&lt;/em&gt; is used to refer to the number of elements of the collection.&lt;/p&gt;
&lt;p&gt;All the tests performed have been performed on an Intel Core i7 Q 820 Â @ 1.73GHz. The code has been compiled in 64 bits with GCC 4.7.2 with -02 and -march=native. The code has been compiled with C++11 support (-std=c++11).&lt;/p&gt;
&lt;p&gt;For each graph, the vertical axis represent the amount of time necessary to perform the operations, so the lower values are the better. The horizontal axis is always the number of elements of the collection. For some graph, the logarithmic scale could be clearer, a button is available after each graph to change the vertical scale to a logarithmic scale.&lt;/p&gt;
&lt;p&gt;The data types are varying in size, they hold an array of longs and the size of the array varies to change the size of the data type. The non-trivial data type is made of two longs and has very stupid assignment operator and copy constructor that just does some maths (totally meaningless but costly). One may argue that is not a common copy constructor neither a common assignment operator and one will be right, however, the important point here is that it is costly operators which is enough for this benchmark.&lt;/p&gt;
&lt;h3&gt;Fill&lt;/h3&gt;

&lt;p&gt;The first test that is performed is to fill the data structures by adding elements to the back of the container (using &lt;em&gt;push_back&lt;/em&gt;). Two variations of vector are used, &lt;em&gt;vector_pre&lt;/em&gt; being a std::vector using vector::reserve at the beginning, resulting in only one allocation of memory.&lt;/p&gt;
&lt;p&gt;Lets see the results with a very small data type:&lt;/p&gt;
&lt;div id="graph_0" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_0" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_0(){var graph=new google.visualization.LineChart(document.getElementById('graph_0'));var data=google.visualization.arrayToDataTable([['x','list','vector','deque','vector_pre'],['100000',2545,271,2012,317],['200000',4927,552,998,334],['300000',7310,944,1707,595],['400000',9463,936,2056,1099],['500000',12591,1140,2642,1058],['600000',14351,1894,3125,1237],['700000',16561,1995,3686,1208],['800000',18820,2648,4291,1365],['900000',20832,2777,4962,2268],['1000000',23430,3015,5396,2585],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"fill_back - 8 bytes",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"us",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_0');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;The pre-allocated vector is the fastest by a small margin and the list is 3 times slower than a vector. deque and vector.&lt;/p&gt;
&lt;p&gt;If we consider higher data type:&lt;/p&gt;
&lt;div id="graph_1" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_1" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_1(){var graph=new google.visualization.LineChart(document.getElementById('graph_1'));var data=google.visualization.arrayToDataTable([['x','list','vector','deque','vector_pre'],['100000',104867,55545,66852,21738],['200000',226215,108289,136035,42532],['300000',340910,198343,153446,60317],['400000',445035,217325,269316,80616],['500000',559619,236576,189613,101371],['600000',688422,391354,303729,122447],['700000',799902,405771,426373,138868],['800000',921441,415707,537057,160637],['900000',1006331,439635,263650,177052],['1000000',1113690,464416,372000,199434],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"fill_back - 4096 bytes",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"us",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_1');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;This time vector and list are performing at about the same speed. The deque is a bit faster than list and vector. The pre-allocated vector is clearly the winner here. The variations in the results of deque and vector are probably coming from my system that doesn't like allocating so much memory back and forth at this speed.&lt;/p&gt;
&lt;p&gt;Finally, if we use a non-trivial data type:&lt;/p&gt;
&lt;div id="graph_2" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_2" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_2(){var graph=new google.visualization.LineChart(document.getElementById('graph_2'));var data=google.visualization.arrayToDataTable([['x','list','vector','deque','vector_pre'],['100000',8093,8123,10251,8095],['200000',15433,15305,16061,13897],['300000',25964,24643,24450,19954],['400000',33414,30322,32148,27171],['500000',40416,37817,40752,35058],['600000',48991,48594,48785,41049],['700000',55059,55124,55092,47609],['800000',63688,61360,64505,55659],['900000',70550,67636,72329,60952],['1000000',79271,73533,79522,67787],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"fill_back - 16 bytes",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"us",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_2');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;All data structures are performing more or less the same, with vector_pre being the fastest.&lt;/p&gt;
&lt;p&gt;For push_back operations, pre-allocated vectors is a very good choice if the size is known in advance. The others performs more of less the same.&lt;/p&gt;
&lt;p&gt;I would have expected a better result for pre-allocated vector. If someone find an explanation for such a small margin, I'm interested.&lt;/p&gt;
&lt;h3&gt;Linear Search&lt;/h3&gt;

&lt;p&gt;The first operation is that is tested is the search. The container is filled with all the numbers in [0, N] and shuffled. Then, each number in [0,N] is searched in the container with std::find that performs a simple linear search. In theory, all the data structures should perform the same if we consider their complexity.&lt;/p&gt;
&lt;div id="graph_3" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_3" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_3(){var graph=new google.visualization.LineChart(document.getElementById('graph_3'));var data=google.visualization.arrayToDataTable([['x','deque','list','vector'],['1000',593,1098,318],['2000',2927,5307,1271],['3000',5891,12228,3020],['4000',8663,24415,5081],['5000',12859,36316,8066],['6000',18493,55057,11463],['7000',25057,74344,16022],['8000',38980,99990,21051],['9000',44951,127575,26650],['10000',52281,158216,32557],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"linear_search - 8 bytes",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"us",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_3');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;It is clear from the graph that the list has very poor performance for searching. The growth is much worse for a list than for a vector or a deque.&lt;/p&gt;
&lt;p&gt;The only reason is the usage of the cache line. When a data is accessed, the data is fetched from the main memory to the cache. Not only the accessed data is accessed, but a whole cacheline is fetched. As the elements in a vector are contiguous, when you access an element, the next element is automatically in the cache. As the main memory is orders of magnitude slower than the cache, this makes a huge difference. In the list case, the processor spends its whole time waiting for data being fetched from memory to the cache, at each fetch, the processor fetches a lot of unnecessary data that are almost always useless.&lt;/p&gt;
&lt;p&gt;The deque is a bit slower than the vector, that is logical because here there are more cache misses due to the segmented parts.&lt;/p&gt;
&lt;p&gt;If we take a bigger data type:&lt;/p&gt;
&lt;div id="graph_4" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_4" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_4(){var graph=new google.visualization.LineChart(document.getElementById('graph_4'));var data=google.visualization.arrayToDataTable([['x','deque','list','vector'],['1000',1116,2683,776],['2000',4983,16675,3537],['3000',12255,44379,10874],['4000',23212,83026,20189],['5000',37392,133353,33609],['6000',55295,193428,47636],['7000',74877,261314,63911],['8000',100903,340157,84647],['9000',126299,435816,107922],['10000',156386,545160,135680],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"linear_search - 128 bytes",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"us",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_4');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;The list is still much slower than the others, but what is interesting is that gap between the deque and the array is decreasing. Let's try with a 4KB data type:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;/p&gt;&lt;div id="graph_5" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;&lt;input id="button_graph_5" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_5(){var graph=new google.visualization.LineChart(document.getElementById('graph_5'));var data=google.visualization.arrayToDataTable([['x','deque','list','vector'],['1000',4258,7190,4445],['2000',20584,38411,19825],['3000',48236,113189,55341],['4000',87475,223174,118453],['5000',136945,362421,191967],['6000',197856,530943,281252],['7000',273359,726323,387940],['8000',351223,954463,511276],['9000',447525,1211581,652269],['10000',551556,1497916,807161],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"linear_search - 4096 bytes",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"us",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_5');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;
&lt;/blockquote&gt;
&lt;p&gt;The performance of the list are still poor but the gap is decreasing. The interesting point is that deque is now faster than vector. I'm not really sure of the reason of this result. It is possible that it comes only from this special size. One thing is sure, the bigger the data size, the more cache misses the processor will get because elements don't fit in cache lines.&lt;/p&gt;
&lt;p&gt;For search, list is clearly slow where deque and vector have about the same performance. It seems that deque is faster than a vector for very large data sizes.&lt;/p&gt;
&lt;h3&gt;Random Insert (+Linear Search)&lt;/h3&gt;

&lt;p&gt;In the case of random insert, in theory, the list should be much faster, its insert operation being in O(1) versus O(n) for a vector or a deque.&lt;/p&gt;
&lt;p&gt;The container is filled with all the numbers in [0, N] and shuffled. Then, 1000 random values are inserted at a random position in the container. The random position is found by linear search. In both cases, the complexity of the search is O(n), the only difference comes from the insert that follow the search. We saw before that the performance of the list were poor for searching, so we'll see if the fast insertion can compensate the slow search.&lt;/p&gt;
&lt;div id="graph_6" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_6" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_6(){var graph=new google.visualization.LineChart(document.getElementById('graph_6'));var data=google.visualization.arrayToDataTable([['x','deque','list','vector'],['10000',8,27,8],['20000',15,45,14],['30000',22,63,21],['40000',29,74,27],['50000',37,87,38],['60000',43,105,44],['70000',50,114,48],['80000',61,130,55],['90000',66,139,61],['100000',70,155,68],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"random_insert - 8 bytes",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"ms",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_6');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;List is clearly slower than the other two data structures that exhibit the same performance. This comes from the very slow linear search. Even if the two other data structures have to move a lot of data, the copy is cheap for small data types.&lt;/p&gt;
&lt;p&gt;Let's increase the size a bit:&lt;/p&gt;
&lt;div id="graph_7" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_7" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_7(){var graph=new google.visualization.LineChart(document.getElementById('graph_7'));var data=google.visualization.arrayToDataTable([['x','deque','list','vector'],['10000',21,53,25],['20000',39,80,48],['30000',57,103,68],['40000',71,122,90],['50000',88,146,112],['60000',102,165,130],['70000',124,190,152],['80000',140,214,175],['90000',157,238,195],['100000',174,268,213],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"random_insert - 32 bytes",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"ms",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_7');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;The result are interesting. The list is still the slowest but with a smaller margin. This time deque is faster than the vector by a small margin.&lt;/p&gt;
&lt;p&gt;Again, increasing the data size:&lt;/p&gt;
&lt;div id="graph_8" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_8" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_8(){var graph=new google.visualization.LineChart(document.getElementById('graph_8'));var data=google.visualization.arrayToDataTable([['x','deque','list','vector'],['10000',64,80,89],['20000',108,128,154],['30000',158,182,248],['40000',212,248,347],['50000',281,348,469],['60000',402,443,735],['70000',569,643,1034],['80000',767,775,1347],['90000',978,1002,1614],['100000',1190,1202,1962],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"random_insert - 128 bytes",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"ms",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_8');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;This time, the vector is clearly the looser and deque and list have the same performance. We can say that with a size of 128 bytes, the time to move a lot of the elements is more expensive than searching in the list.&lt;/p&gt;
&lt;p&gt;A huge data type gives us clearer results:&lt;/p&gt;
&lt;div id="graph_9" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_9" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_9(){var graph=new google.visualization.LineChart(document.getElementById('graph_9'));var data=google.visualization.arrayToDataTable([['x','deque','list','vector'],['10000',4430,178,8074],['20000',7918,311,14121],['30000',11043,444,20014],['40000',13806,555,26783],['50000',17421,694,33519],['60000',20663,904,39175],['70000',23599,1147,45111],['80000',26736,1470,50887],['90000',29524,1940,60139],['100000',32005,2534,65098],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"random_insert - 4096 bytes",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"ms",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_9');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;The list is more than 20 times faster than the vector and an order of magnitude faster than the deque ! The deque is also twice faster than the vector.&lt;/p&gt;
&lt;p&gt;The fact than the deque is faster than vector is quite simple. When an insertion is made in a deque, the elements can either moved to the end or the beginning. The closer point will be chosen. An insert in the middle is the most costly operation with O(n/2) complexity. It is always more efficient to insert elements in a deque than in vector because at least twice less elements will be moved.&lt;/p&gt;
&lt;p&gt;If we look at the non-trivial data type:&lt;/p&gt;
&lt;div id="graph_10" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_10" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_10(){var graph=new google.visualization.LineChart(document.getElementById('graph_10'));var data=google.visualization.arrayToDataTable([['x','deque','list','vector'],['10000',230,41,425],['20000',376,65,705],['30000',552,84,1054],['40000',692,101,1345],['50000',862,119,1661],['60000',1003,141,1984],['70000',1186,155,2277],['80000',1358,172,2681],['90000',1540,186,2965],['100000',1658,203,3236],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"random_insert - 16 bytes",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"ms",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_10');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;The results are about the same as for the previous graph, but the data type is only 16B. The cost of the copy constructors and assignment operators is very important for vector and deque. The list doesn't care because no copy neither assignment of the existing elements is made during insertions (only the inserted element is copied).&lt;/p&gt;
&lt;h3&gt;Random Remove&lt;/h3&gt;

&lt;p&gt;In theory, random remove is the same case than random insert. Now that we've seen the results with random insert, we could expect the same behavior for random remove.&lt;/p&gt;
&lt;p&gt;The container is filled with all the numbers in [0, N] and shuffled. Then, 1000 random values are removed from a random position in the container.&lt;/p&gt;
&lt;p&gt;If we take the same data sizes as the random insert case:&lt;/p&gt;
&lt;div id="graph_11" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_11" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_11(){var graph=new google.visualization.LineChart(document.getElementById('graph_11'));var data=google.visualization.arrayToDataTable([['x','deque','list','vector'],['10000',6,19,5],['20000',12,41,11],['30000',20,55,18],['40000',27,68,25],['50000',34,81,33],['60000',43,101,40],['70000',49,113,45],['80000',59,126,52],['90000',67,138,61],['100000',72,157,65],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"random_remove - 8 bytes",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"ms",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_11');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;div id="graph_12" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_12" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_12(){var graph=new google.visualization.LineChart(document.getElementById('graph_12'));var data=google.visualization.arrayToDataTable([['x','deque','list','vector'],['10000',40,40,63],['20000',85,83,134],['30000',127,132,198],['40000',181,189,282],['50000',245,263,473],['60000',363,376,664],['70000',524,502,960],['80000',743,688,1343],['90000',977,812,1639],['100000',1228,1017,2004],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"random_remove - 128 bytes",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"ms",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_12');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;div id="graph_13" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_13" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_13(){var graph=new google.visualization.LineChart(document.getElementById('graph_13'));var data=google.visualization.arrayToDataTable([['x','deque','list','vector'],['10000',2906,109,5649],['20000',6190,233,11760],['30000',9379,359,18218],['40000',12840,490,23634],['50000',16027,585,30046],['60000',18918,773,36100],['70000',22213,999,42453],['80000',25788,1317,48793],['90000',28975,1762,55043],['100000',30860,2128,59791],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"random_remove - 4096 bytes",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"ms",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_13');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;div id="graph_14" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_14" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_14(){var graph=new google.visualization.LineChart(document.getElementById('graph_14'));var data=google.visualization.arrayToDataTable([['x','deque','list','vector'],['10000',149,27,294],['20000',319,50,608],['30000',481,68,934],['40000',638,89,1236],['50000',794,108,1547],['60000',954,120,1894],['70000',1101,144,2185],['80000',1253,160,2513],['90000',1399,177,2812],['100000',1595,194,3108],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"random_remove - 16 bytes",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"ms",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_14');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;The behavior of random remove is the same as the behavior of random insert, for the same reasons. The results are not very interesting, so, let's get to the next workload.&lt;/p&gt;
&lt;h3&gt;Push Front&lt;/h3&gt;

&lt;p&gt;The next operation that we will compare is inserting elements in front of the collection. This is the worst case for vector, because after each insertion, all the previously inserted will be moved and copied. For a list or a deque, it does not make a difference compared to pushing to the back.&lt;/p&gt;
&lt;p&gt;So let's see the results:&lt;/p&gt;
&lt;div id="graph_15" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_15" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_15(){var graph=new google.visualization.LineChart(document.getElementById('graph_15'));var data=google.visualization.arrayToDataTable([['x','deque','list','vector'],['10000',0,0,33],['20000',0,0,135],['30000',0,0,313],['40000',0,0,585],['50000',0,1,913],['60000',0,1,1327],['70000',0,1,1823],['80000',0,1,2405],['90000',0,2,3107],['100000',0,2,4017],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"fill_front - 8 bytes",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"ms",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_15');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;The results are crystal-clear and as expected, vector is very bad at inserting elements to the front. The list and the deque results are almost invisible in the graph because it is a free operation for the two data structures. This does not need further explanations. There is no need to change the data size, it will only make vector much slower and my processor hotter.&lt;/p&gt;
&lt;h3&gt;Sort&lt;/h3&gt;

&lt;p&gt;The next operation that is tested is the time necessary to sort the data structures. For the vector and the deque std::sort is used and for a list the member function sort is used.&lt;/p&gt;
&lt;div id="graph_16" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_16" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_16(){var graph=new google.visualization.LineChart(document.getElementById('graph_16'));var data=google.visualization.arrayToDataTable([['x','deque','list','vector'],['100000',9,25,6],['200000',19,61,14],['300000',29,115,22],['400000',40,175,30],['500000',50,233,39],['600000',60,321,48],['700000',71,378,57],['800000',85,457,66],['900000',95,517,74],['1000000',108,593,83],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"sort - 8 bytes",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"ms",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_16');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;For a small data type, the list is several times slower than the other two data structures. This is again due to the very poor spatial locality of the list during the search. vector is slightly faster than a deque, but the difference is not very significant.&lt;/p&gt;
&lt;p&gt;If we increase the size:&lt;/p&gt;
&lt;div id="graph_17" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_17" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_17(){var graph=new google.visualization.LineChart(document.getElementById('graph_17'));var data=google.visualization.arrayToDataTable([['x','deque','list','vector'],['100000',25,32,20],['200000',65,80,48],['300000',103,143,80],['400000',136,197,113],['500000',180,246,149],['600000',223,340,181],['700000',274,396,222],['800000',302,469,266],['900000',358,514,303],['1000000',395,579,337],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"sort - 128 bytes",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"ms",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_17');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;The order remains the same but the difference between the list and the other is decreasing.&lt;/p&gt;
&lt;p&gt;With a 1KB data type:&lt;/p&gt;
&lt;div id="graph_18" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_18" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_18(){var graph=new google.visualization.LineChart(document.getElementById('graph_18'));var data=google.visualization.arrayToDataTable([['x','deque','list','vector'],['100000',176,39,168],['200000',389,94,376],['300000',620,168,595],['400000',859,228,823],['500000',1100,285,1059],['600000',1355,392,1301],['700000',1609,452,1555],['800000',1844,539,1797],['900000',2111,597,2054],['1000000',2397,670,2278],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"sort - 1024 bytes",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"ms",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_18');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;The list is almost five times faster than the vector and the deque which are both performing the same (with a very slight advantage for vector).&lt;/p&gt;
&lt;p&gt;If we use the non-trivial data type:&lt;/p&gt;
&lt;div id="graph_19" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_19" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_19(){var graph=new google.visualization.LineChart(document.getElementById('graph_19'));var data=google.visualization.arrayToDataTable([['x','deque','list','vector'],['100000',92,26,89],['200000',195,70,188],['300000',301,135,296],['400000',410,195,399],['500000',519,255,510],['600000',638,350,623],['700000',763,410,729],['800000',858,492,846],['900000',971,552,954],['1000000',1090,628,1072],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"sort - 16 bytes",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"ms",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_19');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;Again, the cost of the operators of this type have a strong impact on the vector and deque.&lt;/p&gt;
&lt;h3&gt;Destruction&lt;/h3&gt;

&lt;p&gt;The next test is to calculate the time necessary to the destruction of a container. The containers are dynamically allocated, are filled with n numbers and then their destruction time (via delete) is computed.&lt;/p&gt;
&lt;div id="graph_20" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_20" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_20(){var graph=new google.visualization.LineChart(document.getElementById('graph_20'));var data=google.visualization.arrayToDataTable([['x','deque','list','vector'],['100000',34,1489,0],['200000',70,2838,0],['300000',102,4677,0],['400000',142,6072,0],['500000',173,7737,0],['600000',215,8828,0],['700000',353,10599,1],['800000',321,12115,0],['900000',355,13932,1],['1000000',410,15345,0],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"destruction - 8 bytes",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"us",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_20');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;The results are already interesting. The vector is almost free to destroy, which is logical because that incurs only freeing one array and the vector itself. The deque is slower due to the freeing of each segments. But the list is much more costly than the other two, more than an order of magnitude slower. This is expected because the list have to free the dynamic memory of each node and also has to iterate through all the elements which we saw was slow.&lt;/p&gt;
&lt;p&gt;If we increase the data type:&lt;/p&gt;
&lt;div id="graph_21" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_21" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_21(){var graph=new google.visualization.LineChart(document.getElementById('graph_21'));var data=google.visualization.arrayToDataTable([['x','deque','list','vector'],['100000',898,4403,1],['200000',2488,8499,1],['300000',4091,12499,1430],['400000',5461,16379,1909],['500000',6729,21128,2459],['600000',8164,25719,2729],['700000',9517,31046,3227],['800000',10871,34550,3756],['900000',12392,37176,4163],['1000000',13762,40119,4523],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"destruction - 128 bytes",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"us",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_21');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;This time we can see that the deque is three times slower than a vector and that the list is still an order of magnitude slower than a vector ! However, the is less difference than before.&lt;/p&gt;
&lt;p&gt;With our biggest data type, now:&lt;/p&gt;
&lt;div id="graph_22" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_22" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_22(){var graph=new google.visualization.LineChart(document.getElementById('graph_22'));var data=google.visualization.arrayToDataTable([['x','deque','list','vector'],['100000',20575,22434,15499],['200000',44234,47254,29848],['300000',67196,69374,39818],['400000',89253,91128,54229],['500000',108689,112557,68090],['600000',131751,135764,75063],['700000',150801,155610,90761],['800000',172365,176957,102830],['900000',192575,193897,112728],['1000000',211507,215274,126348],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"destruction - 4096 bytes",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"us",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_22');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;There is no more difference between list and deque. The vector is still twice faster than them.&lt;/p&gt;
&lt;p&gt;Even if the vector is always faster than the list and deque, keep in mind that the graphs for destruction are in microseconds and so the operations are not very costly. It could make a difference is very time-sensitive application but unlikely in most applications. Moreover, destruction is made only once per data structure, generally, it is not a very important operation.&lt;/p&gt;
&lt;h3&gt;Number Crunching&lt;/h3&gt;

&lt;p&gt;Finally, we can also test a number crunching operation. Here, random elements are inserted into the container that is kept sorted. It means, that the position where the element has to be inserted is first searched by iterating through elements and the inserted. As we talk about number crunching, only 8 bytes elements are tested.&lt;/p&gt;
&lt;div id="graph_23" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_23" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_23(){var graph=new google.visualization.LineChart(document.getElementById('graph_23'));var data=google.visualization.arrayToDataTable([['x','deque','list','vector'],['10000',39,187,33],['20000',150,1247,134],['30000',339,3380,310],['40000',623,6513,547],['50000',958,10757,864],['60000',1394,16098,1257],['70000',1894,22623,1713],['80000',2479,30656,2249],['90000',3162,39451,2858],['100000',3932,49906,3576],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"number_crunching",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"ms",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_23');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;Even if there is only 100'000 elements, the list is already an order of magnitude slower than the other two data structures. If we look a the curves of the results, it is easy to see that this will be only worse with higher collection sizes. The list is absolutely not adapted for number crunching operations due to its poor spatial locality.&lt;/p&gt;
&lt;h3&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;To conclude, we can get some facts about each data structure:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;std::list is very very slow to iterate through the collection due to its very poor spatial locality.&lt;/li&gt;
&lt;li&gt;std::vector and std::deque perform always faster than std::list with very small data&lt;/li&gt;
&lt;li&gt;std::list handles very well large elements&lt;/li&gt;
&lt;li&gt;std::deque performs better than a std::vector for inserting at random positions (especially at the front, which is constant time)&lt;/li&gt;
&lt;li&gt;std::deque and std::vector do not support very well data types with high cost of copy/assignment&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This draw simple conclusions on usage of each data structure:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Number crunching: use std::vector or std::deque&lt;/li&gt;
&lt;li&gt;Linear search: use std::vector or std::deque&lt;/li&gt;
&lt;li&gt;Random Insert/Remove:&lt;ul&gt;
&lt;li&gt;Small data size: use std::vector&lt;/li&gt;
&lt;li&gt;Large element size: use std::list (unless if intended principally for searching)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Non-trivial data type: use std::list unless you need the container especially for searching. But for multiple modifications of the container, it will be very slow.&lt;/li&gt;
&lt;li&gt;Push to front: use std::deque or std::list&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I have to say that before writing this new version of the benchmark I did not know std::deque a lot. This is a very good data structure that is very good at inserting at both ends and even in the middle while exposing a very good spatial locality. Even if sometimes slower than a vector, when the operations involves both searching and inserting in the middle, I would say that this structure should be preferred over vectors, especially for data types of medium sizes.&lt;/p&gt;
&lt;p&gt;If you have the time, in practice, the best way to decide is always to benchmark each version, or even to try another data structures. Two operations with the same Big O complexity can perform quite differently in practice.&lt;/p&gt;
&lt;p&gt;I hope that you found this article interesting. If you have any comment or have an idea about an other workload that you would like to test, don't hesitate to post a comment ;) If you have a question on results, don't hesitate as well.&lt;/p&gt;
&lt;p&gt;The code source of the benchmark is available online: &lt;a href="https://github.com/wichtounet/articles/blob/master/src/vector_list/bench.cpp" title="Source code of the benchmark"&gt;https://github.com/wichtounet/articles/blob/master/src/vector_list/bench.cpp&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The older version of the article is still available: &lt;a href="http://www.baptiste-wicht.com/2012/11/cpp-benchmark-vector-vs-list/" title="C++ benchmark â€“ std::vector VS std::list"&gt;C++ benchmark â€“ std::vector VS std::list&lt;/a&gt;&lt;/p&gt;
&lt;script type="text/javascript"&gt;function draw_visualization(){draw_graph_0();draw_graph_1();draw_graph_2();draw_graph_3();draw_graph_4();draw_graph_5();draw_graph_6();draw_graph_7();draw_graph_8();draw_graph_9();draw_graph_10();draw_graph_11();draw_graph_12();draw_graph_13();draw_graph_14();draw_graph_15();draw_graph_16();draw_graph_17();draw_graph_18();draw_graph_19();draw_graph_20();draw_graph_21();draw_graph_22();draw_graph_23();}google.setOnLoadCallback(draw_visualization);&lt;/script&gt;&lt;/div&gt;</description><category>Benchmarks</category><category>C++</category><category>C++11</category><category>Performances</category><guid>http://baptiste-wicht.com/posts/2012/12/cpp-benchmark-vector-list-deque.html</guid><pubDate>Mon, 03 Dec 2012 07:58:29 GMT</pubDate></item><item><title>C++ benchmark - std::vector VS std::list</title><link>http://baptiste-wicht.com/posts/2012/11/cpp-benchmark-vector-vs-list.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;div&gt;&lt;script type="text/javascript" src="https://www.google.com/jsapi"&gt;&lt;/script&gt;

&lt;script type="text/javascript"&gt;google.load('visualization','1',{packages:['corechart']});&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;A updated version of this article is available: &lt;a title="C++ benchmark â€“ std::vector VS std::list VS std::deque" href="http://www.baptiste-wicht.com/2012/12/cpp-benchmark-vector-list-deque/"&gt;C++ benchmark â€“ std::vector VS std::list VS std::deque&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In C++, the two most used data structures are the std::vector and the std::list. In this article, we will compare the performance in practice of these two data structures on several different workloads. In this article, when I talk about a list it is the std::list implementation and vector refers to the std::vector implementation.&lt;/p&gt;
&lt;p&gt;It is generally said that a list should be used when random insert and remove will be performed (performed in O(1) versus O(n) for a vector). If we look only at the complexity, search in both data structures should be roughly equivalent, complexity being in O(n). When random insert/replace operations are performed on a vector, all the subsequent data needs to be moved and so each element will be copied. That is why the size of the data type is an important factor when comparing those two data structures.&lt;/p&gt;
&lt;p&gt;However, in practice, there is a huge difference, the usage of the memory caches. All the data in a vector is contiguous where the std::list allocates separately memory for each element. How does that change the results in practice ?&lt;/p&gt;
&lt;p&gt;Keep in mind that all the tests performed are made on vector and list even if other data structures could be better suited to the given workload.&lt;/p&gt;
&lt;p&gt;In the graphs and in the text, &lt;em&gt;n&lt;/em&gt; is used to refer to the number of elements of the collection.&lt;/p&gt;
&lt;p&gt;All the tests performed have been performed on an Intel Core i7 Q 820 Â @ 1.73GHz. The code has been compiled in 64 bits with GCC 4.7.2 with -02 and -march=native. The code has been compiled with C++11 support (-std=c++11).&lt;/p&gt;
&lt;h3&gt;Fill&lt;/h3&gt;

&lt;p&gt;The first test that is performed is to fill the data structures by adding elements to the back of the container. Two variations of vector are used, vector_pre being a std::vector with the size passed in parameters to the constructor, resulting in only one allocation of memory.&lt;/p&gt;
&lt;div id="graph_0" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_0" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_0(){var graph=new google.visualization.LineChart(document.getElementById('graph_0'));var data=google.visualization.arrayToDataTable([['x','vector_pre','vector','list'],['1000',0,0,1],['10000',0,1,10],['100000',4,11,100],['1000000',7,234,1023]]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"Fill (8 bytes)",width:'600px',height:'400px',vAxis:{title:"Milliseconds",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_0');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;&lt;div id="graph_1" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;&lt;input id="button_graph_1" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_1(){var graph=new google.visualization.LineChart(document.getElementById('graph_1'));var data=google.visualization.arrayToDataTable([['x','vector_pre','vector','list'],['1000',0,9,1],['10000',12,245,18],['100000',949,2635,1153],['1000000',9138,23654,11270]]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"Fill (1024 bytes)",width:'600px',height:'400px',vAxis:{title:"Milliseconds",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_1');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;
&lt;p&gt;All data structures are impacted the same way when the data size increases, because there will be more memory to allocate. The vector_pre is clearly the winner of this test, being one order of magnitude faster than a list and about twice faster than a vector without pre-allocation. The result are directly linked to the allocations that have to be performed, allocation being slow. Whatever the data size is, push_back to a vector will always be faster than to a list. This is logical becomes vector allocates more memory than necessary and so does not need to allocate memory for each element.&lt;/p&gt;
&lt;p&gt;But this test is not very interesting, generally building the data structure is not critical. What is critical is the operations that are performed on the data structure. That will be tested in the next sections.&lt;/p&gt;
&lt;!--nextpage--&gt;

&lt;h3&gt;Random Find&lt;/h3&gt;

&lt;p&gt;The first operation is that is tested is the search. The container is filled with all the numbers in [0, N] and shuffled. Then, each number in [0,N] is searched in the container with std::find that performs a simple linear search.&lt;/p&gt;
&lt;div id="graph_2" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_2" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_2(){var graph=new google.visualization.LineChart(document.getElementById('graph_2'));var data=google.visualization.arrayToDataTable([['x','vector','list'],['100',0,11],['1000',0,1545],['5000',0,35886],['10000',0,150865],['20000',0,614496]]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"Find (8 bytes)",width:'600px',height:'400px',vAxis:{title:"Microseconds",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_2');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;Yes, vector is present in the graph, its line is the same as the x line ! Performing a &lt;strong&gt;linear search in a vector is several orders of magnitude faster than in a list&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;The only reason is the usage of the cache line. When a data is accessed, the data is fetched from the main memory to the cache. Not only the accessed data is accessed, but a whole cacheline is fetched. As the elements in a vector are contiguous, when you access an element, the next element is automatically in the cache. As the main memory is orders of magnitude slower than the cache, this makes a huge difference. In the list case, the processor spends its whole time waiting for data being fetched from memory to the cache.&lt;/p&gt;
&lt;p&gt;If we augment the size of the data type to 1KB, the results remain the same, but slower:&lt;/p&gt;
&lt;div id="graph_3" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_3" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_3(){var graph=new google.visualization.LineChart(document.getElementById('graph_3'));var data=google.visualization.arrayToDataTable([['x','vector','list'],['100',0,11],['1000',0,3551],['5000',0,195429],['10000',0,829631],['20000',0,3356432]]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"Find (1024 bytes)",width:'600px',height:'400px',vAxis:{title:"Microseconds",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_3');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;!--nextpage--&gt;

&lt;h3&gt;Random Insert&lt;/h3&gt;

&lt;p&gt;In the case of random insert, in theory, the list should be much faster, its insert operation being in O(1) versus O(n) for a vector.&lt;/p&gt;
&lt;p&gt;The container is filled with all the numbers in [0, N] and shuffled. Then, 1000 random values are inserted at a random position in the container. The random position is found by linear search. In both cases, the complexity of the search is O(n), the only difference comes from the insert that follow the search.&lt;/p&gt;
&lt;div id="graph_4" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_4" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_4(){var graph=new google.visualization.LineChart(document.getElementById('graph_4'));var data=google.visualization.arrayToDataTable([['x','vector','list'],['1000',9,85],['2000',9,85],['4000',10,94],['6000',12,98],['8000',13,106],['10000',14,106]]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"Insert (8 bytes)",width:'600px',height:'400px',vAxis:{title:"Milliseconds",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_4');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;When, the vector should be slower than the list, it is almost an order of magnitude faster. Again, this is because finding the position in a list is much slower than copying a lot of small elements.&lt;/p&gt;
&lt;p&gt;If we increase the size:&lt;/p&gt;
&lt;div id="graph_5" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_5" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_5(){var graph=new google.visualization.LineChart(document.getElementById('graph_5'));var data=google.visualization.arrayToDataTable([['x','vector','list'],['1000',27,120],['2000',30,113],['4000',34,122],['6000',37,140],['8000',42,145],['10000',47,155]]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"Insert (32 bytes)",width:'600px',height:'400px',vAxis:{title:"Milliseconds",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_5');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;The two lines are getting closer, but vector is still faster.&lt;/p&gt;
&lt;p&gt;Increase it to 1KB:&lt;/p&gt;
&lt;div id="graph_6" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_6" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_6(){var graph=new google.visualization.LineChart(document.getElementById('graph_6'));var data=google.visualization.arrayToDataTable([['x','vector','list'],['1000',1821,167],['2000',1941,163],['4000',2383,191],['6000',2679,207],['8000',2960,214],['10000',3308,228]]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"Insert (1024 bytes)",width:'600px',height:'400px',vAxis:{title:"Milliseconds",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_6');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;This time, list outperforms vector by an order of magnitude ! The performance of random insert in a list are not impacted much by the size of the data type, where vector suffers a lot when big sizes are used. We can also see that list doesn't seem to care about the size of the collection. It is because the size of the collection only impact the search and not the insertion and as few search are performed, it does not change the results a lot.&lt;/p&gt;
&lt;p&gt;If the iterator was already known (no need for linear search), it would be faster to insert into a list than into the vector.&lt;/p&gt;
&lt;h3&gt;Random Remove&lt;/h3&gt;

&lt;p&gt;In theory, random remove is the same case than random insert. Now that we've seen the results with random insert, we could expect the same behavior for random remove.&lt;/p&gt;
&lt;p&gt;The container is filled with all the numbers in [0, N] and shuffled. Then, 1000 random values are removed from a random position in the container.&lt;/p&gt;
&lt;div id="graph_7" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_7" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_7(){var graph=new google.visualization.LineChart(document.getElementById('graph_7'));var data=google.visualization.arrayToDataTable([['x','vector','list'],['100',0,0],['1000',0,0],['10000',40,0],['50000',949,2],['100000',3937,4],['200000',16003,9],['300000',42393,12]]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"Push front (8 bytes)",width:'600px',height:'400px',vAxis:{title:"Milliseconds",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_7');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;Again, vector is several times faster and looks to scale better. Again, this is because it is very cheap to copy small elements.&lt;/p&gt;
&lt;p&gt;Let's increase it directly to 1KB element.&lt;/p&gt;
&lt;div id="graph_8" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_8" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_8(){var graph=new google.visualization.LineChart(document.getElementById('graph_8'));var data=google.visualization.arrayToDataTable([['x','vector','list'],['1000',0,0],['10000',2,26],['100000',163,684],['1000000',2147,15950],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"Sort (8 bytes)",width:'600px',height:'400px',vAxis:{title:"Milliseconds",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_8');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;The two lines have been reversed !&lt;/p&gt;
&lt;p&gt;The behavior of random remove is the same as the behavior of random insert, for the same reasons.&lt;/p&gt;
&lt;!--nextpage--&gt;

&lt;h3&gt;Push Front&lt;/h3&gt;

&lt;p&gt;The next operation that we will compare is inserting elements in front of the collection. This is the worst case for vector, because after each insertion, all the previously inserted will be moved and copied. For a list, it does not make a difference compared to pushing to the back.&lt;/p&gt;
&lt;div id="graph_9" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_9" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_9(){var graph=new google.visualization.LineChart(document.getElementById('graph_9'));var data=google.visualization.arrayToDataTable([['x','vector','list'],['100',0,0],['1000',0,0],['10000',40,0],['50000',949,2],['100000',3937,4],['200000',16003,9],['300000',42393,12]]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"Push front (8 bytes)",width:'600px',height:'400px',vAxis:{title:"Milliseconds",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_9');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;The results are crystal-clear and as expected. vector is very bad at inserting elements to the front. This does not need further explanations. There is no need to change the data size, it will only make vector much slower.&lt;/p&gt;
&lt;h3&gt;Sort&lt;/h3&gt;

&lt;p&gt;The next operation that is tested is the performance of sorting a vector or a list. For a vector std::sort is used and for a list the member function sort is used.&lt;/p&gt;
&lt;div id="graph_10" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_10" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_10(){var graph=new google.visualization.LineChart(document.getElementById('graph_10'));var data=google.visualization.arrayToDataTable([['x','vector','list'],['1000',0,0],['10000',2,26],['100000',163,684],['1000000',2147,15950],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"Sort (8 bytes)",width:'600px',height:'400px',vAxis:{title:"Milliseconds",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_10');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;We can see that sorting a list is several times slower. It comes from the poor usage of the cache.&lt;/p&gt;
&lt;p&gt;If we increase the size of the element to 1KB:&lt;/p&gt;
&lt;div id="graph_11" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_11" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_11(){var graph=new google.visualization.LineChart(document.getElementById('graph_11'));var data=google.visualization.arrayToDataTable([['x','vector','list'],['1000',2,0],['10000',224,50],['100000',4289,1083],['1000000',50973,17975],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"Sort (1024 bytes)",width:'600px',height:'400px',vAxis:{title:"Milliseconds",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_11');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;This time the list is faster than the vector. It is not very clear on the graph, but the values for the list are almost the same as for the previous results. That is because std::list::sort() does not perform any copy, only pointers to the elements are changed. On the other hand, swapping two elements in a vector involves at least three copies, so the cost of sorting will increase as the cost of copying increases.&lt;/p&gt;
&lt;!--nextpage--&gt;

&lt;h3&gt;Number Crunching&lt;/h3&gt;

&lt;p&gt;Finally, we can also test a number crunching operation. Here, random elements are inserted into the container that is kept sorted. It means, that the position where the element has to be inserted is first searched by iterating through elements and the inserted. As we talk about number crunching, only 8 bytes elements are tested.&lt;/p&gt;
&lt;div id="graph_12" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_12" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_12(){var graph=new google.visualization.LineChart(document.getElementById('graph_12'));var data=google.visualization.arrayToDataTable([['x','vector','list'],['1000',0,0],['10000',45,166],['50000',928,10665],['100000',3753,50766],['200000',15185,231480],['300000',34293,715892]]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"Random Sorted Insert (8 bytes)",width:'600px',height:'400px',vAxis:{title:"Milliseconds",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_12');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;We can clearly see that vector is more than an order of magnitude faster than list and this will only be more as the size of the collection increase. This is because traversing the list is much more expensive than copying the elements of the vector.&lt;/p&gt;
&lt;h3&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;To conclude, we can get some facts about each data structure:&lt;/p&gt;
&lt;ul&gt;
    &lt;li&gt;std::vector is insanely faster than std::list to find an element&lt;/li&gt;
    &lt;li&gt;std::vector performs always faster than std::list with very small data&lt;/li&gt;
    &lt;li&gt;std::vector is always faster to push elements at the back than std::list&lt;/li&gt;
    &lt;li&gt;std::list handles very well large elements, especially for sorting or inserting in the front&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This draw simple conclusions on usage of each data structure:&lt;/p&gt;
&lt;ul&gt;
    &lt;li&gt;Number crunching: use std::vector&lt;/li&gt;
    &lt;li&gt;Linear search: use std::vector&lt;/li&gt;
    &lt;li&gt;Random Insert/Remove: use std::list (if data size very small (&amp;lt; 64B on my computer), use std::vector)&lt;/li&gt;
    &lt;li&gt;Big data size: use std::list (not if intended for searching)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If you have the time, in practice, the best way to decide is always to benchmark both versions, or even to try another data structures.&lt;/p&gt;
&lt;p&gt;I hope that you found this article interesting. If you have any comment or have an idea about an other workload that you would like to test, don't hesitate to post a comment ;) If you have a question on results, don't hesitate as well.&lt;/p&gt;
&lt;p&gt;The code source of the benchmark is available online: &lt;a title="Source code of the benchmark" href="https://github.com/wichtounet/articles/blob/master/src/vector_list/bench.cpp"&gt;https://github.com/wichtounet/articles/blob/master/src/vector_list/bench.cpp&lt;/a&gt;&lt;/p&gt;
&lt;script type="text/javascript"&gt;function draw_visualization(){draw_graph_0();draw_graph_1();draw_graph_2();draw_graph_3();draw_graph_4();draw_graph_5();draw_graph_6();draw_graph_7();draw_graph_8();draw_graph_9();draw_graph_10();draw_graph_11();draw_graph_12();}google.setOnLoadCallback(draw_visualization);&lt;/script&gt;&lt;/div&gt;</description><category>Benchmarks</category><category>C++</category><category>C++11</category><category>Performances</category><guid>http://baptiste-wicht.com/posts/2012/11/cpp-benchmark-vector-vs-list.html</guid><pubDate>Mon, 26 Nov 2012 07:47:35 GMT</pubDate></item><item><title>EDDIC 0.7.1 : Boolean conditions and new operators</title><link>http://baptiste-wicht.com/posts/2012/02/eddic-0-7-1-boolean-operators.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;div&gt;&lt;p&gt;I just finished working on the 0.7.1 version of eddic.&lt;/p&gt;
&lt;p&gt;Even it it's a minor version, there are several new features in the language itself.&lt;/p&gt;
&lt;p&gt;First of all, the boolean conditions have been greatly improved. You can now use &amp;amp;&amp;amp; (short circuit and operator) and || (short circuit or operator) operators to make complex conditions for &lt;strong&gt;if&lt;/strong&gt; and &lt;strong&gt;while&lt;/strong&gt; structure. Moreover, you can now declare variables of &lt;strong&gt;bool&lt;/strong&gt; type. You can also print bool variables. That will simplify the code that can be written with EDDI.&lt;/p&gt;
&lt;p&gt;Another big improvement to the language is the addition of &lt;strong&gt;increment&lt;/strong&gt; and &lt;strong&gt;decrement&lt;/strong&gt; operators. Both postfix and prefix forms are available. You can use an increment or decrement as a single statement or inside another expressions.&lt;/p&gt;
&lt;p&gt;Increment and decrement operators are not the only operators added to the language. You can now use compound operators (+=, -=, *=, /= and %=) to make direct modifications to variables.&lt;/p&gt;
&lt;p&gt;In the next version, there will certainly be some improvements of the generated assembly. I don't know what improvement will be done on the language. &lt;/p&gt;
&lt;p&gt;If some of you have an idea of improvement for the language or the compiler itself, don't hesitate to make me know :)&lt;/p&gt;
&lt;h4&gt;Download&lt;/h4&gt;

&lt;p&gt;You can find the compiler sources on the Github repository : &lt;a title="eddic on Github" href="https://github.com/wichtounet/eddic"&gt;https://github.com/wichtounet/eddic&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The exact version I refer to is the v0.7.1 available in the github tags or directly as the release branch.&lt;/p&gt;&lt;/div&gt;</description><category>C++11</category><category>Compilers</category><category>EDDI</category><guid>http://baptiste-wicht.com/posts/2012/02/eddic-0-7-1-boolean-operators.html</guid><pubDate>Fri, 03 Feb 2012 08:11:09 GMT</pubDate></item><item><title>EDDIC 0.5 : Functions and foreach</title><link>http://baptiste-wicht.com/posts/2011/10/eddic-0-5-functions-foreach.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;div&gt;&lt;p&gt;I'm pleased to release the version 0.5. of the EDDI Compiler.&lt;/p&gt;
&lt;p&gt;This new version introduced the first version of function calls. The function can take several parameters but cannot return anything at this moment. A version of foreach loop is now available in the language.&lt;/p&gt;
&lt;p&gt;You can also declare variables globally in the source code. The global variables are stored in the .data section of the ELF file and the local variables are stored on the stack.&lt;/p&gt;
&lt;p&gt;The error reporting of the compiler has been improved. Indeed, now the syntactical errors are reported with the exact location of the source.&lt;/p&gt;
&lt;p&gt;There are also a lot of improvements in the source code. The big header files have been splitted into several files. I replaced all the pointers by smart pointers that allowed me to remove all the memory leaks of the applications and to simplify the memory management. Finally, I started using some new features of C++11 to improve the source code of the application.&lt;/p&gt;
&lt;p&gt;The next version will certainly see return types for functions and perhaps a first version of switch case. Moreover, I have a lot of improvements to do at the assembly level. Indeed, the generated assembly is not efficient at all. Perhaps, I will consider adding arrays too to this version.&lt;/p&gt;
&lt;p&gt;You can find the compiler on the Github repository : &lt;a title="EDDI COmpiler Repository" href="http://github.com/wichtounet/eddic"&gt;https://github.com/wichtounet/eddic&lt;/a&gt;. If you watch the repository, you'll see that I followed a new branching model, the one proposed and enforced by the git-flow tool.&lt;/p&gt;
&lt;p&gt;The exact version I refer to is the v0.5 available in the github tags.&lt;/p&gt;&lt;/div&gt;</description><category>C++</category><category>C++11</category><category>EDDI</category><category>Git</category><category>Releases</category><guid>http://baptiste-wicht.com/posts/2011/10/eddic-0-5-functions-foreach.html</guid><pubDate>Mon, 10 Oct 2011 00:38:50 GMT</pubDate></item></channel></rss>