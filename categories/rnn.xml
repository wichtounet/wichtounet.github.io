<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Blog blog("Baptiste Wicht"); (Posts about rnn)</title><link>http://baptiste-wicht.com/</link><description></description><atom:link href="http://baptiste-wicht.com/categories/rnn.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><lastBuildDate>Sun, 26 Nov 2017 15:45:15 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Initial support for Long Short Term Memory (LSTM) in DLL</title><link>http://baptiste-wicht.com/posts/2017/11/initial-support-for-long-short-term-memory-lstm-in-dll.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;div&gt;&lt;p&gt;I'm really happy to announce that I just merged support for&lt;/p&gt;
&lt;p&gt;Long Short Term Memory
(LSTM) cells into my Deep Learning Library (DLL) machine learning framework. Two
weeks ago, &lt;a class="reference external" href="https://baptiste-wicht.com/posts/2017/11/initial-support-for-recurrent-neural-network-rnn-in-dll.html"&gt;I already merged suport for Recurrent Neural network (RNN)&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;It's nothing fancy yet, but forward propagation of LSTM and basic
Backpropagation Through Time (BPTT) are now supported. It was not really
complicated to implemenet the forward pass but the backward pass is much
complicated for an LSTM than for a RNN. It took me quite a long time to figure
out all the gradients formulas and the documentation on that is quite scarce.&lt;/p&gt;
&lt;p&gt;For now, still only existing classification loss is supported for RNN and LSTM.
As I said last time, I still plan to add support for sequence-to-sequence loss
in order to be able to train models able to generate characters. However, I don't
know when I'll be able to work on that. Now that I've got the code for LSTM,
I should be able to implement a GRU cell and NAS cell quite easily I believe.&lt;/p&gt;
&lt;p&gt;For example, here is a simple LSTM used on MNIST for classification:&lt;/p&gt;
&lt;pre class="code cpp"&gt;&lt;a name="rest_code_46428948f03c4ce3974867842b7c3854-1"&gt;&lt;/a&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;"dll/neural/dense_layer.hpp"&lt;/span&gt;&lt;span class="cp"&gt;&lt;/span&gt;
&lt;a name="rest_code_46428948f03c4ce3974867842b7c3854-2"&gt;&lt;/a&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;"dll/neural/lstm_layer.hpp"&lt;/span&gt;&lt;span class="cp"&gt;&lt;/span&gt;
&lt;a name="rest_code_46428948f03c4ce3974867842b7c3854-3"&gt;&lt;/a&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;"dll/neural/recurrent_last_layer.hpp"&lt;/span&gt;&lt;span class="cp"&gt;&lt;/span&gt;
&lt;a name="rest_code_46428948f03c4ce3974867842b7c3854-4"&gt;&lt;/a&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;"dll/network.hpp"&lt;/span&gt;&lt;span class="cp"&gt;&lt;/span&gt;
&lt;a name="rest_code_46428948f03c4ce3974867842b7c3854-5"&gt;&lt;/a&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;"dll/datasets.hpp"&lt;/span&gt;&lt;span class="cp"&gt;&lt;/span&gt;
&lt;a name="rest_code_46428948f03c4ce3974867842b7c3854-6"&gt;&lt;/a&gt;
&lt;a name="rest_code_46428948f03c4ce3974867842b7c3854-7"&gt;&lt;/a&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="cm"&gt;/*argc*/&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;char&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="cm"&gt;/*argv*/&lt;/span&gt; &lt;span class="p"&gt;[])&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;a name="rest_code_46428948f03c4ce3974867842b7c3854-8"&gt;&lt;/a&gt;    &lt;span class="c1"&gt;// Load the dataset&lt;/span&gt;
&lt;a name="rest_code_46428948f03c4ce3974867842b7c3854-9"&gt;&lt;/a&gt;    &lt;span class="k"&gt;auto&lt;/span&gt; &lt;span class="n"&gt;dataset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;make_mnist_dataset_nc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;{},&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;scale_pre&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;255&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;{});&lt;/span&gt;
&lt;a name="rest_code_46428948f03c4ce3974867842b7c3854-10"&gt;&lt;/a&gt;
&lt;a name="rest_code_46428948f03c4ce3974867842b7c3854-11"&gt;&lt;/a&gt;    &lt;span class="k"&gt;constexpr&lt;/span&gt; &lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;time_steps&lt;/span&gt;      &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;28&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_46428948f03c4ce3974867842b7c3854-12"&gt;&lt;/a&gt;    &lt;span class="k"&gt;constexpr&lt;/span&gt; &lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;sequence_length&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;28&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_46428948f03c4ce3974867842b7c3854-13"&gt;&lt;/a&gt;    &lt;span class="k"&gt;constexpr&lt;/span&gt; &lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;hidden_units&lt;/span&gt;    &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_46428948f03c4ce3974867842b7c3854-14"&gt;&lt;/a&gt;
&lt;a name="rest_code_46428948f03c4ce3974867842b7c3854-15"&gt;&lt;/a&gt;    &lt;span class="c1"&gt;// Build the network&lt;/span&gt;
&lt;a name="rest_code_46428948f03c4ce3974867842b7c3854-16"&gt;&lt;/a&gt;
&lt;a name="rest_code_46428948f03c4ce3974867842b7c3854-17"&gt;&lt;/a&gt;    &lt;span class="k"&gt;using&lt;/span&gt; &lt;span class="n"&gt;network_t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dyn_network_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;
&lt;a name="rest_code_46428948f03c4ce3974867842b7c3854-18"&gt;&lt;/a&gt;        &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;network_layers&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;
&lt;a name="rest_code_46428948f03c4ce3974867842b7c3854-19"&gt;&lt;/a&gt;            &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;lstm_layer&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;time_steps&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sequence_length&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;hidden_units&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;last_only&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_46428948f03c4ce3974867842b7c3854-20"&gt;&lt;/a&gt;            &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;recurrent_last_layer&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;time_steps&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;hidden_units&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_46428948f03c4ce3974867842b7c3854-21"&gt;&lt;/a&gt;            &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dense_layer&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;hidden_units&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;softmax&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_46428948f03c4ce3974867842b7c3854-22"&gt;&lt;/a&gt;        &lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_46428948f03c4ce3974867842b7c3854-23"&gt;&lt;/a&gt;        &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;updater&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;updater_type&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;ADAM&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;      &lt;span class="c1"&gt;// Adam&lt;/span&gt;
&lt;a name="rest_code_46428948f03c4ce3974867842b7c3854-24"&gt;&lt;/a&gt;        &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;                       &lt;span class="c1"&gt;// The mini-batch size&lt;/span&gt;
&lt;a name="rest_code_46428948f03c4ce3974867842b7c3854-25"&gt;&lt;/a&gt;    &lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;network_t&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_46428948f03c4ce3974867842b7c3854-26"&gt;&lt;/a&gt;
&lt;a name="rest_code_46428948f03c4ce3974867842b7c3854-27"&gt;&lt;/a&gt;    &lt;span class="k"&gt;auto&lt;/span&gt; &lt;span class="n"&gt;net&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;make_unique&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;network_t&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;a name="rest_code_46428948f03c4ce3974867842b7c3854-28"&gt;&lt;/a&gt;
&lt;a name="rest_code_46428948f03c4ce3974867842b7c3854-29"&gt;&lt;/a&gt;    &lt;span class="c1"&gt;// Display the network and dataset&lt;/span&gt;
&lt;a name="rest_code_46428948f03c4ce3974867842b7c3854-30"&gt;&lt;/a&gt;    &lt;span class="n"&gt;net&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;display&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;a name="rest_code_46428948f03c4ce3974867842b7c3854-31"&gt;&lt;/a&gt;    &lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;display&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;a name="rest_code_46428948f03c4ce3974867842b7c3854-32"&gt;&lt;/a&gt;
&lt;a name="rest_code_46428948f03c4ce3974867842b7c3854-33"&gt;&lt;/a&gt;    &lt;span class="c1"&gt;// Train the network for performance sake&lt;/span&gt;
&lt;a name="rest_code_46428948f03c4ce3974867842b7c3854-34"&gt;&lt;/a&gt;    &lt;span class="n"&gt;net&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;fine_tune&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a name="rest_code_46428948f03c4ce3974867842b7c3854-35"&gt;&lt;/a&gt;
&lt;a name="rest_code_46428948f03c4ce3974867842b7c3854-36"&gt;&lt;/a&gt;    &lt;span class="c1"&gt;// Test the network on test set&lt;/span&gt;
&lt;a name="rest_code_46428948f03c4ce3974867842b7c3854-37"&gt;&lt;/a&gt;    &lt;span class="n"&gt;net&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;evaluate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;test&lt;/span&gt;&lt;span class="p"&gt;());&lt;/span&gt;
&lt;a name="rest_code_46428948f03c4ce3974867842b7c3854-38"&gt;&lt;/a&gt;
&lt;a name="rest_code_46428948f03c4ce3974867842b7c3854-39"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_46428948f03c4ce3974867842b7c3854-40"&gt;&lt;/a&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;The network is quite similar to the one used previously with an RNN, just
replace rnn with lstm and that's it. It starts with LSTM layer, followed by
a layer extracting the last time step and finally a dense layer with a softmax
function. The network is trained with Adam for 50 epochs. You can change the
activation function , the initializer for the weights and the biases and number
of steps for BPTT truncation.&lt;/p&gt;
&lt;p&gt;Here is the result I got on my last run:&lt;/p&gt;
&lt;pre class="code text"&gt;&lt;a name="rest_code_ae889957e735441095395a7bd801573f-1"&gt;&lt;/a&gt;------------------------------------------------------------
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-2"&gt;&lt;/a&gt;| Index | Layer                | Parameters | Output Shape |
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-3"&gt;&lt;/a&gt;------------------------------------------------------------
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-4"&gt;&lt;/a&gt;| 0     | LSTM (TANH) (dyn)    |      51200 | [Bx28x100]   |
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-5"&gt;&lt;/a&gt;| 1     | RNN(last)            |          0 | [Bx100]      |
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-6"&gt;&lt;/a&gt;| 2     | Dense(SOFTMAX) (dyn) |       1000 | [Bx10]       |
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-7"&gt;&lt;/a&gt;------------------------------------------------------------
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-8"&gt;&lt;/a&gt;              Total Parameters:      52200
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-9"&gt;&lt;/a&gt;
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-10"&gt;&lt;/a&gt;--------------------------------------------
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-11"&gt;&lt;/a&gt;| mnist | Size  | Batches | Augmented Size |
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-12"&gt;&lt;/a&gt;--------------------------------------------
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-13"&gt;&lt;/a&gt;| train | 60000 | 600     | 60000          |
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-14"&gt;&lt;/a&gt;| test  | 10000 | 100     | 10000          |
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-15"&gt;&lt;/a&gt;--------------------------------------------
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-16"&gt;&lt;/a&gt;
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-17"&gt;&lt;/a&gt;Network with 3 layers
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-18"&gt;&lt;/a&gt;    LSTM(dyn): 28x28 -&amp;gt; TANH -&amp;gt; 28x100
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-19"&gt;&lt;/a&gt;    RNN(last): 28x100 -&amp;gt; 100
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-20"&gt;&lt;/a&gt;    Dense(dyn): 100 -&amp;gt; SOFTMAX -&amp;gt; 10
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-21"&gt;&lt;/a&gt;Total parameters: 52200
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-22"&gt;&lt;/a&gt;Dataset
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-23"&gt;&lt;/a&gt;Training: In-Memory Data Generator
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-24"&gt;&lt;/a&gt;              Size: 60000
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-25"&gt;&lt;/a&gt;           Batches: 600
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-26"&gt;&lt;/a&gt;Testing: In-Memory Data Generator
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-27"&gt;&lt;/a&gt;              Size: 10000
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-28"&gt;&lt;/a&gt;           Batches: 100
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-29"&gt;&lt;/a&gt;
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-30"&gt;&lt;/a&gt;Train the network with "Stochastic Gradient Descent"
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-31"&gt;&lt;/a&gt;    Updater: ADAM
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-32"&gt;&lt;/a&gt;       Loss: CATEGORICAL_CROSS_ENTROPY
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-33"&gt;&lt;/a&gt; Early Stop: Goal(error)
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-34"&gt;&lt;/a&gt;
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-35"&gt;&lt;/a&gt;With parameters:
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-36"&gt;&lt;/a&gt;          epochs=50
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-37"&gt;&lt;/a&gt;      batch_size=100
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-38"&gt;&lt;/a&gt;   learning_rate=0.001
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-39"&gt;&lt;/a&gt;           beta1=0.9
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-40"&gt;&lt;/a&gt;           beta2=0.999
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-41"&gt;&lt;/a&gt;
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-42"&gt;&lt;/a&gt;epoch   0/50 batch  600/ 600 - error: 0.07943 loss: 0.28504 time 20910ms
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-43"&gt;&lt;/a&gt;epoch   1/50 batch  600/ 600 - error: 0.06683 loss: 0.24021 time 20889ms
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-44"&gt;&lt;/a&gt;epoch   2/50 batch  600/ 600 - error: 0.04828 loss: 0.18233 time 21061ms
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-45"&gt;&lt;/a&gt;epoch   3/50 batch  600/ 600 - error: 0.04407 loss: 0.16665 time 20839ms
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-46"&gt;&lt;/a&gt;epoch   4/50 batch  600/ 600 - error: 0.03515 loss: 0.13290 time 22108ms
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-47"&gt;&lt;/a&gt;epoch   5/50 batch  600/ 600 - error: 0.03207 loss: 0.12019 time 21393ms
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-48"&gt;&lt;/a&gt;epoch   6/50 batch  600/ 600 - error: 0.02973 loss: 0.11239 time 28199ms
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-49"&gt;&lt;/a&gt;epoch   7/50 batch  600/ 600 - error: 0.02653 loss: 0.10455 time 37039ms
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-50"&gt;&lt;/a&gt;epoch   8/50 batch  600/ 600 - error: 0.02482 loss: 0.09657 time 23127ms
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-51"&gt;&lt;/a&gt;epoch   9/50 batch  600/ 600 - error: 0.02177 loss: 0.08422 time 41766ms
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-52"&gt;&lt;/a&gt;epoch  10/50 batch  600/ 600 - error: 0.02453 loss: 0.09382 time 29765ms
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-53"&gt;&lt;/a&gt;epoch  11/50 batch  600/ 600 - error: 0.02575 loss: 0.09796 time 21449ms
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-54"&gt;&lt;/a&gt;epoch  12/50 batch  600/ 600 - error: 0.02107 loss: 0.07833 time 42056ms
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-55"&gt;&lt;/a&gt;epoch  13/50 batch  600/ 600 - error: 0.01877 loss: 0.07171 time 24673ms
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-56"&gt;&lt;/a&gt;epoch  14/50 batch  600/ 600 - error: 0.02095 loss: 0.08481 time 20878ms
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-57"&gt;&lt;/a&gt;epoch  15/50 batch  600/ 600 - error: 0.02040 loss: 0.07578 time 41515ms
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-58"&gt;&lt;/a&gt;epoch  16/50 batch  600/ 600 - error: 0.01580 loss: 0.06083 time 25705ms
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-59"&gt;&lt;/a&gt;epoch  17/50 batch  600/ 600 - error: 0.01945 loss: 0.07046 time 20903ms
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-60"&gt;&lt;/a&gt;epoch  18/50 batch  600/ 600 - error: 0.01728 loss: 0.06683 time 41828ms
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-61"&gt;&lt;/a&gt;epoch  19/50 batch  600/ 600 - error: 0.01577 loss: 0.05947 time 27810ms
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-62"&gt;&lt;/a&gt;epoch  20/50 batch  600/ 600 - error: 0.01528 loss: 0.05883 time 21477ms
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-63"&gt;&lt;/a&gt;epoch  21/50 batch  600/ 600 - error: 0.01345 loss: 0.05127 time 44718ms
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-64"&gt;&lt;/a&gt;epoch  22/50 batch  600/ 600 - error: 0.01410 loss: 0.05357 time 25174ms
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-65"&gt;&lt;/a&gt;epoch  23/50 batch  600/ 600 - error: 0.01268 loss: 0.04765 time 23827ms
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-66"&gt;&lt;/a&gt;epoch  24/50 batch  600/ 600 - error: 0.01342 loss: 0.05004 time 47232ms
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-67"&gt;&lt;/a&gt;epoch  25/50 batch  600/ 600 - error: 0.01730 loss: 0.06872 time 22532ms
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-68"&gt;&lt;/a&gt;epoch  26/50 batch  600/ 600 - error: 0.01337 loss: 0.05016 time 30114ms
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-69"&gt;&lt;/a&gt;epoch  27/50 batch  600/ 600 - error: 0.01842 loss: 0.07049 time 40136ms
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-70"&gt;&lt;/a&gt;epoch  28/50 batch  600/ 600 - error: 0.01262 loss: 0.04639 time 21793ms
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-71"&gt;&lt;/a&gt;epoch  29/50 batch  600/ 600 - error: 0.01403 loss: 0.05292 time 34096ms
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-72"&gt;&lt;/a&gt;epoch  30/50 batch  600/ 600 - error: 0.01185 loss: 0.04456 time 35420ms
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-73"&gt;&lt;/a&gt;epoch  31/50 batch  600/ 600 - error: 0.01098 loss: 0.04180 time 20909ms
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-74"&gt;&lt;/a&gt;epoch  32/50 batch  600/ 600 - error: 0.01337 loss: 0.04687 time 30113ms
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-75"&gt;&lt;/a&gt;epoch  33/50 batch  600/ 600 - error: 0.01415 loss: 0.05292 time 37393ms
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-76"&gt;&lt;/a&gt;epoch  34/50 batch  600/ 600 - error: 0.00982 loss: 0.03615 time 20962ms
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-77"&gt;&lt;/a&gt;epoch  35/50 batch  600/ 600 - error: 0.01178 loss: 0.04830 time 29305ms
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-78"&gt;&lt;/a&gt;epoch  36/50 batch  600/ 600 - error: 0.00882 loss: 0.03408 time 38293ms
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-79"&gt;&lt;/a&gt;epoch  37/50 batch  600/ 600 - error: 0.01148 loss: 0.04341 time 20841ms
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-80"&gt;&lt;/a&gt;epoch  38/50 batch  600/ 600 - error: 0.00960 loss: 0.03701 time 29204ms
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-81"&gt;&lt;/a&gt;epoch  39/50 batch  600/ 600 - error: 0.00850 loss: 0.03094 time 39802ms
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-82"&gt;&lt;/a&gt;epoch  40/50 batch  600/ 600 - error: 0.01473 loss: 0.05136 time 20831ms
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-83"&gt;&lt;/a&gt;epoch  41/50 batch  600/ 600 - error: 0.01007 loss: 0.03579 time 29856ms
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-84"&gt;&lt;/a&gt;epoch  42/50 batch  600/ 600 - error: 0.00943 loss: 0.03370 time 38200ms
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-85"&gt;&lt;/a&gt;epoch  43/50 batch  600/ 600 - error: 0.01205 loss: 0.04409 time 21162ms
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-86"&gt;&lt;/a&gt;epoch  44/50 batch  600/ 600 - error: 0.00980 loss: 0.03674 time 32279ms
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-87"&gt;&lt;/a&gt;epoch  45/50 batch  600/ 600 - error: 0.01068 loss: 0.04133 time 38448ms
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-88"&gt;&lt;/a&gt;epoch  46/50 batch  600/ 600 - error: 0.00913 loss: 0.03478 time 20797ms
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-89"&gt;&lt;/a&gt;epoch  47/50 batch  600/ 600 - error: 0.00985 loss: 0.03759 time 28885ms
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-90"&gt;&lt;/a&gt;epoch  48/50 batch  600/ 600 - error: 0.00912 loss: 0.03295 time 41120ms
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-91"&gt;&lt;/a&gt;epoch  49/50 batch  600/ 600 - error: 0.00930 loss: 0.03438 time 21282ms
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-92"&gt;&lt;/a&gt;Restore the best (error) weights from epoch 39
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-93"&gt;&lt;/a&gt;Training took 1460s
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-94"&gt;&lt;/a&gt;
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-95"&gt;&lt;/a&gt;Evaluation Results
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-96"&gt;&lt;/a&gt;   error: 0.02440
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-97"&gt;&lt;/a&gt;    loss: 0.11315
&lt;a name="rest_code_ae889957e735441095395a7bd801573f-98"&gt;&lt;/a&gt;evaluation took 1000ms
&lt;/pre&gt;&lt;p&gt;Again, nothing fancy yet, but this example has not been optimized for
performance nor for accuracy.&lt;/p&gt;
&lt;p&gt;I also made a few changes to the RNN layer. I added support for biases and
improved the code as well for performance and readability.&lt;/p&gt;
&lt;p&gt;All this support is now in the &lt;strong&gt;master&lt;/strong&gt; branch of the DLL project if you want
to check it out. You can also check out the example online:
&lt;a class="reference external" href="https://github.com/wichtounet/dll/blob/master/examples/src/mnist_lstm.cpp"&gt;mnist_lstm.cpp&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;You can access the project &lt;a class="reference external" href="https://github.com/wichtounet/dll"&gt;on Github&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Currently I'm working on the GPU performance again. The performance of some is
still not as good as I want it to be, especially complex operation like used in
Adam and Nadam. Currently, there are many calls to GPU BLAS libraries and
I want to try to extract some more optimized patterns. Once it's done, I'll post
more on that later on the blog.&lt;/p&gt;&lt;/div&gt;</description><category>Deep Learning</category><category>dll</category><category>Machine Learning</category><category>projects</category><category>rnn</category><guid>http://baptiste-wicht.com/posts/2017/11/initial-support-for-long-short-term-memory-lstm-in-dll.html</guid><pubDate>Fri, 24 Nov 2017 14:16:37 GMT</pubDate></item><item><title>Initial support for Recurrent Neural Network (RNN) in DLL</title><link>http://baptiste-wicht.com/posts/2017/11/initial-support-for-recurrent-neural-network-rnn-in-dll.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;div&gt;&lt;p&gt;I'm happy to announce that I just merged support for Recurrent Neural Networks
(RNNs) into my Deep Learning Library (DLL) machine learning framework.&lt;/p&gt;
&lt;p&gt;It's nothing fancy yet, but forward propagation of RNN and basic Backpropagation
Through Time (BPTT) are now supported. For now, only existing classification
loss is supported for RNN. I plan to add support for sequence-to-sequence loss
in order to be able to train models able to generate characters, but I don't
know when I'll be able to work on that. I also plan to add support for other
types of cells such as LSTM and GRU (maybe NAS) in the future.&lt;/p&gt;
&lt;p&gt;For example, here is a simple RNN used on MNIST:&lt;/p&gt;
&lt;pre class="code cpp"&gt;&lt;a name="rest_code_26d4164c41c74b52a7e4b27bfbd42b79-1"&gt;&lt;/a&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;"dll/neural/dense_layer.hpp"&lt;/span&gt;&lt;span class="cp"&gt;&lt;/span&gt;
&lt;a name="rest_code_26d4164c41c74b52a7e4b27bfbd42b79-2"&gt;&lt;/a&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;"dll/neural/recurrent_layer.hpp"&lt;/span&gt;&lt;span class="cp"&gt;&lt;/span&gt;
&lt;a name="rest_code_26d4164c41c74b52a7e4b27bfbd42b79-3"&gt;&lt;/a&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;"dll/neural/recurrent_last_layer.hpp"&lt;/span&gt;&lt;span class="cp"&gt;&lt;/span&gt;
&lt;a name="rest_code_26d4164c41c74b52a7e4b27bfbd42b79-4"&gt;&lt;/a&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;"dll/network.hpp"&lt;/span&gt;&lt;span class="cp"&gt;&lt;/span&gt;
&lt;a name="rest_code_26d4164c41c74b52a7e4b27bfbd42b79-5"&gt;&lt;/a&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;"dll/datasets.hpp"&lt;/span&gt;&lt;span class="cp"&gt;&lt;/span&gt;
&lt;a name="rest_code_26d4164c41c74b52a7e4b27bfbd42b79-6"&gt;&lt;/a&gt;
&lt;a name="rest_code_26d4164c41c74b52a7e4b27bfbd42b79-7"&gt;&lt;/a&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="cm"&gt;/*argc*/&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;char&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="cm"&gt;/*argv*/&lt;/span&gt; &lt;span class="p"&gt;[])&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;a name="rest_code_26d4164c41c74b52a7e4b27bfbd42b79-8"&gt;&lt;/a&gt;    &lt;span class="c1"&gt;// Load the dataset&lt;/span&gt;
&lt;a name="rest_code_26d4164c41c74b52a7e4b27bfbd42b79-9"&gt;&lt;/a&gt;    &lt;span class="k"&gt;auto&lt;/span&gt; &lt;span class="n"&gt;dataset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;make_mnist_dataset_nc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;{},&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;scale_pre&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;255&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;{});&lt;/span&gt;
&lt;a name="rest_code_26d4164c41c74b52a7e4b27bfbd42b79-10"&gt;&lt;/a&gt;
&lt;a name="rest_code_26d4164c41c74b52a7e4b27bfbd42b79-11"&gt;&lt;/a&gt;    &lt;span class="k"&gt;constexpr&lt;/span&gt; &lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;time_steps&lt;/span&gt;      &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;28&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_26d4164c41c74b52a7e4b27bfbd42b79-12"&gt;&lt;/a&gt;    &lt;span class="k"&gt;constexpr&lt;/span&gt; &lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;sequence_length&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;28&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_26d4164c41c74b52a7e4b27bfbd42b79-13"&gt;&lt;/a&gt;    &lt;span class="k"&gt;constexpr&lt;/span&gt; &lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;hidden_units&lt;/span&gt;    &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_26d4164c41c74b52a7e4b27bfbd42b79-14"&gt;&lt;/a&gt;
&lt;a name="rest_code_26d4164c41c74b52a7e4b27bfbd42b79-15"&gt;&lt;/a&gt;    &lt;span class="c1"&gt;// Build the network&lt;/span&gt;
&lt;a name="rest_code_26d4164c41c74b52a7e4b27bfbd42b79-16"&gt;&lt;/a&gt;
&lt;a name="rest_code_26d4164c41c74b52a7e4b27bfbd42b79-17"&gt;&lt;/a&gt;    &lt;span class="k"&gt;using&lt;/span&gt; &lt;span class="n"&gt;network_t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dyn_network_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;
&lt;a name="rest_code_26d4164c41c74b52a7e4b27bfbd42b79-18"&gt;&lt;/a&gt;        &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;network_layers&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;
&lt;a name="rest_code_26d4164c41c74b52a7e4b27bfbd42b79-19"&gt;&lt;/a&gt;            &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;recurrent_layer&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;time_steps&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sequence_length&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;hidden_units&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;last_only&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_26d4164c41c74b52a7e4b27bfbd42b79-20"&gt;&lt;/a&gt;            &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;recurrent_last_layer&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;time_steps&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;hidden_units&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_26d4164c41c74b52a7e4b27bfbd42b79-21"&gt;&lt;/a&gt;            &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dense_layer&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;hidden_units&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;softmax&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_26d4164c41c74b52a7e4b27bfbd42b79-22"&gt;&lt;/a&gt;        &lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_26d4164c41c74b52a7e4b27bfbd42b79-23"&gt;&lt;/a&gt;        &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;updater&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;updater_type&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;ADAM&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;      &lt;span class="c1"&gt;// Adam&lt;/span&gt;
&lt;a name="rest_code_26d4164c41c74b52a7e4b27bfbd42b79-24"&gt;&lt;/a&gt;        &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;                       &lt;span class="c1"&gt;// The mini-batch size&lt;/span&gt;
&lt;a name="rest_code_26d4164c41c74b52a7e4b27bfbd42b79-25"&gt;&lt;/a&gt;    &lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;network_t&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_26d4164c41c74b52a7e4b27bfbd42b79-26"&gt;&lt;/a&gt;
&lt;a name="rest_code_26d4164c41c74b52a7e4b27bfbd42b79-27"&gt;&lt;/a&gt;    &lt;span class="k"&gt;auto&lt;/span&gt; &lt;span class="n"&gt;net&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;make_unique&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;network_t&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;a name="rest_code_26d4164c41c74b52a7e4b27bfbd42b79-28"&gt;&lt;/a&gt;
&lt;a name="rest_code_26d4164c41c74b52a7e4b27bfbd42b79-29"&gt;&lt;/a&gt;    &lt;span class="c1"&gt;// Display the network and dataset&lt;/span&gt;
&lt;a name="rest_code_26d4164c41c74b52a7e4b27bfbd42b79-30"&gt;&lt;/a&gt;    &lt;span class="n"&gt;net&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;display&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;a name="rest_code_26d4164c41c74b52a7e4b27bfbd42b79-31"&gt;&lt;/a&gt;
&lt;a name="rest_code_26d4164c41c74b52a7e4b27bfbd42b79-32"&gt;&lt;/a&gt;    &lt;span class="c1"&gt;// Train the network for performance sake&lt;/span&gt;
&lt;a name="rest_code_26d4164c41c74b52a7e4b27bfbd42b79-33"&gt;&lt;/a&gt;    &lt;span class="n"&gt;net&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;fine_tune&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a name="rest_code_26d4164c41c74b52a7e4b27bfbd42b79-34"&gt;&lt;/a&gt;
&lt;a name="rest_code_26d4164c41c74b52a7e4b27bfbd42b79-35"&gt;&lt;/a&gt;    &lt;span class="c1"&gt;// Test the network on test set&lt;/span&gt;
&lt;a name="rest_code_26d4164c41c74b52a7e4b27bfbd42b79-36"&gt;&lt;/a&gt;    &lt;span class="n"&gt;net&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;evaluate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;test&lt;/span&gt;&lt;span class="p"&gt;());&lt;/span&gt;
&lt;a name="rest_code_26d4164c41c74b52a7e4b27bfbd42b79-37"&gt;&lt;/a&gt;
&lt;a name="rest_code_26d4164c41c74b52a7e4b27bfbd42b79-38"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_26d4164c41c74b52a7e4b27bfbd42b79-39"&gt;&lt;/a&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;The network starts with recurrent layer, followed by a layer that extracts only
the last layer and finally a dense layer with a softmax function. The recurrent
layer has support to change the activation function, change the initializer for
the two weights matrices of the RNN and the number of steps for BPTT truncation.&lt;/p&gt;
&lt;p&gt;Here is a possible result:&lt;/p&gt;
&lt;pre class="code text"&gt;&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-1"&gt;&lt;/a&gt;Network with 3 layers
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-2"&gt;&lt;/a&gt;    RNN(dyn): 28x28 -&amp;gt; TANH -&amp;gt; 28x100
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-3"&gt;&lt;/a&gt;    RNN(last): 28x100 -&amp;gt; 100
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-4"&gt;&lt;/a&gt;    Dense(dyn): 100 -&amp;gt; SOFTMAX -&amp;gt; 10
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-5"&gt;&lt;/a&gt;Total parameters: 13800
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-6"&gt;&lt;/a&gt;Train the network with "Stochastic Gradient Descent"
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-7"&gt;&lt;/a&gt;    Updater: ADAM
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-8"&gt;&lt;/a&gt;       Loss: CATEGORICAL_CROSS_ENTROPY
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-9"&gt;&lt;/a&gt; Early Stop: Goal(error)
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-10"&gt;&lt;/a&gt;
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-11"&gt;&lt;/a&gt;With parameters:
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-12"&gt;&lt;/a&gt;          epochs=50
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-13"&gt;&lt;/a&gt;      batch_size=100
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-14"&gt;&lt;/a&gt;   learning_rate=0.001
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-15"&gt;&lt;/a&gt;           beta1=0.9
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-16"&gt;&lt;/a&gt;           beta2=0.999
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-17"&gt;&lt;/a&gt;
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-18"&gt;&lt;/a&gt;Epoch   0/50 - Classification error: 0.11635 Loss: 0.39999 Time 4717ms
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-19"&gt;&lt;/a&gt;Epoch   1/50 - Classification error: 0.11303 Loss: 0.36994 Time 4702ms
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-20"&gt;&lt;/a&gt;Epoch   2/50 - Classification error: 0.06732 Loss: 0.23469 Time 4702ms
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-21"&gt;&lt;/a&gt;Epoch   3/50 - Classification error: 0.04865 Loss: 0.17091 Time 4696ms
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-22"&gt;&lt;/a&gt;Epoch   4/50 - Classification error: 0.05957 Loss: 0.20437 Time 4706ms
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-23"&gt;&lt;/a&gt;Epoch   5/50 - Classification error: 0.05022 Loss: 0.16888 Time 4696ms
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-24"&gt;&lt;/a&gt;Epoch   6/50 - Classification error: 0.03912 Loss: 0.13743 Time 4698ms
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-25"&gt;&lt;/a&gt;Epoch   7/50 - Classification error: 0.04097 Loss: 0.14509 Time 4706ms
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-26"&gt;&lt;/a&gt;Epoch   8/50 - Classification error: 0.03938 Loss: 0.13397 Time 4694ms
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-27"&gt;&lt;/a&gt;Epoch   9/50 - Classification error: 0.03525 Loss: 0.12284 Time 4706ms
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-28"&gt;&lt;/a&gt;Epoch  10/50 - Classification error: 0.03927 Loss: 0.13770 Time 4694ms
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-29"&gt;&lt;/a&gt;Epoch  11/50 - Classification error: 0.03315 Loss: 0.11315 Time 4711ms
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-30"&gt;&lt;/a&gt;Epoch  12/50 - Classification error: 0.05037 Loss: 0.17123 Time 4711ms
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-31"&gt;&lt;/a&gt;Epoch  13/50 - Classification error: 0.02927 Loss: 0.10042 Time 4780ms
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-32"&gt;&lt;/a&gt;Epoch  14/50 - Classification error: 0.03322 Loss: 0.11027 Time 4746ms
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-33"&gt;&lt;/a&gt;Epoch  15/50 - Classification error: 0.03397 Loss: 0.11585 Time 4684ms
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-34"&gt;&lt;/a&gt;Epoch  16/50 - Classification error: 0.02938 Loss: 0.09984 Time 4708ms
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-35"&gt;&lt;/a&gt;Epoch  17/50 - Classification error: 0.03262 Loss: 0.11152 Time 4690ms
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-36"&gt;&lt;/a&gt;Epoch  18/50 - Classification error: 0.02872 Loss: 0.09753 Time 4672ms
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-37"&gt;&lt;/a&gt;Epoch  19/50 - Classification error: 0.02548 Loss: 0.08605 Time 4691ms
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-38"&gt;&lt;/a&gt;Epoch  20/50 - Classification error: 0.02245 Loss: 0.07797 Time 4693ms
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-39"&gt;&lt;/a&gt;Epoch  21/50 - Classification error: 0.02705 Loss: 0.08984 Time 4684ms
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-40"&gt;&lt;/a&gt;Epoch  22/50 - Classification error: 0.02422 Loss: 0.08164 Time 4688ms
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-41"&gt;&lt;/a&gt;Epoch  23/50 - Classification error: 0.02645 Loss: 0.08804 Time 4690ms
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-42"&gt;&lt;/a&gt;Epoch  24/50 - Classification error: 0.02927 Loss: 0.09739 Time 4715ms
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-43"&gt;&lt;/a&gt;Epoch  25/50 - Classification error: 0.02578 Loss: 0.08669 Time 4702ms
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-44"&gt;&lt;/a&gt;Epoch  26/50 - Classification error: 0.02785 Loss: 0.09368 Time 4700ms
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-45"&gt;&lt;/a&gt;Epoch  27/50 - Classification error: 0.02472 Loss: 0.08237 Time 4695ms
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-46"&gt;&lt;/a&gt;Epoch  28/50 - Classification error: 0.02125 Loss: 0.07324 Time 4690ms
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-47"&gt;&lt;/a&gt;Epoch  29/50 - Classification error: 0.01977 Loss: 0.06635 Time 4688ms
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-48"&gt;&lt;/a&gt;Epoch  30/50 - Classification error: 0.03635 Loss: 0.12140 Time 4689ms
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-49"&gt;&lt;/a&gt;Epoch  31/50 - Classification error: 0.02862 Loss: 0.09704 Time 4698ms
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-50"&gt;&lt;/a&gt;Epoch  32/50 - Classification error: 0.02463 Loss: 0.08158 Time 4686ms
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-51"&gt;&lt;/a&gt;Epoch  33/50 - Classification error: 0.02565 Loss: 0.08771 Time 4697ms
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-52"&gt;&lt;/a&gt;Epoch  34/50 - Classification error: 0.02278 Loss: 0.07634 Time 4718ms
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-53"&gt;&lt;/a&gt;Epoch  35/50 - Classification error: 0.02105 Loss: 0.07075 Time 4697ms
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-54"&gt;&lt;/a&gt;Epoch  36/50 - Classification error: 0.02770 Loss: 0.09358 Time 4711ms
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-55"&gt;&lt;/a&gt;Epoch  37/50 - Classification error: 0.02627 Loss: 0.08805 Time 4742ms
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-56"&gt;&lt;/a&gt;Epoch  38/50 - Classification error: 0.02282 Loss: 0.07712 Time 4708ms
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-57"&gt;&lt;/a&gt;Epoch  39/50 - Classification error: 0.02305 Loss: 0.07661 Time 4697ms
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-58"&gt;&lt;/a&gt;Epoch  40/50 - Classification error: 0.02243 Loss: 0.07773 Time 4700ms
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-59"&gt;&lt;/a&gt;Epoch  41/50 - Classification error: 0.02467 Loss: 0.08234 Time 4712ms
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-60"&gt;&lt;/a&gt;Epoch  42/50 - Classification error: 0.01808 Loss: 0.06186 Time 4691ms
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-61"&gt;&lt;/a&gt;Epoch  43/50 - Classification error: 0.02388 Loss: 0.07917 Time 4681ms
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-62"&gt;&lt;/a&gt;Epoch  44/50 - Classification error: 0.02162 Loss: 0.07508 Time 4699ms
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-63"&gt;&lt;/a&gt;Epoch  45/50 - Classification error: 0.01877 Loss: 0.06289 Time 4735ms
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-64"&gt;&lt;/a&gt;Epoch  46/50 - Classification error: 0.02263 Loss: 0.07969 Time 4764ms
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-65"&gt;&lt;/a&gt;Epoch  47/50 - Classification error: 0.02100 Loss: 0.07207 Time 4684ms
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-66"&gt;&lt;/a&gt;Epoch  48/50 - Classification error: 0.02425 Loss: 0.08076 Time 4752ms
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-67"&gt;&lt;/a&gt;Epoch  49/50 - Classification error: 0.02328 Loss: 0.07803 Time 4718ms
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-68"&gt;&lt;/a&gt;Restore the best (error) weights from epoch 42
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-69"&gt;&lt;/a&gt;Training took 235s
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-70"&gt;&lt;/a&gt;Evaluation Results
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-71"&gt;&lt;/a&gt;   error: 0.03000
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-72"&gt;&lt;/a&gt;    loss: 0.12260
&lt;a name="rest_code_5f651d989a014ec39f1859d00ab7ec25-73"&gt;&lt;/a&gt;evaluation took 245ms
&lt;/pre&gt;&lt;p&gt;Nothing fancy, but this example is not necessarily optimized.&lt;/p&gt;
&lt;p&gt;All this support is now in the &lt;strong&gt;master&lt;/strong&gt; branch of the DLL project if you want
to check it out. You can also check out the example online:
&lt;a class="reference external" href="https://github.com/wichtounet/dll/blob/master/examples/src/mnist_rnn.cpp"&gt;mnist_rnn.cpp&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;You can access the project &lt;a class="reference external" href="https://github.com/wichtounet/dll"&gt;on Github&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;</description><category>Deep Learning</category><category>dll</category><category>Machine Learning</category><category>projects</category><category>rnn</category><guid>http://baptiste-wicht.com/posts/2017/11/initial-support-for-recurrent-neural-network-rnn-in-dll.html</guid><pubDate>Sun, 12 Nov 2017 14:22:44 GMT</pubDate></item></channel></rss>