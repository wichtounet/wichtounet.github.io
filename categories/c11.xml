<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>@Blog("Baptiste Wicht") (C++11)</title><link>http://baptiste-wicht.com/</link><description></description><atom:link href="http://baptiste-wicht.com/categories/c11.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><lastBuildDate>Sat, 05 Apr 2014 17:06:41 GMT</lastBuildDate><generator>Nikola &lt;http://getnikola.com/&gt;</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Improving eddic Boost Spirit parser performances</title><link>http://baptiste-wicht.com/posts/2013/06/improving-eddic-boost-spirit-parser-performances.html</link><description>&lt;div&gt;&lt;p&gt;After the last changes on the data-flow framework, the parsing pass of the eddic compiler became the slowest one. I was sure there was some area of optimizations, so I decided to improve its performances.&lt;/p&gt;
&lt;p&gt;In this post, I will present the different techniques I applied and their results.&lt;/p&gt;
&lt;h4&gt;Static grammar&lt;/h4&gt;

&lt;p&gt;The first optimization that I tried was to make the grammar static, meaning that we can declare it static and it will be constructed only once and will be allocated on the data segment.It is indeed heavy to build the lexer especially but also the grammar. I would like to thank &lt;a title="sehe on github" href="https://github.com/sehe"&gt;sehe&lt;/a&gt; for this optimization, he found it after I posted a question on Stackoverflow.&lt;/p&gt;
&lt;p&gt;The lexer was very easy to make static (only add static keyword :) ), but the parser was a bit more complicated because it needs the lexer iterator to get the current position in the file. This problem has been resolved by saving the iterator into the qi::locals of the rules.&lt;/p&gt;
&lt;p&gt;The result of this optimization are amazing. It saved 33% of the time.&lt;/p&gt;
&lt;h4&gt;Expectation points&lt;/h4&gt;

&lt;p&gt;Expectation points have the interesting point that they disallow backtracking and so can improve performances in some cases. Moreover, they are always interesting because they make the grammar clearer and the error messages much better.&lt;/p&gt;
&lt;p&gt;I tried adding more expectation points to the grammar. Unfortunately, there weren't a lot of them to add. Moreover, it seems that there are some quite weird behavior with them because some times it is impossible to add them (causes compilation failure) and sometimes it just make the code don't work anymore the same way, though I don't understand why.&lt;/p&gt;
&lt;p&gt;Anyway, I have been able to add some to the grammar. These changes improve the performance by a bit more than 1%. It is not a lot, but it is still an improvement. Moreover, I'm quite sure that there are more expectation points that can be added to the code. I will take some time again later to try to add more and to understand them better.&lt;/p&gt;
&lt;h4&gt;Less skips&lt;/h4&gt;

&lt;p&gt;In my grammar, I've a special parser for getting the current position in the file to add "debug information" to the AST. This special parser was skipping over its content, but it has no content, since it is artificial. Removing it improved the performance by about half a percent.&lt;/p&gt;
&lt;h4&gt;Improve Position (debug information)&lt;/h4&gt;

&lt;p&gt;As said before, there is a special parser to get the current position in the file. This information is then stored into an eddic::ast::Position structure. This structure was holding the line number, the column, the file name and the contents of the line. The first two were ints and the last two were std::string. Each time, a copy of the strings were necessary.&lt;/p&gt;
&lt;p&gt;I avoided storing the std::string directly by storing only the number of the line as well as the index of the file. Then, the content of the file is stored in the global context and can be accessed if it is necessary to display the line where the error happened.&lt;/p&gt;
&lt;p&gt;This change gave an increase of 10% of the parsing performance.&lt;/p&gt;
&lt;h4&gt;Auto Rules&lt;/h4&gt;

&lt;p&gt;Rules in Boost Spirit have an overhead due to the cost of the virtual calls that are necessary. In theory, auto rules can improve the efficiency of the rules by removing the cost of virtual calls. Moreover, auto rules should also avoid code bloat when the rules are compiled. The rules can be inlined and better optimized.&lt;/p&gt;
&lt;p&gt;I transformed some rules to auto rules to improve performances. Unfortunately, I found that this did not improve the performances. Moreover, transforming some rules to auto rules made the performance worse. I still did let some of the rules as auto rules. I have to say that I was very disappointed by this result, I was really expecting more from this :(&lt;/p&gt;
&lt;h4&gt;Generated Static Lexer&lt;/h4&gt;

&lt;p&gt;The first time the lexer is used, it has to generate the Deterministic Finite Automaton (DFA) that is used to identify the different tokens. This process takes time. There is way to avoid this by using the static model of Boost Spirit Lex. With that, the code is generated with the complete DFA and then it doesn't have to be initialized again.&lt;/p&gt;
&lt;p&gt;I was not expecting a lot from this because the lexer was already static and so was initialized only once. Indeed, it resulted in less than half a percent improvement.&lt;/p&gt;
&lt;h4&gt;Conclusion&lt;/h4&gt;

&lt;p&gt;Even if I've been able to largely reduce the overhead of the parsing by more than 40%, it still has a big overhead. Indeed, it still represents 36 percent of the whole process of compiling a source file. I think it is still too much.&lt;/p&gt;
&lt;p&gt;Moreover, an interesting fact is that the optimization I would have thought to be very effective (auto rules especially) did not have the expected effect, but making the grammar static, which I would not have thought of, was very effective.&lt;/p&gt;
&lt;p&gt;When profiled, the final version shows that quite some time is spent in destructing the multi_pass, which is quite odd. And it also seems that transforming the string operators to ast::Operator is not very effective, but I do not know how to improve that at this point.&lt;/p&gt;
&lt;p&gt;I won't probably work on that again for the version 1.2.4 of eddic, but I will eventually take some time again for the version 1.3.0 to improve it again.&lt;/p&gt;&lt;/div&gt;</description><category>Benchmarks</category><category>Boost</category><category>C++11</category><category>Compilers</category><category>EDDI</category><category>Performances</category><guid>http://baptiste-wicht.com/posts/2013/06/improving-eddic-boost-spirit-parser-performances.html</guid><pubDate>Mon, 10 Jun 2013 06:16:42 GMT</pubDate></item><item><title>eddic 1.2.2 - Performances, improved optimizations and additions to standard library</title><link>http://baptiste-wicht.com/posts/2013/01/eddic-1-2-2-performances-optimization-library.html</link><description>&lt;div&gt;&lt;p&gt;These last weeks, I had more work than expected with my Master thesis so it took me longer to finish this new version of eddic. Moreover, I included more stuff than I though in this version. Anyway, I'm happy to announce the version 1.2.2 of eddic.&lt;/p&gt;
&lt;p&gt;It is a minor version regarding the language itself. On the other, there are a lot of changes in the compiler itself.&lt;/p&gt;
&lt;p&gt;For the language:&lt;/p&gt;
&lt;ol&gt;
    &lt;li&gt;Structures are now correclty copy constructed when passed by value&lt;/li&gt;
    &lt;li&gt;When the same header is included several times accross the program, it is not parsed again&lt;/li&gt;
    &lt;li&gt;The vector structure has now functions to insert and remove elements in arbitrary positions&lt;/li&gt;
    &lt;li&gt;The functions to print bools, floats and integers are now written in EDDI directly. Only the functions to print chars and raw string are now written in assembly&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I worked on improving the performances by improving the constant propagation pass that runs less times now and by tuning a bit the data-flow framework, avoiding virtual calls.&lt;/p&gt;
&lt;p&gt;Another improvement is that all the mtac::Statement types have been merged in mtac::Quadruple, this removes one level of indirection and simplifies several passes. Moreover, there are now directly stored inside a vector and not allocated via shared_ptr. This removes another level of indirection.&lt;/p&gt;
&lt;p&gt;Put together, these two optimizations improved the performances of the compiler by about 15%. On the other hand, now that printF and printI are written in EDDI, it takes much longer to compile. I will work on that for the next version too. One way to improve the performances will be to tune the ordering of passes and also to tune the passes themselves so that they do more work at once. I will also try to merge constant propagation and offset constant propagation together. They perform very similar work.&lt;/p&gt;
&lt;p&gt;There are also several improvements in the optimization engine:&lt;/p&gt;
&lt;ul&gt;
    &lt;li&gt;The loop analysis has been fixed to handle loops bigger than one basic block. There was a problem in my implement of &lt;strong&gt;Lengauer and Tarjan&lt;/strong&gt; making that dominators were not computed.&lt;/li&gt;
    &lt;li&gt;The optimization engine now create a call graph of the program. This call graph is used to remove unused functions that are called but not reachable from the main function.&lt;/li&gt;
    &lt;li&gt;A new analysis pass has been added: pure_analysis. This pass test if a function is pure (no write to pointers or global variables) and thus avoid creating a basic block for it&lt;/li&gt;
    &lt;li&gt;The L&lt;strong&gt;oop Invariant Code Motion algorithm&lt;/strong&gt; has been improved to handle more invariants&lt;/li&gt;
    &lt;li&gt;The &lt;strong&gt;Common Subexpression Elimination&lt;/strong&gt; algorithm has been improved to handle more expression&lt;/li&gt;
    &lt;li&gt;The &lt;strong&gt;Induction Variables analysis&lt;/strong&gt; has been reviewed and several bugs have been corrected. It is now a bit complicated.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A big bug has been fixed in the handling of the MEMSET LTAC instruction. This will be completely reviewed in the next version (See Future Work).&lt;/p&gt;
&lt;p&gt;Some analysis starts to become quite complicated. I'm thinking of using SSA in MTAC in order to simplify some of the passes and to easily compute ud-chains. Another thing that I'm thinking is to add a powerful and complete alias analysis that would really improve the efficiency of some passes (offset constant propagation for instance) by making them less conservative.&lt;/p&gt;
&lt;p&gt;I also have removed some memory leaks (will try to remove all of them in the next version). I added a new optimization level: O3. This level enables loop unrolling and complete loop peeling.&lt;/p&gt;
&lt;h4&gt;Future Work&lt;/h4&gt;

&lt;p&gt;The next version of the EDDI compiler (eddic) will be the version 1.2.3. The inliner will be improved to work directly in the call graph in postorder. That should produce better code. I will also try to improve the inlining heuristics. A first basic version of loop unswitching will be added as well. I will add a small local constant propagation pass for globals. I will also continue to work on the performances of the passes to avoid repeating them too much. MEMSET will be completely reviewed. That should produce smaller and faster code. Until now, the sizes of the types bool and chars were the same as int. They will be optimized to take only 1 byte.&lt;/p&gt;
&lt;p&gt;I will also continue the improvements of the data structures by merging all ltac::Statement into ltac::Instruction and storing them directly.&lt;/p&gt;
&lt;p&gt;And there will probably be some bug fixing as well.&lt;/p&gt;
&lt;h4&gt;Download&lt;/h4&gt;

&lt;p&gt;You can find the EDDI Compiler sources on the Github repository: &lt;a title="Github repository of eddic" href="https://github.com/wichtounet/eddic"&gt;https://github.com/wichtounet/eddic&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The version is available in the &lt;em&gt;v1.2.2&lt;/em&gt; tag available in the GitHub or directly in the &lt;em&gt;master&lt;/em&gt; branch.&lt;/p&gt;&lt;/div&gt;</description><category>C++11</category><category>EDDI</category><category>Releases</category><guid>http://baptiste-wicht.com/posts/2013/01/eddic-1-2-2-performances-optimization-library.html</guid><pubDate>Sat, 26 Jan 2013 15:35:42 GMT</pubDate></item><item><title>C++ Benchmark - std::list VS boost::intrusive::list</title><link>http://baptiste-wicht.com/posts/2012/12/cpp-benchmark-std-list-boost-intrusive-list.html</link><description>&lt;p&gt;Recently, we saw that the &lt;a title="C++ benchmark – std::vector VS std::list VS std::deque" href="http://www.baptiste-wicht.com/2012/12/cpp-benchmark-vector-list-deque/"&gt;std::list performance was not really good&lt;/a&gt; when it comes to searching it or iterating through it.In this post, we will see an alternative to the std::list: the boost::intrusive::list from the Boost C++ libraries. It is not a well known library but it can be useful in some specific cases. I will focus on how this implementation performs compared to an std::list.&lt;/p&gt;
&lt;p&gt;An intrusive list does not store copies of the object but the objects itself. Because it stores the objects, it is necessary to add information to the object data structure directly to link them together, that is why it is called an intrusive list. This has a big advantage, the list does not have to allocate any memory at all to insert objects. In a std::list if you insert an object, a node object will be created containing a copy of the object, but not in an intrusive list where only the pointers to the next and to the previous element of the inserted object are updated. Another advantage is that if you have a reference to an object you can directly obtain an iterator to this object in O(1), an operation that would be in O(n) with a std::list. Iteration is faster because it needs less memory accesses.&lt;/p&gt;
&lt;p&gt;On the other hand, an intrusive list has also several drawbacks. First of all, it is intrusive. It means that you have to change the definition of the type that is stored inside the intrusive list. Then, and it be very complicated, it is up to the developer to manage the life time of the objects. It means that it is up to you to allocate and deallocate memory for each objects that you want to put in your collection. For instance, if you store an object into an intrusive list and later delete this object without removing it from the list, you will have broken you list. It is also less safe because the container can be modified from outside simply by modifying the pointers directly inside the objects.&lt;/p&gt;
&lt;p&gt;This article is not a tutorial for Boost intrusive collections, I will just focus on the performance aspect, if you want to learn how to use them, you can consult &lt;a href="http://www.boost.org/doc/libs/1_52_0/doc/html/intrusive.html" title="Boost Intrusive 1.52"&gt;the official documentation&lt;/a&gt;. &lt;/p&gt;
&lt;p&gt;A boost::intrusive::list can be configured in three mode:&lt;/p&gt;
&lt;ol&gt;
    &lt;li&gt;Normal mode: No special features&lt;/li&gt;
    &lt;li&gt;Safe mode: The hook is initialized to a default safe state and the container check this state before inserting a value. The state of a removed node is also updated correctly. It can be used to detect programming errors. It implies a small performance overhead. This is the default mode.&lt;/li&gt;
    &lt;li&gt;Auto unlink mode: When an object gets destructed it is automatically removed from the container. This mode has also the properties of the safe mode.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The mode is chosen at constant time by configuring the hook of the data type. In this article, all three mode will be tested. Here are the four types that will be tested:&lt;/p&gt;
&lt;ul&gt;
    &lt;li&gt;list : std::list&lt;/li&gt;
    &lt;li&gt;normal_ilist : boost::intrusive::list in normal mode&lt;/li&gt;
    &lt;li&gt;safe_ilist : boost::intrusive::list in safe mode&lt;/li&gt;
    &lt;li&gt;auto_unlink_ilist : boost::intrusive::list in auto unlink mode&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The data types are varying in size, they hold an array of longs and the size of the array varies to change the size of the data type. In each graph, the size of the data type is indicated. It is the size of the normal data type. The intrusive data types are always 16 bytes bigger than the normal data types. &lt;/p&gt;
&lt;p&gt;In the graphs and in the text, &lt;em&gt;n&lt;/em&gt; is used to refer to the number of elements of the collection.&lt;/p&gt;
&lt;p&gt;All the tests performed have been performed on an Intel Core i7 Q 820  @ 1.73GHz. The code has been compiled in 64 bits with GCC 4.7.2 with the given options: &lt;em&gt;-std=c++11 -O2 -fomit-frame-pointer -march=native&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;For each graph, the vertical axis represent the amount of time necessary to perform the operations, so the lower values are the better. The horizontal axis is always the number of elements of the collection. For some graph, the logarithmic scale could be clearer, a button is available after each graph to change the vertical scale to a logarithmic scale.&lt;/p&gt;
&lt;p&gt;So let's see these data structures in practice.&lt;/p&gt;
&lt;!--nextpage--&gt;

&lt;h3&gt;Fill list&lt;/h3&gt;

&lt;p&gt;The first test that is performed is how long does it take to fill each data structure. For the std::list, each value is entered directly. For the intrusive list variations, the data are entered into a vector and then pushed back to the intrusive list. &lt;/p&gt;
&lt;p&gt;So, let's test them: &lt;/p&gt;
&lt;div id="graph_0" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_0" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_0(){var graph=new google.visualization.LineChart(document.getElementById('graph_0'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['100000',265,261,491,2926],['200000',534,498,773,4717],['300000',1874,1841,1901,7201],['400000',2670,2657,2749,9696],['500000',3410,3447,3486,11608],['600000',4044,4095,4050,14024],['700000',4653,4549,4626,16750],['800000',5406,5320,5414,18568],['900000',5995,5926,6160,20880],['1000000',6806,6785,6784,22795],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"fill_back - Normal&amp;lt;8u&amp;gt;",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"us",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_0');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;We can see that filling a list is about thrice slower than an intrusive version. This is quite logical because there are much less memory allocations in the case of the intrusive lists. The differences between the different intrusive versions are not very big. The normal version is the fastest, then the auto unlink and finally the safe version is the slowest. &lt;/p&gt;
&lt;p&gt;If we increase the size of the data type a bit: &lt;/p&gt;
&lt;div id="graph_1" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_1" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_1(){var graph=new google.visualization.LineChart(document.getElementById('graph_1'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['100000',850,894,967,2685],['200000',1760,1671,1747,5742],['300000',3987,3916,3970,8517],['400000',5257,5191,5238,10919],['500000',6561,6813,6661,13614],['600000',7943,8197,7954,15874],['700000',9251,9523,9049,18625],['800000',10463,10865,10417,21114],['900000',11736,11992,11734,23824],['1000000',13137,13423,13055,26555],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"fill_back - Normal&amp;lt;32u&amp;gt;",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"us",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_1');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;The results remains more or less the same, but this time there is less difference between list and intrusive list. &lt;/p&gt;
&lt;div id="graph_2" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_2" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_2(){var graph=new google.visualization.LineChart(document.getElementById('graph_2'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['100000',2131,2109,2923,39337],['200000',3834,3830,5792,90984],['300000',6454,6508,8604,138087],['400000',8499,8926,11614,185607],['500000',11068,10874,14455,230798],['600000',13009,13052,17307,275473],['700000',14965,15008,20593,326638],['800000',17082,17186,23109,372022],['900000',19283,19476,26182,415426],['1000000',21503,21569,29463,463462],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"fill_back - Normal&amp;lt;1024u&amp;gt;",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"us",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_2');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;This time, the results are really different. The intrusive versions are twenty times faster than a standard list. This comes from dynamic allocations of large blocks that is very expensive. In the case of intrusive list, there are no memory allocations, just modifications of pointers, so it it is normal that for big blocks the difference is higher. &lt;/p&gt;
&lt;p&gt;We can see that for push_back operations, the intrusive are clearly faster. For small data types, they can be up to three times faster. The difference can be much higher with very big data types. There are no big differences between the different versions of the intrusive lists. The normal mode is about 10% faster than the safe mode. &lt;/p&gt;
&lt;!--nextpage--&gt;

&lt;h3&gt;Destruction of list&lt;/h3&gt;

&lt;p&gt;The second test is about the time necessary to destruct a collection. For a list, the list is simply allocated on the heap and destructed with delete operator. For an intrusive list, both the vector and the list are allocated on the heap. The time is computed to delete both the vector and the intrusive list. &lt;/p&gt;
&lt;p&gt;Let's take a look at the results: &lt;/p&gt;
&lt;div id="graph_3" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_3" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_3(){var graph=new google.visualization.LineChart(document.getElementById('graph_3'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['100000',298,283,0,2420],['200000',588,585,0,3132],['300000',1196,1217,1,4487],['400000',2180,2350,1,6478],['500000',3169,3098,1,7259],['600000',3975,3957,1,8609],['700000',4569,4798,1,10018],['800000',5189,5311,1,11501],['900000',5927,6022,1,13004],['1000000',6616,6592,1,14423],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"destruction - Normal&amp;lt;8u&amp;gt;",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"us",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_3');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;The impressive result is that the normal mode is almost free. It is normal because the destructor of the objects does not do anything. Neither the list does anything about the state of the object after it has been removed. The other two intrusive versions performs the same and twice faster than a list. &lt;/p&gt;
&lt;p&gt;Let's increase a bit the size: &lt;/p&gt;
&lt;div id="graph_4" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_4" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_4(){var graph=new google.visualization.LineChart(document.getElementById('graph_4'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['100000',515,531,0,1490],['200000',1997,1964,0,3370],['300000',4022,3818,1,5585],['400000',5219,5456,1,7099],['500000',6693,6847,1,9054],['600000',7859,7984,1,11131],['700000',9456,9382,1,12248],['800000',10637,10493,1,14059],['900000',12433,11882,1,15933],['1000000',13646,13098,1,17434],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"destruction - Normal&amp;lt;32u&amp;gt;",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"us",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_4');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;This time, the std::list version is getting closer to the auto unlink and safe versions. The auto unlink version is a bit slower than the safe version. The normal mode is still free. &lt;/p&gt;
&lt;p&gt;Increasing it a bit again: &lt;/p&gt;
&lt;div id="graph_5" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_5" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_5(){var graph=new google.visualization.LineChart(document.getElementById('graph_5'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['100000',4110,4158,1,4388],['200000',8357,8231,1,8949],['300000',12461,11871,1,12417],['400000',16097,16064,1,16249],['500000',19754,19990,1,19181],['600000',23724,24022,1,22019],['700000',28973,28421,2,24928],['800000',32638,32793,1,31896],['900000',37257,36320,1,35455],['1000000',40422,41037,1,39357],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"destruction - Normal&amp;lt;128u&amp;gt;",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"us",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_5');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;We can see that the list is a small bit faster than the other two versions. &lt;/p&gt;
&lt;p&gt;If we push the memory to its limit: &lt;/p&gt;
&lt;div id="graph_6" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_6" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_6(){var graph=new google.visualization.LineChart(document.getElementById('graph_6'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['100000',2582,2689,1,5669],['200000',10506,10450,1,19719],['300000',16490,16429,1,33569],['400000',21521,21702,1,47179],['500000',27188,27217,1,59640],['600000',32507,32470,1,70116],['700000',37288,37344,1,81122],['800000',42825,42611,1,91972],['900000',48004,48315,1,104401],['1000000',53439,53988,1,114482],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"destruction - Normal&amp;lt;1024u&amp;gt;",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"us",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_6');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;This time, the list is again slower. I'm not sure of why this happens, but it is certainly because of the memory allocator that has two allocate too many big blocks, which tends to be more costly than many small. &lt;/p&gt;
&lt;p&gt;For the destruction, the normal mode proved its high strength, being totally free to destroy. The safe and auto unlink modes are proving much more expensive during destruction, but still quite a bit faster than a standard list. &lt;/p&gt;
&lt;p&gt;It is also necessary to keep in mind that the destruction is generally not a common operation and is about 4 times faster than insertion. In practice, neither push_back nor destruction are critical in choosing a data structure. &lt;/p&gt;
&lt;!--nextpage--&gt;

&lt;h3&gt;Linear Search in a list&lt;/h3&gt;

&lt;p&gt;The next operation that will benchmark is the linear search. The container is filled with all the numbers in [0, n] and shuffled. Then, each number in [0, n] is searched in the container with std::find that performs a simple linear search.&lt;/p&gt;
&lt;p&gt;How do the different data structures perform: &lt;/p&gt;
&lt;div id="graph_7" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_7" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_7(){var graph=new google.visualization.LineChart(document.getElementById('graph_7'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['1000',1213,1211,1200,1463],['2000',5715,5561,5931,6992],['3000',12451,11619,11608,14251],['4000',19338,20142,19208,24840],['5000',30147,30889,29863,40523],['6000',42941,44530,43289,59541],['7000',59717,62534,58851,80416],['8000',77519,78889,77188,104198],['9000',99738,99434,100375,135452],['10000',123829,123216,123506,169720],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"linear_search - Normal&amp;lt;8u&amp;gt;",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"us",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_7');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;As expected, the intrusive list versions are faster than the standard list. The margin is about 40%. The intrusive versions have a better locality than the standard list because there is one less indirection. &lt;/p&gt;
&lt;p&gt;Increasing the data type size: &lt;/p&gt;
&lt;div id="graph_8" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_8" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_8(){var graph=new google.visualization.LineChart(document.getElementById('graph_8'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['1000',2901,2862,2940,2757],['2000',14258,14242,14413,18990],['3000',37327,37078,37387,48716],['4000',69310,68935,69152,86224],['5000',109444,110199,108283,134128],['6000',158570,158392,158398,202273],['7000',219949,220489,219070,266387],['8000',285885,289721,283485,342109],['9000',363603,361367,362935,424984],['10000',445068,451009,447940,525289],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"linear_search - Normal&amp;lt;128u&amp;gt;",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"us",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_8');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;The margin has decreased a bit to about 15%. As the data object does not fit in cache we have higher cache misses rate. &lt;/p&gt;
&lt;p&gt;If we increase it to the maximum: &lt;/p&gt;
&lt;div id="graph_9" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_9" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_9(){var graph=new google.visualization.LineChart(document.getElementById('graph_9'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['1000',3517,3818,3487,3570],['2000',19342,18999,18875,22972],['3000',59722,59728,60953,60749],['4000',116755,118256,117172,123127],['5000',194630,195522,192977,204278],['6000',287911,287099,291353,296178],['7000',395506,404527,396043,413398],['8000',519636,527051,527183,549713],['9000',662320,669371,672484,693154],['10000',831052,828032,832995,859092],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"linear_search - Normal&amp;lt;1024u&amp;gt;",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"us",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_9');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;Again, the margin decreased, to 3%. &lt;/p&gt;
&lt;p&gt;For linear searching, the intrusive versions are clearly faster, however, not by a high advantage and this advantage tends to get lower with bigger data types. I would really have expected a more interesting result here. We will see with the next results if it gets better. &lt;/p&gt;
&lt;!--nextpage--&gt;

&lt;h3&gt;Iteration over a list&lt;/h3&gt;

&lt;p&gt;This time, we will test the iteration over a whole collection. The iterate is done with the C++11 foreach loop (taking a reference) and the data is used to increment a counter (to make sure the loop is not optimized away. &lt;/p&gt;
&lt;p&gt;Let's start with our small data type: &lt;/p&gt;
&lt;div id="graph_10" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_10" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_10(){var graph=new google.visualization.LineChart(document.getElementById('graph_10'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['100000',204,202,209,276],['200000',430,404,439,715],['300000',967,956,1086,1969],['400000',1837,1826,1870,2672],['500000',2705,2668,2699,3130],['600000',3176,3110,3217,3815],['700000',3856,3678,3575,4363],['800000',4209,4090,4095,4860],['900000',4778,4334,4433,5511],['1000000',4934,4908,4656,5541],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"iterate - Normal&amp;lt;8u&amp;gt;",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"us",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_10');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;The standard list is indeed slower than the other versions (by about 20%). Which is expected due to their better data locality. However, the results are not very stable (probably too fast, many things can intervene). I was expecting better results. &lt;/p&gt;
&lt;p&gt;Let's go with a higher data type: &lt;/p&gt;
&lt;div id="graph_11" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_11" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_11(){var graph=new google.visualization.LineChart(document.getElementById('graph_11'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['100000',3694,3635,3467,3830],['200000',6779,6766,6430,7070],['300000',9472,9819,9291,10270],['400000',12354,12322,12165,13588],['500000',15188,15270,15079,16725],['600000',18447,18246,17797,19875],['700000',20925,20578,20596,23256],['800000',23539,23780,23421,26451],['900000',26492,26237,25975,29785],['1000000',29757,29482,28681,32752],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"iterate - Normal&amp;lt;128u&amp;gt;",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"us",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_11');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;This time, the results look better, but there are less difference between the standard list and the intrusive versions. The intrusive versions are faster by about 10%. &lt;/p&gt;
&lt;p&gt;If we take a bigger data type: &lt;/p&gt;
&lt;div id="graph_12" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_12" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_12(){var graph=new google.visualization.LineChart(document.getElementById('graph_12'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['100000',2797,2649,2496,5211],['200000',10148,10227,10199,10701],['300000',15379,15544,15458,15189],['400000',20181,20599,20213,20135],['500000',25481,25517,25381,25567],['600000',30407,30408,30326,29938],['700000',35187,35343,35498,34985],['800000',40094,39874,40172,40027],['900000',44875,45329,45314,44964],['1000000',49584,50143,50405,49737],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"iterate - Normal&amp;lt;1024u&amp;gt;",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"us",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_12');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;This time, there is no more difference between the different versions. &lt;/p&gt;
&lt;p&gt;Just like the results for linear search, the intrusive versions are faster but the difference is not huge. For very small data type, there is a gain of about 15 to 20 percent, but on very big data types, there is no more increase in performance. Again, I would have expected better results for the intrusive versions. &lt;/p&gt;
&lt;!--nextpage--&gt;

&lt;h3&gt;Write to elements of the list&lt;/h3&gt;

&lt;p&gt;This test is almost the same as the previous one, but this time each element of the collection is modified by incrementing one of its field. &lt;/p&gt;
&lt;p&gt;Let's see if the results are different this time. &lt;/p&gt;
&lt;div id="graph_13" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_13" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_13(){var graph=new google.visualization.LineChart(document.getElementById('graph_13'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['100000',267,290,263,343],['200000',579,583,548,889],['300000',1111,1142,1114,2151],['400000',2155,2143,2146,3197],['500000',3193,3186,3163,4168],['600000',4016,3991,3978,5179],['700000',4727,4916,4717,6026],['800000',5560,5534,5440,6977],['900000',6125,6157,6064,7693],['1000000',6830,6920,6785,8613],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"write - Normal&amp;lt;8u&amp;gt;",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"us",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_13');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;The results are more stable than before. We can see that the normal mode is leading the results by a bit less than 30%. Just like for iteration, there no real difference between the different modes. &lt;/p&gt;
&lt;p&gt;Let's increase the data size by a bit: &lt;/p&gt;
&lt;div id="graph_14" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_14" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_14(){var graph=new google.visualization.LineChart(document.getElementById('graph_14'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['100000',505,513,530,1069],['200000',1957,1991,2023,3222],['300000',4056,4053,4000,4806],['400000',5572,5493,5587,6408],['500000',6763,6798,6714,8578],['600000',8224,8142,8050,10037],['700000',9520,9622,9568,12272],['800000',10982,11451,10947,13818],['900000',12195,12305,12185,15103],['1000000',14043,13657,13775,17187],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"write - Normal&amp;lt;32u&amp;gt;",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"us",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_14');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;The results are the same, still 30% better for the intrusive version. &lt;/p&gt;
&lt;p&gt;Bigger data type again: &lt;/p&gt;
&lt;div id="graph_15" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_15" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_15(){var graph=new google.visualization.LineChart(document.getElementById('graph_15'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['100000',3263,3415,3172,4444],['200000',9467,9434,9513,8855],['300000',13996,13888,14227,13379],['400000',18181,18458,18255,17684],['500000',22751,23292,22956,22067],['600000',27371,27511,27329,25995],['700000',31236,31389,31404,31164],['800000',35749,35970,36132,35224],['900000',39972,40684,40549,39786],['1000000',45119,45124,44840,43937],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"write - Normal&amp;lt;1024u&amp;gt;",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"us",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_15');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;This time, the intrusive version is not faster anymore than the standard list. &lt;/p&gt;
&lt;p&gt;We have seen that when write is made to the data, intrusive list are better than list. The margin is higher than when doing only iteration. &lt;/p&gt;
&lt;!--nextpage--&gt;

&lt;h3&gt;Reverse the list&lt;/h3&gt;

&lt;p&gt;Let's test something more useful with a reverse operation. The reverse member function is used to reverse all the containers. &lt;/p&gt;
&lt;p&gt;Let's see how they perform: &lt;/p&gt;
&lt;div id="graph_16" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_16" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_16(){var graph=new google.visualization.LineChart(document.getElementById('graph_16'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['100000',366,410,390,372],['200000',761,892,758,867],['300000',1278,1354,1308,2062],['400000',2313,2348,2324,3083],['500000',3265,3297,3300,3994],['600000',4036,4171,4063,4890],['700000',4603,4575,4689,6052],['800000',5344,5241,5321,6682],['900000',6107,5912,6251,7623],['1000000',6725,6626,6663,8548],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"reverse - Normal&amp;lt;8u&amp;gt;",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"us",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_16');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;The intrusive versions are about 25% faster than standard list. Even if reversal does not need to access the values, the pointers of the intrusive lists have a better locality than the one of a list that can be dispersed through memory. &lt;/p&gt;
&lt;div id="graph_17" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_17" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_17(){var graph=new google.visualization.LineChart(document.getElementById('graph_17'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['100000',585,563,601,1057],['200000',1903,1902,2011,3043],['300000',4121,4041,4049,4671],['400000',5291,5352,5275,6504],['500000',6831,6711,6584,8273],['600000',7980,8113,8105,9900],['700000',9366,9216,9426,11612],['800000',10680,10622,10602,13377],['900000',11917,11908,11915,15140],['1000000',13442,13239,13268,16718],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"reverse - Normal&amp;lt;32u&amp;gt;",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"us",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_17');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;The performance improved a bit, to 30% improvement for an intrusive list. &lt;/p&gt;
&lt;p&gt;Let's see if this continue: &lt;/p&gt;
&lt;div id="graph_18" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_18" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_18(){var graph=new google.visualization.LineChart(document.getElementById('graph_18'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['100000',2901,2901,2676,4562],['200000',5889,5942,5613,9059],['300000',8696,8618,8372,13501],['400000',11344,11597,11039,17985],['500000',14431,14123,13954,22546],['600000',17084,16955,16605,27246],['700000',19563,19795,19431,31866],['800000',22806,22428,22092,36645],['900000',25553,25283,25003,41025],['1000000',28049,28174,27590,45780],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"reverse - Normal&amp;lt;128u&amp;gt;",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"us",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_18');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;It did, the intrusive list is more than 40% faster than the standard list !&lt;/p&gt;
&lt;p&gt;What happens a bigger one: &lt;/p&gt;
&lt;div id="graph_19" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_19" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_19(){var graph=new google.visualization.LineChart(document.getElementById('graph_19'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['100000',4723,4823,4585,4373],['200000',11566,11566,11842,8704],['300000',17471,17377,17587,12985],['400000',22778,22867,22866,17452],['500000',28548,28434,28837,21357],['600000',34005,34089,33913,25907],['700000',39189,39235,39284,30398],['800000',45186,44900,44838,34632],['900000',50337,50529,50677,38540],['1000000',56045,56026,56007,42867],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"reverse - Normal&amp;lt;1024u&amp;gt;",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"us",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_19');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;The lines have been interchanged! This time the standard list is about 25% faster than the intrusive versions. This time, the better locality of the intrusive versions is not a gain but a loss. &lt;/p&gt;
&lt;p&gt;It is logical that the margin decrease with very big objects during reversal. Indeed, each element is very close one to another, but the pairs of pointers are separated by the size of the data type. The bigger the data type, the higher distance between the pointers and so the worse spatial locality for the pointers. However, I do not explain why there is this big difference... &lt;/p&gt;
&lt;p&gt;The performance of intrusive list are clearly interesting for reversing collection of small data types. However, it seems that for high data types, the standard list is faster.&lt;/p&gt;
&lt;!--nextpage--&gt;

&lt;h3&gt;Sort the list&lt;/h3&gt;

&lt;p&gt;Let's continue with an even more interesting operation, sorting the list. All the versions are sorted with the sort member function.&lt;/p&gt;
&lt;div id="graph_20" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_20" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_20(){var graph=new google.visualization.LineChart(document.getElementById('graph_20'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['100000',16314,16503,16364,24992],['200000',38251,37599,38206,62834],['300000',63573,63521,63878,112848],['400000',90236,88561,88996,168037],['500000',114442,114456,116137,236389],['600000',167279,165879,166617,324302],['700000',190762,190586,190292,377142],['800000',223884,223900,224622,477313],['900000',255248,252795,253070,540602],['1000000',287262,286842,288404,614163],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"sort - Normal&amp;lt;8u&amp;gt;",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"ms",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_20');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;The intrusive versions are really interesting, being twice faster than a standard list. &lt;/p&gt;
&lt;p&gt;Let's see with a see a higher data type: &lt;/p&gt;
&lt;div id="graph_21" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_21" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_21(){var graph=new google.visualization.LineChart(document.getElementById('graph_21'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['100000',25335,25030,25318,31655],['200000',67224,65937,67185,80637],['300000',118284,116947,119686,139629],['400000',169014,165868,169723,194916],['500000',208261,208245,209291,248475],['600000',294572,287231,294284,339917],['700000',337154,332205,338323,389665],['800000',401654,393743,401249,461721],['900000',440058,434855,440984,506999],['1000000',494861,491360,497710,578176],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"sort - Normal&amp;lt;128u&amp;gt;",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"ms",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_21');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;The difference is decreasing to about 20%. &lt;/p&gt;
&lt;p&gt;Increasing it again:&lt;/p&gt;
&lt;div id="graph_22" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_22" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_22(){var graph=new google.visualization.LineChart(document.getElementById('graph_22'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_list','safe_list','normal_ilist','list'],['100000',31568,33319,32201,40331],['200000',82407,85932,83987,97310],['300000',143651,150155,144553,163818],['400000',202050,209178,203821,232728],['500000',250514,256374,253415,289493],['600000',345760,351034,348564,391229],['700000',397848,402385,402371,454434],['800000',471832,479947,477681,538873],['900000',518542,527961,524002,596696],['1000000',583622,596696,591025,672353],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"sort - Normal&amp;lt;1024u&amp;gt;",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"ms",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_22');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;It decreased again to 18%. &lt;/p&gt;
&lt;p&gt;For sort operations, the intrusive versions are clearly interesting, especially for small data types. &lt;/p&gt;
&lt;!--nextpage--&gt;

&lt;h3&gt;Random insert into the list&lt;/h3&gt;

&lt;p&gt;The last operation that we will test is the random insert. I have to say that this test is not fair. Indeed, in an intrusive list, from an object we can directly get an iterator and insert at a random position. For a standard list, we have to find the iterator by linear search. I think that it is still important because it is one of the advantages of an intrusive container.&lt;/p&gt;
&lt;div id="graph_23" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_23" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_23(){var graph=new google.visualization.LineChart(document.getElementById('graph_23'));var data=google.visualization.arrayToDataTable([['x','auto_unlink_ilist','safe_ilist','normal_ilist','list'],['10000',42,46,41,27729],['20000',49,66,45,48736],['30000',64,66,47,62440],['40000',54,53,48,75253],['50000',59,54,49,88493],['60000',67,49,63,104516],['70000',50,53,50,115514],['80000',55,50,50,128950],['90000',51,51,55,144367],['100000',52,52,76,152721],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"random_insert - Normal&amp;lt;8u&amp;gt;",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"us",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_23');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;It is very clear that the performance are much better but it is logical because we are comparing something in O(1) versus something in O(n). &lt;/p&gt;
&lt;h3&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;In conclusion, intrusive lists are almost always faster than a standard list. However, on my computer and with GCC, the difference is not always very important. It can brings about 20%-30% on some workloads but most likely around 15%. Even if not negligible, it is not a huge improvement. I would have thought that intrusive lists were faster by an higher margin. On some operations like sort, it is clearly more interesting. It has a better data locality than standard list. &lt;/p&gt;
&lt;p&gt;It is also more interesting to fill the collection, because no memory allocation is involved. But of course, you need to take care of memory allocation by yourself, for example in a vector like here or by dynamically allocating the objects one after one. This has also a cost that is not counted in the benchmark. &lt;/p&gt;
&lt;p&gt;If you really have to use a linked list and performance is critical, I advice you to use Boost intrusive list. If performance is not really critical, it is not perhaps not interesting because of the increased complexity. &lt;/p&gt;
&lt;p&gt;There are situations when only intrusive lists can work. If you want the same object to be present in two different list, you can use boost intrusive list with several member hooks, which is not possible with standard list because only a copy is stored, not the object itself. The same is true for objects that are non-copyable, only intrusive list can handle them. And finally, with intrusive lists you can directly get an iterator to an object in O(1) if you have a reference to an object. For a standard list, you have to iterate through the list to find the object. Sometimes, it can be very useful. &lt;/p&gt;
&lt;p&gt;If you are interested, the Boost documentation provides also a &lt;a href="http://www.boost.org/doc/libs/1_52_0/doc/html/intrusive/performance.html" title="Boost Intrusive Performance"&gt;performance benchmark for intrusive list&lt;/a&gt;, but it is very old (GCC 4.1.2). It is interesting to see that the results are better for intrusive lists than on my benchmark. I do not know if it comes from the processor, the memory or from the compiler. &lt;/p&gt;
&lt;p&gt;I hope you found this benchmark interesting. If you have questions, comments, ideas or whatever to say about this benchmark, don't hesitate to comment. I would be glad to answer you :) The same if you find errors in this article. If you have different results, don't hesitate to comment as well. &lt;/p&gt;
&lt;p&gt;The code source of the benchmark is available online: https://github.com/wichtounet/articles/blob/master/src/intrusive_list/bench.cpp&lt;/p&gt;
&lt;script type="text/javascript"&gt;function draw_visualization(){draw_graph_0();draw_graph_1();draw_graph_2();draw_graph_3();draw_graph_4();draw_graph_5();draw_graph_6();draw_graph_7();draw_graph_8();draw_graph_9();draw_graph_10();draw_graph_11();draw_graph_12();draw_graph_13();draw_graph_14();draw_graph_15();draw_graph_16();draw_graph_17();draw_graph_18();draw_graph_19();draw_graph_20();draw_graph_21();draw_graph_22();draw_graph_23();} google.setOnLoadCallback(draw_visualization);&lt;/script&gt;</description><category>Benchmark</category><category>Boost</category><category>C++</category><category>C++11</category><category>Performances</category><guid>http://baptiste-wicht.com/posts/2012/12/cpp-benchmark-std-list-boost-intrusive-list.html</guid><pubDate>Wed, 12 Dec 2012 07:53:17 GMT</pubDate></item><item><title>C++ benchmark – std::vector VS std::list VS std::deque</title><link>http://baptiste-wicht.com/posts/2012/12/cpp-benchmark-vector-list-deque.html</link><description>&lt;p&gt;Last week, I wrote a benchmark comparing the performance of std::vector and std::list on different workloads. This previous article received a lot of comments and several suggestions to improve it. The present article is an improvement over the previous article. &lt;/p&gt;
&lt;p&gt;In this article, I will compare the performance of std::vector, std::list and std::deque on several different workloads and with different data types. In this article, when I talk about a list refers to std::list, a vector refers to std::vector and deque to std::deque.&lt;/p&gt;
&lt;p&gt;It is generally said that a list should be used when random insert and remove will be performed (performed in O(1) versus O(n) for a vector or a deque). If we look only at the complexity, the scale of linear search in both data structures should be equivalent, complexity being in O(n). When random insert/replace operations are performed on a vector or a deque, all the subsequent data needs to be moved and so each element will be copied. That is why the size of the data type is an important factor when comparing those two data structures. Because the size of the data type will play an important role on the cost of copying an element. &lt;/p&gt;
&lt;p&gt;However, in practice, there is a huge difference: the usage of the memory caches. All the data in a vector is contiguous where the std::list allocates separately memory for each element. How does that change the results in practice ? The deque is a data structure aiming at having the advantages of both data structures without their drawbacks, we will see how it perform in practice. Complexity analysis does not take the memory hierarchy into level. I believe that in practice, memory hierarchy usage is as important as complexity analysis. &lt;/p&gt;
&lt;p&gt;Keep in mind that all the tests performed are made on vector, list and deque even if other data structures could be better suited to the given workload. &lt;/p&gt;
&lt;p&gt;In the graphs and in the text, &lt;em&gt;n&lt;/em&gt; is used to refer to the number of elements of the collection. &lt;/p&gt;
&lt;p&gt;All the tests performed have been performed on an Intel Core i7 Q 820  @ 1.73GHz. The code has been compiled in 64 bits with GCC 4.7.2 with -02 and -march=native. The code has been compiled with C++11 support (-std=c++11). &lt;/p&gt;
&lt;p&gt;For each graph, the vertical axis represent the amount of time necessary to perform the operations, so the lower values are the better. The horizontal axis is always the number of elements of the collection. For some graph, the logarithmic scale could be clearer, a button is available after each graph to change the vertical scale to a logarithmic scale. &lt;/p&gt;
&lt;p&gt;The data types are varying in size, they hold an array of longs and the size of the array varies to change the size of the data type. The non-trivial data type is made of two longs and has very stupid assignment operator and copy constructor that just does some maths (totally meaningless but costly). One may argue that is not a common copy constructor neither a common assignment operator and one will be right, however, the important point here is that it is costly operators which is enough for this benchmark. &lt;/p&gt;
&lt;h3&gt;Fill&lt;/h3&gt;

&lt;p&gt;The first test that is performed is to fill the data structures by adding elements to the back of the container (using &lt;em&gt;push_back&lt;/em&gt;). Two variations of vector are used, &lt;em&gt;vector_pre&lt;/em&gt; being a std::vector using vector::reserve at the beginning, resulting in only one allocation of memory.&lt;/p&gt;
&lt;p&gt;Lets see the results with a very small data type: &lt;/p&gt;
&lt;div id="graph_0" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_0" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_0(){var graph=new google.visualization.LineChart(document.getElementById('graph_0'));var data=google.visualization.arrayToDataTable([['x','list','vector','deque','vector_pre'],['100000',2545,271,2012,317],['200000',4927,552,998,334],['300000',7310,944,1707,595],['400000',9463,936,2056,1099],['500000',12591,1140,2642,1058],['600000',14351,1894,3125,1237],['700000',16561,1995,3686,1208],['800000',18820,2648,4291,1365],['900000',20832,2777,4962,2268],['1000000',23430,3015,5396,2585],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"fill_back - 8 bytes",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"us",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_0');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;The pre-allocated vector is the fastest by a small margin and the list is 3 times slower than a vector. deque and vector. &lt;/p&gt;
&lt;p&gt;If we consider higher data type: &lt;/p&gt;
&lt;div id="graph_1" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_1" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_1(){var graph=new google.visualization.LineChart(document.getElementById('graph_1'));var data=google.visualization.arrayToDataTable([['x','list','vector','deque','vector_pre'],['100000',104867,55545,66852,21738],['200000',226215,108289,136035,42532],['300000',340910,198343,153446,60317],['400000',445035,217325,269316,80616],['500000',559619,236576,189613,101371],['600000',688422,391354,303729,122447],['700000',799902,405771,426373,138868],['800000',921441,415707,537057,160637],['900000',1006331,439635,263650,177052],['1000000',1113690,464416,372000,199434],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"fill_back - 4096 bytes",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"us",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_1');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;This time vector and list are performing at about the same speed. The deque is a bit faster than list and vector. The pre-allocated vector is clearly the winner here. The variations in the results of deque and vector are probably coming from my system that doesn't like allocating so much memory back and forth at this speed. &lt;/p&gt;
&lt;p&gt;Finally, if we use a non-trivial data type: &lt;/p&gt;
&lt;div id="graph_2" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_2" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_2(){var graph=new google.visualization.LineChart(document.getElementById('graph_2'));var data=google.visualization.arrayToDataTable([['x','list','vector','deque','vector_pre'],['100000',8093,8123,10251,8095],['200000',15433,15305,16061,13897],['300000',25964,24643,24450,19954],['400000',33414,30322,32148,27171],['500000',40416,37817,40752,35058],['600000',48991,48594,48785,41049],['700000',55059,55124,55092,47609],['800000',63688,61360,64505,55659],['900000',70550,67636,72329,60952],['1000000',79271,73533,79522,67787],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"fill_back - 16 bytes",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"us",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_2');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;All data structures are performing more or less the same, with vector_pre being the fastest. &lt;/p&gt;
&lt;p&gt;For push_back operations, pre-allocated vectors is a very good choice if the size is known in advance. The others performs more of less the same.&lt;/p&gt;
&lt;p&gt;I would have expected a better result for pre-allocated vector. If someone find an explanation for such a small margin, I'm interested. &lt;/p&gt;
&lt;h3&gt;Linear Search&lt;/h3&gt;

&lt;p&gt;The first operation is that is tested is the search. The container is filled with all the numbers in [0, N] and shuffled. Then, each number in [0,N] is searched in the container with std::find that performs a simple linear search. In theory, all the data structures should perform the same if we consider their complexity. &lt;/p&gt;
&lt;div id="graph_3" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_3" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_3(){var graph=new google.visualization.LineChart(document.getElementById('graph_3'));var data=google.visualization.arrayToDataTable([['x','deque','list','vector'],['1000',593,1098,318],['2000',2927,5307,1271],['3000',5891,12228,3020],['4000',8663,24415,5081],['5000',12859,36316,8066],['6000',18493,55057,11463],['7000',25057,74344,16022],['8000',38980,99990,21051],['9000',44951,127575,26650],['10000',52281,158216,32557],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"linear_search - 8 bytes",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"us",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_3');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;It is clear from the graph that the list has very poor performance for searching. The growth is much worse for a list than for a vector or a deque.&lt;/p&gt;
&lt;p&gt;The only reason is the usage of the cache line. When a data is accessed, the data is fetched from the main memory to the cache. Not only the accessed data is accessed, but a whole cacheline is fetched. As the elements in a vector are contiguous, when you access an element, the next element is automatically in the cache. As the main memory is orders of magnitude slower than the cache, this makes a huge difference. In the list case, the processor spends its whole time waiting for data being fetched from memory to the cache, at each fetch, the processor fetches a lot of unnecessary data that are almost always useless. &lt;/p&gt;
&lt;p&gt;The deque is a bit slower than the vector, that is logical because here there are more cache misses due to the segmented parts. &lt;/p&gt;
&lt;p&gt;If we take a bigger data type: &lt;/p&gt;
&lt;div id="graph_4" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_4" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_4(){var graph=new google.visualization.LineChart(document.getElementById('graph_4'));var data=google.visualization.arrayToDataTable([['x','deque','list','vector'],['1000',1116,2683,776],['2000',4983,16675,3537],['3000',12255,44379,10874],['4000',23212,83026,20189],['5000',37392,133353,33609],['6000',55295,193428,47636],['7000',74877,261314,63911],['8000',100903,340157,84647],['9000',126299,435816,107922],['10000',156386,545160,135680],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"linear_search - 128 bytes",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"us",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_4');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;The list is still much slower than the others, but what is interesting is that gap between the deque and the array is decreasing. Let's try with a 4KB data type: &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;/p&gt;&lt;div id="graph_5" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;&lt;input id="button_graph_5" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_5(){var graph=new google.visualization.LineChart(document.getElementById('graph_5'));var data=google.visualization.arrayToDataTable([['x','deque','list','vector'],['1000',4258,7190,4445],['2000',20584,38411,19825],['3000',48236,113189,55341],['4000',87475,223174,118453],['5000',136945,362421,191967],['6000',197856,530943,281252],['7000',273359,726323,387940],['8000',351223,954463,511276],['9000',447525,1211581,652269],['10000',551556,1497916,807161],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"linear_search - 4096 bytes",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"us",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_5');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;
&lt;/blockquote&gt;
&lt;p&gt;The performance of the list are still poor but the gap is decreasing. The interesting point is that deque is now faster than vector. I'm not really sure of the reason of this result. It is possible that it comes only from this special size. One thing is sure, the bigger the data size, the more cache misses the processor will get because elements don't fit in cache lines. &lt;/p&gt;
&lt;p&gt;For search, list is clearly slow where deque and vector have about the same performance. It seems that deque is faster than a vector for very large data sizes. &lt;/p&gt;
&lt;h3&gt;Random Insert (+Linear Search)&lt;/h3&gt;

&lt;p&gt;In the case of random insert, in theory, the list should be much faster, its insert operation being in O(1) versus O(n) for a vector or a deque. &lt;/p&gt;
&lt;p&gt;The container is filled with all the numbers in [0, N] and shuffled. Then, 1000 random values are inserted at a random position in the container. The random position is found by linear search. In both cases, the complexity of the search is O(n), the only difference comes from the insert that follow the search. We saw before that the performance of the list were poor for searching, so we'll see if the fast insertion can compensate the slow search. &lt;/p&gt;
&lt;div id="graph_6" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_6" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_6(){var graph=new google.visualization.LineChart(document.getElementById('graph_6'));var data=google.visualization.arrayToDataTable([['x','deque','list','vector'],['10000',8,27,8],['20000',15,45,14],['30000',22,63,21],['40000',29,74,27],['50000',37,87,38],['60000',43,105,44],['70000',50,114,48],['80000',61,130,55],['90000',66,139,61],['100000',70,155,68],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"random_insert - 8 bytes",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"ms",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_6');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;List is clearly slower than the other two data structures that exhibit the same performance. This comes from the very slow linear search. Even if the two other data structures have to move a lot of data, the copy is cheap for small data types. &lt;/p&gt;
&lt;p&gt;Let's increase the size a bit: &lt;/p&gt;
&lt;div id="graph_7" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_7" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_7(){var graph=new google.visualization.LineChart(document.getElementById('graph_7'));var data=google.visualization.arrayToDataTable([['x','deque','list','vector'],['10000',21,53,25],['20000',39,80,48],['30000',57,103,68],['40000',71,122,90],['50000',88,146,112],['60000',102,165,130],['70000',124,190,152],['80000',140,214,175],['90000',157,238,195],['100000',174,268,213],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"random_insert - 32 bytes",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"ms",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_7');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;The result are interesting. The list is still the slowest but with a smaller margin. This time deque is faster than the vector by a small margin. &lt;/p&gt;
&lt;p&gt;Again, increasing the data size: &lt;/p&gt;
&lt;div id="graph_8" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_8" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_8(){var graph=new google.visualization.LineChart(document.getElementById('graph_8'));var data=google.visualization.arrayToDataTable([['x','deque','list','vector'],['10000',64,80,89],['20000',108,128,154],['30000',158,182,248],['40000',212,248,347],['50000',281,348,469],['60000',402,443,735],['70000',569,643,1034],['80000',767,775,1347],['90000',978,1002,1614],['100000',1190,1202,1962],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"random_insert - 128 bytes",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"ms",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_8');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;This time, the vector is clearly the looser and deque and list have the same performance. We can say that with a size of 128 bytes, the time to move a lot of the elements is more expensive than searching in the list. &lt;/p&gt;
&lt;p&gt;A huge data type gives us clearer results: &lt;/p&gt;
&lt;div id="graph_9" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_9" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_9(){var graph=new google.visualization.LineChart(document.getElementById('graph_9'));var data=google.visualization.arrayToDataTable([['x','deque','list','vector'],['10000',4430,178,8074],['20000',7918,311,14121],['30000',11043,444,20014],['40000',13806,555,26783],['50000',17421,694,33519],['60000',20663,904,39175],['70000',23599,1147,45111],['80000',26736,1470,50887],['90000',29524,1940,60139],['100000',32005,2534,65098],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"random_insert - 4096 bytes",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"ms",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_9');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;The list is more than 20 times faster than the vector and an order of magnitude faster than the deque ! The deque is also twice faster than the vector. &lt;/p&gt;
&lt;p&gt;The fact than the deque is faster than vector is quite simple. When an insertion is made in a deque, the elements can either moved to the end or the beginning. The closer point will be chosen. An insert in the middle is the most costly operation with O(n/2) complexity. It is always more efficient to insert elements in a deque than in vector because at least twice less elements will be moved. &lt;/p&gt;
&lt;p&gt;If we look at the non-trivial data type: &lt;/p&gt;
&lt;div id="graph_10" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_10" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_10(){var graph=new google.visualization.LineChart(document.getElementById('graph_10'));var data=google.visualization.arrayToDataTable([['x','deque','list','vector'],['10000',230,41,425],['20000',376,65,705],['30000',552,84,1054],['40000',692,101,1345],['50000',862,119,1661],['60000',1003,141,1984],['70000',1186,155,2277],['80000',1358,172,2681],['90000',1540,186,2965],['100000',1658,203,3236],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"random_insert - 16 bytes",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"ms",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_10');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;The results are about the same as for the previous graph, but the data type is only 16B. The cost of the copy constructors and assignment operators is very important for vector and deque. The list doesn't care because no copy neither assignment of the existing elements is made during insertions (only the inserted element is copied). &lt;/p&gt;
&lt;h3&gt;Random Remove&lt;/h3&gt;

&lt;p&gt;In theory, random remove is the same case than random insert. Now that we've seen the results with random insert, we could expect the same behavior for random remove. &lt;/p&gt;
&lt;p&gt;The container is filled with all the numbers in [0, N] and shuffled. Then, 1000 random values are removed from a random position in the container. &lt;/p&gt;
&lt;p&gt;If we take the same data sizes as the random insert case: &lt;/p&gt;
&lt;div id="graph_11" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_11" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_11(){var graph=new google.visualization.LineChart(document.getElementById('graph_11'));var data=google.visualization.arrayToDataTable([['x','deque','list','vector'],['10000',6,19,5],['20000',12,41,11],['30000',20,55,18],['40000',27,68,25],['50000',34,81,33],['60000',43,101,40],['70000',49,113,45],['80000',59,126,52],['90000',67,138,61],['100000',72,157,65],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"random_remove - 8 bytes",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"ms",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_11');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;div id="graph_12" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_12" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_12(){var graph=new google.visualization.LineChart(document.getElementById('graph_12'));var data=google.visualization.arrayToDataTable([['x','deque','list','vector'],['10000',40,40,63],['20000',85,83,134],['30000',127,132,198],['40000',181,189,282],['50000',245,263,473],['60000',363,376,664],['70000',524,502,960],['80000',743,688,1343],['90000',977,812,1639],['100000',1228,1017,2004],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"random_remove - 128 bytes",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"ms",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_12');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;div id="graph_13" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_13" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_13(){var graph=new google.visualization.LineChart(document.getElementById('graph_13'));var data=google.visualization.arrayToDataTable([['x','deque','list','vector'],['10000',2906,109,5649],['20000',6190,233,11760],['30000',9379,359,18218],['40000',12840,490,23634],['50000',16027,585,30046],['60000',18918,773,36100],['70000',22213,999,42453],['80000',25788,1317,48793],['90000',28975,1762,55043],['100000',30860,2128,59791],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"random_remove - 4096 bytes",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"ms",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_13');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;div id="graph_14" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_14" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_14(){var graph=new google.visualization.LineChart(document.getElementById('graph_14'));var data=google.visualization.arrayToDataTable([['x','deque','list','vector'],['10000',149,27,294],['20000',319,50,608],['30000',481,68,934],['40000',638,89,1236],['50000',794,108,1547],['60000',954,120,1894],['70000',1101,144,2185],['80000',1253,160,2513],['90000',1399,177,2812],['100000',1595,194,3108],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"random_remove - 16 bytes",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"ms",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_14');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;The behavior of random remove is the same as the behavior of random insert, for the same reasons. The results are not very interesting, so, let's get to the next workload. &lt;/p&gt;
&lt;h3&gt;Push Front&lt;/h3&gt;

&lt;p&gt;The next operation that we will compare is inserting elements in front of the collection. This is the worst case for vector, because after each insertion, all the previously inserted will be moved and copied. For a list or a deque, it does not make a difference compared to pushing to the back. &lt;/p&gt;
&lt;p&gt;So let's see the results: &lt;/p&gt;
&lt;div id="graph_15" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_15" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_15(){var graph=new google.visualization.LineChart(document.getElementById('graph_15'));var data=google.visualization.arrayToDataTable([['x','deque','list','vector'],['10000',0,0,33],['20000',0,0,135],['30000',0,0,313],['40000',0,0,585],['50000',0,1,913],['60000',0,1,1327],['70000',0,1,1823],['80000',0,1,2405],['90000',0,2,3107],['100000',0,2,4017],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"fill_front - 8 bytes",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"ms",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_15');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;The results are crystal-clear and as expected, vector is very bad at inserting elements to the front. The list and the deque results are almost invisible in the graph because it is a free operation for the two data structures. This does not need further explanations. There is no need to change the data size, it will only make vector much slower and my processor hotter. &lt;/p&gt;
&lt;h3&gt;Sort&lt;/h3&gt;

&lt;p&gt;The next operation that is tested is the time necessary to sort the data structures. For the vector and the deque std::sort is used and for a list the member function sort is used. &lt;/p&gt;
&lt;div id="graph_16" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_16" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_16(){var graph=new google.visualization.LineChart(document.getElementById('graph_16'));var data=google.visualization.arrayToDataTable([['x','deque','list','vector'],['100000',9,25,6],['200000',19,61,14],['300000',29,115,22],['400000',40,175,30],['500000',50,233,39],['600000',60,321,48],['700000',71,378,57],['800000',85,457,66],['900000',95,517,74],['1000000',108,593,83],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"sort - 8 bytes",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"ms",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_16');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;For a small data type, the list is several times slower than the other two data structures. This is again due to the very poor spatial locality of the list during the search. vector is slightly faster than a deque, but the difference is not very significant. &lt;/p&gt;
&lt;p&gt;If we increase the size: &lt;/p&gt;
&lt;div id="graph_17" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_17" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_17(){var graph=new google.visualization.LineChart(document.getElementById('graph_17'));var data=google.visualization.arrayToDataTable([['x','deque','list','vector'],['100000',25,32,20],['200000',65,80,48],['300000',103,143,80],['400000',136,197,113],['500000',180,246,149],['600000',223,340,181],['700000',274,396,222],['800000',302,469,266],['900000',358,514,303],['1000000',395,579,337],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"sort - 128 bytes",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"ms",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_17');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;The order remains the same but the difference between the list and the other is decreasing. &lt;/p&gt;
&lt;p&gt;With a 1KB data type: &lt;/p&gt;
&lt;div id="graph_18" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_18" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_18(){var graph=new google.visualization.LineChart(document.getElementById('graph_18'));var data=google.visualization.arrayToDataTable([['x','deque','list','vector'],['100000',176,39,168],['200000',389,94,376],['300000',620,168,595],['400000',859,228,823],['500000',1100,285,1059],['600000',1355,392,1301],['700000',1609,452,1555],['800000',1844,539,1797],['900000',2111,597,2054],['1000000',2397,670,2278],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"sort - 1024 bytes",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"ms",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_18');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;The list is almost five times faster than the vector and the deque which are both performing the same (with a very slight advantage for vector). &lt;/p&gt;
&lt;p&gt;If we use the non-trivial data type:&lt;/p&gt;
&lt;div id="graph_19" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_19" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_19(){var graph=new google.visualization.LineChart(document.getElementById('graph_19'));var data=google.visualization.arrayToDataTable([['x','deque','list','vector'],['100000',92,26,89],['200000',195,70,188],['300000',301,135,296],['400000',410,195,399],['500000',519,255,510],['600000',638,350,623],['700000',763,410,729],['800000',858,492,846],['900000',971,552,954],['1000000',1090,628,1072],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"sort - 16 bytes",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"ms",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_19');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;Again, the cost of the operators of this type have a strong impact on the vector and deque. &lt;/p&gt;
&lt;h3&gt;Destruction&lt;/h3&gt;

&lt;p&gt;The next test is to calculate the time necessary to the destruction of a container. The containers are dynamically allocated, are filled with n numbers and then their destruction time (via delete) is computed. &lt;/p&gt;
&lt;div id="graph_20" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_20" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_20(){var graph=new google.visualization.LineChart(document.getElementById('graph_20'));var data=google.visualization.arrayToDataTable([['x','deque','list','vector'],['100000',34,1489,0],['200000',70,2838,0],['300000',102,4677,0],['400000',142,6072,0],['500000',173,7737,0],['600000',215,8828,0],['700000',353,10599,1],['800000',321,12115,0],['900000',355,13932,1],['1000000',410,15345,0],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"destruction - 8 bytes",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"ms",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_20');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;The results are already interesting. The vector is almost free to destroy, which is logical because that incurs only freeing one array and the vector itself. The deque is slower due to the freeing of each segments. But the list is much more costly than the other two, more than an order of magnitude slower. This is expected because the list have to free the dynamic memory of each node and also has to iterate through all the elements which we saw was slow. &lt;/p&gt;
&lt;p&gt;If we increase the data type: &lt;/p&gt;
&lt;div id="graph_21" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_21" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_21(){var graph=new google.visualization.LineChart(document.getElementById('graph_21'));var data=google.visualization.arrayToDataTable([['x','deque','list','vector'],['100000',898,4403,1],['200000',2488,8499,1],['300000',4091,12499,1430],['400000',5461,16379,1909],['500000',6729,21128,2459],['600000',8164,25719,2729],['700000',9517,31046,3227],['800000',10871,34550,3756],['900000',12392,37176,4163],['1000000',13762,40119,4523],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"destruction - 128 bytes",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"ms",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_21');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;This time we can see that the deque is three times slower than a vector and that the list is still an order of magnitude slower than a vector ! However, the is less difference than before. &lt;/p&gt;
&lt;p&gt;With our biggest data type, now: &lt;/p&gt;
&lt;div id="graph_22" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_22" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_22(){var graph=new google.visualization.LineChart(document.getElementById('graph_22'));var data=google.visualization.arrayToDataTable([['x','deque','list','vector'],['100000',20575,22434,15499],['200000',44234,47254,29848],['300000',67196,69374,39818],['400000',89253,91128,54229],['500000',108689,112557,68090],['600000',131751,135764,75063],['700000',150801,155610,90761],['800000',172365,176957,102830],['900000',192575,193897,112728],['1000000',211507,215274,126348],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"destruction - 4096 bytes",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"ms",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_22');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;There is no more difference between list and deque. The vector is still twice faster than them. &lt;/p&gt;
&lt;p&gt;Even if the vector is always faster than the list and deque, keep in mind that the graphs for destruction are in microseconds and so the operations are not very costly. It could make a difference is very time-sensitive application but unlikely in most applications. Moreover, destruction is made only once per data structure, generally, it is not a very important operation. &lt;/p&gt;
&lt;h3&gt;Number Crunching&lt;/h3&gt;

&lt;p&gt;Finally, we can also test a number crunching operation. Here, random elements are inserted into the container that is kept sorted. It means, that the position where the element has to be inserted is first searched by iterating through elements and the inserted. As we talk about number crunching, only 8 bytes elements are tested. &lt;/p&gt;
&lt;div id="graph_23" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_23" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_23(){var graph=new google.visualization.LineChart(document.getElementById('graph_23'));var data=google.visualization.arrayToDataTable([['x','deque','list','vector'],['10000',39,187,33],['20000',150,1247,134],['30000',339,3380,310],['40000',623,6513,547],['50000',958,10757,864],['60000',1394,16098,1257],['70000',1894,22623,1713],['80000',2479,30656,2249],['90000',3162,39451,2858],['100000',3932,49906,3576],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"number_crunching",width:'600px',height:'400px',hAxis:{title:"Number of elements",slantedText:true},vAxis:{title:"ms",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_23');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;Even if there is only 100'000 elements, the list is already an order of magnitude slower than the other two data structures. If we look a the curves of the results, it is easy to see that this will be only worse with higher collection sizes. The list is absolutely not adapted for number crunching operations due to its poor spatial locality. &lt;/p&gt;
&lt;h3&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;To conclude, we can get some facts about each data structure:&lt;/p&gt;
&lt;ul&gt;
   &lt;li&gt;std::list is very very slow to iterate through the collection due to its very poor spatial locality.&lt;/li&gt;
   &lt;li&gt;std::vector and std::deque perform always faster than std::list with very small data&lt;/li&gt;
   &lt;li&gt;std::list handles very well large elements&lt;/li&gt;
   &lt;li&gt;std::deque performs better than a std::vector for inserting at random positions (especially at the front, which is constant time)&lt;/li&gt;
   &lt;li&gt;std::deque and std::vector do not support very well data types with high cost of copy/assignment&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This draw simple conclusions on usage of each data structure: &lt;/p&gt;
&lt;ul&gt;
   &lt;li&gt;Number crunching: use std::vector or std::deque&lt;/li&gt;
   &lt;li&gt;Linear search: use std::vector or std::deque&lt;/li&gt;
   &lt;li&gt;Random Insert/Remove: use std::list (if data size very small (
   &lt;/li&gt;&lt;li&gt;Big data size: use std::list (not if intended for searching)&lt;/li&gt;
   &lt;li&gt;Non-trivial data type: use std::list unless you need the container especially for searching. But for multiple modifications of the container, it will be very slow. &lt;/li&gt;
   &lt;li&gt;Push to front: use std::deque or std::list&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I have to say that before writing this new version of the benchmark I did not know std::deque a lot. This is a very good data structure that is very good at inserting at both ends and even in the middle while exposing a very good spatial locality. Even if sometimes slower than a vector, when the operations involves both searching and inserting in the middle, I would say that this structure should be preferred over vectors, especially for data types of medium sizes. &lt;/p&gt;
&lt;p&gt;If you have the time, in practice, the best way to decide is always to benchmark each version, or even to try another data structures. Two operations with the same Big O complexity can perform quite differently in practice. &lt;/p&gt;
&lt;p&gt;I hope that you found this article interesting. If you have any comment or have an idea about an other workload that you would like to test, don't hesitate to post a comment ;) If you have a question on results, don't hesitate as well. &lt;/p&gt;
&lt;p&gt;The code source of the benchmark is available online: &lt;a href="https://github.com/wichtounet/articles/blob/master/src/vector_list/bench.cpp" title="Source code of the benchmark"&gt;https://github.com/wichtounet/articles/blob/master/src/vector_list/bench.cpp&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The older version of the article is still available: &lt;a href="http://www.baptiste-wicht.com/2012/11/cpp-benchmark-vector-vs-list/" title="C++ benchmark – std::vector VS std::list"&gt;C++ benchmark – std::vector VS std::list&lt;/a&gt;&lt;/p&gt;
&lt;script type="text/javascript"&gt;function draw_visualization(){draw_graph_0();draw_graph_1();draw_graph_2();draw_graph_3();draw_graph_4();draw_graph_5();draw_graph_6();draw_graph_7();draw_graph_8();draw_graph_9();draw_graph_10();draw_graph_11();draw_graph_12();draw_graph_13();draw_graph_14();draw_graph_15();draw_graph_16();draw_graph_17();draw_graph_18();draw_graph_19();draw_graph_20();draw_graph_21();draw_graph_22();draw_graph_23();}google.setOnLoadCallback(draw_visualization);&lt;/script&gt;</description><category>Benchmarks</category><category>C++</category><category>C++11</category><category>Performances</category><guid>http://baptiste-wicht.com/posts/2012/12/cpp-benchmark-vector-list-deque.html</guid><pubDate>Mon, 03 Dec 2012 07:58:29 GMT</pubDate></item><item><title>C++ benchmark - std::vector VS std::list</title><link>http://baptiste-wicht.com/posts/2012/11/cpp-benchmark-vector-vs-list.html</link><description>&lt;p&gt;&lt;strong&gt;A updated version of this article is available: &lt;a title="C++ benchmark – std::vector VS std::list VS std::deque" href="http://www.baptiste-wicht.com/2012/12/cpp-benchmark-vector-list-deque/"&gt;C++ benchmark – std::vector VS std::list VS std::deque&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In C++, the two most used data structures are the std::vector and the std::list. In this article, we will compare the performance in practice of these two data structures on several different workloads. In this article, when I talk about a list it is the std::list implementation and vector refers to the std::vector implementation.&lt;/p&gt;
&lt;p&gt;It is generally said that a list should be used when random insert and remove will be performed (performed in O(1) versus O(n) for a vector). If we look only at the complexity, search in both data structures should be roughly equivalent, complexity being in O(n). When random insert/replace operations are performed on a vector, all the subsequent data needs to be moved and so each element will be copied. That is why the size of the data type is an important factor when comparing those two data structures.&lt;/p&gt;
&lt;p&gt;However, in practice, there is a huge difference, the usage of the memory caches. All the data in a vector is contiguous where the std::list allocates separately memory for each element. How does that change the results in practice ?&lt;/p&gt;
&lt;p&gt;Keep in mind that all the tests performed are made on vector and list even if other data structures could be better suited to the given workload.&lt;/p&gt;
&lt;p&gt;In the graphs and in the text, &lt;em&gt;n&lt;/em&gt; is used to refer to the number of elements of the collection.&lt;/p&gt;
&lt;p&gt;All the tests performed have been performed on an Intel Core i7 Q 820  @ 1.73GHz. The code has been compiled in 64 bits with GCC 4.7.2 with -02 and -march=native. The code has been compiled with C++11 support (-std=c++11).&lt;/p&gt;
&lt;h3&gt;Fill&lt;/h3&gt;

&lt;p&gt;The first test that is performed is to fill the data structures by adding elements to the back of the container. Two variations of vector are used, vector_pre being a std::vector with the size passed in parameters to the constructor, resulting in only one allocation of memory.&lt;/p&gt;
&lt;div id="graph_0" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_0" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_0(){var graph=new google.visualization.LineChart(document.getElementById('graph_0'));var data=google.visualization.arrayToDataTable([['x','vector_pre','vector','list'],['1000',0,0,1],['10000',0,1,10],['100000',4,11,100],['1000000',7,234,1023]]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"Fill (8 bytes)",width:'600px',height:'400px',vAxis:{title:"Milliseconds",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_0');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;&lt;div id="graph_1" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;&lt;input id="button_graph_1" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_1(){var graph=new google.visualization.LineChart(document.getElementById('graph_1'));var data=google.visualization.arrayToDataTable([['x','vector_pre','vector','list'],['1000',0,9,1],['10000',12,245,18],['100000',949,2635,1153],['1000000',9138,23654,11270]]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"Fill (1024 bytes)",width:'600px',height:'400px',vAxis:{title:"Milliseconds",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_1');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;
&lt;p&gt;All data structures are impacted the same way when the data size increases, because there will be more memory to allocate. The vector_pre is clearly the winner of this test, being one order of magnitude faster than a list and about twice faster than a vector without pre-allocation. The result are directly linked to the allocations that have to be performed, allocation being slow. Whatever the data size is, push_back to a vector will always be faster than to a list. This is logical becomes vector allocates more memory than necessary and so does not need to allocate memory for each element.&lt;/p&gt;
&lt;p&gt;But this test is not very interesting, generally building the data structure is not critical. What is critical is the operations that are performed on the data structure. That will be tested in the next sections.&lt;/p&gt;
&lt;!--nextpage--&gt;

&lt;h3&gt;Random Find&lt;/h3&gt;

&lt;p&gt;The first operation is that is tested is the search. The container is filled with all the numbers in [0, N] and shuffled. Then, each number in [0,N] is searched in the container with std::find that performs a simple linear search.&lt;/p&gt;
&lt;div id="graph_2" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_2" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_2(){var graph=new google.visualization.LineChart(document.getElementById('graph_2'));var data=google.visualization.arrayToDataTable([['x','vector','list'],['100',0,11],['1000',0,1545],['5000',0,35886],['10000',0,150865],['20000',0,614496]]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"Find (8 bytes)",width:'600px',height:'400px',vAxis:{title:"Microseconds",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_2');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;Yes, vector is present in the graph, its line is the same as the x line ! Performing a &lt;strong&gt;linear search in a vector is several orders of magnitude faster than in a list&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;The only reason is the usage of the cache line. When a data is accessed, the data is fetched from the main memory to the cache. Not only the accessed data is accessed, but a whole cacheline is fetched. As the elements in a vector are contiguous, when you access an element, the next element is automatically in the cache. As the main memory is orders of magnitude slower than the cache, this makes a huge difference. In the list case, the processor spends its whole time waiting for data being fetched from memory to the cache.&lt;/p&gt;
&lt;p&gt;If we augment the size of the data type to 1KB, the results remain the same, but slower:&lt;/p&gt;
&lt;div id="graph_3" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_3" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_3(){var graph=new google.visualization.LineChart(document.getElementById('graph_3'));var data=google.visualization.arrayToDataTable([['x','vector','list'],['100',0,11],['1000',0,3551],['5000',0,195429],['10000',0,829631],['20000',0,3356432]]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"Find (1024 bytes)",width:'600px',height:'400px',vAxis:{title:"Microseconds",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_3');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;!--nextpage--&gt;

&lt;h3&gt;Random Insert&lt;/h3&gt;

&lt;p&gt;In the case of random insert, in theory, the list should be much faster, its insert operation being in O(1) versus O(n) for a vector.&lt;/p&gt;
&lt;p&gt;The container is filled with all the numbers in [0, N] and shuffled. Then, 1000 random values are inserted at a random position in the container. The random position is found by linear search. In both cases, the complexity of the search is O(n), the only difference comes from the insert that follow the search.&lt;/p&gt;
&lt;div id="graph_4" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_4" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_4(){var graph=new google.visualization.LineChart(document.getElementById('graph_4'));var data=google.visualization.arrayToDataTable([['x','vector','list'],['1000',9,85],['2000',9,85],['4000',10,94],['6000',12,98],['8000',13,106],['10000',14,106]]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"Insert (8 bytes)",width:'600px',height:'400px',vAxis:{title:"Milliseconds",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_4');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;When, the vector should be slower than the list, it is almost an order of magnitude faster. Again, this is because finding the position in a list is much slower than copying a lot of small elements.&lt;/p&gt;
&lt;p&gt;If we increase the size:&lt;/p&gt;
&lt;div id="graph_5" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_5" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_5(){var graph=new google.visualization.LineChart(document.getElementById('graph_5'));var data=google.visualization.arrayToDataTable([['x','vector','list'],['1000',27,120],['2000',30,113],['4000',34,122],['6000',37,140],['8000',42,145],['10000',47,155]]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"Insert (32 bytes)",width:'600px',height:'400px',vAxis:{title:"Milliseconds",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_5');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;The two lines are getting closer, but vector is still faster.&lt;/p&gt;
&lt;p&gt;Increase it to 1KB:&lt;/p&gt;
&lt;div id="graph_6" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_6" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_6(){var graph=new google.visualization.LineChart(document.getElementById('graph_6'));var data=google.visualization.arrayToDataTable([['x','vector','list'],['1000',1821,167],['2000',1941,163],['4000',2383,191],['6000',2679,207],['8000',2960,214],['10000',3308,228]]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"Insert (1024 bytes)",width:'600px',height:'400px',vAxis:{title:"Milliseconds",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_6');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;This time, list outperforms vector by an order of magnitude ! The performance of random insert in a list are not impacted much by the size of the data type, where vector suffers a lot when big sizes are used. We can also see that list doesn't seem to care about the size of the collection. It is because the size of the collection only impact the search and not the insertion and as few search are performed, it does not change the results a lot.&lt;/p&gt;
&lt;p&gt;If the iterator was already known (no need for linear search), it would be faster to insert into a list than into the vector.&lt;/p&gt;
&lt;h3&gt;Random Remove&lt;/h3&gt;

&lt;p&gt;In theory, random remove is the same case than random insert. Now that we've seen the results with random insert, we could expect the same behavior for random remove.&lt;/p&gt;
&lt;p&gt;The container is filled with all the numbers in [0, N] and shuffled. Then, 1000 random values are removed from a random position in the container.&lt;/p&gt;
&lt;div id="graph_7" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_7" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_7(){var graph=new google.visualization.LineChart(document.getElementById('graph_7'));var data=google.visualization.arrayToDataTable([['x','vector','list'],['100',0,0],['1000',0,0],['10000',40,0],['50000',949,2],['100000',3937,4],['200000',16003,9],['300000',42393,12]]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"Push front (8 bytes)",width:'600px',height:'400px',vAxis:{title:"Milliseconds",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_7');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;Again, vector is several times faster and looks to scale better. Again, this is because it is very cheap to copy small elements.&lt;/p&gt;
&lt;p&gt;Let's increase it directly to 1KB element.&lt;/p&gt;
&lt;div id="graph_8" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_8" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_8(){var graph=new google.visualization.LineChart(document.getElementById('graph_8'));var data=google.visualization.arrayToDataTable([['x','vector','list'],['1000',0,0],['10000',2,26],['100000',163,684],['1000000',2147,15950],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"Sort (8 bytes)",width:'600px',height:'400px',vAxis:{title:"Milliseconds",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_8');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;The two lines have been reversed !&lt;/p&gt;
&lt;p&gt;The behavior of random remove is the same as the behavior of random insert, for the same reasons.&lt;/p&gt;
&lt;!--nextpage--&gt;

&lt;h3&gt;Push Front&lt;/h3&gt;

&lt;p&gt;The next operation that we will compare is inserting elements in front of the collection. This is the worst case for vector, because after each insertion, all the previously inserted will be moved and copied. For a list, it does not make a difference compared to pushing to the back.&lt;/p&gt;
&lt;div id="graph_9" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_9" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_9(){var graph=new google.visualization.LineChart(document.getElementById('graph_9'));var data=google.visualization.arrayToDataTable([['x','vector','list'],['100',0,0],['1000',0,0],['10000',40,0],['50000',949,2],['100000',3937,4],['200000',16003,9],['300000',42393,12]]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"Push front (8 bytes)",width:'600px',height:'400px',vAxis:{title:"Milliseconds",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_9');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;The results are crystal-clear and as expected. vector is very bad at inserting elements to the front. This does not need further explanations. There is no need to change the data size, it will only make vector much slower.&lt;/p&gt;
&lt;h3&gt;Sort&lt;/h3&gt;

&lt;p&gt;The next operation that is tested is the performance of sorting a vector or a list. For a vector std::sort is used and for a list the member function sort is used.&lt;/p&gt;
&lt;div id="graph_10" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_10" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_10(){var graph=new google.visualization.LineChart(document.getElementById('graph_10'));var data=google.visualization.arrayToDataTable([['x','vector','list'],['1000',0,0],['10000',2,26],['100000',163,684],['1000000',2147,15950],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"Sort (8 bytes)",width:'600px',height:'400px',vAxis:{title:"Milliseconds",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_10');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;We can see that sorting a list is several times slower. It comes from the poor usage of the cache.&lt;/p&gt;
&lt;p&gt;If we increase the size of the element to 1KB:&lt;/p&gt;
&lt;div id="graph_11" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_11" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_11(){var graph=new google.visualization.LineChart(document.getElementById('graph_11'));var data=google.visualization.arrayToDataTable([['x','vector','list'],['1000',2,0],['10000',224,50],['100000',4289,1083],['1000000',50973,17975],]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"Sort (1024 bytes)",width:'600px',height:'400px',vAxis:{title:"Milliseconds",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_11');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;This time the list is faster than the vector. It is not very clear on the graph, but the values for the list are almost the same as for the previous results. That is because std::list::sort() does not perform any copy, only pointers to the elements are changed. On the other hand, swapping two elements in a vector involves at least three copies, so the cost of sorting will increase as the cost of copying increases.&lt;/p&gt;
&lt;!--nextpage--&gt;

&lt;h3&gt;Number Crunching&lt;/h3&gt;

&lt;p&gt;Finally, we can also test a number crunching operation. Here, random elements are inserted into the container that is kept sorted. It means, that the position where the element has to be inserted is first searched by iterating through elements and the inserted. As we talk about number crunching, only 8 bytes elements are tested.&lt;/p&gt;
&lt;div id="graph_12" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_12" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_12(){var graph=new google.visualization.LineChart(document.getElementById('graph_12'));var data=google.visualization.arrayToDataTable([['x','vector','list'],['1000',0,0],['10000',45,166],['50000',928,10665],['100000',3753,50766],['200000',15185,231480],['300000',34293,715892]]);var options={curveType:"function",animation:{duration:1200,easing:"in"},title:"Random Sorted Insert (8 bytes)",width:'600px',height:'400px',vAxis:{title:"Milliseconds",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_12');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;We can clearly see that vector is more than an order of magnitude faster than list and this will only be more as the size of the collection increase. This is because traversing the list is much more expensive than copying the elements of the vector.&lt;/p&gt;
&lt;h3&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;To conclude, we can get some facts about each data structure:&lt;/p&gt;
&lt;ul&gt;
    &lt;li&gt;std::vector is insanely faster than std::list to find an element&lt;/li&gt;
    &lt;li&gt;std::vector performs always faster than std::list with very small data&lt;/li&gt;
    &lt;li&gt;std::vector is always faster to push elements at the back than std::list&lt;/li&gt;
    &lt;li&gt;std::list handles very well large elements, especially for sorting or inserting in the front&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This draw simple conclusions on usage of each data structure:&lt;/p&gt;
&lt;ul&gt;
    &lt;li&gt;Number crunching: use std::vector&lt;/li&gt;
    &lt;li&gt;Linear search: use std::vector&lt;/li&gt;
    &lt;li&gt;Random Insert/Remove: use std::list (if data size very small (&amp;lt; 64B on my computer), use std::vector)&lt;/li&gt;
    &lt;li&gt;Big data size: use std::list (not if intended for searching)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If you have the time, in practice, the best way to decide is always to benchmark both versions, or even to try another data structures.&lt;/p&gt;
&lt;p&gt;I hope that you found this article interesting. If you have any comment or have an idea about an other workload that you would like to test, don't hesitate to post a comment ;) If you have a question on results, don't hesitate as well.&lt;/p&gt;
&lt;p&gt;The code source of the benchmark is available online: &lt;a title="Source code of the benchmark" href="https://github.com/wichtounet/articles/blob/master/src/vector_list/bench.cpp"&gt;https://github.com/wichtounet/articles/blob/master/src/vector_list/bench.cpp&lt;/a&gt;&lt;/p&gt;
&lt;script type="text/javascript"&gt;function draw_visualization(){draw_graph_0();draw_graph_1();draw_graph_2();draw_graph_3();draw_graph_4();draw_graph_5();draw_graph_6();draw_graph_7();draw_graph_8();draw_graph_9();draw_graph_10();draw_graph_11();draw_graph_12();}google.setOnLoadCallback(draw_visualization);&lt;/script&gt;</description><category>Benchmarks</category><category>C++</category><category>C++11</category><category>Performances</category><guid>http://baptiste-wicht.com/posts/2012/11/cpp-benchmark-vector-vs-list.html</guid><pubDate>Mon, 26 Nov 2012 07:47:35 GMT</pubDate></item><item><title>EDDIC 0.7.1 : Boolean conditions and new operators</title><link>http://baptiste-wicht.com/posts/2012/02/eddic-0-7-1-boolean-operators.html</link><description>&lt;div&gt;&lt;p&gt;I just finished working on the 0.7.1 version of eddic.&lt;/p&gt;
&lt;p&gt;Even it it's a minor version, there are several new features in the language itself.&lt;/p&gt;
&lt;p&gt;First of all, the boolean conditions have been greatly improved. You can now use &amp;amp;&amp;amp; (short circuit and operator) and || (short circuit or operator) operators to make complex conditions for &lt;strong&gt;if&lt;/strong&gt; and &lt;strong&gt;while&lt;/strong&gt; structure. Moreover, you can now declare variables of &lt;strong&gt;bool&lt;/strong&gt; type. You can also print bool variables. That will simplify the code that can be written with EDDI.&lt;/p&gt;
&lt;p&gt;Another big improvement to the language is the addition of &lt;strong&gt;increment&lt;/strong&gt; and &lt;strong&gt;decrement&lt;/strong&gt; operators. Both postfix and prefix forms are available. You can use an increment or decrement as a single statement or inside another expressions.&lt;/p&gt;
&lt;p&gt;Increment and decrement operators are not the only operators added to the language. You can now use compound operators (+=, -=, *=, /= and %=) to make direct modifications to variables.&lt;/p&gt;
&lt;p&gt;In the next version, there will certainly be some improvements of the generated assembly. I don't know what improvement will be done on the language. &lt;/p&gt;
&lt;p&gt;If some of you have an idea of improvement for the language or the compiler itself, don't hesitate to make me know :)&lt;/p&gt;
&lt;h4&gt;Download&lt;/h4&gt;

&lt;p&gt;You can find the compiler sources on the Github repository : &lt;a title="eddic on Github" href="https://github.com/wichtounet/eddic"&gt;https://github.com/wichtounet/eddic&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The exact version I refer to is the v0.7.1 available in the github tags or directly as the release branch.&lt;/p&gt;&lt;/div&gt;</description><category>C++11</category><category>Compilers</category><category>EDDI</category><guid>http://baptiste-wicht.com/posts/2012/02/eddic-0-7-1-boolean-operators.html</guid><pubDate>Fri, 03 Feb 2012 08:11:09 GMT</pubDate></item><item><title>EDDIC 0.5 : Functions and foreach</title><link>http://baptiste-wicht.com/posts/2011/10/eddic-0-5-functions-foreach.html</link><description>&lt;div&gt;&lt;p&gt;I'm pleased to release the version 0.5. of the EDDI Compiler.&lt;/p&gt;
&lt;p&gt;This new version introduced the first version of function calls. The function can take several parameters but cannot return anything at this moment. A version of foreach loop is now available in the language.&lt;/p&gt;
&lt;p&gt;You can also declare variables globally in the source code. The global variables are stored in the .data section of the ELF file and the local variables are stored on the stack.&lt;/p&gt;
&lt;p&gt;The error reporting of the compiler has been improved. Indeed, now the syntactical errors are reported with the exact location of the source.&lt;/p&gt;
&lt;p&gt;There are also a lot of improvements in the source code. The big header files have been splitted into several files. I replaced all the pointers by smart pointers that allowed me to remove all the memory leaks of the applications and to simplify the memory management. Finally, I started using some new features of C++11 to improve the source code of the application.&lt;/p&gt;
&lt;p&gt;The next version will certainly see return types for functions and perhaps a first version of switch case. Moreover, I have a lot of improvements to do at the assembly level. Indeed, the generated assembly is not efficient at all. Perhaps, I will consider adding arrays too to this version.&lt;/p&gt;
&lt;p&gt;You can find the compiler on the Github repository : &lt;a title="EDDI COmpiler Repository" href="http://github.com/wichtounet/eddic"&gt;https://github.com/wichtounet/eddic&lt;/a&gt;. If you watch the repository, you'll see that I followed a new branching model, the one proposed and enforced by the git-flow tool.&lt;/p&gt;
&lt;p&gt;The exact version I refer to is the v0.5 available in the github tags.&lt;/p&gt;&lt;/div&gt;</description><category>C++</category><category>C++11</category><category>EDDI</category><category>Git</category><category>Releases</category><guid>http://baptiste-wicht.com/posts/2011/10/eddic-0-5-functions-foreach.html</guid><pubDate>Mon, 10 Oct 2011 00:38:50 GMT</pubDate></item></channel></rss>