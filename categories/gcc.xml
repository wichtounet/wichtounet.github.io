<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>@Blog("Baptiste Wicht") (gcc)</title><link>http://baptiste-wicht.com/</link><description></description><atom:link href="http://baptiste-wicht.com/categories/gcc.xml" type="application/rss+xml" rel="self"></atom:link><language>en</language><lastBuildDate>Sun, 27 Nov 2016 14:43:16 GMT</lastBuildDate><generator>https://getnikola.com/</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Blazing fast unit test compilation with doctest 1.1</title><link>http://baptiste-wicht.com/posts/2016/09/blazing-fast-unit-test-compilation-with-doctest-11.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;div&gt;&lt;p&gt;You may remember &lt;a class="reference external" href="http://baptiste-wicht.com/posts/2016/06/reduce-compilation-time-by-another-16-with-catch.html"&gt;my quest for faster compilation times&lt;/a&gt;. I had made several changes to the Catch test framework macros in order to save some compilation at the expense of my test code looking a bit less nice:&lt;/p&gt;
&lt;pre class="code cpp"&gt;&lt;a name="rest_code_9e9deba023dd4a378f6a33b6c3f21c97-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;REQUIRE&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="c1"&gt;//Before&lt;/span&gt;
&lt;a name="rest_code_9e9deba023dd4a378f6a33b6c3f21c97-2"&gt;&lt;/a&gt;&lt;span class="n"&gt;REQUIRE_EQUALS&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="c1"&gt;//After&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;The first line is a little bit better, but using several optimizations, I was
able to dramatically change the compilation time of the test cases of ETL. In
the end, I don't think that the difference between the two lines justifies the
high overhead in compilation times.&lt;/p&gt;
&lt;div class="section" id="doctest"&gt;
&lt;h2&gt;doctest&lt;/h2&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/onqtam/doctest"&gt;doctest&lt;/a&gt; is a framework quite similar to
Catch but that claims to be much lighter. I tested doctest 1.0 early on, but at
this point it was actually slower than Catch and especially slower than my
versions of the macro.&lt;/p&gt;
&lt;p&gt;Today, doctest 1.1 was released with promises of being even lighter than before
and providing several new ways of speeding up compilation. If you want the
results directly, you can take a look at the next section.&lt;/p&gt;
&lt;p&gt;First of all, this new version improved the basic macros to make expression
decomposition faster. When you use the standard REQUIRE macro, the expression is
composed by using several template techniques and operator overloading. This is
really slow to compile. By removing the need for this decomposition, the fast
Catch macros are much faster to compile.&lt;/p&gt;
&lt;p&gt;Moreover, doctest 1.1 also introduces CHECK_EQ that does not any expression
decomposition. This is close to what I did in my macros expect that it is
directly integrated into the framework and preserves all its features. It is
also possible to bypass the expression checking code by using FAST_CHECK_EQ
macro. In that case, the exceptions are not captured. Finally, a new
configuration option is introduced (DOCTEST_CONFIG_SUPER_FAST_ASSERTS) that
removes some features related to automatic debugger breaks. Since I don't use
the debugger features and I don't need to capture exception everywhere (it's
sufficient for me that the test fails completely if an exception is thrown), I'm
more than eager to use these new features.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="results"&gt;
&lt;h2&gt;Results&lt;/h2&gt;
&lt;p&gt;For evaluation, I have compiled the complete test suite of ETL, with 1 thread,
using gcc 4.9.3 with various different options, starting from Catch to doctest
1.1 with all compilation time features. Here are the results, in seconds:&lt;/p&gt;
&lt;table border="1" class="docutils"&gt;
&lt;colgroup&gt;
&lt;col width="29%"&gt;
&lt;col width="12%"&gt;
&lt;col width="14%"&gt;
&lt;col width="22%"&gt;
&lt;col width="23%"&gt;
&lt;/colgroup&gt;
&lt;thead valign="bottom"&gt;
&lt;tr&gt;&lt;th class="head"&gt;Version&lt;/th&gt;
&lt;th class="head"&gt;Time&lt;/th&gt;
&lt;th class="head"&gt;VS Catch&lt;/th&gt;
&lt;th class="head"&gt;VS Fast Catch&lt;/th&gt;
&lt;th class="head"&gt;VS doctest 1.0&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td&gt;Catch&lt;/td&gt;
&lt;td&gt;724.22&lt;/td&gt;
&lt;td&gt; &lt;/td&gt;
&lt;td&gt; &lt;/td&gt;
&lt;td&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Fast Catch&lt;/td&gt;
&lt;td&gt;464.52&lt;/td&gt;
&lt;td&gt;-36%&lt;/td&gt;
&lt;td&gt; &lt;/td&gt;
&lt;td&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;doctest 1.0&lt;/td&gt;
&lt;td&gt;871.54&lt;/td&gt;
&lt;td&gt;+20%&lt;/td&gt;
&lt;td&gt;+87%&lt;/td&gt;
&lt;td&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;doctest 1.1&lt;/td&gt;
&lt;td&gt;614.67&lt;/td&gt;
&lt;td&gt;-16%&lt;/td&gt;
&lt;td&gt;+32%&lt;/td&gt;
&lt;td&gt;-30%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;REQUIRE_EQ&lt;/td&gt;
&lt;td&gt;493.97&lt;/td&gt;
&lt;td&gt;-32%&lt;/td&gt;
&lt;td&gt;+6%&lt;/td&gt;
&lt;td&gt;-43%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;FAST_REQUIRE_EQ&lt;/td&gt;
&lt;td&gt;439.09&lt;/td&gt;
&lt;td&gt;-39%&lt;/td&gt;
&lt;td&gt;-6%&lt;/td&gt;
&lt;td&gt;-50%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;SUPER_FAST_ASSERTS&lt;/td&gt;
&lt;td&gt;411.11&lt;/td&gt;
&lt;td&gt;-43%&lt;/td&gt;
&lt;td&gt;-12%&lt;/td&gt;
&lt;td&gt;-53%&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;As you can see, doctest 1.1 is much faster to compile than doctest 1.0! This is
really great news. Moreover, it is already 16% faster than Catch. When all the
features are used, doctest is 12% faster than my stripped down versions of Catch
macros (and 43% faster than Catch standard macros). This is really cool! It
means that I don't have to do any change in the code (no need to strip macros
myself) and I can gain a lot of compilation time compared to the bare Catch
framework.&lt;/p&gt;
&lt;p&gt;I really think the author of doctest did a great job with the new version.
Although this was not of as much interest for me, there are also a lot of
other changes in the new version. You can consult the
&lt;a class="reference external" href="https://github.com/onqtam/doctest/blob/master/CHANGELOG.md"&gt;changelog&lt;/a&gt; if you want more information.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="conclusion"&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Overall, doctest 1.1 is much faster to compile than doctest 1.0. Moreover, it
offers very fast macros for test assertions that are much faster to compile
than Catch versions and even faster than the versions I created myself to reduce
compilation time. I really thing this is a great advance for doctest. When
compiling with all the optimizations, doctest 1.1 saves me 50 seconds in
compilation time compared to the fast version of Catch macro and more than
5 minutes compared to the standard version of Catch macros.&lt;/p&gt;
&lt;p&gt;I'll probably start using doctest on my development machine. For now, I'll keep
Catch as well since I need it to generate the unit test reports in XML format
for Sonarqube. Once this feature appears in doctest, I'll probably drop Catch
from ETL and DLL&lt;/p&gt;
&lt;p&gt;If you need blazing fast compilation times for your unit tests, doctest 1.1 is
probably the way to go.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;</description><category>C++</category><category>Catch</category><category>Compilers</category><category>doctest</category><category>etl</category><category>gcc</category><category>Performances</category><category>Tests</category><category>time</category><guid>http://baptiste-wicht.com/posts/2016/09/blazing-fast-unit-test-compilation-with-doctest-11.html</guid><pubDate>Wed, 21 Sep 2016 19:45:13 GMT</pubDate></item><item><title>Improve DLL and ETL Compile Time further</title><link>http://baptiste-wicht.com/posts/2016/01/improve-dll-and-etl-compile-time-further.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;div&gt;&lt;p&gt;For a while, the compilation time of my matrix/vector computation library (ETL), based on Expression Templates has become more and more problematic. I've already worked on this problem &lt;a class="reference external" href="http://baptiste-wicht.com/posts/2015/06/how-i-improved-a-bit-compile-time-of-etl.html"&gt;here&lt;/a&gt; and &lt;a class="reference external" href="http://baptiste-wicht.com/posts/2015/06/improve-etl-compile-time-with-precompiled-headers.html"&gt;there&lt;/a&gt;, using some general techniques (pragmas, precompiled headers, header removals and so on). On this post, I'll talk about two major improvements I have been able to do directly in the code.&lt;/p&gt;
&lt;div class="section" id="use-of-static-if"&gt;
&lt;h2&gt;Use of static_if&lt;/h2&gt;
&lt;p&gt;Remember &lt;a class="reference external" href="http://baptiste-wicht.com/posts/2015/07/simulate-static_if-with-c11c14.html"&gt;static_if&lt;/a&gt; ? I was able to use it to really reduce the compile time of DLL.&lt;/p&gt;
&lt;p&gt;I wrote a script to time each test case of the DLL project to find the test cases that took the longest to compile. Once I found the best candidate, I isolated the functions that took the longest to compile. It was quite tedious and I did it by hand, primarily by commenting parts of the code and going deeper and deeper in the code. I was quite suprised to find that a single function call (template function of course ;) ) was responsible for 60% of the compilation time of my candidate test case. The function was instantiating a whole bunch of expression templates (to compute the free energy of several models). The function itself was not really optimizable, but what was really interesting is that this function was only used in some very rare cases and that these cases were known at compile-time :) This was a perfect case to use a static_if. And once the call was inside the static_if, the test case was indeed about 60% faster. &lt;strong&gt;This reduced the overall compilation time of DLL by about 30%&lt;/strong&gt;!&lt;/p&gt;
&lt;p&gt;This could also of course also have been achieved by using two functions, one with the call, one empty and selected by SFINAE (Substitution Failure Is Not An Error). I prefer the statif_if version since this really shows the intent and hides SFINAE behind nicer syntax.&lt;/p&gt;
&lt;p&gt;I was also able to use static_if at other places in the DLL code to avoid instantiating some templates, but the improvements were much less dramatic (about 1% of the total compilation time). I was very lucky to find a single function that accounted for so much compile time. After some more tests, I concluded that much of the compilation time of DLL was spent compiling the Expression Templates from my ETL library so I decided to delve into ETL code directly.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="removal-of-std-async"&gt;
&lt;h2&gt;Removal of std::async&lt;/h2&gt;
&lt;p&gt;The second improvement was very surprising. I was working on improving the compilation of ETL and found out that the sum and average reductions of matrices were dramatically slow, about an order of magnitude slower than standard operations on matrices. In parallel (but the two facts are linked), I also found out another weird fact when splitting a file into 10 parts (the file was comprised of 10 test cases). Compiling the 10 parts separarely (and sequentially, not multiple threads) was about 40% faster than compiling the complete file. There was no swapping so it was not a memory issue. This is not expected. Generally, it is faster to compile a big file than to compile its parts separately. The advantage of smaller files is that you can compile them in parallel and that incremental builds are faster (only compile a small part).&lt;/p&gt;
&lt;p&gt;By elimination, I found out that most of the time was spent inside the function that was dispatching in parallel the work for accumulating the sum of a matrix. Here is the function:&lt;/p&gt;
&lt;pre class="code cpp"&gt;&lt;a name="rest_code_16ede87dfbc14e63a1910e4e1f14dfd2-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;Functor&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;AccFunctor&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_16ede87dfbc14e63a1910e4e1f14dfd2-2"&gt;&lt;/a&gt;&lt;span class="kr"&gt;inline&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="n"&gt;dispatch_1d_acc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;bool&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Functor&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;functor&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;AccFunctor&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;acc_functor&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;first&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;last&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
&lt;a name="rest_code_16ede87dfbc14e63a1910e4e1f14dfd2-3"&gt;&lt;/a&gt;    &lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
&lt;a name="rest_code_16ede87dfbc14e63a1910e4e1f14dfd2-4"&gt;&lt;/a&gt;        &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;vector&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;future&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;futures&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;threads&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a name="rest_code_16ede87dfbc14e63a1910e4e1f14dfd2-5"&gt;&lt;/a&gt;
&lt;a name="rest_code_16ede87dfbc14e63a1910e4e1f14dfd2-6"&gt;&lt;/a&gt;        &lt;span class="k"&gt;auto&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;last&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;first&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_16ede87dfbc14e63a1910e4e1f14dfd2-7"&gt;&lt;/a&gt;        &lt;span class="k"&gt;auto&lt;/span&gt; &lt;span class="n"&gt;batch&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;threads&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_16ede87dfbc14e63a1910e4e1f14dfd2-8"&gt;&lt;/a&gt;
&lt;a name="rest_code_16ede87dfbc14e63a1910e4e1f14dfd2-9"&gt;&lt;/a&gt;        &lt;span class="k"&gt;for&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;threads&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
&lt;a name="rest_code_16ede87dfbc14e63a1910e4e1f14dfd2-10"&gt;&lt;/a&gt;            &lt;span class="n"&gt;futures&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;async&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;launch&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;async&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;functor&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;first&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;batch&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;first&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;batch&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a name="rest_code_16ede87dfbc14e63a1910e4e1f14dfd2-11"&gt;&lt;/a&gt;        &lt;span class="p"&gt;}&lt;/span&gt;
&lt;a name="rest_code_16ede87dfbc14e63a1910e4e1f14dfd2-12"&gt;&lt;/a&gt;
&lt;a name="rest_code_16ede87dfbc14e63a1910e4e1f14dfd2-13"&gt;&lt;/a&gt;        &lt;span class="n"&gt;acc_functor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;functor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;first&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;threads&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;batch&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;last&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;
&lt;a name="rest_code_16ede87dfbc14e63a1910e4e1f14dfd2-14"&gt;&lt;/a&gt;
&lt;a name="rest_code_16ede87dfbc14e63a1910e4e1f14dfd2-15"&gt;&lt;/a&gt;        &lt;span class="k"&gt;for&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;auto&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt; &lt;span class="nl"&gt;fut&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;futures&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
&lt;a name="rest_code_16ede87dfbc14e63a1910e4e1f14dfd2-16"&gt;&lt;/a&gt;            &lt;span class="n"&gt;acc_functor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fut&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;());&lt;/span&gt;
&lt;a name="rest_code_16ede87dfbc14e63a1910e4e1f14dfd2-17"&gt;&lt;/a&gt;        &lt;span class="p"&gt;}&lt;/span&gt;
&lt;a name="rest_code_16ede87dfbc14e63a1910e4e1f14dfd2-18"&gt;&lt;/a&gt;    &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;a name="rest_code_16ede87dfbc14e63a1910e4e1f14dfd2-19"&gt;&lt;/a&gt;        &lt;span class="n"&gt;acc_functor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;functor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;first&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;last&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;
&lt;a name="rest_code_16ede87dfbc14e63a1910e4e1f14dfd2-20"&gt;&lt;/a&gt;    &lt;span class="p"&gt;}&lt;/span&gt;
&lt;a name="rest_code_16ede87dfbc14e63a1910e4e1f14dfd2-21"&gt;&lt;/a&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;There isn't anything really fancy about this function. This takes one functor that will be done in parallel and one function for accumulation.  It dispatches all the work in batch and then accumulates the results. I tried several things to optimize the compilation time of this function, but nothing worked. The line that was consuming all the time was the std::async line. This function was using std::async because the thread pool that I'm generally using does not support returning values from parallel functors. I decided to use a workaround and use my thread pool and I came out with this version:&lt;/p&gt;
&lt;pre class="code cpp"&gt;&lt;a name="rest_code_cbb111f9b3b84ccaa37dd4be7e9a7cf8-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;template&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;Functor&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="k"&gt;typename&lt;/span&gt; &lt;span class="n"&gt;AccFunctor&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_cbb111f9b3b84ccaa37dd4be7e9a7cf8-2"&gt;&lt;/a&gt;&lt;span class="kr"&gt;inline&lt;/span&gt; &lt;span class="kt"&gt;void&lt;/span&gt; &lt;span class="n"&gt;dispatch_1d_acc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;bool&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Functor&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;functor&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;AccFunctor&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;acc_functor&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;first&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;last&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
&lt;a name="rest_code_cbb111f9b3b84ccaa37dd4be7e9a7cf8-3"&gt;&lt;/a&gt;    &lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
&lt;a name="rest_code_cbb111f9b3b84ccaa37dd4be7e9a7cf8-4"&gt;&lt;/a&gt;        &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;vector&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;futures&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;threads&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a name="rest_code_cbb111f9b3b84ccaa37dd4be7e9a7cf8-5"&gt;&lt;/a&gt;        &lt;span class="n"&gt;cpp&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;default_thread_pool&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;pool&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;threads&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a name="rest_code_cbb111f9b3b84ccaa37dd4be7e9a7cf8-6"&gt;&lt;/a&gt;
&lt;a name="rest_code_cbb111f9b3b84ccaa37dd4be7e9a7cf8-7"&gt;&lt;/a&gt;        &lt;span class="k"&gt;auto&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;last&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;first&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_cbb111f9b3b84ccaa37dd4be7e9a7cf8-8"&gt;&lt;/a&gt;        &lt;span class="k"&gt;auto&lt;/span&gt; &lt;span class="n"&gt;batch&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;threads&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_cbb111f9b3b84ccaa37dd4be7e9a7cf8-9"&gt;&lt;/a&gt;
&lt;a name="rest_code_cbb111f9b3b84ccaa37dd4be7e9a7cf8-10"&gt;&lt;/a&gt;        &lt;span class="k"&gt;auto&lt;/span&gt; &lt;span class="n"&gt;sub_functor&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;futures&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;functor&lt;/span&gt;&lt;span class="p"&gt;](&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;first&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;last&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
&lt;a name="rest_code_cbb111f9b3b84ccaa37dd4be7e9a7cf8-11"&gt;&lt;/a&gt;            &lt;span class="n"&gt;futures&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;functor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;first&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;last&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a name="rest_code_cbb111f9b3b84ccaa37dd4be7e9a7cf8-12"&gt;&lt;/a&gt;        &lt;span class="p"&gt;};&lt;/span&gt;
&lt;a name="rest_code_cbb111f9b3b84ccaa37dd4be7e9a7cf8-13"&gt;&lt;/a&gt;
&lt;a name="rest_code_cbb111f9b3b84ccaa37dd4be7e9a7cf8-14"&gt;&lt;/a&gt;        &lt;span class="k"&gt;for&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;threads&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
&lt;a name="rest_code_cbb111f9b3b84ccaa37dd4be7e9a7cf8-15"&gt;&lt;/a&gt;            &lt;span class="n"&gt;pool&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;do_task&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sub_functor&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;first&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;batch&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;first&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;batch&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a name="rest_code_cbb111f9b3b84ccaa37dd4be7e9a7cf8-16"&gt;&lt;/a&gt;        &lt;span class="p"&gt;}&lt;/span&gt;
&lt;a name="rest_code_cbb111f9b3b84ccaa37dd4be7e9a7cf8-17"&gt;&lt;/a&gt;
&lt;a name="rest_code_cbb111f9b3b84ccaa37dd4be7e9a7cf8-18"&gt;&lt;/a&gt;        &lt;span class="n"&gt;acc_functor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;functor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;first&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;threads&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;batch&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;last&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;
&lt;a name="rest_code_cbb111f9b3b84ccaa37dd4be7e9a7cf8-19"&gt;&lt;/a&gt;
&lt;a name="rest_code_cbb111f9b3b84ccaa37dd4be7e9a7cf8-20"&gt;&lt;/a&gt;        &lt;span class="n"&gt;pool&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;wait&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;a name="rest_code_cbb111f9b3b84ccaa37dd4be7e9a7cf8-21"&gt;&lt;/a&gt;
&lt;a name="rest_code_cbb111f9b3b84ccaa37dd4be7e9a7cf8-22"&gt;&lt;/a&gt;        &lt;span class="k"&gt;for&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;auto&lt;/span&gt; &lt;span class="nl"&gt;fut&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;futures&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
&lt;a name="rest_code_cbb111f9b3b84ccaa37dd4be7e9a7cf8-23"&gt;&lt;/a&gt;            &lt;span class="n"&gt;acc_functor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fut&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a name="rest_code_cbb111f9b3b84ccaa37dd4be7e9a7cf8-24"&gt;&lt;/a&gt;        &lt;span class="p"&gt;}&lt;/span&gt;
&lt;a name="rest_code_cbb111f9b3b84ccaa37dd4be7e9a7cf8-25"&gt;&lt;/a&gt;    &lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;a name="rest_code_cbb111f9b3b84ccaa37dd4be7e9a7cf8-26"&gt;&lt;/a&gt;        &lt;span class="n"&gt;acc_functor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;functor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;first&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;last&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;
&lt;a name="rest_code_cbb111f9b3b84ccaa37dd4be7e9a7cf8-27"&gt;&lt;/a&gt;    &lt;span class="p"&gt;}&lt;/span&gt;
&lt;a name="rest_code_cbb111f9b3b84ccaa37dd4be7e9a7cf8-28"&gt;&lt;/a&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;I simply preallocate space for all the threads and create a new functor calling the input functor and saving its result inside the vector. It is less nice, but it works well. And it compiles MUCH faster. This &lt;strong&gt;reduced the compilation time&lt;/strong&gt; of my biggest test case &lt;strong&gt;by a factor of 8&lt;/strong&gt; (from 344 seconds to 44 seconds). This is really crazy. It also fixed the problem where splitting the test case was faster than big file (it is now twice faster to compile the big files than compiling all the small files separately). &lt;strong&gt;This reduced the total compilation time of dll by about 400%&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;As of now, I still have no idea why this makes such a big difference. I have looked at the std::async code, but I haven't found a valid reason for this slowdown. If someone has any idea, I'd be very glad to discuss in the comments below.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="improving-the-template-instantiation-tree"&gt;
&lt;h2&gt;Improving the template instantiation tree&lt;/h2&gt;
&lt;p&gt;I recently discovered the templight tool that is a profiler for templates (pretty cool). After some time, I was able to build it and use it on ETL. For now, I haven't been able to reduce compile time a lot, but I have been able to reduce the template instantiation tree a lot seeing that some instantiations were completely useless and I optimized the code to remove them.&lt;/p&gt;
&lt;p&gt;I won't be go into much details here because I plan to write a post on this subject in the coming days.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="conclusion"&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;In conclusion, I would say that it is pretty hard to improve the compile time of complex C++ programs once you have gone through all the standard methods. However, I was very happy to found that &lt;strong&gt;two optimizations in the source code reduced the overall compilation of DLL by almost 500%&lt;/strong&gt;. I will continue working on this, but for now, the compilation time is much more reasonable.&lt;/p&gt;
&lt;p&gt;I hope the two main facts in this article were interesting. If you have similar experience, comments or ideas for further improvements, I'd be glad to discuss them with you in the comments :)&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;</description><category>C++</category><category>Compilers</category><category>dll</category><category>etl</category><category>gcc</category><category>Performances</category><guid>http://baptiste-wicht.com/posts/2016/01/improve-dll-and-etl-compile-time-further.html</guid><pubDate>Fri, 29 Jan 2016 16:02:34 GMT</pubDate></item><item><title>Improve ETL compile-time with Precompiled Headers</title><link>http://baptiste-wicht.com/posts/2015/06/improve-etl-compile-time-with-precompiled-headers.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;div&gt;&lt;p&gt;Very recently, I started trying to improve the compile-time of the ETL test suite. While not critical, it is always better to have tests that compile as fast as possible. In a &lt;a class="reference external" href="http://baptiste-wicht.com/posts/2015/06/how-i-improved-a-bit-compile-time-of-etl.html"&gt;previous post&lt;/a&gt;, I was able to improve the time a bit by improve the makefile, using pragra once and avoiding &lt;cite&gt;&amp;lt;iostream&amp;gt;&lt;/cite&gt; headers. With these techniques, I reduced the compile-time from 87.5 to 84.1, which is not bad, but not as good as I would have expected.&lt;/p&gt;
&lt;p&gt;In the previous, I had not tried to use Precompiled Headers (PCH) to improve the compile time, so I thought it would be a good time to do it.&lt;/p&gt;
&lt;div class="section" id="precompiled-headers"&gt;
&lt;h2&gt;Precompiled Headers&lt;/h2&gt;
&lt;p&gt;Precompiled Headers are an option of the compiler, where one header gets compiled. Normally, you only compile source files into object files, but you can also compile headers, although it is not the same thing. When a compiler compiles a header, it can do a lot of preprocessing (macros, includes, AST, symbols) and then store all the results into a precompiled header file. Once you compile the source files, the compiler will try to use the precompiled header file instead of the real header file. Of course, this can breaks the C++ standard since with that a header can not have different behaviour based on macros for instance. For these reasons (and probably implementation reasons as well), precompiled headers are really limited.&lt;/p&gt;
&lt;p&gt;If we take the case of G++, G++ will consider the precompiled header file instead of the standard header only if (for a complete list, take a look at the GCC docs):&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;The same compilation flags are the same between the two compilations&lt;/li&gt;
&lt;li&gt;The same compiler binary is used for the compilations&lt;/li&gt;
&lt;li&gt;Only one precompiled header can be used in each compilation&lt;/li&gt;
&lt;li&gt;The same macros must be defined&lt;/li&gt;
&lt;li&gt;The include of the header must be before every possible C/C++ token&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If all these conditions are met and you try to &lt;cite&gt;#include "header.hpp&lt;/cite&gt; and there is a header.hpp.gch (the precompiled file) available in the search path, then the precompiled header will be taken instead of the standard one.&lt;/p&gt;
&lt;p&gt;With clang, it is a bit different because the precompiled header cannot be included automatically, but has to be included explicitely in the source code, meaning you have to modify your code for this technique to work. This is a bad thing in my opinion, you never should have to modify your code to profit from a compiler feature. This is why I haven't used and don't plan to use precompiled headers with clang.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="how-to"&gt;
&lt;h2&gt;How-to&lt;/h2&gt;
&lt;p&gt;Once you know all the conditions for a precompiled header to be automatically included, it is quite straightforward to use them.&lt;/p&gt;
&lt;p&gt;To generate a PCH file is easy:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
g++ options header.hpp
&lt;/pre&gt;
&lt;p&gt;This will generate header.hpp.gch. When you compile your source file using header.hpp, you don't have anything to do, you just have to compile it as usually and if all the conditions are met, the PCH file will be used instead of the other header.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="results-and-conclusion"&gt;
&lt;h2&gt;Results and conclusion&lt;/h2&gt;
&lt;p&gt;I added precompiled header support into my &lt;a class="reference external" href="https://github.com/wichtounet/make-utils"&gt;make-utils&lt;/a&gt; collection of Makefile utilities and tested it on ETL. I have precompiled a header that itself included Catch and ETL. Almost all test files are including this header. With this change, I went from 84 seconds to 78seconds. Headers are taking 1.5seconds to be precompiled. This is a nice result I think. If your application is not as template-heavy as mine or if you have more source files, you should expect better improvements.&lt;/p&gt;
&lt;p&gt;To conclude, even if precompiled headers are a sound way to reduce compile-time, they are really limited to some cases. I'm not a fan of the feature overally. It is not portable between compilers and not standard. Anyway, if you are really in need of saving some time, you should not hesitate too much ;)&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;</description><category>C++</category><category>Compilers</category><category>etl</category><category>gcc</category><category>Performances</category><guid>http://baptiste-wicht.com/posts/2015/06/improve-etl-compile-time-with-precompiled-headers.html</guid><pubDate>Sat, 20 Jun 2015 13:08:31 GMT</pubDate></item><item><title>How I improved (a bit) compile time of ETL ?</title><link>http://baptiste-wicht.com/posts/2015/06/how-i-improved-a-bit-compile-time-of-etl.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;div&gt;&lt;p&gt;Recently I read several articles about C++ and compile time and I wondered if I could improve the compile time of my Expression Template Library (ETL) project. ETL is a header-only and template-heavy library. I'm not going to the change the design completely or to use type erasure techniques to reduce the compile time, ETL is all about performance.&lt;/p&gt;
&lt;p&gt;As a disclaimer, don't expect fancy results from this post, I haven't been able to reduce compile time a lot, but I still wanted to share my experience.&lt;/p&gt;
&lt;p&gt;I've used g++-4.9.2 to perform these tests.&lt;/p&gt;
&lt;p&gt;I'm compiling the complete test suite (around 6900 source lines of codes in 36 files) in release mode. Each test file includes the ETL (around 10K SLOC). Each test is run with 8 threads (make -j8). For each result, I have run a complete build 5 times and taken the best result as the final result. Everything is run on a SSD and I have more than enough RAM to handle all the compilation in parallel.&lt;/p&gt;
&lt;p&gt;The reference build time was 87.5 seconds.&lt;/p&gt;
&lt;div class="section" id="compile-and-generate-dependency-files-at-the-same-time"&gt;
&lt;h2&gt;Compile and generate dependency files at the same time&lt;/h2&gt;
&lt;p&gt;To help write my makefiles, I'm using a set of functions that I have written. This includes automatic dependency generation using -MM -MT options of the compiler. Until now, I had two targets, one to compile the cpp file into the object file and another one to generate the dependency file. I recently saw that compilers were able to do both at the same time! Clang, G++ and the Intel compiler all have a -MD -MF options that lets you generate the dependency file at the same time you compile your file, saving you at least one read of the file.&lt;/p&gt;
&lt;p&gt;My compilation rule in my makefile has now become:&lt;/p&gt;
&lt;pre class="code makefile"&gt;&lt;a name="rest_code_9717aa8f02364e18a48365b1430e7c32-1"&gt;&lt;/a&gt;&lt;span class="nf"&gt;release/$(1)/%.cpp.o&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;)&lt;/span&gt;/%.&lt;span class="n"&gt;cpp&lt;/span&gt;
&lt;a name="rest_code_9717aa8f02364e18a48365b1430e7c32-2"&gt;&lt;/a&gt;    @ mkdir -p release/&lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;)&lt;/span&gt;/
&lt;a name="rest_code_9717aa8f02364e18a48365b1430e7c32-3"&gt;&lt;/a&gt;    &lt;span class="k"&gt;$(&lt;/span&gt;CXX&lt;span class="k"&gt;)&lt;/span&gt; &lt;span class="k"&gt;$(&lt;/span&gt;CXX_FLAGS&lt;span class="k"&gt;)&lt;/span&gt; &lt;span class="k"&gt;$(&lt;/span&gt;RELEASE_FLAGS&lt;span class="k"&gt;)&lt;/span&gt; &lt;span class="k"&gt;$(&lt;/span&gt;2&lt;span class="k"&gt;)&lt;/span&gt; -MD -MF release/&lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;)&lt;/span&gt;/&lt;span class="nv"&gt;$$&lt;/span&gt;*.cpp.d -o release/&lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;)&lt;/span&gt;/&lt;span class="nv"&gt;$$&lt;/span&gt;*.cpp.o -c &lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;)&lt;/span&gt;/&lt;span class="nv"&gt;$$&lt;/span&gt;*.cpp
&lt;a name="rest_code_9717aa8f02364e18a48365b1430e7c32-4"&gt;&lt;/a&gt;    @ sed -i -e &lt;span class="s1"&gt;'s@^\(.*\)\.o:@\1.d \1.o:@'&lt;/span&gt; release/&lt;span class="k"&gt;$(&lt;/span&gt;1&lt;span class="k"&gt;)&lt;/span&gt;/&lt;span class="nv"&gt;$$&lt;/span&gt;*.cpp.d
&lt;/pre&gt;&lt;p&gt;This reduced the compilation time to 86.8 seconds. Not that much reduction, but it still is quite nice to know that. I would have expected this to reduce more the compile time.&lt;/p&gt;
&lt;div class="section" id="use-pragma-once"&gt;
&lt;h3&gt;Use #pragma once&lt;/h3&gt;
&lt;p&gt;Normally, I'm not a fan of #pragma since it is not standard, but for now ETL only supports three compilers and only very recent of them, so I have the guarantee that #pragma once is available, so what the hell!&lt;/p&gt;
&lt;p&gt;I've replaced all the include guards by single #pragma once directives.&lt;/p&gt;
&lt;p&gt;Again, the results are not impressive, this reduced the compile time to 86.2 seconds. I would only advise to use this if you are sure of the compilers you want to support and you need the extra time.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="avoid-iostream"&gt;
&lt;h3&gt;Avoid &amp;lt;iostream&amp;gt;&lt;/h3&gt;
&lt;p&gt;I've read that the &amp;lt;iostream&amp;gt; header was one of the slowest to compile of the STL. It is only one that is included several times in my headers only for stream operators and it turns out that there is a &amp;lt;iosfwd&amp;gt; header that forward declares a lot of things from the &amp;lt;iostream&amp;gt; and other I/O headers.&lt;/p&gt;
&lt;p&gt;By replacing all &amp;lt;iostream&amp;gt; include by &amp;lt;iosfwd&amp;gt;, compile time has gone down to 84.1 seconds.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="conclusion"&gt;
&lt;h3&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;By using the three techniques, I've reduced the compile time from 87.5 to 84.1 seconds. I would have honestly hoped for more improvements, but this is a already a good start.&lt;/p&gt;
&lt;p&gt;As a side note, clang compile time is 45.2 seconds under the same conditions (was 46.2 seconds before the optimizations). It is really much faster :) I'm still using GCC a lot since in several cases, it does generate much better code and in average, the generated code if faster (on my benchmarks at least). I don't have the numbers for icc, but icc is definitely the slowest of the three. When I have it available (at work), I use for release build before running something. The generated executables are generally faster (I only use Intel processors) and sometimes the difference can be quite important.&lt;/p&gt;
&lt;p&gt;If you have ideas to reduce further the compile time on this test case, I'd be glad to hear them and put them to the test.&lt;/p&gt;
&lt;p&gt;I hope that this small experience would be helpful to some of you :)&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="other-techniques"&gt;
&lt;h3&gt;Other techniques&lt;/h3&gt;
&lt;p&gt;There are several other techniques that you can use to reduce compile time:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Precompiled Headers are supported by both Clang and GCC, altough not in a compatible. I haven't tested this in a while, but it is quite effective and a very interesting technique. The main problem with this is that is not standard and not compatible between compilers. But it probably is the most efficient techniques when you have lots of headers and lots of templates as in my case.&lt;/li&gt;
&lt;li&gt;Unity builds can make full rebuild much faster. I personally don't like unity builds especially because it is only really good for full builds and you generally don't do full rebuilds that much (I know, I know, this is also the test done in this article :) ). Moreover, it also sucks at doing parallel builds.&lt;/li&gt;
&lt;li&gt;Pimpl idioms and other type erasure techniques can reduce compile time a lot. If it is well done, it can be implemented without so much overhead.&lt;/li&gt;
&lt;li&gt;Explicit instantiation of templates can also help, but only in the case of a user program. In the case of a library itself, you cannot do anything.&lt;/li&gt;
&lt;li&gt;Reduce inclusions and use forward declarations, obviously...&lt;/li&gt;
&lt;li&gt;Use tools like distcc (I very rarely use it) and ccache (I generally use it).&lt;/li&gt;
&lt;li&gt;Update your compiler&lt;/li&gt;
&lt;li&gt;Upgrade your computer ;)&lt;/li&gt;
&lt;li&gt;...&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;</description><category>C++</category><category>Compilers</category><category>gcc</category><category>Performance</category><guid>http://baptiste-wicht.com/posts/2015/06/how-i-improved-a-bit-compile-time-of-etl.html</guid><pubDate>Tue, 16 Jun 2015 20:00:21 GMT</pubDate></item><item><title>GCC 4.7 vs CLang 3.1 on eddic</title><link>http://baptiste-wicht.com/posts/2012/11/gcc-4-7-clang-3-1-eddic.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;div&gt;&lt;script type="text/javascript" src="http://www.google.com/jsapi"&gt;&lt;/script&gt;

&lt;script type="text/javascript"&gt;google.load('visualization','1',{packages:['corechart']});&lt;/script&gt;

&lt;p&gt;&lt;a href="http://www.baptiste-wicht.com/2012/11/eddic-compiles-with-clang-3-1/" title="eddic compiles with CLang 3.1"&gt;Now that eddic can be compiled with CLang&lt;/a&gt;, I wanted to compare the differences in compilation time and in performance of the generated executable between those two compilers. The tests are done using GCC 4.7.2 and CLang 3.1 on Gentoo.
&lt;/p&gt;&lt;h3&gt;Compilation Time&lt;/h3&gt;
&lt;p&gt;The first thing that I tested has been the compilation time of the two compilers to compile eddic with different flags. I tested the compilation in debug mode and with -O2 and -O3.&lt;/p&gt;
&lt;div id="graph_0" style="width: 400px; height: 300px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_0" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_0(){var graph=new google.visualization.ColumnChart(document.getElementById('graph_0'));var data=google.visualization.arrayToDataTable([['Options','GCC','CLang'],['-g',234.59,119.59],['-O2',273.02,178.22],['-O3',276.87,183.78],]);var options={title:"Compilation Time - Less is better",animation:{duration:1200,easing:"in"},width:'400px',height:'300px',hAxis:{title:"Options"},vAxis:{title:"Seconds",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_0');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;The most interesting fact in these results is that CLang is much faster than GCC. It takes twice less times to compile eddic with CLang in debug mode than with GCC. The impact on optimizations on CLang's compilation is also more important than on GCC. For both compilers, -O3 does not seems to add a lot of overhead.&lt;/p&gt;
&lt;h3&gt;Runtime performance&lt;/h3&gt;

&lt;p&gt;Then, I tested the performance of the generated executable. I tested it on three things, the whole test suite and two test cases that I know are the slowest for the EDDI Compiler. For each case, I took the slowest value of 5 consecutive executions. &lt;/p&gt;
&lt;div id="graph_1" style="width: 600px; height: 400px;"&gt;&lt;/div&gt;

&lt;p&gt;&lt;input id="button_graph_1" type="button" value="Logarithmic scale"&gt;&lt;script type="text/javascript"&gt;function draw_graph_1(){var graph=new google.visualization.ColumnChart(document.getElementById('graph_1'));var data=google.visualization.arrayToDataTable([['Compiler','GCC -O2','GCC -O3','CLang -O2','CLang -O3'],['testsuite',6.58,6.59,6.74,6.58],['assembly',1.2,1.2,1.2,1.2],['linked_list',0.51,0.5,0.49,0.49],]);var options={title:"Runtime Performance - Less is better",animation:{duration:1200,easing:"in"},width:'600px',height:'400px',hAxis:{title:"Options"},vAxis:{title:"Seconds",viewWindow:{min:0}}};graph.draw(data,options);var button=document.getElementById('button_graph_1');button.onclick=function(){if(options.vAxis.logScale){button.value="Logarithmic Scale";}else{button.value="Normal scale";}options.vAxis.logScale=!options.vAxis.logScale;graph.draw(data,options);};}&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;The difference are very small. In -02, GCC performs a bit better, but in -O3, the performance are equivalent. I was a bit disappointed by the results, because I thought that there would be higher differences. It seems that CLang is not as far from GCC that some people would like to say. It also certainly depends on the program being compiled. &lt;/p&gt;
&lt;h3&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;It is clear that CLang is much faster than GCC to compile eddic. Moreover, the performance of the generated executable are almost similar. &lt;/p&gt;
&lt;p&gt;I will continue to use CLang as my development compiler and switches between the two when I'm doing performance benchmarking. I will try to update the benchmark once new versions of GCC / CLang are available.&lt;/p&gt;
&lt;script type="text/javascript"&gt;function draw_visualization(){draw_graph_0();draw_graph_1();}google.setOnLoadCallback(draw_visualization);&lt;/script&gt;&lt;/div&gt;</description><category>Benchmarks</category><category>clang</category><category>Compilers</category><category>EDDI</category><category>gcc</category><category>Performances</category><guid>http://baptiste-wicht.com/posts/2012/11/gcc-4-7-clang-3-1-eddic.html</guid><pubDate>Mon, 12 Nov 2012 08:28:44 GMT</pubDate></item><item><title>eddic compiles with CLang 3.1</title><link>http://baptiste-wicht.com/posts/2012/11/eddic-compiles-with-clang-3-1.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;div&gt;&lt;p&gt;I finally added support for compiling eddic with LLVM CLang 3.1 !&lt;/p&gt;
&lt;p&gt;The current development version can be completely compiled with CLang. Starting with the version 1.1.4, all versions of eddic will be support GCC and CLang. &lt;/p&gt;
&lt;p&gt;The changes have not been as painful as I first thought. &lt;/p&gt;
&lt;ul&gt;
    &lt;li&gt;The main problem that I has was about a static const variable of a class that had no user-constructor. GCC allows that, but it is not standard compliant and CLang was complaining. &lt;/li&gt;
    &lt;li&gt;Another problem that I encountered was about the used of bit flags and Template Meta Programming. I simplified that by the use of a simple type traits and it worked. I don't really know why this does not worked at first. &lt;/li&gt;
    &lt;li&gt;The remaining effort was to fix the several warnings that CLang had. &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;CLang also fixed a bug in my code with a warning on a assignment that was not supposed to be an assignment, thanks CLang. &lt;/p&gt;
&lt;p&gt;The most interesting fact about CLang is that &lt;strong&gt;is it twice faster to build eddic than GCC&lt;/strong&gt;. I think I'm gonna use it during development to fasten the compile time. Moreover, even if I only worked two days with it, it seems that the error messages are indeed better than the GCC's ones. &lt;/p&gt;
&lt;p&gt;I haven't tried to compare the performances of eddic in both cases, but I will do that in the future, soon after the 1.1.4 version is released. &lt;/p&gt;
&lt;p&gt;I tried the CLang static analyzer on eddic but it didn't found any bugs. Moreover, it crashed on several of my files. I didn't found why for now, but I will continue to investigate, perhaps I'm not using it correctly. &lt;/p&gt;
&lt;p&gt;I expect to publish the next version of eddic in the next two weeks. This version has much more improvements that I thought at first and I have less time to work now that &lt;a href="http://www.baptiste-wicht.com/2012/09/back-in-berkeley-california/" title="Back in Berkeley, California" target="_blank"&gt;I'm working on my Master thesis&lt;/a&gt;. &lt;/p&gt;
&lt;p&gt;More informations on CLang: &lt;a href="http://clang.llvm.org/" title="CLang official site"&gt;The official site&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;</description><category>clang</category><category>Compilers</category><category>EDDI</category><category>gcc</category><category>Linux</category><guid>http://baptiste-wicht.com/posts/2012/11/eddic-compiles-with-clang-3-1.html</guid><pubDate>Thu, 01 Nov 2012 08:11:05 GMT</pubDate></item><item><title>Back in Berkeley, California</title><link>http://baptiste-wicht.com/posts/2012/09/back-in-berkeley-california.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;div&gt;&lt;p&gt;I arrived yesterday to Berkeley, California.&lt;/p&gt;
&lt;p&gt;Just like I did my Bachelor thesis in Lawrence Berkeley National Laboratory (LBNL), I will do my Master Thesis there too. The thesis will last a bit less than a semester.&lt;/p&gt;
&lt;p&gt;During my Master Thesis I will try to use profiling samples from the Linux perf tools in GCC or Clang to optimize processor cache usage (avoid cache and page faults).&lt;/p&gt;
&lt;p&gt;I will try to publish some posts about that during the semester if I have time.&lt;/p&gt;&lt;/div&gt;</description><category>Compilers</category><category>gcc</category><category>Others</category><category>Personal</category><category>The site</category><guid>http://baptiste-wicht.com/posts/2012/09/back-in-berkeley-california.html</guid><pubDate>Thu, 13 Sep 2012 08:35:43 GMT</pubDate></item><item><title>Install the Insight Debugger on Linux Mint (works for Ubuntu too)</title><link>http://baptiste-wicht.com/posts/2012/01/install-insight-debugger-linux-mint-ubuntu.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;div&gt;&lt;p&gt;Insight is a very good debugger based on gdb. I prefer it over ddd or kdbg as I find it clearer and easier to use. Moreover, this debugger is also the one used in the book &lt;strong&gt;Assembly language Step by Step, for Linux&lt;/strong&gt;. However, Insight has been removed from Debian packages already more than a year ago. &lt;/p&gt;
&lt;p&gt;But, thanks to SevenMachines, a PPA repository is available to install it on Linux Mint (works also on Ubuntu and Ubuntu-based Linux distributions). &lt;/p&gt;
&lt;p&gt;To add the repository to your apt sources, add the following lines to the /etc/apt/sources.list file:&lt;/p&gt;
&lt;pre&gt;deb http://ppa.launchpad.net/sevenmachines/dev/ubuntu natty main 
deb-src http://ppa.launchpad.net/sevenmachines/dev/ubuntu natty main &lt;/pre&gt;

&lt;p&gt;and update your apt sources: &lt;/p&gt;
&lt;pre&gt;sudo apt-get update&lt;/pre&gt;

&lt;p&gt;Then you can install insight: &lt;/p&gt;
&lt;pre&gt;sudo apt-get install insight&lt;/pre&gt;

&lt;p&gt;And now you are ready to use Insight as your debugger. &lt;/p&gt;
&lt;p&gt;If you don't trust this PPA repository, you can also try it to install it from the sources (http://sources.redhat.com/insight/), but doesn't seem to very simple to install it. I wasn't able to build it on my Linux Mint 12.&lt;/p&gt;&lt;/div&gt;</description><category>Assembly</category><category>C++</category><category>gcc</category><category>Linux</category><category>Mint</category><category>Tools</category><guid>http://baptiste-wicht.com/posts/2012/01/install-insight-debugger-linux-mint-ubuntu.html</guid><pubDate>Thu, 26 Jan 2012 08:28:41 GMT</pubDate></item><item><title>Diploma Thesis : Inlining Assistance for large-scale object-oriented applications</title><link>http://baptiste-wicht.com/posts/2011/10/diploma-thesis-inlining-assistance-for-large-scale-object-oriented-applications.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;div&gt;&lt;p&gt;One month ago, my diploma thesis has been accepted and I got my Bachelor of Science in Computer Science.&lt;/p&gt;
&lt;p&gt;I made my diploma thesis at Lawrence Berkeley National Laboratory, Berkeley, California. I was in the team responsible of the developmenet of the ATLAS Software for the LHC in Cern. The title of my thesis is &lt;strong&gt;Inlining Assistance for large-scale object-oriented applications&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The goal of this project was to create a C++ analyzer to find the best functions and call sites to inline. The input of the analyzer is a call graph generated by CallGrind of the Valgrind project.&lt;/p&gt;
&lt;p&gt;The functions and call sites to inline are computed using a heuristic, called the temperature. This heuristic is based on the cost of calling the given function, the frequency of calls and the size of the function. The cost of calling a function is based on the number of parameters, the virtuality of the function and the shared object the function is located in.&lt;/p&gt;
&lt;p&gt;The analyzer is also able to find clusters of call sites. A cluster is a set of hot call sites related to each other. It can also finds the functions that should be moved from one library to the other or the function that should not be virtual by testing the use of each function in a class hierarchy.&lt;/p&gt;
&lt;p&gt;To achieve this project, it has been necessary to study in details how a function is called on the Linux platform. The inlining optimization has also been studied to know what were the advantages and the problems of this technique.&lt;/p&gt;
&lt;p&gt;To retrieve the information about the sizes and the virtuality of the function, it has been necessary to read the shared libraries and executables files. For that, we used &lt;em&gt;libelf&lt;/em&gt;. The virtuality of a function is calculated by reading each virtual table and searching for the function in the virtual tables content.&lt;/p&gt;
&lt;p&gt;The graph manipulation is made by the &lt;em&gt;Boost Graph Library&lt;/em&gt;. As it was an advanced library, it has helped me improving my skills in specific topics like templates, traits or Template Metaprogramming.&lt;/p&gt;
&lt;p&gt;The analyzer is able to run on the Linux platform on any program that has been compiled using gcc.&lt;/p&gt;
&lt;p class="more"&gt;&lt;a href="http://baptiste-wicht.com/posts/2011/10/diploma-thesis-inlining-assistance-for-large-scale-object-oriented-applications.html"&gt;Read more…&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;</description><category>Boost</category><category>C++</category><category>Compilers</category><category>gcc</category><category>Linux</category><category>Optimization</category><category>Performances</category><category>Personal</category><guid>http://baptiste-wicht.com/posts/2011/10/diploma-thesis-inlining-assistance-for-large-scale-object-oriented-applications.html</guid><pubDate>Mon, 03 Oct 2011 06:44:17 GMT</pubDate></item><item><title>How to install a specific version of GCC on Ubuntu 11.04 (natty)</title><link>http://baptiste-wicht.com/posts/2011/06/install-specific-version-gcc-ubuntu.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;div&gt;&lt;p&gt;Sometimes you need to install a specific version of gcc for some reasons, for example when you need to have the same compiler version as the one used by your team. &lt;/p&gt;
&lt;p&gt;In that, the package manager doesn't help because not every version of gcc is packaged in every version of Ubuntu. So you must install it by hand and it can take a little time and there is some things that has to be done in order to work. &lt;/p&gt;
&lt;p&gt;I'm talking here of Ubuntu 11.04 (natty), because this is the version I installed Ubuntu on. This procedure will certainly work but you could have a problem with some dependencies that are installed in natty and not in your version or in the contrary have a dependency already installed. &lt;/p&gt;
&lt;p&gt;So this article will detail every step to install a specific version of gcc &lt;/p&gt;
&lt;p class="more"&gt;&lt;a href="http://baptiste-wicht.com/posts/2011/06/install-specific-version-gcc-ubuntu.html"&gt;Read more…&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;</description><category>C++</category><category>gcc</category><category>Linux</category><guid>http://baptiste-wicht.com/posts/2011/06/install-specific-version-gcc-ubuntu.html</guid><pubDate>Fri, 17 Jun 2011 06:18:29 GMT</pubDate></item></channel></rss>