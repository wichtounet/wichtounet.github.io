<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" version="2.0"><channel><title>Blog blog("Baptiste Wicht"); (Posts about Machine Learning)</title><link>http://baptiste-wicht.com/</link><description></description><atom:link rel="self" href="http://baptiste-wicht.com/categories/machine-learning.xml" type="application/rss+xml"></atom:link><language>en</language><lastBuildDate>Fri, 24 Nov 2017 15:16:30 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Initial support for Long Short Term Memory (LSTM) in DLL</title><link>http://baptiste-wicht.com/posts/2017/11/initial-support-for-long-short-term-memory-lstm-in-dll.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;div&gt;&lt;p&gt;I'm really happy to announce that I just merged support for&lt;/p&gt;
&lt;p&gt;Long Short Term Memory
(LSTM) cells into my Deep Learning Library (DLL) machine learning framework. Two
weeks ago, &lt;a href="http://baptiste-wicht.com/posts/2017/11/initial-support-for-long-short-term-memory-lstm-in-dll.html#id1"&gt;&lt;span class="problematic" id="id2"&gt;`I already merged suport for Recurrent Neural network (RNN) https://baptiste-wicht.com/posts/2017/11/initial-support-for-recurrent-neural-network-rnn-in-dll.html&amp;gt;`_&lt;/span&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;It's nothing fancy yet, but forward propagation of LSTM and basic
Backpropagation Through Time (BPTT) are now supported. It was not really
complicated to implemenet the forward pass but the backward pass is much
complicated for an LSTM than for a RNN. It took me quite a long time to figure
out all the gradients formulas and the documentation on that is quite scarce.&lt;/p&gt;
&lt;p&gt;For now, still only existing classification loss is supported for RNN and LSTM.
As I said last time, I still plan to add support for sequence-to-sequence loss
in order to be able to train models able to generate characters. However, I don't
know when I'll be able to work on that. Now that I've got the code for LSTM,
I should be able to implement a GRU cell and NAS cell quite easily I believe.&lt;/p&gt;
&lt;p&gt;For example, here is a simple LSTM used on MNIST for classification:&lt;/p&gt;
&lt;pre class="code cpp"&gt;&lt;a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-1"&gt;&lt;/a&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;"dll/neural/dense_layer.hpp"&lt;/span&gt;&lt;span class="cp"&gt;&lt;/span&gt;
&lt;a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-2"&gt;&lt;/a&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;"dll/neural/lstm_layer.hpp"&lt;/span&gt;&lt;span class="cp"&gt;&lt;/span&gt;
&lt;a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-3"&gt;&lt;/a&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;"dll/neural/recurrent_last_layer.hpp"&lt;/span&gt;&lt;span class="cp"&gt;&lt;/span&gt;
&lt;a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-4"&gt;&lt;/a&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;"dll/network.hpp"&lt;/span&gt;&lt;span class="cp"&gt;&lt;/span&gt;
&lt;a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-5"&gt;&lt;/a&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;"dll/datasets.hpp"&lt;/span&gt;&lt;span class="cp"&gt;&lt;/span&gt;
&lt;a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-6"&gt;&lt;/a&gt;
&lt;a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-7"&gt;&lt;/a&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="cm"&gt;/*argc*/&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;char&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="cm"&gt;/*argv*/&lt;/span&gt; &lt;span class="p"&gt;[])&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-8"&gt;&lt;/a&gt;    &lt;span class="c1"&gt;// Load the dataset&lt;/span&gt;
&lt;a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-9"&gt;&lt;/a&gt;    &lt;span class="k"&gt;auto&lt;/span&gt; &lt;span class="n"&gt;dataset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;make_mnist_dataset_nc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;{},&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;scale_pre&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;255&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;{});&lt;/span&gt;
&lt;a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-10"&gt;&lt;/a&gt;
&lt;a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-11"&gt;&lt;/a&gt;    &lt;span class="k"&gt;constexpr&lt;/span&gt; &lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;time_steps&lt;/span&gt;      &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;28&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-12"&gt;&lt;/a&gt;    &lt;span class="k"&gt;constexpr&lt;/span&gt; &lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;sequence_length&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;28&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-13"&gt;&lt;/a&gt;    &lt;span class="k"&gt;constexpr&lt;/span&gt; &lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;hidden_units&lt;/span&gt;    &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-14"&gt;&lt;/a&gt;
&lt;a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-15"&gt;&lt;/a&gt;    &lt;span class="c1"&gt;// Build the network&lt;/span&gt;
&lt;a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-16"&gt;&lt;/a&gt;
&lt;a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-17"&gt;&lt;/a&gt;    &lt;span class="k"&gt;using&lt;/span&gt; &lt;span class="n"&gt;network_t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dyn_network_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;
&lt;a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-18"&gt;&lt;/a&gt;        &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;network_layers&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;
&lt;a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-19"&gt;&lt;/a&gt;            &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;lstm_layer&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;time_steps&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sequence_length&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;hidden_units&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;last_only&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-20"&gt;&lt;/a&gt;            &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;recurrent_last_layer&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;time_steps&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;hidden_units&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-21"&gt;&lt;/a&gt;            &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dense_layer&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;hidden_units&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;softmax&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-22"&gt;&lt;/a&gt;        &lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-23"&gt;&lt;/a&gt;        &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;updater&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;updater_type&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;ADAM&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;      &lt;span class="c1"&gt;// Adam&lt;/span&gt;
&lt;a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-24"&gt;&lt;/a&gt;        &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;                       &lt;span class="c1"&gt;// The mini-batch size&lt;/span&gt;
&lt;a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-25"&gt;&lt;/a&gt;    &lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;network_t&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-26"&gt;&lt;/a&gt;
&lt;a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-27"&gt;&lt;/a&gt;    &lt;span class="k"&gt;auto&lt;/span&gt; &lt;span class="n"&gt;net&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;make_unique&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;network_t&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-28"&gt;&lt;/a&gt;
&lt;a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-29"&gt;&lt;/a&gt;    &lt;span class="c1"&gt;// Display the network and dataset&lt;/span&gt;
&lt;a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-30"&gt;&lt;/a&gt;    &lt;span class="n"&gt;net&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;display&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-31"&gt;&lt;/a&gt;    &lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;display&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-32"&gt;&lt;/a&gt;
&lt;a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-33"&gt;&lt;/a&gt;    &lt;span class="c1"&gt;// Train the network for performance sake&lt;/span&gt;
&lt;a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-34"&gt;&lt;/a&gt;    &lt;span class="n"&gt;net&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;fine_tune&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-35"&gt;&lt;/a&gt;
&lt;a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-36"&gt;&lt;/a&gt;    &lt;span class="c1"&gt;// Test the network on test set&lt;/span&gt;
&lt;a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-37"&gt;&lt;/a&gt;    &lt;span class="n"&gt;net&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;evaluate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;test&lt;/span&gt;&lt;span class="p"&gt;());&lt;/span&gt;
&lt;a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-38"&gt;&lt;/a&gt;
&lt;a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-39"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-40"&gt;&lt;/a&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;The network is quite similar to the one used previously with an RNN, just
replace rnn with lstm and that's it. It starts with LSTM layer, followed by
a layer extracting the last time step and finally a dense layer with a softmax
function. The network is trained with Adam for 50 epochs. You can change the
activation function , the initializer for the weights and the biases and number
of steps for BPTT truncation.&lt;/p&gt;
&lt;p&gt;Here is the result I got on my last run:&lt;/p&gt;
&lt;pre class="code text"&gt;&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-1"&gt;&lt;/a&gt;------------------------------------------------------------
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-2"&gt;&lt;/a&gt;| Index | Layer                | Parameters | Output Shape |
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-3"&gt;&lt;/a&gt;------------------------------------------------------------
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-4"&gt;&lt;/a&gt;| 0     | LSTM (TANH) (dyn)    |      51200 | [Bx28x100]   |
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-5"&gt;&lt;/a&gt;| 1     | RNN(last)            |          0 | [Bx100]      |
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-6"&gt;&lt;/a&gt;| 2     | Dense(SOFTMAX) (dyn) |       1000 | [Bx10]       |
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-7"&gt;&lt;/a&gt;------------------------------------------------------------
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-8"&gt;&lt;/a&gt;              Total Parameters:      52200
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-9"&gt;&lt;/a&gt;
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-10"&gt;&lt;/a&gt;--------------------------------------------
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-11"&gt;&lt;/a&gt;| mnist | Size  | Batches | Augmented Size |
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-12"&gt;&lt;/a&gt;--------------------------------------------
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-13"&gt;&lt;/a&gt;| train | 60000 | 600     | 60000          |
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-14"&gt;&lt;/a&gt;| test  | 10000 | 100     | 10000          |
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-15"&gt;&lt;/a&gt;--------------------------------------------
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-16"&gt;&lt;/a&gt;
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-17"&gt;&lt;/a&gt;Network with 3 layers
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-18"&gt;&lt;/a&gt;    LSTM(dyn): 28x28 -&amp;gt; TANH -&amp;gt; 28x100
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-19"&gt;&lt;/a&gt;    RNN(last): 28x100 -&amp;gt; 100
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-20"&gt;&lt;/a&gt;    Dense(dyn): 100 -&amp;gt; SOFTMAX -&amp;gt; 10
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-21"&gt;&lt;/a&gt;Total parameters: 52200
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-22"&gt;&lt;/a&gt;Dataset
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-23"&gt;&lt;/a&gt;Training: In-Memory Data Generator
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-24"&gt;&lt;/a&gt;              Size: 60000
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-25"&gt;&lt;/a&gt;           Batches: 600
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-26"&gt;&lt;/a&gt;Testing: In-Memory Data Generator
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-27"&gt;&lt;/a&gt;              Size: 10000
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-28"&gt;&lt;/a&gt;           Batches: 100
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-29"&gt;&lt;/a&gt;
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-30"&gt;&lt;/a&gt;Train the network with "Stochastic Gradient Descent"
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-31"&gt;&lt;/a&gt;    Updater: ADAM
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-32"&gt;&lt;/a&gt;       Loss: CATEGORICAL_CROSS_ENTROPY
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-33"&gt;&lt;/a&gt; Early Stop: Goal(error)
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-34"&gt;&lt;/a&gt;
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-35"&gt;&lt;/a&gt;With parameters:
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-36"&gt;&lt;/a&gt;          epochs=50
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-37"&gt;&lt;/a&gt;      batch_size=100
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-38"&gt;&lt;/a&gt;   learning_rate=0.001
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-39"&gt;&lt;/a&gt;           beta1=0.9
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-40"&gt;&lt;/a&gt;           beta2=0.999
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-41"&gt;&lt;/a&gt;
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-42"&gt;&lt;/a&gt;epoch   0/50 batch  600/ 600 - error: 0.07943 loss: 0.28504 time 20910ms
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-43"&gt;&lt;/a&gt;epoch   1/50 batch  600/ 600 - error: 0.06683 loss: 0.24021 time 20889ms
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-44"&gt;&lt;/a&gt;epoch   2/50 batch  600/ 600 - error: 0.04828 loss: 0.18233 time 21061ms
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-45"&gt;&lt;/a&gt;epoch   3/50 batch  600/ 600 - error: 0.04407 loss: 0.16665 time 20839ms
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-46"&gt;&lt;/a&gt;epoch   4/50 batch  600/ 600 - error: 0.03515 loss: 0.13290 time 22108ms
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-47"&gt;&lt;/a&gt;epoch   5/50 batch  600/ 600 - error: 0.03207 loss: 0.12019 time 21393ms
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-48"&gt;&lt;/a&gt;epoch   6/50 batch  600/ 600 - error: 0.02973 loss: 0.11239 time 28199ms
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-49"&gt;&lt;/a&gt;epoch   7/50 batch  600/ 600 - error: 0.02653 loss: 0.10455 time 37039ms
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-50"&gt;&lt;/a&gt;epoch   8/50 batch  600/ 600 - error: 0.02482 loss: 0.09657 time 23127ms
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-51"&gt;&lt;/a&gt;epoch   9/50 batch  600/ 600 - error: 0.02177 loss: 0.08422 time 41766ms
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-52"&gt;&lt;/a&gt;epoch  10/50 batch  600/ 600 - error: 0.02453 loss: 0.09382 time 29765ms
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-53"&gt;&lt;/a&gt;epoch  11/50 batch  600/ 600 - error: 0.02575 loss: 0.09796 time 21449ms
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-54"&gt;&lt;/a&gt;epoch  12/50 batch  600/ 600 - error: 0.02107 loss: 0.07833 time 42056ms
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-55"&gt;&lt;/a&gt;epoch  13/50 batch  600/ 600 - error: 0.01877 loss: 0.07171 time 24673ms
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-56"&gt;&lt;/a&gt;epoch  14/50 batch  600/ 600 - error: 0.02095 loss: 0.08481 time 20878ms
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-57"&gt;&lt;/a&gt;epoch  15/50 batch  600/ 600 - error: 0.02040 loss: 0.07578 time 41515ms
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-58"&gt;&lt;/a&gt;epoch  16/50 batch  600/ 600 - error: 0.01580 loss: 0.06083 time 25705ms
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-59"&gt;&lt;/a&gt;epoch  17/50 batch  600/ 600 - error: 0.01945 loss: 0.07046 time 20903ms
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-60"&gt;&lt;/a&gt;epoch  18/50 batch  600/ 600 - error: 0.01728 loss: 0.06683 time 41828ms
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-61"&gt;&lt;/a&gt;epoch  19/50 batch  600/ 600 - error: 0.01577 loss: 0.05947 time 27810ms
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-62"&gt;&lt;/a&gt;epoch  20/50 batch  600/ 600 - error: 0.01528 loss: 0.05883 time 21477ms
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-63"&gt;&lt;/a&gt;epoch  21/50 batch  600/ 600 - error: 0.01345 loss: 0.05127 time 44718ms
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-64"&gt;&lt;/a&gt;epoch  22/50 batch  600/ 600 - error: 0.01410 loss: 0.05357 time 25174ms
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-65"&gt;&lt;/a&gt;epoch  23/50 batch  600/ 600 - error: 0.01268 loss: 0.04765 time 23827ms
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-66"&gt;&lt;/a&gt;epoch  24/50 batch  600/ 600 - error: 0.01342 loss: 0.05004 time 47232ms
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-67"&gt;&lt;/a&gt;epoch  25/50 batch  600/ 600 - error: 0.01730 loss: 0.06872 time 22532ms
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-68"&gt;&lt;/a&gt;epoch  26/50 batch  600/ 600 - error: 0.01337 loss: 0.05016 time 30114ms
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-69"&gt;&lt;/a&gt;epoch  27/50 batch  600/ 600 - error: 0.01842 loss: 0.07049 time 40136ms
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-70"&gt;&lt;/a&gt;epoch  28/50 batch  600/ 600 - error: 0.01262 loss: 0.04639 time 21793ms
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-71"&gt;&lt;/a&gt;epoch  29/50 batch  600/ 600 - error: 0.01403 loss: 0.05292 time 34096ms
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-72"&gt;&lt;/a&gt;epoch  30/50 batch  600/ 600 - error: 0.01185 loss: 0.04456 time 35420ms
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-73"&gt;&lt;/a&gt;epoch  31/50 batch  600/ 600 - error: 0.01098 loss: 0.04180 time 20909ms
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-74"&gt;&lt;/a&gt;epoch  32/50 batch  600/ 600 - error: 0.01337 loss: 0.04687 time 30113ms
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-75"&gt;&lt;/a&gt;epoch  33/50 batch  600/ 600 - error: 0.01415 loss: 0.05292 time 37393ms
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-76"&gt;&lt;/a&gt;epoch  34/50 batch  600/ 600 - error: 0.00982 loss: 0.03615 time 20962ms
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-77"&gt;&lt;/a&gt;epoch  35/50 batch  600/ 600 - error: 0.01178 loss: 0.04830 time 29305ms
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-78"&gt;&lt;/a&gt;epoch  36/50 batch  600/ 600 - error: 0.00882 loss: 0.03408 time 38293ms
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-79"&gt;&lt;/a&gt;epoch  37/50 batch  600/ 600 - error: 0.01148 loss: 0.04341 time 20841ms
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-80"&gt;&lt;/a&gt;epoch  38/50 batch  600/ 600 - error: 0.00960 loss: 0.03701 time 29204ms
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-81"&gt;&lt;/a&gt;epoch  39/50 batch  600/ 600 - error: 0.00850 loss: 0.03094 time 39802ms
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-82"&gt;&lt;/a&gt;epoch  40/50 batch  600/ 600 - error: 0.01473 loss: 0.05136 time 20831ms
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-83"&gt;&lt;/a&gt;epoch  41/50 batch  600/ 600 - error: 0.01007 loss: 0.03579 time 29856ms
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-84"&gt;&lt;/a&gt;epoch  42/50 batch  600/ 600 - error: 0.00943 loss: 0.03370 time 38200ms
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-85"&gt;&lt;/a&gt;epoch  43/50 batch  600/ 600 - error: 0.01205 loss: 0.04409 time 21162ms
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-86"&gt;&lt;/a&gt;epoch  44/50 batch  600/ 600 - error: 0.00980 loss: 0.03674 time 32279ms
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-87"&gt;&lt;/a&gt;epoch  45/50 batch  600/ 600 - error: 0.01068 loss: 0.04133 time 38448ms
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-88"&gt;&lt;/a&gt;epoch  46/50 batch  600/ 600 - error: 0.00913 loss: 0.03478 time 20797ms
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-89"&gt;&lt;/a&gt;epoch  47/50 batch  600/ 600 - error: 0.00985 loss: 0.03759 time 28885ms
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-90"&gt;&lt;/a&gt;epoch  48/50 batch  600/ 600 - error: 0.00912 loss: 0.03295 time 41120ms
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-91"&gt;&lt;/a&gt;epoch  49/50 batch  600/ 600 - error: 0.00930 loss: 0.03438 time 21282ms
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-92"&gt;&lt;/a&gt;Restore the best (error) weights from epoch 39
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-93"&gt;&lt;/a&gt;Training took 1460s
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-94"&gt;&lt;/a&gt;
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-95"&gt;&lt;/a&gt;Evaluation Results
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-96"&gt;&lt;/a&gt;   error: 0.02440
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-97"&gt;&lt;/a&gt;    loss: 0.11315
&lt;a name="rest_code_cac13a9e51474881adc905e6630b17ab-98"&gt;&lt;/a&gt;evaluation took 1000ms
&lt;/pre&gt;&lt;p&gt;Again, nothing fancy yet, but this example has not been optimized for
performance nor for accuracy.&lt;/p&gt;
&lt;p&gt;I also made a few changes to the RNN layer. I added support for biases and
improved the code as well for performance and readability.&lt;/p&gt;
&lt;p&gt;All this support is now in the &lt;strong&gt;master&lt;/strong&gt; branch of the DLL project if you want
to check it out. You can also check out the example online:
&lt;a class="reference external" href="https://github.com/wichtounet/dll/blob/master/examples/src/mnist_lstm.cpp"&gt;mnist_lstm.cpp&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;You can access the project &lt;a class="reference external" href="https://github.com/wichtounet/dll"&gt;on Github&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Currently I'm working on the GPU performance again. The performance of some is
still not as good as I want it to be, especially complex operation like used in
Adam and Nadam. Currently, there are many calls to GPU BLAS libraries and
I want to try to extract some more optimized patterns. Once it's done, I'll post
more on that later on the blog.&lt;/p&gt;
&lt;div class="system-messages section"&gt;
&lt;h2&gt;Docutils System Messages&lt;/h2&gt;
&lt;div class="system-message" id="id1"&gt;
&lt;p class="system-message-title"&gt;System Message: ERROR/3 (&lt;tt class="docutils"&gt;&amp;lt;string&amp;gt;&lt;/tt&gt;, line 3); &lt;em&gt;&lt;a href="http://baptiste-wicht.com/posts/2017/11/initial-support-for-long-short-term-memory-lstm-in-dll.html#id2"&gt;backlink&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
Unknown target name: "i already merged suport for recurrent neural network (rnn) https://baptiste-wicht.com/posts/2017/11/initial-support-for-recurrent-neural-network-rnn-in-dll.html&amp;gt;".&lt;/div&gt;
&lt;/div&gt;&lt;/div&gt;</description><category>deep learning</category><category>dll</category><category>Machine Learning</category><category>projects</category><category>rnn</category><guid>http://baptiste-wicht.com/posts/2017/11/initial-support-for-long-short-term-memory-lstm-in-dll.html</guid><pubDate>Fri, 24 Nov 2017 14:16:37 GMT</pubDate></item><item><title>DLL: Pretty printing and live output</title><link>http://baptiste-wicht.com/posts/2017/11/dll-pretty-printing-and-live-output.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;div&gt;&lt;p&gt;I've improved a lot the display of my Deep Learning Library (DLL). I know this
is generally not the most important point in a machine learning framework, but
the first impression being important. Therefore, I decided it was time to get
a nicer output in the console for training networks.&lt;/p&gt;
&lt;p&gt;A network or a dataset can be displayed using the &lt;code&gt;display()&lt;/code&gt; function.
I've added a &lt;code&gt;display_pretty()&lt;/code&gt; function to them to display it more
nicely. I've also added the &lt;code&gt;dll::dump_timers_nice()&lt;/code&gt; function to do the
same for &lt;code&gt;dll::dump_timers()&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;I've also improved the display for the results of the batches during training.
Now, the display is updated every 100ms and it also displays the current
estimated time until the end of the epoch. With that, the user should have
a much better idea on what's going on during training, especially when training
networks when the epochs are taking a long time to complete.&lt;/p&gt;
&lt;p&gt;Here is a full output of the training of fully-connected network on MNIST
(&lt;cite&gt;mnist_mlp.cpp &amp;lt;https://github.com/wichtounet/dll/blob/master/examples/src/mnist_mlp.cpp&amp;gt;&lt;/cite&gt;):&lt;/p&gt;
&lt;pre class="code bash"&gt;&lt;a name="rest_code_da1bfede7721421f865a0df880090001-1"&gt;&lt;/a&gt; ------------------------------------------------------------
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-2"&gt;&lt;/a&gt; &lt;span class="p"&gt;|&lt;/span&gt; Index &lt;span class="p"&gt;|&lt;/span&gt; Layer                &lt;span class="p"&gt;|&lt;/span&gt; Parameters &lt;span class="p"&gt;|&lt;/span&gt; Output Shape &lt;span class="p"&gt;|&lt;/span&gt;
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-3"&gt;&lt;/a&gt; ------------------------------------------------------------
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-4"&gt;&lt;/a&gt; &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;     &lt;span class="p"&gt;|&lt;/span&gt; Dense&lt;span class="o"&gt;(&lt;/span&gt;SIGMOID&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;dyn&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt;     &lt;span class="m"&gt;392000&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt;Bx500&lt;span class="o"&gt;]&lt;/span&gt;      &lt;span class="p"&gt;|&lt;/span&gt;
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-5"&gt;&lt;/a&gt; &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;     &lt;span class="p"&gt;|&lt;/span&gt; Dropout&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;.50&lt;span class="o"&gt;)(&lt;/span&gt;dyn&lt;span class="o"&gt;)&lt;/span&gt;   &lt;span class="p"&gt;|&lt;/span&gt;          &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt;Bx500&lt;span class="o"&gt;]&lt;/span&gt;      &lt;span class="p"&gt;|&lt;/span&gt;
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-6"&gt;&lt;/a&gt; &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;2&lt;/span&gt;     &lt;span class="p"&gt;|&lt;/span&gt; Dense&lt;span class="o"&gt;(&lt;/span&gt;SIGMOID&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;dyn&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt;     &lt;span class="m"&gt;125000&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt;Bx250&lt;span class="o"&gt;]&lt;/span&gt;      &lt;span class="p"&gt;|&lt;/span&gt;
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-7"&gt;&lt;/a&gt; &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;3&lt;/span&gt;     &lt;span class="p"&gt;|&lt;/span&gt; Dropout&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;.50&lt;span class="o"&gt;)(&lt;/span&gt;dyn&lt;span class="o"&gt;)&lt;/span&gt;   &lt;span class="p"&gt;|&lt;/span&gt;          &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt;Bx250&lt;span class="o"&gt;]&lt;/span&gt;      &lt;span class="p"&gt;|&lt;/span&gt;
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-8"&gt;&lt;/a&gt; &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;4&lt;/span&gt;     &lt;span class="p"&gt;|&lt;/span&gt; Dense&lt;span class="o"&gt;(&lt;/span&gt;SOFTMAX&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;dyn&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt;       &lt;span class="m"&gt;2500&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt;Bx10&lt;span class="o"&gt;]&lt;/span&gt;       &lt;span class="p"&gt;|&lt;/span&gt;
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-9"&gt;&lt;/a&gt; ------------------------------------------------------------
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-10"&gt;&lt;/a&gt;                Total Parameters:     &lt;span class="m"&gt;519500&lt;/span&gt;
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-11"&gt;&lt;/a&gt;
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-12"&gt;&lt;/a&gt; --------------------------------------------
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-13"&gt;&lt;/a&gt; &lt;span class="p"&gt;|&lt;/span&gt; mnist &lt;span class="p"&gt;|&lt;/span&gt; Size  &lt;span class="p"&gt;|&lt;/span&gt; Batches &lt;span class="p"&gt;|&lt;/span&gt; Augmented Size &lt;span class="p"&gt;|&lt;/span&gt;
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-14"&gt;&lt;/a&gt; --------------------------------------------
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-15"&gt;&lt;/a&gt; &lt;span class="p"&gt;|&lt;/span&gt; train &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;60000&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;600&lt;/span&gt;     &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;60000&lt;/span&gt;          &lt;span class="p"&gt;|&lt;/span&gt;
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-16"&gt;&lt;/a&gt; &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="nb"&gt;test&lt;/span&gt;  &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;10000&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;100&lt;/span&gt;     &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;10000&lt;/span&gt;          &lt;span class="p"&gt;|&lt;/span&gt;
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-17"&gt;&lt;/a&gt; --------------------------------------------
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-18"&gt;&lt;/a&gt;
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-19"&gt;&lt;/a&gt;Train the network with &lt;span class="s2"&gt;"Stochastic Gradient Descent"&lt;/span&gt;
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-20"&gt;&lt;/a&gt;    Updater: NADAM
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-21"&gt;&lt;/a&gt;       Loss: CATEGORICAL_CROSS_ENTROPY
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-22"&gt;&lt;/a&gt; Early Stop: Goal&lt;span class="o"&gt;(&lt;/span&gt;error&lt;span class="o"&gt;)&lt;/span&gt;
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-23"&gt;&lt;/a&gt;
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-24"&gt;&lt;/a&gt;With parameters:
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-25"&gt;&lt;/a&gt;          &lt;span class="nv"&gt;epochs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;50&lt;/span&gt;
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-26"&gt;&lt;/a&gt;      &lt;span class="nv"&gt;batch_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;100&lt;/span&gt;
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-27"&gt;&lt;/a&gt;   &lt;span class="nv"&gt;learning_rate&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;.002
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-28"&gt;&lt;/a&gt;           &lt;span class="nv"&gt;beta1&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;.9
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-29"&gt;&lt;/a&gt;           &lt;span class="nv"&gt;beta2&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;.999
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-30"&gt;&lt;/a&gt;
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-31"&gt;&lt;/a&gt;epoch   &lt;span class="m"&gt;0&lt;/span&gt;/50 batch  &lt;span class="m"&gt;600&lt;/span&gt;/ &lt;span class="m"&gt;600&lt;/span&gt; - error: &lt;span class="m"&gt;0&lt;/span&gt;.04623 loss: &lt;span class="m"&gt;0&lt;/span&gt;.15097 &lt;span class="nb"&gt;time&lt;/span&gt; 3230ms
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-32"&gt;&lt;/a&gt;epoch   &lt;span class="m"&gt;1&lt;/span&gt;/50 batch  &lt;span class="m"&gt;600&lt;/span&gt;/ &lt;span class="m"&gt;600&lt;/span&gt; - error: &lt;span class="m"&gt;0&lt;/span&gt;.03013 loss: &lt;span class="m"&gt;0&lt;/span&gt;.09947 &lt;span class="nb"&gt;time&lt;/span&gt; 3188ms
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-33"&gt;&lt;/a&gt;epoch   &lt;span class="m"&gt;2&lt;/span&gt;/50 batch  &lt;span class="m"&gt;600&lt;/span&gt;/ &lt;span class="m"&gt;600&lt;/span&gt; - error: &lt;span class="m"&gt;0&lt;/span&gt;.02048 loss: &lt;span class="m"&gt;0&lt;/span&gt;.06565 &lt;span class="nb"&gt;time&lt;/span&gt; 3102ms
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-34"&gt;&lt;/a&gt;epoch   &lt;span class="m"&gt;3&lt;/span&gt;/50 batch  &lt;span class="m"&gt;600&lt;/span&gt;/ &lt;span class="m"&gt;600&lt;/span&gt; - error: &lt;span class="m"&gt;0&lt;/span&gt;.01593 loss: &lt;span class="m"&gt;0&lt;/span&gt;.05258 &lt;span class="nb"&gt;time&lt;/span&gt; 3189ms
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-35"&gt;&lt;/a&gt;epoch   &lt;span class="m"&gt;4&lt;/span&gt;/50 batch  &lt;span class="m"&gt;600&lt;/span&gt;/ &lt;span class="m"&gt;600&lt;/span&gt; - error: &lt;span class="m"&gt;0&lt;/span&gt;.01422 loss: &lt;span class="m"&gt;0&lt;/span&gt;.04623 &lt;span class="nb"&gt;time&lt;/span&gt; 3160ms
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-36"&gt;&lt;/a&gt;epoch   &lt;span class="m"&gt;5&lt;/span&gt;/50 batch  &lt;span class="m"&gt;600&lt;/span&gt;/ &lt;span class="m"&gt;600&lt;/span&gt; - error: &lt;span class="m"&gt;0&lt;/span&gt;.01112 loss: &lt;span class="m"&gt;0&lt;/span&gt;.03660 &lt;span class="nb"&gt;time&lt;/span&gt; 3131ms
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-37"&gt;&lt;/a&gt;epoch   &lt;span class="m"&gt;6&lt;/span&gt;/50 batch  &lt;span class="m"&gt;600&lt;/span&gt;/ &lt;span class="m"&gt;600&lt;/span&gt; - error: &lt;span class="m"&gt;0&lt;/span&gt;.01078 loss: &lt;span class="m"&gt;0&lt;/span&gt;.03546 &lt;span class="nb"&gt;time&lt;/span&gt; 3200ms
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-38"&gt;&lt;/a&gt;epoch   &lt;span class="m"&gt;7&lt;/span&gt;/50 batch  &lt;span class="m"&gt;600&lt;/span&gt;/ &lt;span class="m"&gt;600&lt;/span&gt; - error: &lt;span class="m"&gt;0&lt;/span&gt;.01003 loss: &lt;span class="m"&gt;0&lt;/span&gt;.03184 &lt;span class="nb"&gt;time&lt;/span&gt; 3246ms
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-39"&gt;&lt;/a&gt;epoch   &lt;span class="m"&gt;8&lt;/span&gt;/50 batch  &lt;span class="m"&gt;600&lt;/span&gt;/ &lt;span class="m"&gt;600&lt;/span&gt; - error: &lt;span class="m"&gt;0&lt;/span&gt;.00778 loss: &lt;span class="m"&gt;0&lt;/span&gt;.02550 &lt;span class="nb"&gt;time&lt;/span&gt; 3222ms
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-40"&gt;&lt;/a&gt;epoch   &lt;span class="m"&gt;9&lt;/span&gt;/50 batch  &lt;span class="m"&gt;600&lt;/span&gt;/ &lt;span class="m"&gt;600&lt;/span&gt; - error: &lt;span class="m"&gt;0&lt;/span&gt;.00782 loss: &lt;span class="m"&gt;0&lt;/span&gt;.02505 &lt;span class="nb"&gt;time&lt;/span&gt; 3119ms
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-41"&gt;&lt;/a&gt;epoch  &lt;span class="m"&gt;10&lt;/span&gt;/50 batch  &lt;span class="m"&gt;600&lt;/span&gt;/ &lt;span class="m"&gt;600&lt;/span&gt; - error: &lt;span class="m"&gt;0&lt;/span&gt;.00578 loss: &lt;span class="m"&gt;0&lt;/span&gt;.02056 &lt;span class="nb"&gt;time&lt;/span&gt; 3284ms
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-42"&gt;&lt;/a&gt;epoch  &lt;span class="m"&gt;11&lt;/span&gt;/50 batch  &lt;span class="m"&gt;600&lt;/span&gt;/ &lt;span class="m"&gt;600&lt;/span&gt; - error: &lt;span class="m"&gt;0&lt;/span&gt;.00618 loss: &lt;span class="m"&gt;0&lt;/span&gt;.02045 &lt;span class="nb"&gt;time&lt;/span&gt; 3220ms
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-43"&gt;&lt;/a&gt;epoch  &lt;span class="m"&gt;12&lt;/span&gt;/50 batch  &lt;span class="m"&gt;600&lt;/span&gt;/ &lt;span class="m"&gt;600&lt;/span&gt; - error: &lt;span class="m"&gt;0&lt;/span&gt;.00538 loss: &lt;span class="m"&gt;0&lt;/span&gt;.01775 &lt;span class="nb"&gt;time&lt;/span&gt; 3444ms
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-44"&gt;&lt;/a&gt;epoch  &lt;span class="m"&gt;13&lt;/span&gt;/50 batch  &lt;span class="m"&gt;600&lt;/span&gt;/ &lt;span class="m"&gt;600&lt;/span&gt; - error: &lt;span class="m"&gt;0&lt;/span&gt;.00563 loss: &lt;span class="m"&gt;0&lt;/span&gt;.01803 &lt;span class="nb"&gt;time&lt;/span&gt; 3304ms
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-45"&gt;&lt;/a&gt;epoch  &lt;span class="m"&gt;14&lt;/span&gt;/50 batch  &lt;span class="m"&gt;600&lt;/span&gt;/ &lt;span class="m"&gt;600&lt;/span&gt; - error: &lt;span class="m"&gt;0&lt;/span&gt;.00458 loss: &lt;span class="m"&gt;0&lt;/span&gt;.01598 &lt;span class="nb"&gt;time&lt;/span&gt; 3577ms
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-46"&gt;&lt;/a&gt;epoch  &lt;span class="m"&gt;15&lt;/span&gt;/50 batch  &lt;span class="m"&gt;600&lt;/span&gt;/ &lt;span class="m"&gt;600&lt;/span&gt; - error: &lt;span class="m"&gt;0&lt;/span&gt;.00437 loss: &lt;span class="m"&gt;0&lt;/span&gt;.01436 &lt;span class="nb"&gt;time&lt;/span&gt; 3228ms
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-47"&gt;&lt;/a&gt;epoch  &lt;span class="m"&gt;16&lt;/span&gt;/50 batch  &lt;span class="m"&gt;600&lt;/span&gt;/ &lt;span class="m"&gt;600&lt;/span&gt; - error: &lt;span class="m"&gt;0&lt;/span&gt;.00360 loss: &lt;span class="m"&gt;0&lt;/span&gt;.01214 &lt;span class="nb"&gt;time&lt;/span&gt; 3180ms
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-48"&gt;&lt;/a&gt;epoch  &lt;span class="m"&gt;17&lt;/span&gt;/50 batch  &lt;span class="m"&gt;600&lt;/span&gt;/ &lt;span class="m"&gt;600&lt;/span&gt; - error: &lt;span class="m"&gt;0&lt;/span&gt;.00405 loss: &lt;span class="m"&gt;0&lt;/span&gt;.01309 &lt;span class="nb"&gt;time&lt;/span&gt; 3090ms
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-49"&gt;&lt;/a&gt;epoch  &lt;span class="m"&gt;18&lt;/span&gt;/50 batch  &lt;span class="m"&gt;600&lt;/span&gt;/ &lt;span class="m"&gt;600&lt;/span&gt; - error: &lt;span class="m"&gt;0&lt;/span&gt;.00408 loss: &lt;span class="m"&gt;0&lt;/span&gt;.01346 &lt;span class="nb"&gt;time&lt;/span&gt; 3045ms
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-50"&gt;&lt;/a&gt;epoch  &lt;span class="m"&gt;19&lt;/span&gt;/50 batch  &lt;span class="m"&gt;600&lt;/span&gt;/ &lt;span class="m"&gt;600&lt;/span&gt; - error: &lt;span class="m"&gt;0&lt;/span&gt;.00337 loss: &lt;span class="m"&gt;0&lt;/span&gt;.01153 &lt;span class="nb"&gt;time&lt;/span&gt; 3071ms
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-51"&gt;&lt;/a&gt;epoch  &lt;span class="m"&gt;20&lt;/span&gt;/50 batch  &lt;span class="m"&gt;600&lt;/span&gt;/ &lt;span class="m"&gt;600&lt;/span&gt; - error: &lt;span class="m"&gt;0&lt;/span&gt;.00297 loss: &lt;span class="m"&gt;0&lt;/span&gt;.01021 &lt;span class="nb"&gt;time&lt;/span&gt; 3131ms
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-52"&gt;&lt;/a&gt;epoch  &lt;span class="m"&gt;21&lt;/span&gt;/50 batch  &lt;span class="m"&gt;600&lt;/span&gt;/ &lt;span class="m"&gt;600&lt;/span&gt; - error: &lt;span class="m"&gt;0&lt;/span&gt;.00318 loss: &lt;span class="m"&gt;0&lt;/span&gt;.01103 &lt;span class="nb"&gt;time&lt;/span&gt; 3076ms
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-53"&gt;&lt;/a&gt;epoch  &lt;span class="m"&gt;22&lt;/span&gt;/50 batch  &lt;span class="m"&gt;600&lt;/span&gt;/ &lt;span class="m"&gt;600&lt;/span&gt; - error: &lt;span class="m"&gt;0&lt;/span&gt;.00277 loss: &lt;span class="m"&gt;0&lt;/span&gt;.00909 &lt;span class="nb"&gt;time&lt;/span&gt; 3090ms
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-54"&gt;&lt;/a&gt;epoch  &lt;span class="m"&gt;23&lt;/span&gt;/50 batch  &lt;span class="m"&gt;600&lt;/span&gt;/ &lt;span class="m"&gt;600&lt;/span&gt; - error: &lt;span class="m"&gt;0&lt;/span&gt;.00242 loss: &lt;span class="m"&gt;0&lt;/span&gt;.00818 &lt;span class="nb"&gt;time&lt;/span&gt; 3163ms
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-55"&gt;&lt;/a&gt;epoch  &lt;span class="m"&gt;24&lt;/span&gt;/50 batch  &lt;span class="m"&gt;600&lt;/span&gt;/ &lt;span class="m"&gt;600&lt;/span&gt; - error: &lt;span class="m"&gt;0&lt;/span&gt;.00267 loss: &lt;span class="m"&gt;0&lt;/span&gt;.00913 &lt;span class="nb"&gt;time&lt;/span&gt; 3229ms
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-56"&gt;&lt;/a&gt;epoch  &lt;span class="m"&gt;25&lt;/span&gt;/50 batch  &lt;span class="m"&gt;600&lt;/span&gt;/ &lt;span class="m"&gt;600&lt;/span&gt; - error: &lt;span class="m"&gt;0&lt;/span&gt;.00295 loss: &lt;span class="m"&gt;0&lt;/span&gt;.00947 &lt;span class="nb"&gt;time&lt;/span&gt; 3156ms
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-57"&gt;&lt;/a&gt;epoch  &lt;span class="m"&gt;26&lt;/span&gt;/50 batch  &lt;span class="m"&gt;600&lt;/span&gt;/ &lt;span class="m"&gt;600&lt;/span&gt; - error: &lt;span class="m"&gt;0&lt;/span&gt;.00252 loss: &lt;span class="m"&gt;0&lt;/span&gt;.00809 &lt;span class="nb"&gt;time&lt;/span&gt; 3066ms
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-58"&gt;&lt;/a&gt;epoch  &lt;span class="m"&gt;27&lt;/span&gt;/50 batch  &lt;span class="m"&gt;600&lt;/span&gt;/ &lt;span class="m"&gt;600&lt;/span&gt; - error: &lt;span class="m"&gt;0&lt;/span&gt;.00227 loss: &lt;span class="m"&gt;0&lt;/span&gt;.00773 &lt;span class="nb"&gt;time&lt;/span&gt; 3156ms
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-59"&gt;&lt;/a&gt;epoch  &lt;span class="m"&gt;28&lt;/span&gt;/50 batch  &lt;span class="m"&gt;600&lt;/span&gt;/ &lt;span class="m"&gt;600&lt;/span&gt; - error: &lt;span class="m"&gt;0&lt;/span&gt;.00203 loss: &lt;span class="m"&gt;0&lt;/span&gt;.00728 &lt;span class="nb"&gt;time&lt;/span&gt; 3158ms
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-60"&gt;&lt;/a&gt;epoch  &lt;span class="m"&gt;29&lt;/span&gt;/50 batch  &lt;span class="m"&gt;600&lt;/span&gt;/ &lt;span class="m"&gt;600&lt;/span&gt; - error: &lt;span class="m"&gt;0&lt;/span&gt;.00240 loss: &lt;span class="m"&gt;0&lt;/span&gt;.00753 &lt;span class="nb"&gt;time&lt;/span&gt; 3114ms
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-61"&gt;&lt;/a&gt;epoch  &lt;span class="m"&gt;30&lt;/span&gt;/50 batch  &lt;span class="m"&gt;600&lt;/span&gt;/ &lt;span class="m"&gt;600&lt;/span&gt; - error: &lt;span class="m"&gt;0&lt;/span&gt;.00263 loss: &lt;span class="m"&gt;0&lt;/span&gt;.00864 &lt;span class="nb"&gt;time&lt;/span&gt; 3099ms
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-62"&gt;&lt;/a&gt;epoch  &lt;span class="m"&gt;31&lt;/span&gt;/50 batch  &lt;span class="m"&gt;600&lt;/span&gt;/ &lt;span class="m"&gt;600&lt;/span&gt; - error: &lt;span class="m"&gt;0&lt;/span&gt;.00210 loss: &lt;span class="m"&gt;0&lt;/span&gt;.00675 &lt;span class="nb"&gt;time&lt;/span&gt; 3096ms
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-63"&gt;&lt;/a&gt;epoch  &lt;span class="m"&gt;32&lt;/span&gt;/50 batch  &lt;span class="m"&gt;600&lt;/span&gt;/ &lt;span class="m"&gt;600&lt;/span&gt; - error: &lt;span class="m"&gt;0&lt;/span&gt;.00163 loss: &lt;span class="m"&gt;0&lt;/span&gt;.00628 &lt;span class="nb"&gt;time&lt;/span&gt; 3120ms
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-64"&gt;&lt;/a&gt;epoch  &lt;span class="m"&gt;33&lt;/span&gt;/50 batch  &lt;span class="m"&gt;600&lt;/span&gt;/ &lt;span class="m"&gt;600&lt;/span&gt; - error: &lt;span class="m"&gt;0&lt;/span&gt;.00182 loss: &lt;span class="m"&gt;0&lt;/span&gt;.00611 &lt;span class="nb"&gt;time&lt;/span&gt; 3045ms
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-65"&gt;&lt;/a&gt;epoch  &lt;span class="m"&gt;34&lt;/span&gt;/50 batch  &lt;span class="m"&gt;600&lt;/span&gt;/ &lt;span class="m"&gt;600&lt;/span&gt; - error: &lt;span class="m"&gt;0&lt;/span&gt;.00125 loss: &lt;span class="m"&gt;0&lt;/span&gt;.00468 &lt;span class="nb"&gt;time&lt;/span&gt; 3140ms
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-66"&gt;&lt;/a&gt;epoch  &lt;span class="m"&gt;35&lt;/span&gt;/50 batch  &lt;span class="m"&gt;600&lt;/span&gt;/ &lt;span class="m"&gt;600&lt;/span&gt; - error: &lt;span class="m"&gt;0&lt;/span&gt;.00183 loss: &lt;span class="m"&gt;0&lt;/span&gt;.00598 &lt;span class="nb"&gt;time&lt;/span&gt; 3093ms
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-67"&gt;&lt;/a&gt;epoch  &lt;span class="m"&gt;36&lt;/span&gt;/50 batch  &lt;span class="m"&gt;600&lt;/span&gt;/ &lt;span class="m"&gt;600&lt;/span&gt; - error: &lt;span class="m"&gt;0&lt;/span&gt;.00232 loss: &lt;span class="m"&gt;0&lt;/span&gt;.00711 &lt;span class="nb"&gt;time&lt;/span&gt; 3068ms
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-68"&gt;&lt;/a&gt;epoch  &lt;span class="m"&gt;37&lt;/span&gt;/50 batch  &lt;span class="m"&gt;600&lt;/span&gt;/ &lt;span class="m"&gt;600&lt;/span&gt; - error: &lt;span class="m"&gt;0&lt;/span&gt;.00170 loss: &lt;span class="m"&gt;0&lt;/span&gt;.00571 &lt;span class="nb"&gt;time&lt;/span&gt; 3057ms
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-69"&gt;&lt;/a&gt;epoch  &lt;span class="m"&gt;38&lt;/span&gt;/50 batch  &lt;span class="m"&gt;600&lt;/span&gt;/ &lt;span class="m"&gt;600&lt;/span&gt; - error: &lt;span class="m"&gt;0&lt;/span&gt;.00162 loss: &lt;span class="m"&gt;0&lt;/span&gt;.00530 &lt;span class="nb"&gt;time&lt;/span&gt; 3115ms
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-70"&gt;&lt;/a&gt;epoch  &lt;span class="m"&gt;39&lt;/span&gt;/50 batch  &lt;span class="m"&gt;600&lt;/span&gt;/ &lt;span class="m"&gt;600&lt;/span&gt; - error: &lt;span class="m"&gt;0&lt;/span&gt;.00155 loss: &lt;span class="m"&gt;0&lt;/span&gt;.00513 &lt;span class="nb"&gt;time&lt;/span&gt; 3226ms
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-71"&gt;&lt;/a&gt;epoch  &lt;span class="m"&gt;40&lt;/span&gt;/50 batch  &lt;span class="m"&gt;600&lt;/span&gt;/ &lt;span class="m"&gt;600&lt;/span&gt; - error: &lt;span class="m"&gt;0&lt;/span&gt;.00150 loss: &lt;span class="m"&gt;0&lt;/span&gt;.00501 &lt;span class="nb"&gt;time&lt;/span&gt; 2987ms
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-72"&gt;&lt;/a&gt;epoch  &lt;span class="m"&gt;41&lt;/span&gt;/50 batch  &lt;span class="m"&gt;600&lt;/span&gt;/ &lt;span class="m"&gt;600&lt;/span&gt; - error: &lt;span class="m"&gt;0&lt;/span&gt;.00122 loss: &lt;span class="m"&gt;0&lt;/span&gt;.00425 &lt;span class="nb"&gt;time&lt;/span&gt; 3117ms
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-73"&gt;&lt;/a&gt;epoch  &lt;span class="m"&gt;42&lt;/span&gt;/50 batch  &lt;span class="m"&gt;600&lt;/span&gt;/ &lt;span class="m"&gt;600&lt;/span&gt; - error: &lt;span class="m"&gt;0&lt;/span&gt;.00108 loss: &lt;span class="m"&gt;0&lt;/span&gt;.00383 &lt;span class="nb"&gt;time&lt;/span&gt; 3102ms
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-74"&gt;&lt;/a&gt;epoch  &lt;span class="m"&gt;43&lt;/span&gt;/50 batch  &lt;span class="m"&gt;600&lt;/span&gt;/ &lt;span class="m"&gt;600&lt;/span&gt; - error: &lt;span class="m"&gt;0&lt;/span&gt;.00165 loss: &lt;span class="m"&gt;0&lt;/span&gt;.00533 &lt;span class="nb"&gt;time&lt;/span&gt; 2977ms
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-75"&gt;&lt;/a&gt;epoch  &lt;span class="m"&gt;44&lt;/span&gt;/50 batch  &lt;span class="m"&gt;600&lt;/span&gt;/ &lt;span class="m"&gt;600&lt;/span&gt; - error: &lt;span class="m"&gt;0&lt;/span&gt;.00142 loss: &lt;span class="m"&gt;0&lt;/span&gt;.00469 &lt;span class="nb"&gt;time&lt;/span&gt; 3009ms
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-76"&gt;&lt;/a&gt;epoch  &lt;span class="m"&gt;45&lt;/span&gt;/50 batch  &lt;span class="m"&gt;600&lt;/span&gt;/ &lt;span class="m"&gt;600&lt;/span&gt; - error: &lt;span class="m"&gt;0&lt;/span&gt;.00098 loss: &lt;span class="m"&gt;0&lt;/span&gt;.00356 &lt;span class="nb"&gt;time&lt;/span&gt; 3055ms
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-77"&gt;&lt;/a&gt;epoch  &lt;span class="m"&gt;46&lt;/span&gt;/50 batch  &lt;span class="m"&gt;600&lt;/span&gt;/ &lt;span class="m"&gt;600&lt;/span&gt; - error: &lt;span class="m"&gt;0&lt;/span&gt;.00127 loss: &lt;span class="m"&gt;0&lt;/span&gt;.00409 &lt;span class="nb"&gt;time&lt;/span&gt; 3076ms
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-78"&gt;&lt;/a&gt;epoch  &lt;span class="m"&gt;47&lt;/span&gt;/50 batch  &lt;span class="m"&gt;600&lt;/span&gt;/ &lt;span class="m"&gt;600&lt;/span&gt; - error: &lt;span class="m"&gt;0&lt;/span&gt;.00132 loss: &lt;span class="m"&gt;0&lt;/span&gt;.00438 &lt;span class="nb"&gt;time&lt;/span&gt; 3068ms
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-79"&gt;&lt;/a&gt;epoch  &lt;span class="m"&gt;48&lt;/span&gt;/50 batch  &lt;span class="m"&gt;600&lt;/span&gt;/ &lt;span class="m"&gt;600&lt;/span&gt; - error: &lt;span class="m"&gt;0&lt;/span&gt;.00130 loss: &lt;span class="m"&gt;0&lt;/span&gt;.00459 &lt;span class="nb"&gt;time&lt;/span&gt; 3045ms
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-80"&gt;&lt;/a&gt;epoch  &lt;span class="m"&gt;49&lt;/span&gt;/50 batch  &lt;span class="m"&gt;600&lt;/span&gt;/ &lt;span class="m"&gt;600&lt;/span&gt; - error: &lt;span class="m"&gt;0&lt;/span&gt;.00107 loss: &lt;span class="m"&gt;0&lt;/span&gt;.00365 &lt;span class="nb"&gt;time&lt;/span&gt; 3103ms
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-81"&gt;&lt;/a&gt;Restore the best &lt;span class="o"&gt;(&lt;/span&gt;error&lt;span class="o"&gt;)&lt;/span&gt; weights from epoch &lt;span class="m"&gt;45&lt;/span&gt;
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-82"&gt;&lt;/a&gt;Training took 160s
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-83"&gt;&lt;/a&gt;
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-84"&gt;&lt;/a&gt;Evaluation Results
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-85"&gt;&lt;/a&gt;   error: &lt;span class="m"&gt;0&lt;/span&gt;.01740
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-86"&gt;&lt;/a&gt;    loss: &lt;span class="m"&gt;0&lt;/span&gt;.07861
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-87"&gt;&lt;/a&gt;evaluation took 67ms
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-88"&gt;&lt;/a&gt;
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-89"&gt;&lt;/a&gt; -----------------------------------------------------------------------------
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-90"&gt;&lt;/a&gt; &lt;span class="p"&gt;|&lt;/span&gt; %        &lt;span class="p"&gt;|&lt;/span&gt; Timer                         &lt;span class="p"&gt;|&lt;/span&gt; Count  &lt;span class="p"&gt;|&lt;/span&gt; Total     &lt;span class="p"&gt;|&lt;/span&gt; Average   &lt;span class="p"&gt;|&lt;/span&gt;
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-91"&gt;&lt;/a&gt; -----------------------------------------------------------------------------
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-92"&gt;&lt;/a&gt; &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;100&lt;/span&gt;.000% &lt;span class="p"&gt;|&lt;/span&gt; net:train:ft                  &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;      &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;160&lt;/span&gt;.183s  &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;160&lt;/span&gt;.183s  &lt;span class="p"&gt;|&lt;/span&gt;
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-93"&gt;&lt;/a&gt; &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;100&lt;/span&gt;.000% &lt;span class="p"&gt;|&lt;/span&gt; net:trainer:train             &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;      &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;160&lt;/span&gt;.183s  &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;160&lt;/span&gt;.183s  &lt;span class="p"&gt;|&lt;/span&gt;
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-94"&gt;&lt;/a&gt; &lt;span class="p"&gt;|&lt;/span&gt;  &lt;span class="m"&gt;99&lt;/span&gt;.997% &lt;span class="p"&gt;|&lt;/span&gt; net:trainer:train:epoch       &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;50&lt;/span&gt;     &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;160&lt;/span&gt;.178s  &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;3&lt;/span&gt;.20356s  &lt;span class="p"&gt;|&lt;/span&gt;
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-95"&gt;&lt;/a&gt; &lt;span class="p"&gt;|&lt;/span&gt;  &lt;span class="m"&gt;84&lt;/span&gt;.422% &lt;span class="p"&gt;|&lt;/span&gt; net:trainer:train:epoch:batch &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;30000&lt;/span&gt;  &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;135&lt;/span&gt;.229s  &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;4&lt;/span&gt;.50764ms &lt;span class="p"&gt;|&lt;/span&gt;
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-96"&gt;&lt;/a&gt; &lt;span class="p"&gt;|&lt;/span&gt;  &lt;span class="m"&gt;84&lt;/span&gt;.261% &lt;span class="p"&gt;|&lt;/span&gt; sgd::train_batch              &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;30000&lt;/span&gt;  &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;134&lt;/span&gt;.971s  &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;4&lt;/span&gt;.49904ms &lt;span class="p"&gt;|&lt;/span&gt;
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-97"&gt;&lt;/a&gt; &lt;span class="p"&gt;|&lt;/span&gt;  &lt;span class="m"&gt;44&lt;/span&gt;.404% &lt;span class="p"&gt;|&lt;/span&gt; sgd::grad                     &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;30000&lt;/span&gt;  &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;71&lt;/span&gt;.1271s  &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;2&lt;/span&gt;.3709ms  &lt;span class="p"&gt;|&lt;/span&gt;
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-98"&gt;&lt;/a&gt; &lt;span class="p"&gt;|&lt;/span&gt;  &lt;span class="m"&gt;35&lt;/span&gt;.453% &lt;span class="p"&gt;|&lt;/span&gt; sgd::forward                  &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;30000&lt;/span&gt;  &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;56&lt;/span&gt;.7893s  &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;.89298ms &lt;span class="p"&gt;|&lt;/span&gt;
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-99"&gt;&lt;/a&gt; &lt;span class="p"&gt;|&lt;/span&gt;  &lt;span class="m"&gt;32&lt;/span&gt;.245% &lt;span class="p"&gt;|&lt;/span&gt; sgd::update_weights           &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;90000&lt;/span&gt;  &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;51&lt;/span&gt;.6505s  &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;573&lt;/span&gt;.894us &lt;span class="p"&gt;|&lt;/span&gt;
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-100"&gt;&lt;/a&gt; &lt;span class="p"&gt;|&lt;/span&gt;  &lt;span class="m"&gt;32&lt;/span&gt;.226% &lt;span class="p"&gt;|&lt;/span&gt; sgd::apply_grad:nadam         &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;180000&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;51&lt;/span&gt;.6211s  &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;286&lt;/span&gt;.783us &lt;span class="p"&gt;|&lt;/span&gt;
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-101"&gt;&lt;/a&gt; &lt;span class="p"&gt;|&lt;/span&gt;  &lt;span class="m"&gt;28&lt;/span&gt;.399% &lt;span class="p"&gt;|&lt;/span&gt; dense:dyn:forward             &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;180300&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;45&lt;/span&gt;.4903s  &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;252&lt;/span&gt;.303us &lt;span class="p"&gt;|&lt;/span&gt;
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-102"&gt;&lt;/a&gt; &lt;span class="p"&gt;|&lt;/span&gt;  &lt;span class="m"&gt;17&lt;/span&gt;.642% &lt;span class="p"&gt;|&lt;/span&gt; dropout:train:forward         &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;60000&lt;/span&gt;  &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;28&lt;/span&gt;.2595s  &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;470&lt;/span&gt;.99us  &lt;span class="p"&gt;|&lt;/span&gt;
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-103"&gt;&lt;/a&gt; &lt;span class="p"&gt;|&lt;/span&gt;  &lt;span class="m"&gt;13&lt;/span&gt;.707% &lt;span class="p"&gt;|&lt;/span&gt; net:trainer:train:epoch:error &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;50&lt;/span&gt;     &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;21&lt;/span&gt;.957s   &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;439&lt;/span&gt;.14ms  &lt;span class="p"&gt;|&lt;/span&gt;
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-104"&gt;&lt;/a&gt; &lt;span class="p"&gt;|&lt;/span&gt;  &lt;span class="m"&gt;12&lt;/span&gt;.148% &lt;span class="p"&gt;|&lt;/span&gt; dense:dyn:gradients           &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;90000&lt;/span&gt;  &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;19&lt;/span&gt;.4587s  &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;216&lt;/span&gt;.207us &lt;span class="p"&gt;|&lt;/span&gt;
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-105"&gt;&lt;/a&gt; &lt;span class="p"&gt;|&lt;/span&gt;   &lt;span class="m"&gt;4&lt;/span&gt;.299% &lt;span class="p"&gt;|&lt;/span&gt; sgd::backward                 &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;30000&lt;/span&gt;  &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;6&lt;/span&gt;.88546s  &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;229&lt;/span&gt;.515us &lt;span class="p"&gt;|&lt;/span&gt;
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-106"&gt;&lt;/a&gt; &lt;span class="p"&gt;|&lt;/span&gt;   &lt;span class="m"&gt;3&lt;/span&gt;.301% &lt;span class="p"&gt;|&lt;/span&gt; dense:dyn:backward            &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;60000&lt;/span&gt;  &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;5&lt;/span&gt;.28729s  &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;88&lt;/span&gt;.121us  &lt;span class="p"&gt;|&lt;/span&gt;
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-107"&gt;&lt;/a&gt; &lt;span class="p"&gt;|&lt;/span&gt;   &lt;span class="m"&gt;0&lt;/span&gt;.560% &lt;span class="p"&gt;|&lt;/span&gt; dense:dyn:errors              &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;60000&lt;/span&gt;  &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;896&lt;/span&gt;.471ms &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;14&lt;/span&gt;.941us  &lt;span class="p"&gt;|&lt;/span&gt;
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-108"&gt;&lt;/a&gt; &lt;span class="p"&gt;|&lt;/span&gt;   &lt;span class="m"&gt;0&lt;/span&gt;.407% &lt;span class="p"&gt;|&lt;/span&gt; dropout:backward              &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;60000&lt;/span&gt;  &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;651&lt;/span&gt;.523ms &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;10&lt;/span&gt;.858us  &lt;span class="p"&gt;|&lt;/span&gt;
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-109"&gt;&lt;/a&gt; &lt;span class="p"&gt;|&lt;/span&gt;   &lt;span class="m"&gt;0&lt;/span&gt;.339% &lt;span class="p"&gt;|&lt;/span&gt; dropout:test:forward          &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;60000&lt;/span&gt;  &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;542&lt;/span&gt;.799ms &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;9&lt;/span&gt;.046us   &lt;span class="p"&gt;|&lt;/span&gt;
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-110"&gt;&lt;/a&gt; &lt;span class="p"&gt;|&lt;/span&gt;   &lt;span class="m"&gt;0&lt;/span&gt;.161% &lt;span class="p"&gt;|&lt;/span&gt; net:compute_loss:CCE          &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;60100&lt;/span&gt;  &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;257&lt;/span&gt;.915ms &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;4&lt;/span&gt;.291us   &lt;span class="p"&gt;|&lt;/span&gt;
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-111"&gt;&lt;/a&gt; &lt;span class="p"&gt;|&lt;/span&gt;   &lt;span class="m"&gt;0&lt;/span&gt;.099% &lt;span class="p"&gt;|&lt;/span&gt; sgd::error                    &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;30000&lt;/span&gt;  &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;158&lt;/span&gt;.33ms  &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="m"&gt;5&lt;/span&gt;.277us   &lt;span class="p"&gt;|&lt;/span&gt;
&lt;a name="rest_code_da1bfede7721421f865a0df880090001-112"&gt;&lt;/a&gt; -----------------------------------------------------------------------------
&lt;/pre&gt;&lt;p&gt;I hope this will make the output of the machine learning framework more useful.&lt;/p&gt;
&lt;p&gt;All this support is now in the &lt;strong&gt;master&lt;/strong&gt; branch of the DLL project if you want
to check it out. You can also check out the example online:
&lt;a class="reference external" href="https://github.com/wichtounet/dll/blob/master/examples/src/mnist_mlp.cpp"&gt;mnist_mlp.cpp&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;You can access the project &lt;a class="reference external" href="https://github.com/wichtounet/dll"&gt;on Github&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;</description><category>dll</category><category>Machine Learning</category><category>projects</category><guid>http://baptiste-wicht.com/posts/2017/11/dll-pretty-printing-and-live-output.html</guid><pubDate>Sun, 19 Nov 2017 14:15:57 GMT</pubDate></item><item><title>Inventor on four new research patents</title><link>http://baptiste-wicht.com/posts/2017/11/inventor-on-four-new-research-patents.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;div&gt;&lt;p&gt;During the first years of my thesis I worked on CTI research project with the
American company Verisign, which has also an office near my school. A CTI
research project is a project that is partially funded by the Commission on
Innovation and Technology (CTI) where a school and a company work together.
I was quite lucky to work on this project with the awesome people at Verisign
Fribourg. After the success of the project, Verisign filled several patents
regarding various points of the projects.&lt;/p&gt;
&lt;p&gt;I'm quite happy now that these four patents are now approved and published. They
They have been approved by both the United States Patent and Trademark Office
(USPTO) and European Patent Office (EPO). The parents have been cl=¬ aimed by
Verisign, I'm only one of the inventor, I got no claim on the patent. But it's
still a great thing.&lt;/p&gt;
&lt;p&gt;Here are the names of the four patents:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Systems and methods for automatic phonetization of domain names¬&lt;/li&gt;
&lt;li&gt;Construction of phonetic representation of a string of characters¬&lt;/li&gt;
&lt;li&gt;Method for writing a foreign language in a pseudo language phonetically resembling native language of the speaker¬&lt;/li&gt;
&lt;li&gt;Construction of a phonetic representation of a generated string of characters¬&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You can take a look at them on USPTO or EPO or on Google Patents, but the way
a patent is written make it relatively hard to follow, it's more on a lawyer
level or maybe I'm simply not used to patents anymore.&lt;/p&gt;
&lt;p&gt;All these patents come from the research done during the CTI project with
Verisign. In this project, name suggestions were generated from the phonetic
sound of the name. The idea being to generate names that sounds the same as
another input (airmix could become rmix or rmics). We are using various
technologies to make this work: IG-Tree, Viterbi and HMM. And since we used
a model with an encoder and a decoder, we can also mix languages. For instance,
write something in French the way a English work would work (for instance school
could become scoule).&lt;/p&gt;
&lt;p&gt;These patents concludes a very interesting and successful project. I'm now
working on yet another CTI research project with Verisign and it will surely be
as successful as the first one.&lt;/p&gt;&lt;/div&gt;</description><category>Machine Learning</category><category>patents</category><category>projects</category><category>publications</category><guid>http://baptiste-wicht.com/posts/2017/11/inventor-on-four-new-research-patents.html</guid><pubDate>Fri, 17 Nov 2017 13:50:33 GMT</pubDate></item><item><title>Initial support for Recurrent Neural Network (RNN) in DLL</title><link>http://baptiste-wicht.com/posts/2017/11/initial-support-for-recurrent-neural-network-rnn-in-dll.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;div&gt;&lt;p&gt;I'm happy to announce that I just merged support for Recurrent Neural Networks
(RNNs) into my Deep Learning Library (DLL) machine learning framework.&lt;/p&gt;
&lt;p&gt;It's nothing fancy yet, but forward propagation of RNN and basic Backpropagation
Through Time (BPTT) are now supported. For now, only existing classification
loss is supported for RNN. I plan to add support for sequence-to-sequence loss
in order to be able to train models able to generate characters, but I don't
know when I'll be able to work on that. I also plan to add support for other
types of cells such as LSTM and GRU (maybe NAS) in the future.&lt;/p&gt;
&lt;p&gt;For example, here is a simple RNN used on MNIST:&lt;/p&gt;
&lt;pre class="code cpp"&gt;&lt;a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-1"&gt;&lt;/a&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;"dll/neural/dense_layer.hpp"&lt;/span&gt;&lt;span class="cp"&gt;&lt;/span&gt;
&lt;a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-2"&gt;&lt;/a&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;"dll/neural/recurrent_layer.hpp"&lt;/span&gt;&lt;span class="cp"&gt;&lt;/span&gt;
&lt;a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-3"&gt;&lt;/a&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;"dll/neural/recurrent_last_layer.hpp"&lt;/span&gt;&lt;span class="cp"&gt;&lt;/span&gt;
&lt;a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-4"&gt;&lt;/a&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;"dll/network.hpp"&lt;/span&gt;&lt;span class="cp"&gt;&lt;/span&gt;
&lt;a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-5"&gt;&lt;/a&gt;&lt;span class="cp"&gt;#include&lt;/span&gt; &lt;span class="cpf"&gt;"dll/datasets.hpp"&lt;/span&gt;&lt;span class="cp"&gt;&lt;/span&gt;
&lt;a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-6"&gt;&lt;/a&gt;
&lt;a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-7"&gt;&lt;/a&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="cm"&gt;/*argc*/&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;char&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="cm"&gt;/*argv*/&lt;/span&gt; &lt;span class="p"&gt;[])&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-8"&gt;&lt;/a&gt;    &lt;span class="c1"&gt;// Load the dataset&lt;/span&gt;
&lt;a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-9"&gt;&lt;/a&gt;    &lt;span class="k"&gt;auto&lt;/span&gt; &lt;span class="n"&gt;dataset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;make_mnist_dataset_nc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;{},&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;scale_pre&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;255&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;{});&lt;/span&gt;
&lt;a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-10"&gt;&lt;/a&gt;
&lt;a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-11"&gt;&lt;/a&gt;    &lt;span class="k"&gt;constexpr&lt;/span&gt; &lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;time_steps&lt;/span&gt;      &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;28&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-12"&gt;&lt;/a&gt;    &lt;span class="k"&gt;constexpr&lt;/span&gt; &lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;sequence_length&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;28&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-13"&gt;&lt;/a&gt;    &lt;span class="k"&gt;constexpr&lt;/span&gt; &lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;hidden_units&lt;/span&gt;    &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-14"&gt;&lt;/a&gt;
&lt;a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-15"&gt;&lt;/a&gt;    &lt;span class="c1"&gt;// Build the network&lt;/span&gt;
&lt;a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-16"&gt;&lt;/a&gt;
&lt;a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-17"&gt;&lt;/a&gt;    &lt;span class="k"&gt;using&lt;/span&gt; &lt;span class="n"&gt;network_t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dyn_network_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;
&lt;a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-18"&gt;&lt;/a&gt;        &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;network_layers&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;
&lt;a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-19"&gt;&lt;/a&gt;            &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;recurrent_layer&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;time_steps&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sequence_length&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;hidden_units&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;last_only&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-20"&gt;&lt;/a&gt;            &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;recurrent_last_layer&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;time_steps&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;hidden_units&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-21"&gt;&lt;/a&gt;            &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dense_layer&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;hidden_units&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;softmax&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-22"&gt;&lt;/a&gt;        &lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-23"&gt;&lt;/a&gt;        &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;updater&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;updater_type&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;ADAM&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;      &lt;span class="c1"&gt;// Adam&lt;/span&gt;
&lt;a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-24"&gt;&lt;/a&gt;        &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;                       &lt;span class="c1"&gt;// The mini-batch size&lt;/span&gt;
&lt;a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-25"&gt;&lt;/a&gt;    &lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;network_t&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-26"&gt;&lt;/a&gt;
&lt;a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-27"&gt;&lt;/a&gt;    &lt;span class="k"&gt;auto&lt;/span&gt; &lt;span class="n"&gt;net&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;make_unique&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;network_t&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-28"&gt;&lt;/a&gt;
&lt;a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-29"&gt;&lt;/a&gt;    &lt;span class="c1"&gt;// Display the network and dataset&lt;/span&gt;
&lt;a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-30"&gt;&lt;/a&gt;    &lt;span class="n"&gt;net&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;display&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-31"&gt;&lt;/a&gt;
&lt;a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-32"&gt;&lt;/a&gt;    &lt;span class="c1"&gt;// Train the network for performance sake&lt;/span&gt;
&lt;a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-33"&gt;&lt;/a&gt;    &lt;span class="n"&gt;net&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;fine_tune&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-34"&gt;&lt;/a&gt;
&lt;a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-35"&gt;&lt;/a&gt;    &lt;span class="c1"&gt;// Test the network on test set&lt;/span&gt;
&lt;a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-36"&gt;&lt;/a&gt;    &lt;span class="n"&gt;net&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;evaluate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;test&lt;/span&gt;&lt;span class="p"&gt;());&lt;/span&gt;
&lt;a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-37"&gt;&lt;/a&gt;
&lt;a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-38"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-39"&gt;&lt;/a&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;The network starts with recurrent layer, followed by a layer that extracts only
the last layer and finally a dense layer with a softmax function. The recurrent
layer has support to change the activation function, change the initializer for
the two weights matrices of the RNN and the number of steps for BPTT truncation.&lt;/p&gt;
&lt;p&gt;Here is a possible result:&lt;/p&gt;
&lt;pre class="code text"&gt;&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-1"&gt;&lt;/a&gt;Network with 3 layers
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-2"&gt;&lt;/a&gt;    RNN(dyn): 28x28 -&amp;gt; TANH -&amp;gt; 28x100
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-3"&gt;&lt;/a&gt;    RNN(last): 28x100 -&amp;gt; 100
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-4"&gt;&lt;/a&gt;    Dense(dyn): 100 -&amp;gt; SOFTMAX -&amp;gt; 10
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-5"&gt;&lt;/a&gt;Total parameters: 13800
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-6"&gt;&lt;/a&gt;Train the network with "Stochastic Gradient Descent"
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-7"&gt;&lt;/a&gt;    Updater: ADAM
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-8"&gt;&lt;/a&gt;       Loss: CATEGORICAL_CROSS_ENTROPY
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-9"&gt;&lt;/a&gt; Early Stop: Goal(error)
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-10"&gt;&lt;/a&gt;
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-11"&gt;&lt;/a&gt;With parameters:
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-12"&gt;&lt;/a&gt;          epochs=50
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-13"&gt;&lt;/a&gt;      batch_size=100
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-14"&gt;&lt;/a&gt;   learning_rate=0.001
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-15"&gt;&lt;/a&gt;           beta1=0.9
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-16"&gt;&lt;/a&gt;           beta2=0.999
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-17"&gt;&lt;/a&gt;
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-18"&gt;&lt;/a&gt;Epoch   0/50 - Classification error: 0.11635 Loss: 0.39999 Time 4717ms
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-19"&gt;&lt;/a&gt;Epoch   1/50 - Classification error: 0.11303 Loss: 0.36994 Time 4702ms
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-20"&gt;&lt;/a&gt;Epoch   2/50 - Classification error: 0.06732 Loss: 0.23469 Time 4702ms
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-21"&gt;&lt;/a&gt;Epoch   3/50 - Classification error: 0.04865 Loss: 0.17091 Time 4696ms
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-22"&gt;&lt;/a&gt;Epoch   4/50 - Classification error: 0.05957 Loss: 0.20437 Time 4706ms
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-23"&gt;&lt;/a&gt;Epoch   5/50 - Classification error: 0.05022 Loss: 0.16888 Time 4696ms
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-24"&gt;&lt;/a&gt;Epoch   6/50 - Classification error: 0.03912 Loss: 0.13743 Time 4698ms
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-25"&gt;&lt;/a&gt;Epoch   7/50 - Classification error: 0.04097 Loss: 0.14509 Time 4706ms
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-26"&gt;&lt;/a&gt;Epoch   8/50 - Classification error: 0.03938 Loss: 0.13397 Time 4694ms
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-27"&gt;&lt;/a&gt;Epoch   9/50 - Classification error: 0.03525 Loss: 0.12284 Time 4706ms
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-28"&gt;&lt;/a&gt;Epoch  10/50 - Classification error: 0.03927 Loss: 0.13770 Time 4694ms
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-29"&gt;&lt;/a&gt;Epoch  11/50 - Classification error: 0.03315 Loss: 0.11315 Time 4711ms
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-30"&gt;&lt;/a&gt;Epoch  12/50 - Classification error: 0.05037 Loss: 0.17123 Time 4711ms
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-31"&gt;&lt;/a&gt;Epoch  13/50 - Classification error: 0.02927 Loss: 0.10042 Time 4780ms
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-32"&gt;&lt;/a&gt;Epoch  14/50 - Classification error: 0.03322 Loss: 0.11027 Time 4746ms
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-33"&gt;&lt;/a&gt;Epoch  15/50 - Classification error: 0.03397 Loss: 0.11585 Time 4684ms
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-34"&gt;&lt;/a&gt;Epoch  16/50 - Classification error: 0.02938 Loss: 0.09984 Time 4708ms
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-35"&gt;&lt;/a&gt;Epoch  17/50 - Classification error: 0.03262 Loss: 0.11152 Time 4690ms
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-36"&gt;&lt;/a&gt;Epoch  18/50 - Classification error: 0.02872 Loss: 0.09753 Time 4672ms
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-37"&gt;&lt;/a&gt;Epoch  19/50 - Classification error: 0.02548 Loss: 0.08605 Time 4691ms
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-38"&gt;&lt;/a&gt;Epoch  20/50 - Classification error: 0.02245 Loss: 0.07797 Time 4693ms
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-39"&gt;&lt;/a&gt;Epoch  21/50 - Classification error: 0.02705 Loss: 0.08984 Time 4684ms
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-40"&gt;&lt;/a&gt;Epoch  22/50 - Classification error: 0.02422 Loss: 0.08164 Time 4688ms
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-41"&gt;&lt;/a&gt;Epoch  23/50 - Classification error: 0.02645 Loss: 0.08804 Time 4690ms
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-42"&gt;&lt;/a&gt;Epoch  24/50 - Classification error: 0.02927 Loss: 0.09739 Time 4715ms
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-43"&gt;&lt;/a&gt;Epoch  25/50 - Classification error: 0.02578 Loss: 0.08669 Time 4702ms
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-44"&gt;&lt;/a&gt;Epoch  26/50 - Classification error: 0.02785 Loss: 0.09368 Time 4700ms
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-45"&gt;&lt;/a&gt;Epoch  27/50 - Classification error: 0.02472 Loss: 0.08237 Time 4695ms
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-46"&gt;&lt;/a&gt;Epoch  28/50 - Classification error: 0.02125 Loss: 0.07324 Time 4690ms
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-47"&gt;&lt;/a&gt;Epoch  29/50 - Classification error: 0.01977 Loss: 0.06635 Time 4688ms
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-48"&gt;&lt;/a&gt;Epoch  30/50 - Classification error: 0.03635 Loss: 0.12140 Time 4689ms
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-49"&gt;&lt;/a&gt;Epoch  31/50 - Classification error: 0.02862 Loss: 0.09704 Time 4698ms
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-50"&gt;&lt;/a&gt;Epoch  32/50 - Classification error: 0.02463 Loss: 0.08158 Time 4686ms
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-51"&gt;&lt;/a&gt;Epoch  33/50 - Classification error: 0.02565 Loss: 0.08771 Time 4697ms
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-52"&gt;&lt;/a&gt;Epoch  34/50 - Classification error: 0.02278 Loss: 0.07634 Time 4718ms
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-53"&gt;&lt;/a&gt;Epoch  35/50 - Classification error: 0.02105 Loss: 0.07075 Time 4697ms
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-54"&gt;&lt;/a&gt;Epoch  36/50 - Classification error: 0.02770 Loss: 0.09358 Time 4711ms
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-55"&gt;&lt;/a&gt;Epoch  37/50 - Classification error: 0.02627 Loss: 0.08805 Time 4742ms
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-56"&gt;&lt;/a&gt;Epoch  38/50 - Classification error: 0.02282 Loss: 0.07712 Time 4708ms
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-57"&gt;&lt;/a&gt;Epoch  39/50 - Classification error: 0.02305 Loss: 0.07661 Time 4697ms
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-58"&gt;&lt;/a&gt;Epoch  40/50 - Classification error: 0.02243 Loss: 0.07773 Time 4700ms
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-59"&gt;&lt;/a&gt;Epoch  41/50 - Classification error: 0.02467 Loss: 0.08234 Time 4712ms
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-60"&gt;&lt;/a&gt;Epoch  42/50 - Classification error: 0.01808 Loss: 0.06186 Time 4691ms
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-61"&gt;&lt;/a&gt;Epoch  43/50 - Classification error: 0.02388 Loss: 0.07917 Time 4681ms
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-62"&gt;&lt;/a&gt;Epoch  44/50 - Classification error: 0.02162 Loss: 0.07508 Time 4699ms
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-63"&gt;&lt;/a&gt;Epoch  45/50 - Classification error: 0.01877 Loss: 0.06289 Time 4735ms
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-64"&gt;&lt;/a&gt;Epoch  46/50 - Classification error: 0.02263 Loss: 0.07969 Time 4764ms
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-65"&gt;&lt;/a&gt;Epoch  47/50 - Classification error: 0.02100 Loss: 0.07207 Time 4684ms
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-66"&gt;&lt;/a&gt;Epoch  48/50 - Classification error: 0.02425 Loss: 0.08076 Time 4752ms
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-67"&gt;&lt;/a&gt;Epoch  49/50 - Classification error: 0.02328 Loss: 0.07803 Time 4718ms
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-68"&gt;&lt;/a&gt;Restore the best (error) weights from epoch 42
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-69"&gt;&lt;/a&gt;Training took 235s
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-70"&gt;&lt;/a&gt;Evaluation Results
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-71"&gt;&lt;/a&gt;   error: 0.03000
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-72"&gt;&lt;/a&gt;    loss: 0.12260
&lt;a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-73"&gt;&lt;/a&gt;evaluation took 245ms
&lt;/pre&gt;&lt;p&gt;Nothing fancy, but this example is not necessarily optimized.&lt;/p&gt;
&lt;p&gt;All this support is now in the &lt;strong&gt;master&lt;/strong&gt; branch of the DLL project if you want
to check it out. You can also check out the example online:
&lt;a class="reference external" href="https://github.com/wichtounet/dll/blob/master/examples/src/mnist_rnn.cpp"&gt;mnist_rnn.cpp&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;You can access the project &lt;a class="reference external" href="https://github.com/wichtounet/dll"&gt;on Github&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;</description><category>deep learning</category><category>dll</category><category>Machine Learning</category><category>projects</category><category>rnn</category><guid>http://baptiste-wicht.com/posts/2017/11/initial-support-for-recurrent-neural-network-rnn-in-dll.html</guid><pubDate>Sun, 12 Nov 2017 14:22:44 GMT</pubDate></item><item><title>DLL New Features: Embeddings and Merge layers</title><link>http://baptiste-wicht.com/posts/2017/10/dll-new-features-embeddings-and-merge-layers.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;div&gt;&lt;p&gt;I've just finished integrating new features into DLL, my deep learning library.
I've added support for an embeddings layer, a group layer and a merge layer.
This is not yet released, but available in the master branch.&lt;/p&gt;
&lt;p&gt;Embeddings are used more and more these days to learn dense representation of
characters or word. An embedding layer in a neural network transform labels into
a vector. It's generally used as the first layer of the network. The embedding
are learned as part of the network.&lt;/p&gt;
&lt;p&gt;The merge layer allows to create branches in the network. The input is passed to
each sub layer and then the output of each layer is concatenated to form the
output of the merged layers. This can be very useful to use different
convolutional filter sizes.&lt;/p&gt;
&lt;p&gt;The group layer is a simple utility to group layers together. This is mostly to
use with merge layers to form several branches.&lt;/p&gt;
&lt;p&gt;I've put together a new example to use these features on text classification.
The dataset is totally synthetic for now, but this can easily be reproduced with
a normal text classification dataset. This kind of model is called a Character
Convolutional Neural Network.&lt;/p&gt;
&lt;p&gt;Here is the code for example:&lt;/p&gt;
&lt;pre class="code cpp"&gt;&lt;a name="rest_code_16c87aa06c274967be5d3c250da7f9af-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;constexpr&lt;/span&gt; &lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;embedding&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="c1"&gt;// The length of the embedding vector&lt;/span&gt;
&lt;a name="rest_code_16c87aa06c274967be5d3c250da7f9af-2"&gt;&lt;/a&gt;&lt;span class="k"&gt;constexpr&lt;/span&gt; &lt;span class="kt"&gt;size_t&lt;/span&gt; &lt;span class="n"&gt;length&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;    &lt;span class="c1"&gt;// The word (or sequence) length&lt;/span&gt;
&lt;a name="rest_code_16c87aa06c274967be5d3c250da7f9af-3"&gt;&lt;/a&gt;
&lt;a name="rest_code_16c87aa06c274967be5d3c250da7f9af-4"&gt;&lt;/a&gt;&lt;span class="k"&gt;using&lt;/span&gt; &lt;span class="n"&gt;embedding_network_t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dyn_network_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;
&lt;a name="rest_code_16c87aa06c274967be5d3c250da7f9af-5"&gt;&lt;/a&gt;    &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;network_layers&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;
&lt;a name="rest_code_16c87aa06c274967be5d3c250da7f9af-6"&gt;&lt;/a&gt;        &lt;span class="c1"&gt;// The embedding layer&lt;/span&gt;
&lt;a name="rest_code_16c87aa06c274967be5d3c250da7f9af-7"&gt;&lt;/a&gt;        &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;embedding_layer&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;26&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;length&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;embedding&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_16c87aa06c274967be5d3c250da7f9af-8"&gt;&lt;/a&gt;
&lt;a name="rest_code_16c87aa06c274967be5d3c250da7f9af-9"&gt;&lt;/a&gt;        &lt;span class="c1"&gt;// The convolutional layers&lt;/span&gt;
&lt;a name="rest_code_16c87aa06c274967be5d3c250da7f9af-10"&gt;&lt;/a&gt;        &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;merge_layer&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;
&lt;a name="rest_code_16c87aa06c274967be5d3c250da7f9af-11"&gt;&lt;/a&gt;            &lt;span class="mi"&gt;0&lt;/span&gt;
&lt;a name="rest_code_16c87aa06c274967be5d3c250da7f9af-12"&gt;&lt;/a&gt;            &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;group_layer&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;
&lt;a name="rest_code_16c87aa06c274967be5d3c250da7f9af-13"&gt;&lt;/a&gt;                  &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;conv_layer&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;length&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;embedding&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;embedding&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_16c87aa06c274967be5d3c250da7f9af-14"&gt;&lt;/a&gt;                &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;mp_2d_layer&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;length&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;length&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_16c87aa06c274967be5d3c250da7f9af-15"&gt;&lt;/a&gt;            &lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_16c87aa06c274967be5d3c250da7f9af-16"&gt;&lt;/a&gt;            &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;group_layer&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;
&lt;a name="rest_code_16c87aa06c274967be5d3c250da7f9af-17"&gt;&lt;/a&gt;                  &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;conv_layer&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;length&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;embedding&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;embedding&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_16c87aa06c274967be5d3c250da7f9af-18"&gt;&lt;/a&gt;                &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;mp_2d_layer&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;length&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;length&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_16c87aa06c274967be5d3c250da7f9af-19"&gt;&lt;/a&gt;            &lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_16c87aa06c274967be5d3c250da7f9af-20"&gt;&lt;/a&gt;            &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;group_layer&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;
&lt;a name="rest_code_16c87aa06c274967be5d3c250da7f9af-21"&gt;&lt;/a&gt;                  &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;conv_layer&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;length&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;embedding&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;embedding&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_16c87aa06c274967be5d3c250da7f9af-22"&gt;&lt;/a&gt;                &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;mp_2d_layer&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;length&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;length&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_16c87aa06c274967be5d3c250da7f9af-23"&gt;&lt;/a&gt;            &lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_16c87aa06c274967be5d3c250da7f9af-24"&gt;&lt;/a&gt;        &lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_16c87aa06c274967be5d3c250da7f9af-25"&gt;&lt;/a&gt;
&lt;a name="rest_code_16c87aa06c274967be5d3c250da7f9af-26"&gt;&lt;/a&gt;        &lt;span class="c1"&gt;// The final softmax layer&lt;/span&gt;
&lt;a name="rest_code_16c87aa06c274967be5d3c250da7f9af-27"&gt;&lt;/a&gt;        &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dense_layer&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;48&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;softmax&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_16c87aa06c274967be5d3c250da7f9af-28"&gt;&lt;/a&gt;    &lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_16c87aa06c274967be5d3c250da7f9af-29"&gt;&lt;/a&gt;    &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;updater&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;updater_type&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;NADAM&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;     &lt;span class="c1"&gt;// Nesterov Adam (NADAM)&lt;/span&gt;
&lt;a name="rest_code_16c87aa06c274967be5d3c250da7f9af-30"&gt;&lt;/a&gt;    &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;                        &lt;span class="c1"&gt;// The mini-batch size&lt;/span&gt;
&lt;a name="rest_code_16c87aa06c274967be5d3c250da7f9af-31"&gt;&lt;/a&gt;    &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;shuffle&lt;/span&gt;                               &lt;span class="c1"&gt;// Shuffle before each epoch&lt;/span&gt;
&lt;a name="rest_code_16c87aa06c274967be5d3c250da7f9af-32"&gt;&lt;/a&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;network_t&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_16c87aa06c274967be5d3c250da7f9af-33"&gt;&lt;/a&gt;
&lt;a name="rest_code_16c87aa06c274967be5d3c250da7f9af-34"&gt;&lt;/a&gt;&lt;span class="k"&gt;auto&lt;/span&gt; &lt;span class="n"&gt;net&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;make_unique&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;embedding_network_t&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;a name="rest_code_16c87aa06c274967be5d3c250da7f9af-35"&gt;&lt;/a&gt;
&lt;a name="rest_code_16c87aa06c274967be5d3c250da7f9af-36"&gt;&lt;/a&gt;&lt;span class="c1"&gt;// Display the network and dataset&lt;/span&gt;
&lt;a name="rest_code_16c87aa06c274967be5d3c250da7f9af-37"&gt;&lt;/a&gt;&lt;span class="n"&gt;net&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;display&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;a name="rest_code_16c87aa06c274967be5d3c250da7f9af-38"&gt;&lt;/a&gt;
&lt;a name="rest_code_16c87aa06c274967be5d3c250da7f9af-39"&gt;&lt;/a&gt;&lt;span class="c1"&gt;// Train the network for performance sake&lt;/span&gt;
&lt;a name="rest_code_16c87aa06c274967be5d3c250da7f9af-40"&gt;&lt;/a&gt;&lt;span class="n"&gt;net&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;fine_tune&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;samples&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a name="rest_code_16c87aa06c274967be5d3c250da7f9af-41"&gt;&lt;/a&gt;
&lt;a name="rest_code_16c87aa06c274967be5d3c250da7f9af-42"&gt;&lt;/a&gt;&lt;span class="c1"&gt;// Test the network on train set&lt;/span&gt;
&lt;a name="rest_code_16c87aa06c274967be5d3c250da7f9af-43"&gt;&lt;/a&gt;&lt;span class="n"&gt;net&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;evaluate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;samples&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;The network starts with an embedding layer. The embedding is then passed to
three convolutional layers with different filter sizes, each followed by
a pooling layer. The outputs of the three layers are merged at the end of the
merge layer. Finally, a softmax layer is used for classification.&lt;/p&gt;
&lt;p&gt;This kind of model can be very powerful and is used regularly. These new
features make for a much larger variety of models that can be build with the DLL
library.&lt;/p&gt;
&lt;p&gt;The full code with the dataset generation can be found online:
&lt;a class="reference external" href="https://github.com/wichtounet/dll/blob/master/examples/src/char_cnn.cpp"&gt;char_cnn.cpp&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The next feature I want to focus on is recurrent neural networks. I'll probably
try a single RNN layer first and then upgrade to multi-layers and LSTM and maybe
GRU.&lt;/p&gt;&lt;/div&gt;</description><category>C++</category><category>deep learning</category><category>dll</category><category>Machine Learning</category><category>projects</category><guid>http://baptiste-wicht.com/posts/2017/10/dll-new-features-embeddings-and-merge-layers.html</guid><pubDate>Tue, 17 Oct 2017 17:50:40 GMT</pubDate></item><item><title>I successfully defended my Ph.D.</title><link>http://baptiste-wicht.com/posts/2017/10/i-successfully-defended-my-phd.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;div&gt;&lt;p&gt;I'm happy to announce that I've successfully defended my thesis "Deep Learning
Features for Image Processing". After four years, I've defended it officially in
front of the thesis committed last Friday and then again two days ago I've
successfully publicly defended in front of my friends, family and colleagues.&lt;/p&gt;
&lt;p&gt;I'm now a "Doctor of Philosophy in Computer Science :)&lt;/p&gt;
&lt;p&gt;I will update my thesis with the last comments in November and send the final
version to the university. At which point, I'll publish it on this website as
well.&lt;/p&gt;&lt;/div&gt;</description><category>Machine Learning</category><category>Personal</category><category>thesis</category><guid>http://baptiste-wicht.com/posts/2017/10/i-successfully-defended-my-phd.html</guid><pubDate>Sun, 15 Oct 2017 15:16:29 GMT</pubDate></item><item><title>Deep Learning Library 1.0 - Fast Neural Network Library</title><link>http://baptiste-wicht.com/posts/2017/10/deep-learning-library-10-fast-neural-network-library.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;div&gt;&lt;img alt="DLL Logo" class="align-center" src="http://baptiste-wicht.com/images/dll_logo.png"&gt;
&lt;p&gt;I'm very happy to announce the release of the first version of Deep Learning
Library (DLL) 1.0. DLL is a neural network library with a focus on speed and
ease of use.&lt;/p&gt;
&lt;p&gt;I started working on this library about 4 years ago for my Ph.D. thesis.
I needed a good library to train and use Restricted Boltzmann Machines (RBMs)
and at this time there was no good support for it. Therefore, I decided to write
my own. It now has very complete support for the RBM and the Convolutional RBM
(CRBM) models. Stacks of RBMs (or Deep Belief Networks (DBNs)) can be pretrained
using Contrastive Divergence and then either fine-tuned with mini-batch gradient
descent or Conjugate Gradient or used as a feature extractor. Over the years,
the library has been extended to handle Artificial Neural Networks (ANNs) and
Convolutional Neural Networks (CNNs). The network is also able to train regular
auto-encoders. Several advanced layers such as Dropout or Batch Normalization
are also available as well as adaptive learning rates techniques such as
Adadelta and Adam. The library also has integrated support for a few datasets:
MNIST, CIFAR-10 and ImageNet.&lt;/p&gt;
&lt;p&gt;This library can be used using a C++ interface. The library is fully
header-only. It requires a C++14 compiler, which means a minimum of clang 3.9 or
GCC 6.3.&lt;/p&gt;
&lt;p&gt;In this post, I'm going to present a few examples on using the library and give
some information about the performance of the library and the roadmap for the
project.&lt;/p&gt;
&lt;p class="more"&gt;&lt;a href="http://baptiste-wicht.com/posts/2017/10/deep-learning-library-10-fast-neural-network-library.html"&gt;Read more…&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;</description><category>C++</category><category>dll</category><category>etl</category><category>GPU</category><category>Machine Learning</category><category>Performances</category><guid>http://baptiste-wicht.com/posts/2017/10/deep-learning-library-10-fast-neural-network-library.html</guid><pubDate>Sat, 07 Oct 2017 13:42:16 GMT</pubDate></item><item><title>DLL: Blazing Fast Neural Network Library</title><link>http://baptiste-wicht.com/posts/2017/08/dll-blazing-fast-neural-network-library.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;div&gt;&lt;p&gt;A few weeks ago, I talked about all
&lt;a class="reference external" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html"&gt;the new features of my Deep Learning Library (DLL)&lt;/a&gt;
project. I've mentioned that, on several experiments, DLL was always
significantly faster than some popular deep learning frameworks such as
TensorFlow. I'll now go into more details into this comparison and provide all
the results. So far, the paper we wrote about these results has not been
published, so I'll not provide the paper directly yet.&lt;/p&gt;
&lt;p&gt;For those that may not know, DLL is the project I've been developing to support
my Ph.D. thesis. This is a neural network framework  that supports
Fully-Connected Neural Network (FCNN), Convolutional Neural Network (CNN),
Restricted Boltzmann Machine (RBM), Deep Belief Network (DBN), Convolutional RBM
(CRBM) and Convolutional DBN (CDBN). It also supports a large variety of options
such as Dropout, Batch Normalization and Adaptive Learning Rates. You can read
read the
&lt;a class="reference external" href="https://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html"&gt;previous post&lt;/a&gt;
if you want more information about the new features of the framework. And, as those of
you that read my blog frequently may know, I'm a bit obsessed with performance
optimization, so I've spent a considerable amount of time optimizing
the performance of neural network training, on CPU. Since, at the beginning of my
thesis, I had no access to GPU for training, I've focused on CPU. Although there
is now support for GPU, the gains are not yet important enough.&lt;/p&gt;
&lt;div class="section" id="evaluation"&gt;
&lt;h2&gt;Evaluation&lt;/h2&gt;
&lt;p&gt;To see how fast, or not, the library was, it was compared against five popular
machine learning libraries:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Caffe, installed from sources&lt;/li&gt;
&lt;li&gt;TensorFlow 1.0, from pip&lt;/li&gt;
&lt;li&gt;Keras 2.0, from pip&lt;/li&gt;
&lt;li&gt;Torch, installed from sources&lt;/li&gt;
&lt;li&gt;DeepLearning4J 0.7, from Maven&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I've run four different experiments with all these frameworks and compared the
efficiency of each of them for training the same neural networks with the same
options. In each case, the training or testing error have also been compared to
ensure that each framework is doing roughly the same. I wont present here the
details, but in each experiment DLL showed around the same accuracies as the
other frameworks. I will only focus on the speed results in this article.&lt;/p&gt;
&lt;p&gt;Each experiment is done once with only CPU and once with a GPU. For DLL, I only
report the CPU time in both modes, since it's more stable and more optimized.&lt;/p&gt;
&lt;p&gt;The code for the evaluation is available online on the
&lt;a class="reference external" href="https://github.com/wichtounet/frameworks"&gt;Github repository of the frameworks project&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="mnist-fully-connected-neural-network"&gt;
&lt;h2&gt;MNIST: Fully Connected Neural Network&lt;/h2&gt;
&lt;p&gt;The first experiment is performed on The MNIST data set. It consists of 60'000
grayscale images of size 28x28. The goal is to classify each image of a digit
from 0 to 9. To solve this task, I trained a very small fully-connected neural
network with 500 hidden units in the first layer, 250 in the second and 10 final
hidden units (or output units) for classification. The first two layers are
using the logistic sigmoid activation function and the last layer is using the
softmax activation function. The network is trained for 50 epochs with a
categorical cross entropy loss, with mini-batches of 100 images. Here are
results of this experiment:&lt;/p&gt;
&lt;div class="figure align-center"&gt;
&lt;img alt="Training time performance for the different frameworks on the Fully-Connected Neural Network experiment, on MNIST." src="http://baptiste-wicht.com/images/dll_fcnn.png"&gt;
&lt;p class="caption"&gt;Training time performance for the different frameworks on the Fully-Connected
Neural Network experiment, on MNIST. All the times are in seconds.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;In DLL mode, the DLL framework is the clear winner here! It's about 35% faster
than TensorFlow and Keras which are coming at the second place. DLL is more than
four times slower than DLL and the last two frameworks (Caffe and
DeepLearning4J) are five times slower than DLL! Once we add a GPU to the system,
the results are very different. Caffe is now the fastest framework, three times
faster than DLL. DLL is less than two times slower than Keras and TensorFlow.
Interestingly, DLL is still faster than Torch and DeepLearning4J.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="mnist-convolutional-neural-network"&gt;
&lt;h2&gt;MNIST: Convolutional Neural Network&lt;/h2&gt;
&lt;p&gt;Although a Fully-Connected Neural Network is an interesting tool, the trend now
is to use Convolutional Neural Network which have proved very efficient at
solving a lot of problems. The second experiment is also using the same data
set. Again, it's a rather small network. The first layer is a convolutional
layer with 8 5x5 kernels, followed by max pooling layer with 2x2 kernel. They
are followed by one more convolutional layers with 8 5x5 kernels and a 2x2 max
pooling layer. These first four layers are followed by two fully-connected
layers, the first with 150 hidden units and the last one with 10 output units.
The activation functions are the same as for the first network, as is the
training procedure. This takes significantly longer to train than the first
network because of the higher complexity of the convolutional layers compared to
the fully-connected layers even though they have much less weights. The results
are present in the next figure:&lt;/p&gt;
&lt;div class="figure align-center"&gt;
&lt;img alt="Training time performance for the different frameworks on the Convolutional Neural Network experiment, on MNIST." src="http://baptiste-wicht.com/images/dll_cnn.png"&gt;
&lt;p class="caption"&gt;Training time performance for the different frameworks on the Convolutional
Neural Network experiment, on MNIST. All the times are in seconds.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Again, on CPU, DLL is the clear winner, by a lot! It's already 3.6 times faster
than the second frameworks Keras and TensorFlow, more than four times faster
than Caffe and Torch and 8 times faster than DeepLearning4J that is proving very
slow on this experiment. Once a GPU is added, Keras and TensorFlow are about
twice faster than DLL. However, DLL is still faster than the other frameworks
even though they are taking advantage of the GPU.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="cifar-10"&gt;
&lt;h2&gt;CIFAR-10&lt;/h2&gt;
&lt;p&gt;The second data set that is tested is the CIFAR-10 data set. It's an object
recognition with 10 classes for classification. The training set is composed of
50'000 colour images for 32x32 pixels. The network that is used for this data
set is similar in architecture than the first network, but has more parameters.
The first convolutional layer now has 12 5x5 kernels and the second
convolutional layer has 24 3x3 kernels. The pooling layers are the same. The
first fully-connected has 64 hidden units and the last one has 10 output units.
The last layer again use a softmax activation function while the other layers
are using Rectifier Linear Units (ReLU). The training is done in the same manner
as for the two first networks. Unfortunately, it was not possible to train
DeepLearning4J on this data set, even though there is official support for this
data set. Since I've had no answer to my question regarding this issue, the
results are simply removed from this experiment. It may not seem so but it's
considerably longer to train this network because of the larger number of input
channels and larger number of convolutional kernels in each layer. Let's get to
the results now:&lt;/p&gt;
&lt;div class="figure align-center"&gt;
&lt;img alt="Training time performance for the different frameworks on the Convolutional Neural Network experiment, on CIFAR-10." src="http://baptiste-wicht.com/images/dll_cifar10.png"&gt;
&lt;p class="caption"&gt;Training time performance for the different frameworks on the Convolutional
Neural Network experiment, on CIFAR-10. All the times are in seconds.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;DLL is still the fastest on CPU, but the margin is less than before. It's about
40% faster than TensorFlow and Keras, twice faster than Torch and 2.6 times
faster than Caffe. Once a GPU is added, DLL is about as fast as Torch but slower
than the other three frameworks. TensorFlow and Keras are about four times
faster than DLL while Caffe is about twice faster than DLL. We can see that
with this larger network, the GPU becomes more interesting and that there is
a smaller margin for improvements compared to the other frameworks.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="imagenet"&gt;
&lt;h2&gt;ImageNet&lt;/h2&gt;
&lt;p&gt;The last experiment is made on the ImageNet data set. I used the ILSVRC 2012
subset, that consists "only" of about 1.2 million images for training. I've
resized all the images to 256x256 pixels, this makes for 250 times more colour
values than a MNIST image. This dimension and the number of images makes it
impractical to keep the dataset in memory. The images must be loaded in batch
from the disk. No random cropping or mirroring was performed. The network is
much larger to solve this task. The network starts with 5 pairs of convolutional
layers and max pooling layers. The convolutional layers have 3x3 kernels, 16 for
the first two layers and 32 for the three following one. The five max pooling
layers use 2x2 kernels. Each convolutional layer uses zero-padding so that their
output features are the same dimensions as the input. They are followed by two
fully-connected layer. The first one with 2048 hidden units and the last one
with 1000 output units (one for each class). Except for the last layer, using
softmax, the layers all uses ReLU. The network is trained with mini-batches of
128 images (except for DeepLearning4J and Torch, which can only use 64 images on
the amount of RAM available on my machine). To ease the comparison, I report the
time necessary to train one batch of data (or two for DeepLearning4J and Torch).
The results, presented in logarithmic scale because of DeepLearning4J disastrous
results, are as follows:&lt;/p&gt;
&lt;div class="figure align-center"&gt;
&lt;img alt="Training time performance for the different frameworks on the Convolutional Neural Network experiment, on ImageNet." src="http://baptiste-wicht.com/images/dll_imagenet.png"&gt;
&lt;p class="caption"&gt;Training time performance for the different frameworks on the Convolutional
Neural Network experiment, on ImageNet. The times are the time necessary to
train a batch of 128 images. All the times are in milliseconds.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;For this final experiment, DLL is again significantly faster than all the other
frameworks. It's about 40% faster than Keras, twice faster than TensorFlow and
Caffe and more than three times faster than Torch. Although 40% may seem not
that much, don't forget that this kind of training may take days, so it can save
you a lot of time. All the frameworks are much faster than DeepLearning4J. Based
on several posts on the internet, I suspect that this comes from the model of
GPU I have been used (GTX 960), but all the other frameworks seem to handle this
card pretty well.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="conclusion"&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;I hope this is not too much of a bragging post :P We can see that my efforts to
make the code as fast as possible have paid :) As was shown in the experiments,
my DLL framework is always the fastest framework when the neural network is
trained on CPU. I'm quite pleased with the results since I've done a lot of work
to optimize the speed as much as possible and since I'm competing with
well-known libraries that have been developed by several persons.  Moreover, the
accuracies of the trained networks is similar to that of the networks trained
with the other frameworks. Even when the other frameworks are using GPU, the
library still remains competitive, although never the fastest.&lt;/p&gt;
&lt;p&gt;In the next step (I've no idea when I'll have the time though), I will want to
focus on GPU speed. This will mostly come from a better support of the GPU in
the ETL library on which DLL is based. I have many ideas to improve it a lot,
but it will take me a lot of time.&lt;/p&gt;
&lt;p&gt;If you want more information on the DLL library, you can have a look at
&lt;a class="reference external" href="https://github.com/wichtounet/dll"&gt;its Github repository&lt;/a&gt; and especially at
&lt;a class="reference external" href="https://github.com/wichtounet/dll/tree/master/examples/src"&gt;the few examples&lt;/a&gt;.
You can also have a look at &lt;a class="reference external" href="https://baptiste-wicht.com/categories/dll.html"&gt;my posts about DLL&lt;/a&gt;.
Finally, don't hesitate to comment or contact me through Github issues if you
have comments or problems with this post, the library or anything ;)&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;</description><category>C++</category><category>dll</category><category>etl</category><category>GPU</category><category>Machine Learning</category><category>projects</category><guid>http://baptiste-wicht.com/posts/2017/08/dll-blazing-fast-neural-network-library.html</guid><pubDate>Fri, 11 Aug 2017 09:09:14 GMT</pubDate></item><item><title>Update on Deep Learning Library (DLL): Dropout, Batch Normalization, Adaptive Learning Rates, ...</title><link>http://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;div&gt;&lt;p&gt;It's been a while since I've posted something on this, especially since I had
one month vacation. This year I've been able to integrate a great number of
changes into my Deep Learning Library (DLL) project. It has seen a lot of
refactorings and a lot of new features making it look like a real neural network
library now. In this post, I'll try to outline the last new features and changes
of the library.&lt;/p&gt;
&lt;p&gt;For those that don't know, DLL is a library for neural network training, written
in C++ and for C++. You can train Fully-Connected Neural Networks and
Convolutional Neural Networks. The focus of the framework is on speed and easy
use in C++.&lt;/p&gt;
&lt;p&gt;As for my ETL project and again thanks to my thesis supervisor, the project now
has a logo:&lt;/p&gt;
&lt;img alt="DLL Logo" class="align-center" src="http://baptiste-wicht.com/images/dll_logo.png"&gt;
&lt;div class="section" id="adaptive-learning-rates"&gt;
&lt;h2&gt;Adaptive Learning Rates&lt;/h2&gt;
&lt;p&gt;Before, the framework only supported simple SGD and Momentum updates for the
different parameters of the network. Moreover, it was not very well extendable.
Therefore, I reviewed the system to be able to configure an optimizer for each
network to train. Once that was done, the first thing I did was to add support
for Nesterov Accelerated Gradients (NAG) as a third optimizer. After this,
I realized it was then easy to integrate support for more advanced optimizers
including support for adaptive learning rates. This means that the learning rate
will be adapted for each parameter depending on what the network is learning.
Some of the optimizers even don't need any learning rate. So far, I've
implemented support for the following optimizers: Adagrad, RMSProp, Adam (with
and without bias correction), Adamax (Adam with infinite norm), Nadam (Adam with
Nesterov momentum) and Adadelta (no more learning rate). The user can now choose
the optimizer of its choice, for instance NADAM, as a parameter of the network:&lt;/p&gt;
&lt;pre class="code c++"&gt;&lt;a name="rest_code_50aa127d7bbe4bfc83db2e693920636a-1"&gt;&lt;/a&gt;&lt;span class="c1"&gt;// Use a Nadam optimizer&lt;/span&gt;
&lt;a name="rest_code_50aa127d7bbe4bfc83db2e693920636a-2"&gt;&lt;/a&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;updater&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;updater_type&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;NADAM&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;Another improvement in the same domain is that the learning rate can also be
decayed over time automatically by the optimizer.&lt;/p&gt;
&lt;p&gt;If you want more information on the different optimizers, you can have a look at
this very good article:
&lt;a class="reference external" href="http://ruder.io/optimizing-gradient-descent/"&gt;An overview of gradient descent optimization algorithms&lt;/a&gt;
from Sebastian Ruder.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="better-loss-support"&gt;
&lt;h2&gt;Better loss support&lt;/h2&gt;
&lt;p&gt;Before, DLL was automatically using Categorical Cross Entropy Loss, but it was
not possible to change it and it was not even possible to see the loss over
time. Now, the current value of the loss is displayed after each epoch of
training and the loss used for training is now configurable. So far, only three
different losses are supported, but it it not difficult to add new loss to the
system. The three losses supported are: Categorical Cross Entropy Loss, Binary
Cross Entropy Loss and Mean Squared Error Loss.&lt;/p&gt;
&lt;p&gt;Again, each network can specify the loss to use:&lt;/p&gt;
&lt;pre class="code C++"&gt;&lt;a name="rest_code_e05ffa8957264a38a00612b2e62fdc0c-1"&gt;&lt;/a&gt;&lt;span class="c1"&gt;// Use a Binary Cross Entropy Loss&lt;/span&gt;
&lt;a name="rest_code_e05ffa8957264a38a00612b2e62fdc0c-2"&gt;&lt;/a&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;loss_function&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;BINARY_CROSS_ENTROPY&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class="section" id="dropout"&gt;
&lt;h2&gt;Dropout&lt;/h2&gt;
&lt;p&gt;Dropout is a relatively new technique for neural network training. This is
especially made to reduce overfitting since a large number of sub networks will
be trained and it should prevent co-adaptation between different neurons. This
technique is relatively simple. Indeed, it simply randomly sets to zero some of
the input neurons of layers. At each batch, a new mask will be used and this
should lead to a large number of sub networks being trained.&lt;/p&gt;
&lt;p&gt;Here is example of a MLP with Dropout (p=0.5):&lt;/p&gt;
&lt;pre class="code C++"&gt;&lt;a name="rest_code_7513c1eacdcb41379cbadc0315b2ce7b-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;using&lt;/span&gt; &lt;span class="n"&gt;network_t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dyn_dbn_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;
&lt;a name="rest_code_7513c1eacdcb41379cbadc0315b2ce7b-2"&gt;&lt;/a&gt;    &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dbn_layers&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;
&lt;a name="rest_code_7513c1eacdcb41379cbadc0315b2ce7b-3"&gt;&lt;/a&gt;        &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dense_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;28&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;28&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;500&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;layer_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_7513c1eacdcb41379cbadc0315b2ce7b-4"&gt;&lt;/a&gt;        &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dropout_layer_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;layer_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_7513c1eacdcb41379cbadc0315b2ce7b-5"&gt;&lt;/a&gt;        &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dense_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;500&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;250&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;layer_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_7513c1eacdcb41379cbadc0315b2ce7b-6"&gt;&lt;/a&gt;        &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dropout_layer_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;layer_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_7513c1eacdcb41379cbadc0315b2ce7b-7"&gt;&lt;/a&gt;        &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dense_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;250&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;activation&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;function&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;SOFTMAX&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;layer_t&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_7513c1eacdcb41379cbadc0315b2ce7b-8"&gt;&lt;/a&gt;    &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;updater&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;updater_type&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;MOMENTUM&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;     &lt;span class="c1"&gt;// Momentum&lt;/span&gt;
&lt;a name="rest_code_7513c1eacdcb41379cbadc0315b2ce7b-9"&gt;&lt;/a&gt;    &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;                          &lt;span class="c1"&gt;// The mini-batch size&lt;/span&gt;
&lt;a name="rest_code_7513c1eacdcb41379cbadc0315b2ce7b-10"&gt;&lt;/a&gt;    &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;shuffle&lt;/span&gt;                                  &lt;span class="c1"&gt;// Shuffle before each epoch&lt;/span&gt;
&lt;a name="rest_code_7513c1eacdcb41379cbadc0315b2ce7b-11"&gt;&lt;/a&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;dbn_t&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class="section" id="batch-normalization"&gt;
&lt;h2&gt;Batch Normalization&lt;/h2&gt;
&lt;p&gt;Batch Normalization is another new technique for training neural networks. This
technique will ensure that each of the layer will receive inputs that look
kind of similar. This is a very large advantage since then you reduce the
different in impact of hyper parameters on different layers. Google reported
much faster training with this technique by getting rid of Dropout and by
increasing the learning rate of training.&lt;/p&gt;
&lt;p&gt;Here is an example of using Batch Normalization in a CNN:&lt;/p&gt;
&lt;pre class="code C++"&gt;&lt;a name="rest_code_d012f7d3c5ec461ea060c2efdc9abc51-1"&gt;&lt;/a&gt;&lt;span class="k"&gt;using&lt;/span&gt; &lt;span class="n"&gt;network_t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dyn_dbn_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;
&lt;a name="rest_code_d012f7d3c5ec461ea060c2efdc9abc51-2"&gt;&lt;/a&gt;    &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dbn_layers&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;
&lt;a name="rest_code_d012f7d3c5ec461ea060c2efdc9abc51-3"&gt;&lt;/a&gt;        &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;conv_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;28&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;28&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;layer_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_d012f7d3c5ec461ea060c2efdc9abc51-4"&gt;&lt;/a&gt;        &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;batch_normalization_layer_4d_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;24&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;24&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;layer_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_d012f7d3c5ec461ea060c2efdc9abc51-5"&gt;&lt;/a&gt;        &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;mp_layer_2d_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;24&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;24&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;layer_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_d012f7d3c5ec461ea060c2efdc9abc51-6"&gt;&lt;/a&gt;        &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;conv_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;layer_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_d012f7d3c5ec461ea060c2efdc9abc51-7"&gt;&lt;/a&gt;        &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;batch_normalization_layer_4d_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;layer_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_d012f7d3c5ec461ea060c2efdc9abc51-8"&gt;&lt;/a&gt;        &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;mp_layer_2d_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;layer_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_d012f7d3c5ec461ea060c2efdc9abc51-9"&gt;&lt;/a&gt;        &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dense_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;150&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;layer_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_d012f7d3c5ec461ea060c2efdc9abc51-10"&gt;&lt;/a&gt;        &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;batch_normalization_layer_2d_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;150&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;layer_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_d012f7d3c5ec461ea060c2efdc9abc51-11"&gt;&lt;/a&gt;        &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dense_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;150&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;activation&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;function&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;SOFTMAX&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;layer_t&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_d012f7d3c5ec461ea060c2efdc9abc51-12"&gt;&lt;/a&gt;    &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;updater&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;updater_type&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;ADADELTA&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;     &lt;span class="c1"&gt;// Adadelta&lt;/span&gt;
&lt;a name="rest_code_d012f7d3c5ec461ea060c2efdc9abc51-13"&gt;&lt;/a&gt;    &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;                          &lt;span class="c1"&gt;// The mini-batch size&lt;/span&gt;
&lt;a name="rest_code_d012f7d3c5ec461ea060c2efdc9abc51-14"&gt;&lt;/a&gt;    &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;shuffle&lt;/span&gt;                                  &lt;span class="c1"&gt;// Shuffle the dataset before each epoch&lt;/span&gt;
&lt;a name="rest_code_d012f7d3c5ec461ea060c2efdc9abc51-15"&gt;&lt;/a&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;dbn_t&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;You may notice that the layer is set as 4D so should only be used after
convolutional layer (or after the input). If you want to use it after
fully-connected layers, you can use the 2D version that works the same way.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="better-dataset-support"&gt;
&lt;h2&gt;Better dataset support&lt;/h2&gt;
&lt;p&gt;At the beginning, I designed DLL so that the user could directly pass data for
training in the form of STL Containers such as the std::vector. This is good in
some cases, but in some cases, the user does not know how to read the data , or
does not want to be bothered with it. Therefore, several data sets reader are
now available. Moreover, the entire system has been reworked to use generators
for data. A generator is simply a concept that has some data to produce. The
advantage of this new system is data augmentation is now supported every where
and much more efficiently than before. It is now possible to perform random
cropping and mirroring of images for instance. Moreover, the data augmentation
can be done in a secondary thread so as to be sure that there is always enough
data available for the training.&lt;/p&gt;
&lt;p&gt;The library now has a powerful dataset reader for both MNIST and CIFAR-10 and
the reader for ImageNet is almost ready. The project has already been used and
tested with these three datasets now. Moreover, the support for directly passing
STL containers has been maintained. In this case, a generator is simply created
around the data provided in the container and the generator is then passed to
the system for training.&lt;/p&gt;
&lt;p&gt;Here for instance is how to read MNIST data and scale (divide) all pixel values
by 255:&lt;/p&gt;
&lt;pre class="code c++"&gt;&lt;a name="rest_code_5819500ff367416f835d3c991dbb86fe-1"&gt;&lt;/a&gt;&lt;span class="c1"&gt;// Load the dataset&lt;/span&gt;
&lt;a name="rest_code_5819500ff367416f835d3c991dbb86fe-2"&gt;&lt;/a&gt;&lt;span class="k"&gt;auto&lt;/span&gt; &lt;span class="n"&gt;dataset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;make_mnist_dataset&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;{},&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;scale_pre&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;255&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;{});&lt;/span&gt;
&lt;a name="rest_code_5819500ff367416f835d3c991dbb86fe-3"&gt;&lt;/a&gt;&lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;display&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;a name="rest_code_5819500ff367416f835d3c991dbb86fe-4"&gt;&lt;/a&gt;
&lt;a name="rest_code_5819500ff367416f835d3c991dbb86fe-5"&gt;&lt;/a&gt;&lt;span class="c1"&gt;// Train the network&lt;/span&gt;
&lt;a name="rest_code_5819500ff367416f835d3c991dbb86fe-6"&gt;&lt;/a&gt;&lt;span class="n"&gt;net&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;fine_tune&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="mi"&gt;25&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a name="rest_code_5819500ff367416f835d3c991dbb86fe-7"&gt;&lt;/a&gt;
&lt;a name="rest_code_5819500ff367416f835d3c991dbb86fe-8"&gt;&lt;/a&gt;&lt;span class="c1"&gt;// Test the network&lt;/span&gt;
&lt;a name="rest_code_5819500ff367416f835d3c991dbb86fe-9"&gt;&lt;/a&gt;&lt;span class="n"&gt;net&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;evaluate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;test&lt;/span&gt;&lt;span class="p"&gt;());&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class="section" id="much-faster-performance"&gt;
&lt;h2&gt;Much faster performance&lt;/h2&gt;
&lt;p&gt;I've spent quite a lot of time improving the performance of the framework. I've
focused on every part of training in order to make training of neural networks
as fast as possible. I've also made a comparison of the framework against
several popular machine learning framework (Caffe, TensorFlow, Keras, Torch and
DeepLearning4J). For instance, here are the results on a small CNN experiment on
MNIST with all the different frameworks in CPU mode and in GPU mode:&lt;/p&gt;
&lt;img alt="DLL Comparison Against other frameworks" class="align-center" src="http://baptiste-wicht.com/images/dll_comparison.png"&gt;
&lt;p&gt;As you can see, DLL is by far the fastest framework on CPU. On GPU, there is
still some work to be done, but this is already ongoing (although a lot of work
remains). This is confirmed on each of the four experiments performed on MNIST,
CIFAR-10 and ImageNet, although the margin is smaller for larger networks (still
about 40% faster than TensorFlow and Keras which are the fastest framework after
DLL on CPU on my tests).&lt;/p&gt;
&lt;p&gt;Overall, DLL is between 2 and 4 times faster than before and is always the
fastest framework for neural network training when training is performed on CPU.&lt;/p&gt;
&lt;p&gt;I proposed a talk about these optimizations and performance for Meeting C++ this
year, but it has unfortunately not been accepted. We also have submitted
a publication about the framework to a conference later this year.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="examples"&gt;
&lt;h2&gt;Examples&lt;/h2&gt;
&lt;p&gt;The project now has a few examples (available &lt;a class="reference external" href="https://github.com/wichtounet/dll/tree/master/examples/src"&gt;here&lt;/a&gt;), well-designed and I try to update them with the latest updates of the framework.&lt;/p&gt;
&lt;p&gt;For instance, here is the CNN example for MNIST (without includes):&lt;/p&gt;
&lt;pre class="code c++"&gt;&lt;a name="rest_code_9d20c39da7344db3871c0d51b4b8d007-1"&gt;&lt;/a&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;int&lt;/span&gt; &lt;span class="cm"&gt;/*argc*/&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kt"&gt;char&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="cm"&gt;/*argv*/&lt;/span&gt; &lt;span class="p"&gt;[])&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;a name="rest_code_9d20c39da7344db3871c0d51b4b8d007-2"&gt;&lt;/a&gt;    &lt;span class="c1"&gt;// Load the dataset&lt;/span&gt;
&lt;a name="rest_code_9d20c39da7344db3871c0d51b4b8d007-3"&gt;&lt;/a&gt;    &lt;span class="k"&gt;auto&lt;/span&gt; &lt;span class="n"&gt;dataset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;make_mnist_dataset&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;{},&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;scale_pre&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;255&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;{});&lt;/span&gt;
&lt;a name="rest_code_9d20c39da7344db3871c0d51b4b8d007-4"&gt;&lt;/a&gt;
&lt;a name="rest_code_9d20c39da7344db3871c0d51b4b8d007-5"&gt;&lt;/a&gt;    &lt;span class="c1"&gt;// Build the network&lt;/span&gt;
&lt;a name="rest_code_9d20c39da7344db3871c0d51b4b8d007-6"&gt;&lt;/a&gt;
&lt;a name="rest_code_9d20c39da7344db3871c0d51b4b8d007-7"&gt;&lt;/a&gt;    &lt;span class="k"&gt;using&lt;/span&gt; &lt;span class="n"&gt;network_t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dyn_dbn_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;
&lt;a name="rest_code_9d20c39da7344db3871c0d51b4b8d007-8"&gt;&lt;/a&gt;        &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dbn_layers&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;
&lt;a name="rest_code_9d20c39da7344db3871c0d51b4b8d007-9"&gt;&lt;/a&gt;            &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;conv_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;28&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;28&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;layer_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_9d20c39da7344db3871c0d51b4b8d007-10"&gt;&lt;/a&gt;            &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;mp_layer_2d_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;24&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;24&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;layer_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_9d20c39da7344db3871c0d51b4b8d007-11"&gt;&lt;/a&gt;            &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;conv_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;layer_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_9d20c39da7344db3871c0d51b4b8d007-12"&gt;&lt;/a&gt;            &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;mp_layer_2d_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;layer_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_9d20c39da7344db3871c0d51b4b8d007-13"&gt;&lt;/a&gt;            &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dense_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;150&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;layer_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_9d20c39da7344db3871c0d51b4b8d007-14"&gt;&lt;/a&gt;            &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;dense_desc&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;150&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;activation&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;function&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;SOFTMAX&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;layer_t&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;a name="rest_code_9d20c39da7344db3871c0d51b4b8d007-15"&gt;&lt;/a&gt;        &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;updater&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;updater_type&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;MOMENTUM&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;     &lt;span class="c1"&gt;// Momentum&lt;/span&gt;
&lt;a name="rest_code_9d20c39da7344db3871c0d51b4b8d007-16"&gt;&lt;/a&gt;        &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;                          &lt;span class="c1"&gt;// The mini-batch size&lt;/span&gt;
&lt;a name="rest_code_9d20c39da7344db3871c0d51b4b8d007-17"&gt;&lt;/a&gt;        &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;shuffle&lt;/span&gt;                                  &lt;span class="c1"&gt;// Shuffle the dataset before each epoch&lt;/span&gt;
&lt;a name="rest_code_9d20c39da7344db3871c0d51b4b8d007-18"&gt;&lt;/a&gt;    &lt;span class="o"&gt;&amp;gt;::&lt;/span&gt;&lt;span class="n"&gt;dbn_t&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_9d20c39da7344db3871c0d51b4b8d007-19"&gt;&lt;/a&gt;
&lt;a name="rest_code_9d20c39da7344db3871c0d51b4b8d007-20"&gt;&lt;/a&gt;    &lt;span class="k"&gt;auto&lt;/span&gt; &lt;span class="n"&gt;net&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;make_unique&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;network_t&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;a name="rest_code_9d20c39da7344db3871c0d51b4b8d007-21"&gt;&lt;/a&gt;
&lt;a name="rest_code_9d20c39da7344db3871c0d51b4b8d007-22"&gt;&lt;/a&gt;    &lt;span class="n"&gt;net&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;learning_rate&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_9d20c39da7344db3871c0d51b4b8d007-23"&gt;&lt;/a&gt;
&lt;a name="rest_code_9d20c39da7344db3871c0d51b4b8d007-24"&gt;&lt;/a&gt;    &lt;span class="c1"&gt;// Display the network and dataset&lt;/span&gt;
&lt;a name="rest_code_9d20c39da7344db3871c0d51b4b8d007-25"&gt;&lt;/a&gt;    &lt;span class="n"&gt;net&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;display&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;a name="rest_code_9d20c39da7344db3871c0d51b4b8d007-26"&gt;&lt;/a&gt;    &lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;display&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;
&lt;a name="rest_code_9d20c39da7344db3871c0d51b4b8d007-27"&gt;&lt;/a&gt;
&lt;a name="rest_code_9d20c39da7344db3871c0d51b4b8d007-28"&gt;&lt;/a&gt;    &lt;span class="c1"&gt;// Train the network&lt;/span&gt;
&lt;a name="rest_code_9d20c39da7344db3871c0d51b4b8d007-29"&gt;&lt;/a&gt;    &lt;span class="n"&gt;net&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;fine_tune&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="mi"&gt;25&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;a name="rest_code_9d20c39da7344db3871c0d51b4b8d007-30"&gt;&lt;/a&gt;
&lt;a name="rest_code_9d20c39da7344db3871c0d51b4b8d007-31"&gt;&lt;/a&gt;    &lt;span class="c1"&gt;// Test the network on test set&lt;/span&gt;
&lt;a name="rest_code_9d20c39da7344db3871c0d51b4b8d007-32"&gt;&lt;/a&gt;    &lt;span class="n"&gt;net&lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="n"&gt;evaluate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;test&lt;/span&gt;&lt;span class="p"&gt;());&lt;/span&gt;
&lt;a name="rest_code_9d20c39da7344db3871c0d51b4b8d007-33"&gt;&lt;/a&gt;
&lt;a name="rest_code_9d20c39da7344db3871c0d51b4b8d007-34"&gt;&lt;/a&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;a name="rest_code_9d20c39da7344db3871c0d51b4b8d007-35"&gt;&lt;/a&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class="section" id="reproducible-results"&gt;
&lt;h2&gt;Reproducible results&lt;/h2&gt;
&lt;p&gt;And last, but maybe not least, I've finally united all the random number
generation code. This means that DLL can now set a global seed and that two
training of the same network and data with the same seed will now produce
exactly the same result.&lt;/p&gt;
&lt;p&gt;The usage is extremely simple:&lt;/p&gt;
&lt;pre class="code c++"&gt;&lt;a name="rest_code_c73cefa9ac4e491d81cb82dd5171073a-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;dll&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;set_seed&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;42&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class="section" id="conclusion"&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;After all these changes, I truly feel that the library is now in a much better
state and could be useful in several projects. I hope that this will be useful
to some more people. Moreover, as you can see by the performance results, the
framework is now extremely efficient at training neural networks on CPU.&lt;/p&gt;
&lt;p&gt;If you want more information, you can consult the
&lt;a class="reference external" href="https://github.com/wichtounet/dll"&gt;dll Github Repository&lt;/a&gt;. You can also add
a comment to this post. If you find any problem on the project or have specific
question or request, don't hesitate to open an issue on Github.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;</description><category>deep learning</category><category>dll</category><category>etl</category><category>Machine Learning</category><category>publications</category><category>thesis</category><guid>http://baptiste-wicht.com/posts/2017/07/update-on-deep-learning-library-dll-dropout-batch-normalization-adaptive-learning-rates.html</guid><pubDate>Sun, 16 Jul 2017 13:41:51 GMT</pubDate></item><item><title>Speed up TensorFlow inference by compiling it from source</title><link>http://baptiste-wicht.com/posts/2017/05/speed-up-tensorflow-inference-compiling-from-source.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;div&gt;&lt;p&gt;The most simple way to install TensorFlow is to work in a virtual Python
environment and simply to use either the TensorFlow official packages in pip or
use one of the official wheels for distributions.  There is one big problem with
that technique and it's the fact that the binaries are precompiled so that they
fit as many hardware configuration as possible. This is normal from Google since
generating precompiled binaries for all the possible combinations of processor
capabilities would be a nightmare. This is not a problem for GPU
since the CUDA Libraries will take care of the difference from one graphics card
to another. But it is a problem with CPU performance. Indeed, different
processors have different capabilities. For instance, the vectorization
capabilities are different from processor to processor (SSE, AVX, AVX2,
AVX-512F, FMA, ...). All those options can make a significant difference in the
performance of the programs. Although most of the machine learning training
occurs on GPU most of the time, the inference is mostly done on the CPU.
Therefore, it probably remains important to be as fast as possible on CPU.&lt;/p&gt;
&lt;p&gt;So if you care about performance on CPU, you should install TensorFlow from
sources directly yourself. This will allow compilation of the TensorFlow sources
with -march=native which will enable all the hardware capabilities of machine on
which you are compiling the library.&lt;/p&gt;
&lt;p&gt;Depending on your problem, this may give you some nice speedup. In my case, on
a very small Recurrent Neural Network, it made inference about 20% faster.  On
a larger problem and depending on your processor, you may gain much more than
that. If you are training on CPU, this may make a very large difference in total
time.&lt;/p&gt;
&lt;p&gt;Installing TensorFlow is sometimes a bit cumbersome. You'll likely have to
compile Bazel from sources as well and depending on your processor, it may take
a long time to finish. Nevertheless, I have successfully compiled TensorFlow
from sources on several machines now without too many problems. Just pay close
attention to the options you are setting while configuring TensorFlow, for
instance CUDA configuration if you want GPU support.&lt;/p&gt;
&lt;p&gt;I hope this little trick will help you gain some time :)&lt;/p&gt;
&lt;p&gt;Here is the &lt;a class="reference external" href="https://www.tensorflow.org/install/install_sources"&gt;link to compile TensorFlow from source&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;</description><category>CPU</category><category>GPU</category><category>Intel</category><category>Machine Learning</category><category>Performance</category><category>tensorflow</category><guid>http://baptiste-wicht.com/posts/2017/05/speed-up-tensorflow-inference-compiling-from-source.html</guid><pubDate>Wed, 10 May 2017 12:18:33 GMT</pubDate></item><item><title>Simplify Deep Learning Library usage on Linux and Windows!</title><link>http://baptiste-wicht.com/posts/2016/04/simplify-deep-learning-library-usage-on-linux-and-windows.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;div&gt;&lt;p&gt;No, I'm not dead ;) I've been very busy with my Ph.D (and playing Path of Exile,
let's be honest...) and haven't had time to write something here in a long time.&lt;/p&gt;
&lt;p&gt;Until now, there was too way to use my
&lt;a class="reference external" href="https://github.com/wichtounet/dll/"&gt;Deep Learning Library (DLL)&lt;/a&gt; project:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Write a C++ program that uses the library&lt;/li&gt;
&lt;li&gt;Install DLL and write a configuration file to define your network and the problem to solve&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The first version gives you all the features of the tool and allows you to build
exactly what you need. The second version is a bit more limited, but does not
require any C++ knowledge. However, it still does require a recent C++ compiler
and build system.&lt;/p&gt;
&lt;p&gt;Due to the high C++ requirements that are not met by Visual Studio and the fact
that I don't work on Windows, this platform is not supported by the tool. Until
now!&lt;/p&gt;
&lt;p&gt;I've added a third option to use DLL in the form of a Docker image to make the
second option even easier and allow the use of DLL on Windows. All you need is
Docker, which is available on Linux, Mac and Windows. This is still limited to
the second option in that you need to write a configuration describing the
network, but you need to build DLL and don't need to install all its
dependencies.&lt;/p&gt;
&lt;div class="section" id="usage"&gt;
&lt;h2&gt;Usage&lt;/h2&gt;
&lt;p&gt;To install the image, you can simply use &lt;cite&gt;docker pull&lt;/cite&gt;:&lt;/p&gt;
&lt;pre class="code bash"&gt;&lt;a name="rest_code_0407c4e38e1940f6895ec7d7f595a1ed-1"&gt;&lt;/a&gt;docker pull wichtounet/docker-dll
&lt;/pre&gt;&lt;p&gt;Then, to run it, you have to create a folder containing a &lt;cite&gt;dll.conf&lt;/cite&gt; file and
mount in the container at &lt;cite&gt;/dll/data/&lt;/cite&gt;. There are some examples in the
&lt;a class="reference external" href="https://github.com/wichtounet/docker-dll/"&gt;image repository&lt;/a&gt;.  For instance,
on Linux from the cloned repository:&lt;/p&gt;
&lt;pre class="code bash"&gt;&lt;a name="rest_code_13e88799dd9b4b0cac8d0177ec40e32c-1"&gt;&lt;/a&gt;docker run -v &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;pwd&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;/rbm_mnist/:/dll/data/ wichtounet/docker-dll
&lt;/pre&gt;&lt;p&gt;or on Windows:&lt;/p&gt;
&lt;pre class="code bash"&gt;&lt;a name="rest_code_62ea6de3c3ad49f8846ba0ff19ff414c-1"&gt;&lt;/a&gt;docker run -v /c/Users/Baptiste/rbm_mnist/:/dll/data wichtounet/docker-dll
&lt;/pre&gt;&lt;p&gt;This will automatically run the actions specified in the configuration file and
train your network.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="conclusion"&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;I would really have thought this would be harder, but it turned out that Docker
is a very good solution to deploy multiplatform demo tools :)&lt;/p&gt;
&lt;p&gt;As of now, there is only support for mnist data format in the tool in this
form, but I plan to add basic CSV support as well in the near future.&lt;/p&gt;
&lt;p&gt;I hope that this will help people willing to try the library with a simpler
usage.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;</description><category>deep learning</category><category>dll</category><category>Linux</category><category>Machine Learning</category><category>projects</category><category>Windows</category><guid>http://baptiste-wicht.com/posts/2016/04/simplify-deep-learning-library-usage-on-linux-and-windows.html</guid><pubDate>Fri, 29 Apr 2016 10:48:18 GMT</pubDate></item><item><title>Some news</title><link>http://baptiste-wicht.com/posts/2013/06/some-news.html</link><dc:creator>Baptiste Wicht</dc:creator><description>&lt;div&gt;&lt;p&gt;No, I'm not dead ;)&lt;/p&gt;
&lt;p&gt;After having finished my Master thesis in March, I took a break from my personal projects including this project. I then started a job in my school, waiting for a Ph.D thesis. I'm now working on a very interesting Machine Learning project about Speech, unfortunately in Java ;)&lt;/p&gt;
&lt;p&gt;I just started again working on eddic this week. I'm gonna try to improve as much as possible the performances of the parser. I will also try to post again some articles on this blog, although I don't know about what.&lt;/p&gt;&lt;/div&gt;</description><category>C++</category><category>EDDI</category><category>Java</category><category>Machine Learning</category><category>Others</category><guid>http://baptiste-wicht.com/posts/2013/06/some-news.html</guid><pubDate>Tue, 04 Jun 2013 21:52:24 GMT</pubDate></item></channel></rss>