<!DOCTYPE html>
<html prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article# " lang="en">
<head>
<meta charset="utf-8">
<base href="http://baptiste-wicht.com/index.html">
<meta name="description" content="Tutorials and short posts about programming, C++, Java, Assembly, Operating Systems Development, Compilers, ...">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>@Blog("Baptiste Wicht")</title>
<link href="assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<meta content="#5670d4" name="theme-color">
<link rel="alternate" type="application/rss+xml" title="RSS" href="rss.xml">
<link rel="canonical" href="http://baptiste-wicht.com/index.html">
<link rel="next" href="index-28.html" type="text/html">
<!--[if lt IE 9]><script src="assets/js/html5.js"></script><![endif]--><script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-2175227-7']);
  _gaq.push(['_trackPageview']);
  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script><link href="favicon.ico" rel="icon" type="image/x-icon">
</head>
<body>

<div class="social_container">
    <div class="social_container_gplus">
        <a target="_blank" title="Share on Google+" href="https://plusone.google.com/_/+1/confirm?hl=en&amp;url=http://baptiste-wicht.com/index.html"><img alt="Google Plus Logo" src="assets/img/google_plus.png"></a>
    </div>
    <div class="social_container_twitter">
        <a target="_blank" title="Tweet on Twitter" href="http://twitter.com/home?status=#url"><img alt="Twitter Logo" src="assets/img/twitter.svg"></a>
    </div>
    <div class="social_container_facebook">
        <a target="_blank" title="Share on Facebook" href="http://www.facebook.com/sharer/sharer.php?u=#url"><img alt="Facebook Logo" src="assets/img/facebook.png"></a>
    </div>
</div>

<!-- Menubar -->

<nav class="navbar navbar-inverse navbar-fixed-top" role="navigation"><div class="container-fluid">
<!-- This keeps the margins nice -->
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-ex1-collapse">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="http://baptiste-wicht.com/">
                <span id="blog-title">@Blog("Baptiste Wicht")</span>
            </a>
        </div>
<!-- /.navbar-header -->

        <div class="collapse navbar-collapse navbar-ex1-collapse">
            <ul class="nav navbar-nav">
<li>
<a href="stories/about.html">About</a>
                </li>
<li>
<a href="stories/publications.html">Publications</a>
                </li>
<li>
<a href="stories/donate.html">Donate</a>
                </li>
<li>
<a href="stories/contact.html">Contact</a>
                </li>
<li>
<a href="stories/faq.html">FAQ</a>
                </li>
<li>
<a href="stories/legal.html">Legal</a>
                </li>
<li>
<a href="categories/index.html">Tags</a>
                </li>
<li>
<a href="archive.html">Archives</a>
                </li>
<li>
<a href="http://feeds.feedburner.com/BaptisteWicht">RSS</a>

            </li>
</ul>
<div class="navbar-form pull-left">
                <form action="stories/search.html">
                    <input type="text" name="q" id="tipue_search_input">
</form>
            </div>

            <ul class="nav navbar-nav navbar-right">
<li>
                    <a target="_blank" title="Follow @wichtounet on Twitter" href="https://twitter.com/wichtounet">
                        <img src="assets/img/twitter.svg" alt="Follow @wichtounet on Twitter"></a>
                </li>
                <li>
                    <a target="_blank" title="Follow +BaptisteWicht on Google+" href="https://plus.google.com/+BaptisteWicht">
                        <img src="assets/img/google_plus.svg" alt="Follow +BaptisteWicht on Google+"></a>
                </li>
            </ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container-fluid -->
</nav><!-- End of Menubar --><div class="body-container">

    <!-- Sidebar -->

    <div class="left-sidebar">
            <div class="left-sidebar-widget">
                <h3>Welcome to my blog</h3>
                <div class="left-sidebar-widget-content">
                    <div class="g-person" data-width="275" data-href="//plus.google.com/u/0/103113673902796202116" data-theme="dark" data-layout="landscape" data-rel="author"></div>
                </div>
            </div>

            <div class="left-sidebar-widget">
                <h3>Tags</h3>
                <div class="left-sidebar-widget-content">
                    <div id="tags_container">
                        <canvas width="275" height="250" id="tags_canvas"><p>Anything in here will be replaced on browsers that support the canvas element</p>
                        </canvas>
</div>
                </div>
            </div>


        <div class="left-sidebar-widget">
            <h3>Recent comments</h3>
            <div class="left-sidebar-widget-content">
                <div id="recentcomments" class="dsq-widget">
                    <script type="text/javascript" src="http://blogwichtounet.disqus.com/recent_comments_widget.js?num_items=5&amp;hide_avatars=0&amp;avatar_size=28&amp;excerpt_length=50"></script>
</div>
            </div>
        </div>

        <div class="left-sidebar-widget">
            <h3>Blogroll</h3>
            <div class="left-sidebar-widget-content">
                <ul>
<li><a target="_blank" href="http://www.asjava.com/">AsJava.com : Java Tutorial</a></li>
                    <li><a target="_blank" href="http://www.mkyong.com/">Mkyong : Java Tutorials</a></li>
                </ul>
</div>
        </div>
    </div>


    <!-- Content -->

    <div class="container">
        <div class="body-content">
            <div class="row">
                
        <article class="postbox h-entry post-text"><h1 class="p-name">
<a href="posts/2016/09/short-review-of-bullseye-coverage.html" class="u-url">Short review of Bullseye Coverage</a>
        <br><small>  
             Posted: <time class="published dt-published" datetime="2016-09-16T13:25:44+02:00">2016-09-16 13:25</time></small>
</h1>
        <hr>
<div class="p-summary">
        <div>
<p><a class="reference external" href="http://www.bullseye.com/">Bullseye</a> is a commercial Code Coverage analyzer.
It is fully-featured with an export to HTML, to XML and even a specific GUI to
see the application.It costs about 800$, with a renewal fee of about 200$ per
year.</p>
<p>I'm currently using gcov and passing the results to Sonar. This works well, but
there are several problems. First, I need to use gcovr to generate the XML file,
that means two tools. Then, gcov has no way to merge coverage reports. In my
tests of ETL, I have seven different profiles being tested and I need the
overall coverage report. lcov has a merge feature but it is slow as hell (it
takes longer to merge the coverage files than to compile and run the complete
test suite seven times...). For now, I'm using a C++ program that I wrote to
combine the XML files or a Python script that does that, but neither are perfect
and it needs maintenance. Finally, it's impossible to exclude some code from the
coverage report (there is code that isn't meant to be executed (exceptional
code)). For now, I'm using yet another C++ program  that I wrote to do this from
comments in code.</p>
<p>Bullseye does have all these feature, so I got an evaluation license online and
tried this tool and wrote a short review of it.</p>
<div class="section" id="usage">
<h2>Usage</h2>
<p>The usage is pretty simple. You put the coverage executables in your PATH
variable and activate coverage globally. Then, we you compile, the compiler
calls will be intercepted and a coverage file will be generated. When the
compilation is done, run the program and the coverage measurements will be
filled.</p>
<p>The coverage results can then be exported to HTML (or XML) or visualized using
the CoverageBrowser tool:</p>
<div class="figure align-center">
<img alt="Screenshot of Bullseye main coverage view" src="images/bullseye_view.png"><p class="caption">The main view of the Bullseye tool code coverage results</p>
</div>
<p>It's a pretty good view of the coverage result. You have a breakdown by folders,
by file, by function and finally by condition. You can view directly the source
code:</p>
<div class="figure align-center">
<img alt="Screenshot of Bullseye source code coverage view" src="images/bullseye_source_view.png"><p class="caption">The source view of the Bullseye tool code coverage results</p>
</div>
<p>If you want to exclude some code from your coverage reports, you can use
a pragma:</p>
<pre class="code cpp"><a name="rest_code_16888397f9fb4d3bb7e444f97374911e-1"></a><span class="k">switch</span> <span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="p">{</span>
<a name="rest_code_16888397f9fb4d3bb7e444f97374911e-2"></a>    <span class="k">case</span> <span class="mi">1</span><span class="o">:</span> <span class="n">one</span><span class="o">++</span><span class="p">;</span> <span class="k">break</span><span class="p">;</span>
<a name="rest_code_16888397f9fb4d3bb7e444f97374911e-3"></a>    <span class="k">case</span> <span class="mi">2</span><span class="o">:</span> <span class="n">two</span><span class="o">++</span><span class="p">;</span> <span class="k">break</span><span class="p">;</span>
<a name="rest_code_16888397f9fb4d3bb7e444f97374911e-4"></a>    <span class="k">case</span> <span class="mi">3</span><span class="o">:</span> <span class="n">three</span><span class="o">++</span><span class="p">;</span> <span class="k">break</span><span class="p">;</span>
<a name="rest_code_16888397f9fb4d3bb7e444f97374911e-5"></a>    <span class="cp">#pragma BullseyeCoverage off</span>
<a name="rest_code_16888397f9fb4d3bb7e444f97374911e-6"></a>    <span class="k">default</span><span class="o">:</span> <span class="n">abort</span><span class="p">();</span>
<a name="rest_code_16888397f9fb4d3bb7e444f97374911e-7"></a>    <span class="cp">#pragma BullseyeCoverage on</span>
<a name="rest_code_16888397f9fb4d3bb7e444f97374911e-8"></a><span class="p">}</span>
</pre>
<p>So that the condition won't be set as uncovered.</p>
<p>As for the coverage, it's pretty straightforward. For example:</p>
<pre class="code bash"><a name="rest_code_cfdeda7487124f539f412885eb44507a-1"></a>covmerge -c -ffinal.cov sse.cov avx.cov
</pre>
<p>and it's really fast. Unfortunately, the merging is only done at the function
level, not at the statement or at the condition level. This is a bit
disappointing, especially from a commercial tool. Nevertheless, it works well.</p>
</div>
<div class="section" id="conclusion">
<h2>Conclusion</h2>
<p>To conclude, Bullseye seems to be a pretty good tool. It has more features than
standard gcov coverage and all features are well integrated together. I have
only covered the features I was interested in, there are plenty of other things
you can look at on the <a class="reference external" href="http://www.bullseye.com/">official website</a>.</p>
<p>However, if you don't need the extra features such as the visualizer (or use
something like Sonar for this), or the merge or code excluding, it's probably
not worth paying the price for it. In my case, since the merge is not better
than my C++ tool (both do almost the same and my tool does some basic line
coverage merging as well) and I don't need the visualizer, I won't pay the price
for it. Moreover, they don't have student or open source licensing, therefore,
I'll continue with my complicated toolchain :)</p>
</div>
</div>
        </div>
            
        
    <a href="posts/2016/09/short-review-of-bullseye-coverage.html#disqus_thread" data-disqus-identifier="cache/posts/2016/09/short-review-of-bullseye-coverage.html">Comments</a>


        </article><article class="postbox h-entry post-text"><h1 class="p-name">
<a href="posts/2016/09/expression-templates-library-etl-10.html" class="u-url">Expression Templates Library (ETL) 1.0</a>
        <br><small>  
             Posted: <time class="published dt-published" datetime="2016-09-02T16:12:38+02:00">2016-09-02 16:12</time></small>
</h1>
        <hr>
<div class="p-summary">
        <div>
<p>I've just released the first official version of my Expression Templates Library
(ETL for short): The version 1.0.</p>
<p>Until now, I was using a simple rolling release model, but I think it's now time
to switch to some basic versioning. The project is now at a stable state.</p>
<p>ETL 1.0 has the following main features:</p>
<ul class="simple">
<li>Smart Expression Templates</li>
<li>Matrix and vector (runtime-sized and compile-time-sized)</li>
<li>Simple element-wise operations</li>
<li>Reductions (sum, mean, max, ...)</li>
<li>Unary operations (sigmoid, log, exp, abs, ...)</li>
<li>Matrix multiplication</li>
<li>Convolution (1D and 2D and higher variations)</li>
<li>Max Pooling</li>
<li>Fast Fourrier Transform</li>
<li>Use of SSE/AVX to speed up operations</li>
<li>Use of BLAS/MKL/CUBLAS/CUFFT/CUDNN libraries to speed up operations</li>
<li>Symmetric matrix adapter (experimental)</li>
<li>Sparse matrix (experimental)</li>
</ul>
<div class="section" id="examples">
<h2>Examples</h2>
<p>Here is an example of expressions in ETL:</p>
<pre class="code cpp"><a name="rest_code_1479b2c9422e4d1bb46f71ff95392996-1"></a><span class="n">etl</span><span class="o">::</span><span class="n">fast_matrix</span><span class="o">&lt;</span><span class="kt">float</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="o">&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="p">{</span><span class="mf">1.1</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.1</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">};</span>
<a name="rest_code_1479b2c9422e4d1bb46f71ff95392996-2"></a><span class="n">etl</span><span class="o">::</span><span class="n">fast_matrix</span><span class="o">&lt;</span><span class="kt">float</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="o">&gt;</span> <span class="n">b</span> <span class="o">=</span> <span class="p">{</span><span class="mf">2.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">};</span>
<a name="rest_code_1479b2c9422e4d1bb46f71ff95392996-3"></a><span class="n">etl</span><span class="o">::</span><span class="n">fast_matrix</span><span class="o">&lt;</span><span class="kt">float</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="o">&gt;</span> <span class="n">c</span> <span class="o">=</span> <span class="p">{</span><span class="mf">2.2</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">3.5</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.2</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">3.5</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">};</span>
<a name="rest_code_1479b2c9422e4d1bb46f71ff95392996-4"></a>
<a name="rest_code_1479b2c9422e4d1bb46f71ff95392996-5"></a><span class="n">etl</span><span class="o">::</span><span class="n">fast_matrix</span><span class="o">&lt;</span><span class="kt">float</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="o">&gt;</span> <span class="n">d</span><span class="p">(</span><span class="mf">2.5</span> <span class="o">*</span> <span class="p">((</span><span class="n">a</span> <span class="o">&gt;&gt;</span> <span class="n">b</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">log</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="o">&gt;&gt;</span> <span class="n">abs</span><span class="p">(</span><span class="n">c</span><span class="p">)))</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.5</span> <span class="o">*</span> <span class="n">scale</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">sign</span><span class="p">(</span><span class="n">b</span><span class="p">))</span> <span class="o">/</span> <span class="n">c</span><span class="p">)</span> <span class="o">+</span> <span class="mf">2.111</span> <span class="o">/</span> <span class="n">log</span><span class="p">(</span><span class="n">c</span><span class="p">));</span>
</pre>
<p>Or another I'm using in my neural networks library:</p>
<pre class="code cpp"><a name="rest_code_4d36c96128a0459ea49d267b5636ac7f-1"></a><span class="n">h</span> <span class="o">=</span> <span class="n">etl</span><span class="o">::</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">b</span> <span class="o">+</span> <span class="n">v</span> <span class="o">*</span> <span class="n">w</span><span class="p">)</span>
</pre>
<p>In that case, the vector-matrix multiplication will be executed using a BLAS
kernel (if ETL is configured correclty) and the assignment, the sigmoid and the
addition will be automatically vectorized to use either AVX or SSE depending
on the machine.</p>
<p>Or with a convolutional layer and a ReLU activation function:</p>
<pre class="code cpp"><a name="rest_code_d79eace305e142939add4ecbd58285f7-1"></a><span class="n">etl</span><span class="o">::</span><span class="n">reshape</span><span class="o">&lt;</span><span class="mi">1</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">NH1</span><span class="p">,</span> <span class="n">NH2</span><span class="o">&gt;</span><span class="p">(</span><span class="n">h_a</span><span class="p">)</span> <span class="o">=</span> <span class="n">etl</span><span class="o">::</span><span class="n">conv_4d_valid_flipped</span><span class="p">(</span><span class="n">etl</span><span class="o">::</span><span class="n">reshape</span><span class="o">&lt;</span><span class="mi">1</span><span class="p">,</span> <span class="n">NC</span><span class="p">,</span> <span class="n">NV1</span><span class="p">,</span> <span class="n">NV2</span><span class="o">&gt;</span><span class="p">(</span><span class="n">v_a</span><span class="p">),</span> <span class="n">w</span><span class="p">);</span>
<a name="rest_code_d79eace305e142939add4ecbd58285f7-2"></a><span class="n">h</span> <span class="o">=</span> <span class="n">max</span><span class="p">(</span><span class="n">b_rep</span> <span class="o">+</span> <span class="n">h_a</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">);</span>
</pre>
<p>This will automatically be computed either with NVIDIA CUDNN (if available) or
with optimized SSE/AVX kernels.</p>
<p>For more information, you can take a look at the <a class="reference external" href="https://github.com/wichtounet/etl/wiki">Reference</a> on the wiki.</p>
</div>
<div class="section" id="next-version">
<h2>Next version</h2>
<p>For the next version, I'll focus on several things:</p>
<ul class="simple">
<li>Improve matrix-matrix multiplication kernels when BLAS is not available. There
is a lot of room for improvement here</li>
<li>Complete support for symmetric matrices (currently experimental)</li>
<li>Maybe some new adapters such as Hermitian matrices</li>
<li>GPU improvements for some operations that can be done entirely on GPU</li>
<li>New convolution performanceimprovements</li>
<li>Perhaps more complete parallel support for some implementations</li>
<li>Drop some compiler support to use full C++14 support</li>
</ul>
</div>
<div class="section" id="download-etl">
<h2>Download ETL</h2>
<p>You can download ETL <a class="reference external" href="https://github.com/wichtounet/etl">on Github</a>. If you
only interested in the 1.0 version, you can look at the
<a class="reference external" href="https://github.com/wichtounet/etl/releases">Releases pages</a> or clone the tag
1.0. There are several branches:</p>
<ul class="simple">
<li>
<em>master</em> Is the eternal development branch, may not always be stable</li>
<li>
<em>stable</em> Is a branch always pointing to the last tag, no development here</li>
</ul>
<p>For the future release, there always will tags pointing to the corresponding
commits. I'm not following the git flow way, I'd rather try to have a more
linear history with one eternal development branch, rather than an useless
develop branch or a load of other branches for releases.</p>
<p>Don't hesitate to comment this post if you have any comment on this library or
any question. You can also open an Issue on Github if you have a problem using
this library or propose a Pull Request if you have any contribution you'd like
to make to the library.</p>
<p>Hope this may be useful to some of you :)</p>
</div>
</div>
        </div>
            
        
    <a href="posts/2016/09/expression-templates-library-etl-10.html#disqus_thread" data-disqus-identifier="cache/posts/2016/09/expression-templates-library-etl-10.html">Comments</a>


        </article><article class="postbox h-entry post-text"><h1 class="p-name">
<a href="posts/2016/08/asgard-home-automation-project.html" class="u-url">Asgard: Home Automation project</a>
        <br><small>  
             Posted: <time class="published dt-published" datetime="2016-08-27T22:28:16+02:00">2016-08-27 22:28</time></small>
</h1>
        <hr>
<div class="p-summary">
        <div>
<p>I have updated my asgard project to make it finally useful for me, so I figured
I'd present the project now.</p>
<p>Asgard is my project of home automation based on a Raspberry Pi. I started this
project after Ninja Blocks kickstarter company went down and I was left with
useless sensors. So I figured why not have fun creating my own :P I know there
are some other projects out there that are pretty good, but I wanted to do some
more low level stuff for once, so what the hell.</p>
<p>Of course, everything is written in C++, no surprise here. The project is built
upon a server / drivers architecture. The drivers and the server are talking via
network sockets, so they can be on different machines.  The server is displaying
the data it got on a web interface and also provide a way to trigger actions of
drivers either from the web interface or through the integrated rules engine.
The data are stored in a database, accessed with CPPSqlite3 (probably going to
be replaced by sqlcpp11) and the web server is handled with mongoose (with a c++
interface).</p>
<p>I must mention that most of the web part of the project was made by a student of
mine, Stéphane Ly, who work on it as part of his study.</p>
<p>Here is a picture of the Raspberry Pi system (not very pretty ;) ):</p>
<img alt="/images/asgard_hardware.jpg" class="align-center" src="images/asgard_hardware.jpg"><p>I plan to try to fit at least some of it on a nicer box with nicer cables and
such. Moreover, I also plan to add real antennas to the RF transmitter and
receiver, but I haven't received them so far.</p>
<div class="section" id="sensors">
<h2>Sensors</h2>
<p>asgard support several sensors:</p>
<ul class="simple">
<li>DHT11 Temperature/Humdity Sensor</li>
<li>WT450 Temperature/Humdity Sensor</li>
<li>RF Button</li>
<li>IR Remote</li>
<li>CPU Temperature Sensor</li>
</ul>
<p>You can see the sensors data displayed on the web interface:</p>
<img alt="/images/asgard_home.png" class="align-center" src="images/asgard_home.png">
</div>
<div class="section" id="actions">
<h2>Actions</h2>
<p>There are currently a few actions provided by the drivers:</p>
<ul class="simple">
<li>Wake-On-Lan a computer by its MAC Address</li>
<li>ITT-1500 smart plugs ON and OFF</li>
<li>Kodi actions: Pause / Play / Next / Previous on Kodi</li>
</ul>
<p>Here are the rules engine:</p>
<img alt="/images/asgard_rules.png" class="align-center" src="images/asgard_rules.png">
</div>
<div class="section" id="my-home-automation">
<h2>My home automation</h2>
<p>I'm currently using this system to monitor the temperature in my appartment.
Nothing great so far because I don't have enough sensors yet. And now, I'm also
using a wireless button to turn on my power socket, wait 2 seconds and then
power on my Kodi Home Theater with wake on lan.</p>
<p>It's nothing fancy so far, but it's already better than what I had with Ninja
Blocks, except for the ugly hardware ;).</p>
</div>
<div class="section" id="future">
<h2>Future</h2>
<p>There are still tons of work on the project and on integration in my home.</p>
<ul class="simple">
<li>I'm really dissatisfied with the WT450 sensor, I've ordered new Oregon sensors to try to do better.</li>
<li>I've ordered a few new sensors: Door intrusion detector and motion detector</li>
<li>The rules system needs to be improve to support multiple conditions</li>
<li>I plan to add a simple state system to the asgard server</li>
<li>There are a lot of refactorings necessary in the code and</li>
</ul>
<p>However, I don't know when I'll work on this again, my work on this project is
pretty episodic to say the least.</p>
</div>
<div class="section" id="code">
<h2>Code</h2>
<p>The code is, as always, available on Github. There are multiple repositories:
<a class="reference external" href="https://github.com/search?q=user%3Awichtounet+asgard">all asgard repositories</a>.
It's not that much code for now, about 2000 lines of code, but some of it may be
useful. If you plan to use the system, keep in mind that it was never tested out
of my environment and that there is no documentation so far, but don't hesitate
to open Issues on Github if you have questions or post a comment here.</p>
</div>
</div>
        </div>
            
        
    <a href="posts/2016/08/asgard-home-automation-project.html#disqus_thread" data-disqus-identifier="cache/posts/2016/08/asgard-home-automation-project.html">Comments</a>


        </article><article class="postbox h-entry post-text"><h1 class="p-name">
<a href="posts/2016/08/update-thor-thesis-and-publications.html" class="u-url">Update: Thor, Thesis and Publications</a>
        <br><small>  
             Posted: <time class="published dt-published" datetime="2016-08-23T07:40:13+02:00">2016-08-23 07:40</time></small>
</h1>
        <hr>
<div class="p-summary">
        <div>
<p>Since it's been a real while since the last post I've written here, I wanted to
write a short status update.</p>
<p>I had to serve one month in the army, which does not help at all for
productivity :P Since the update to Boost Spirit X3, I haven't worked on my
eddic compiler again, but I've switched back to my operating system project:
thor. I'm having a lot of fun with it again and it's in much better state than
before.</p>
<p>We also have been very productive on the publication side, with four new
publications this year in various conferences. I'll update the blog when the
proceedings are published. I'll be going to ICANN 2016 and ANNPR 2016 next week
and probably to ICFHR in October. And of course, I'll go back to Meeting C++ in
November :) As for my thesis, it's finally going great, I've started writing
regularly and it's taking form!</p>
<div class="section" id="thor">
<h2>Thor</h2>
<p>My project Thor Operating System now has much more features than before:</p>
<ul class="simple">
<li>64bit operating system</li>
<li>Preemptive Multiprocessing</li>
<li>Keyboard / Mouse driver</li>
<li>Full ACPI support with ACPICA</li>
<li>Read/Write ATA driver</li>
<li>FAT32 file system support</li>
<li>HPET/RTC/PIT drivers</li>
<li>Basic PCI support</li>
<li>Multi stage booting with FAT32</li>
</ul>
<p>Since last time, I've fixed tons of bug in the system. Although there are still
some culprit, it's much more stable than before. They were a lot of bugs in the
scheduler with loads of race conditions. I hope I've working through most of
them now.</p>
<p>I'm currently working on the network stack. I'm able to receive and send packets
using the Realtek 8139 card. I have working support for Ethernet, IP and ARP.
I'm currently working on adding ICMP support. I've come to realize that the
hardest part is not to develop the code here but to find a way to test it.
Network in Qemu is a huge pain in the ass to configure. And then, you need tools
to generate some packets or at least answer to packets send by the virtual
machine, and it's really bad... Nevertheless, it's pretty fun overall :)</p>
<p>Aside from this, I'm also working on a window manager. I'll try to post an
update on this.</p>
<p>You can take a look at the <a class="reference external" href="https://github.com/wichtounet/thor-os">thor sources</a> if you're interested.</p>
</div>
<div class="section" id="future">
<h2>Future</h2>
<p>For the time being, I'll focus my effort on the thor project. I also have some
development to do on my home automation system: <a class="reference external" href="https://github.com/wichtounet/asgard-server">asgard-server</a> that I plan to finalize and deploy in a useful way this weekend in my apartment. You can also expect some updates on my deep learning library where I've started work to make it more user-friendly (kind of). I'm also still waiting on the first stable version of doctest for a new comparison with Catch.</p>
<p>I really want to try to publish again some more posts on the blog. I'll
especially try to publish some more updates about Thor.</p>
</div>
</div>
        </div>
            
        
    <a href="posts/2016/08/update-thor-thesis-and-publications.html#disqus_thread" data-disqus-identifier="cache/posts/2016/08/update-thor-thesis-and-publications.html">Comments</a>


        </article><article class="postbox h-entry post-text"><h1 class="p-name">
<a href="posts/2016/06/eddic-124-new-boost-spirit-x3-parser-and-minor-cleanups.html" class="u-url">eddic 1.2.4: New Boost Spirit X3 parser and minor cleanups</a>
        <br><small>  
             Posted: <time class="published dt-published" datetime="2016-06-26T22:35:04+02:00">2016-06-26 22:35</time></small>
</h1>
        <hr>
<div class="p-summary">
        <div>
<p>After almost 2 years, the new version of eddic (the compiler of the EDDI
programming language) is out! eddic 1.2.4</p>
<p>I haven't worked a lot on this project in the last years, I have been busy with
my Ph.D. related projects (ETL and DLL), my operating systems, cpm, ... I've
mostly worked on the parser to test the new version of Boost Spirit: X3. This
will be described on the next section, with the other changes in the later
section.</p>
<div class="section" id="new-boost-spirit-x3">
<h2>New Boost Spirit X3</h2>
<p>Boost Spirit X3 is a completely revamped version of Boost Spirit X3. It's aimed
at performance, both at compile-time and at runtime and uses recent features of
modern C++. It's not compatible with Boost Spirit Qi, so you'll most likely
have to rewrite a lot of stuff, in the parser, in the Abstract Syntax Tree
(AST) and in the AST passes as well.</p>
<p>For reference, I'm using the Boost 1.59 version.</p>
<div class="section" id="pros">
<h3>Pros</h3>
<p>Let's start with the pros.</p>
<p>First, the runtime performance is definitely better. Parsing all my eddi test
cases and samples, <em>takes 42% less time than with the previous parser</em>. It is
important to know that the old parser was very optimized, with moves instead of
copies and with a static lexer. You can take a look at <a class="reference external" href="http://baptiste-wicht.com/posts/2013/06/improving-eddic-boost-spirit-parser-performances.html">this post</a>
to see what was necessary to optimize the old Qi. I think it's a good result
since the new grammar does not use a lexer (x3 does not support it) and does
not need these optimizations. This improvement really was my objective. I'll
try to push it farther in the future.</p>
<p>Compile-time performance is also much better. It takes 3 times less time to
compile the new parser (1 minute to around 20 seconds). Moreover, the new
parser is now in only one file, rather than being it necessary to split it all
over the place for compile-time performance. Even though it's not really
important for me, it's still good to have :)</p>
<p>Especially due to the performance point, I've been able to remove some code,
the lexer, the generated static lexer and the special pointers optimizations of
the AST.</p>
</div>
<div class="section" id="cons">
<h3>Cons</h3>
<p>Unfortunately, there are some disadvantages of using the new Spirit X3.</p>
<p>First, the AST needs to be changed. For good parsing performance, you need to
use x3::variant and x3::forward_ast. This is a major pain in the ass since
x3::variant is much less practical to use than boost::variant. Almost
everything is explicit, meaning uglier code than before, in my opinion.
Moreover, you need to work around x3::forward_ast for boost::get, whereas
boost::recursive_wrapper was working better in that matter. I've had to create
my own wrapper around boost::get in order to be able to use the new tree. In my
opinion, this is clearly a regression.</p>
<p>Secondly, although X3 was also meant to remove the need to use some hacks in
the grammar, I ended up having more hacks than before. For instance, many AST
node have a fake field in order to make X3 happy. I've still had to use the
horrible eps hack at one place. I've had to create a few more rules in order to
fix type deduction that is working differently than before (worse for me). And
for some reasons, I had to replace some expectations from the grammar to make it
parse correctly. This is a really important regression in my opinion, since it
may make the parsing slower and will make the error message less nice.</p>
<p>The previous error handling system allowed me to track the file from which an
AST node was parsed from. Although the new error handler is a lot nicer than
the old system, it does not have this feature, so I had to work around this by
using new annotation nodes and a new global handler. Overall, it's probably a
bit worse than before, but makes for lighter AST nodes.</p>
<p>Finally, for some reason, I haven't been able to use the debug option of the
library (lots of compile time errors). That complicated a bit the debugging of
the parser.</p>
</div>
<div class="section" id="spirit-x3-or-spirit-qi">
<h3>Spirit X3 or Spirit Qi ?</h3>
<p>Overall, I have to say I'm a bit disappointed by Spirit X3. Even though it's
faster at runtime and faster to compile, I was really expecting less issues
with it. What I really did not like was all the changes I had to make because
of x3::variant and x3::forward_ast. Overall, I really don't think it was worth
the trouble porting my parser to Spirit X3.</p>
<p>If you have a new project, I would still consider using Boost Spirit X3.</p>
<p>If you have an existing parser, I would probably not advice porting it to X3.
Unless you really have issues with parsing performances (and especially if you
have not already optimized QI parser), it's probably not worth the trouble and
all the time necessary for all the changes.</p>
</div>
</div>
<div class="section" id="other-changes">
<h2>Other changes</h2>
<p>The other changes are much more minor. First of all, I've gotten rid of CMake.
This project has really made me hate CMake. I have actually gotten rid of it on
all my projects. I'm now using plain Makefiles and having a much better time
with them. I've also replaced boost Program Options with cxxopts. It's a much
more modern approach for program options parsing. Moreover, it's much more
lightweight and it's header only. Only advantages. There also have been lots of
changes to code (still not very good quality though).</p>
</div>
<div class="section" id="future">
<h2>Future</h2>
<p>eddic was my first real project in C++ and this can be seen in the code and the
organization. The quality of the code is really bad now that I read it again.
Some things are actually terrible :P It's probably normal since I was a
beginner in C++ at the time.</p>
<p>For the future version of the compiler, I want to clean the code a lot more and
focus on the EDDI language adding new features. Moreover, I'll also get rid of
Boost Test Framework by using Catch (or doctest if it is ready).</p>
<p>As for now, I'm not sure on which project I'm going to focus. Either I'll
continue working on the compiler or I'll start working again on my operating
system (thor-os) in which I was working on process concurrency (without too
much success :P). I'll probably post next updates on this post in the coming
months.</p>
</div>
<div class="section" id="download">
<h2>Download</h2>
<p>You can find the EDDI Compiler sources on the <a class="reference external" href="https://github.com/wichtounet/eddic">Github repository</a></p>
<p>The version is available in the <em>v1.2.4</em> tag available in the GitHub
repository, in the releases pages or directly in the &lt;em&gt;master&lt;/em&gt; branch.</p>
</div>
</div>
        </div>
            
        
    <a href="posts/2016/06/eddic-124-new-boost-spirit-x3-parser-and-minor-cleanups.html#disqus_thread" data-disqus-identifier="cache/posts/2016/06/eddic-124-new-boost-spirit-x3-parser-and-minor-cleanups.html">Comments</a>


        </article><article class="postbox h-entry post-text"><h1 class="p-name">
<a href="posts/2016/06/reduce-compilation-time-by-another-16-with-catch.html" class="u-url">Reduce Catch tests compilation time by another 16%</a>
        <br><small>  
             Posted: <time class="published dt-published" datetime="2016-06-01T07:28:36+02:00">2016-06-01 07:28</time></small>
</h1>
        <hr>
<div class="p-summary">
        <div>
<p>No, it's not the same post as two days! I've been able to reduce the compilation
time of my test cases by another 16%!</p>
<p>Two days ago, I posted an article about how <a class="reference external" href="http://baptiste-wicht.com/posts/2016/05/speedup-compilation-by-13-by-simplifying-unit-test-with-catch.html">I reduced the compilation time of my tests by 13%</a>, by bypassing the expression deduction from Catch. I came up with the macro <code class="cpp"><span class="n">REQUIRE_EQUALS</span></code>:</p>
<pre class="code cpp"><a name="rest_code_903a01cd760f4003a8b46718b4935a55-1"></a><span class="k">template</span><span class="o">&lt;</span><span class="k">typename</span> <span class="n">L</span><span class="p">,</span> <span class="k">typename</span> <span class="n">R</span><span class="o">&gt;</span>
<a name="rest_code_903a01cd760f4003a8b46718b4935a55-2"></a><span class="kt">void</span> <span class="n">evaluate_result</span><span class="p">(</span><span class="n">Catch</span><span class="o">::</span><span class="n">ResultBuilder</span><span class="o">&amp;&amp;</span> <span class="n">__result</span><span class="p">,</span> <span class="n">L</span> <span class="n">lhs</span><span class="p">,</span> <span class="n">R</span> <span class="n">rhs</span><span class="p">){</span>
<a name="rest_code_903a01cd760f4003a8b46718b4935a55-3"></a>    <span class="n">__result</span><span class="p">.</span><span class="n">setResultType</span><span class="p">(</span><span class="n">lhs</span> <span class="o">==</span> <span class="n">rhs</span><span class="p">);</span>
<a name="rest_code_903a01cd760f4003a8b46718b4935a55-4"></a>    <span class="n">__result</span><span class="p">.</span><span class="n">setLhs</span><span class="p">(</span><span class="n">Catch</span><span class="o">::</span><span class="n">toString</span><span class="p">(</span><span class="n">lhs</span><span class="p">));</span>
<a name="rest_code_903a01cd760f4003a8b46718b4935a55-5"></a>    <span class="n">__result</span><span class="p">.</span><span class="n">setRhs</span><span class="p">(</span><span class="n">Catch</span><span class="o">::</span><span class="n">toString</span><span class="p">(</span><span class="n">rhs</span><span class="p">));</span>
<a name="rest_code_903a01cd760f4003a8b46718b4935a55-6"></a>    <span class="n">__result</span><span class="p">.</span><span class="n">setOp</span><span class="p">(</span><span class="s">"=="</span><span class="p">);</span>
<a name="rest_code_903a01cd760f4003a8b46718b4935a55-7"></a>    <span class="n">__result</span><span class="p">.</span><span class="n">endExpression</span><span class="p">();</span>
<a name="rest_code_903a01cd760f4003a8b46718b4935a55-8"></a>    <span class="n">__result</span><span class="p">.</span><span class="n">react</span><span class="p">();</span>
<a name="rest_code_903a01cd760f4003a8b46718b4935a55-9"></a><span class="p">}</span>
<a name="rest_code_903a01cd760f4003a8b46718b4935a55-10"></a>
<a name="rest_code_903a01cd760f4003a8b46718b4935a55-11"></a><span class="cp">#define REQUIRE_EQUALS(lhs, rhs) \</span>
<a name="rest_code_903a01cd760f4003a8b46718b4935a55-12"></a><span class="cp">    evaluate_result(Catch::ResultBuilder( "REQUIRE", CATCH_INTERNAL_LINEINFO, #lhs " == " #rhs, Catch::ResultDisposition::Normal ), lhs, rhs);</span>
</pre>
<p>This has the advantage that the left and right hand sides are directly set, not
deduced with templates and operator overloading. This still has exactly the same
features has the original macro, but it is a bit less nice in the test code.
I was quite happy with that optimization, but it turned out, I was not
aggressive enough in my optimizations.</p>
<p>Even though it seems simple, the macro is still bloated. There are two
constructors calls: <code class="cpp"><span class="n">ResultBuilder</span></code> and <code class="cpp"><span class="n">SourceLineInfo</span></code> (hidden behind
<code class="cpp"><span class="n">CATCH_INTERNAL_LINEINFO</span></code>). That means that if you test case has 100
assertions, 200 constructor calls will need to be processed by the compiler.
Considering that I have some test files with around 400 assertions, this is
a lot of overhead for nothing. Moreover, two parameters have always the same
value, no need to repeat them every time.</p>
<p>Simplifying the macro to the minimum led me to this:</p>
<pre class="code cpp"><a name="rest_code_9fd0922a18d74a9c997a463eda882044-1"></a><span class="k">template</span><span class="o">&lt;</span><span class="k">typename</span> <span class="n">L</span><span class="p">,</span> <span class="k">typename</span> <span class="n">R</span><span class="o">&gt;</span>
<a name="rest_code_9fd0922a18d74a9c997a463eda882044-2"></a><span class="kt">void</span> <span class="n">evaluate_result</span><span class="p">(</span><span class="k">const</span> <span class="kt">char</span><span class="o">*</span> <span class="n">file</span><span class="p">,</span> <span class="n">std</span><span class="o">::</span><span class="kt">size_t</span> <span class="n">line</span><span class="p">,</span> <span class="k">const</span> <span class="kt">char</span><span class="o">*</span> <span class="n">exp</span><span class="p">,</span> <span class="n">L</span> <span class="n">lhs</span><span class="p">,</span> <span class="n">R</span> <span class="n">rhs</span><span class="p">){</span>
<a name="rest_code_9fd0922a18d74a9c997a463eda882044-3"></a>    <span class="n">Catch</span><span class="o">::</span><span class="n">ResultBuilder</span> <span class="n">result</span><span class="p">(</span><span class="s">"REQUIRE"</span><span class="p">,</span> <span class="p">{</span><span class="n">file</span><span class="p">,</span> <span class="n">line</span><span class="p">},</span> <span class="n">exp</span><span class="p">,</span> <span class="n">Catch</span><span class="o">::</span><span class="n">ResultDisposition</span><span class="o">::</span><span class="n">Flags</span><span class="o">::</span><span class="n">Normal</span><span class="p">);</span>
<a name="rest_code_9fd0922a18d74a9c997a463eda882044-4"></a>    <span class="n">result</span><span class="p">.</span><span class="n">setResultType</span><span class="p">(</span><span class="n">lhs</span> <span class="o">==</span> <span class="n">rhs</span><span class="p">);</span>
<a name="rest_code_9fd0922a18d74a9c997a463eda882044-5"></a>    <span class="n">result</span><span class="p">.</span><span class="n">setLhs</span><span class="p">(</span><span class="n">Catch</span><span class="o">::</span><span class="n">toString</span><span class="p">(</span><span class="n">lhs</span><span class="p">));</span>
<a name="rest_code_9fd0922a18d74a9c997a463eda882044-6"></a>    <span class="n">result</span><span class="p">.</span><span class="n">setRhs</span><span class="p">(</span><span class="n">Catch</span><span class="o">::</span><span class="n">toString</span><span class="p">(</span><span class="n">rhs</span><span class="p">));</span>
<a name="rest_code_9fd0922a18d74a9c997a463eda882044-7"></a>    <span class="n">result</span><span class="p">.</span><span class="n">setOp</span><span class="p">(</span><span class="s">"=="</span><span class="p">);</span>
<a name="rest_code_9fd0922a18d74a9c997a463eda882044-8"></a>    <span class="n">result</span><span class="p">.</span><span class="n">endExpression</span><span class="p">();</span>
<a name="rest_code_9fd0922a18d74a9c997a463eda882044-9"></a>    <span class="n">result</span><span class="p">.</span><span class="n">react</span><span class="p">();</span>
<a name="rest_code_9fd0922a18d74a9c997a463eda882044-10"></a><span class="p">}</span>
<a name="rest_code_9fd0922a18d74a9c997a463eda882044-11"></a>
<a name="rest_code_9fd0922a18d74a9c997a463eda882044-12"></a><span class="cp">#define REQUIRE_EQUALS(lhs, rhs) \</span>
<a name="rest_code_9fd0922a18d74a9c997a463eda882044-13"></a><span class="cp">    evaluate_result(__FILE__, __LINE__, #lhs " == " #rhs, lhs, rhs);</span>
</pre>
<p>The macro is now a simple function call. Even though the function is a template
function, it will only be compiled for a few types (<code class="cpp"><span class="kt">double</span></code> and
<code class="cpp"><span class="kt">float</span></code> in my case), whereas the code of the macro would be unconditionally
compiled for each invocation.</p>
<p>With this new macro and function, the compilation time went down from 664
seconds to 554 seconds! This is <strong>more than 16% reduction in compilation
time</strong>. When comparing against the original compilation time (without both
optimizations) of 764 seconds, this is a 27% reduction! And there are absolutely
no difference in features.</p>
<p>This is a really great result, in my opinion. I don't think this can be cut down
more. However, there is still some room for optimization regarding the includes
that Catch need. Indeed, it is very bloated as well. A new test framework,
<a class="reference external" href="https://github.com/onqtam/doctest">doctest</a> follows the same philosophy, but
has much smaller include overhead. Once all the necessary features are in
doctest, I may consider adapting my macros for it and using it in place of Catch
is there is some substantial reduction in compilation time.</p>
<p>If you want to take a look at the code, you can find the adapted code on <a class="reference external" href="https://github.com/wichtounet/etl/blob/master/test/include/fast_catch.hpp">Github</a>.</p>
</div>
        </div>
            
        
    <a href="posts/2016/06/reduce-compilation-time-by-another-16-with-catch.html#disqus_thread" data-disqus-identifier="cache/posts/2016/06/reduce-compilation-time-by-another-16-with-catch.html">Comments</a>


        </article><article class="postbox h-entry post-text"><h1 class="p-name">
<a href="posts/2016/05/speedup-compilation-by-13-by-simplifying-unit-test-with-catch.html" class="u-url">Speed up compilation by 13% by simplifying Catch unit tests</a>
        <br><small>  
             Posted: <time class="published dt-published" datetime="2016-05-25T12:35:16+02:00">2016-05-25 12:35</time></small>
</h1>
        <hr>
<div class="p-summary">
        <div>
<p>In the previous two days, I've working on improving compilation time of my
project Expression Templates Library (ETL). I have been able to reduce the
compilation time of the complete test suite from 794 seconds to 764 seconds
(using only one thread). Trying to get further, I started checking what was
taking the most time in a test case when I saw that the REQUIRE calls of <strong>the
test library were taking a large portion of the compilation time!</strong></p>
<p>I have been <a class="reference external" href="http://baptiste-wicht.com/posts/2014/07/catch-powerful-yet-simple-cpp-test-framework.html">using Catch as my test framework</a>
for more than two years and it's really been great overall. It is a great tool,
header-only, fully-featured, XML reporting for Sonar, ... It really has
everything I need from a test framework.</p>
<p>Contrary to some popular test frameworks that provides ASSERT_EQUALS,
ASSERT_GREATER and all fashion of assert macros, Catch only provides one
version: REQUIRE. For instance:</p>
<pre class="code cpp"><a name="rest_code_531534b054c24c0c9b08426ac436023e-1"></a><span class="n">REQUIRE</span><span class="p">(</span><span class="n">x</span> <span class="o">==</span> <span class="mf">1.0</span><span class="p">);</span>
<a name="rest_code_531534b054c24c0c9b08426ac436023e-2"></a><span class="n">REQUIRE</span><span class="p">(</span><span class="n">y</span> <span class="o">&lt;</span> <span class="mf">5.5</span><span class="p">);</span>
<a name="rest_code_531534b054c24c0c9b08426ac436023e-3"></a><span class="n">REQUIRE</span><span class="p">((</span><span class="n">z</span> <span class="o">+</span> <span class="n">x</span><span class="p">)</span> <span class="o">!=</span> <span class="mf">22.01f</span><span class="p">);</span>
</pre>
<p>The left and right part are detected with some smart template and operator
overloading techniques and this makes for very nice test output in case of
errors, for instance:</p>
<pre class="code text"><a name="rest_code_42d0a44a1e544000b8f68cfb03dd1dc9-1"></a>test/src/dyn_matrix.cpp:16: FAILED:
<a name="rest_code_42d0a44a1e544000b8f68cfb03dd1dc9-2"></a>  REQUIRE( test_matrix.rows() == 2UL )
<a name="rest_code_42d0a44a1e544000b8f68cfb03dd1dc9-3"></a>with expansion:
<a name="rest_code_42d0a44a1e544000b8f68cfb03dd1dc9-4"></a>  3 == 2
</pre>
<p>I think this is pretty nice and the tests are really clear. However, <em>it comes
with a cost</em> and I underestimated this at first.</p>
<p>To overcome this, I create two new macros (and few other variations)
REQUIRE_EQUALS and REQUIRE_DIRECT that simply bypass Catch deduction of the
expression:</p>
<pre class="code cpp"><a name="rest_code_25fc437b2e6d44fb90a6eb655f5a9a47-1"></a><span class="kr">inline</span> <span class="kt">void</span> <span class="nf">evaluate_result_direct</span><span class="p">(</span><span class="n">Catch</span><span class="o">::</span><span class="n">ResultBuilder</span><span class="o">&amp;&amp;</span> <span class="n">__result</span><span class="p">,</span> <span class="kt">bool</span> <span class="n">value</span><span class="p">){</span>
<a name="rest_code_25fc437b2e6d44fb90a6eb655f5a9a47-2"></a>    <span class="n">__result</span><span class="p">.</span><span class="n">setResultType</span><span class="p">(</span><span class="n">value</span><span class="p">);</span>
<a name="rest_code_25fc437b2e6d44fb90a6eb655f5a9a47-3"></a>    <span class="n">__result</span><span class="p">.</span><span class="n">setLhs</span><span class="p">(</span><span class="n">value</span> <span class="o">?</span> <span class="s">"true"</span> <span class="o">:</span> <span class="s">"false"</span><span class="p">);</span>
<a name="rest_code_25fc437b2e6d44fb90a6eb655f5a9a47-4"></a>    <span class="n">__result</span><span class="p">.</span><span class="n">setOp</span><span class="p">(</span><span class="s">""</span><span class="p">);</span>
<a name="rest_code_25fc437b2e6d44fb90a6eb655f5a9a47-5"></a>    <span class="n">__result</span><span class="p">.</span><span class="n">endExpression</span><span class="p">();</span>
<a name="rest_code_25fc437b2e6d44fb90a6eb655f5a9a47-6"></a><span class="p">}</span>
<a name="rest_code_25fc437b2e6d44fb90a6eb655f5a9a47-7"></a>
<a name="rest_code_25fc437b2e6d44fb90a6eb655f5a9a47-8"></a><span class="k">template</span><span class="o">&lt;</span><span class="k">typename</span> <span class="n">L</span><span class="p">,</span> <span class="k">typename</span> <span class="n">R</span><span class="o">&gt;</span>
<a name="rest_code_25fc437b2e6d44fb90a6eb655f5a9a47-9"></a><span class="kt">void</span> <span class="n">evaluate_result</span><span class="p">(</span><span class="n">Catch</span><span class="o">::</span><span class="n">ResultBuilder</span><span class="o">&amp;&amp;</span> <span class="n">__result</span><span class="p">,</span> <span class="n">L</span> <span class="n">lhs</span><span class="p">,</span> <span class="n">R</span> <span class="n">rhs</span><span class="p">){</span>
<a name="rest_code_25fc437b2e6d44fb90a6eb655f5a9a47-10"></a>    <span class="n">__result</span><span class="p">.</span><span class="n">setResultType</span><span class="p">(</span><span class="n">lhs</span> <span class="o">==</span> <span class="n">rhs</span><span class="p">);</span>
<a name="rest_code_25fc437b2e6d44fb90a6eb655f5a9a47-11"></a>    <span class="n">__result</span><span class="p">.</span><span class="n">setLhs</span><span class="p">(</span><span class="n">Catch</span><span class="o">::</span><span class="n">toString</span><span class="p">(</span><span class="n">lhs</span><span class="p">));</span>
<a name="rest_code_25fc437b2e6d44fb90a6eb655f5a9a47-12"></a>    <span class="n">__result</span><span class="p">.</span><span class="n">setRhs</span><span class="p">(</span><span class="n">Catch</span><span class="o">::</span><span class="n">toString</span><span class="p">(</span><span class="n">rhs</span><span class="p">));</span>
<a name="rest_code_25fc437b2e6d44fb90a6eb655f5a9a47-13"></a>    <span class="n">__result</span><span class="p">.</span><span class="n">setOp</span><span class="p">(</span><span class="s">"=="</span><span class="p">);</span>
<a name="rest_code_25fc437b2e6d44fb90a6eb655f5a9a47-14"></a>    <span class="n">__result</span><span class="p">.</span><span class="n">endExpression</span><span class="p">();</span>
<a name="rest_code_25fc437b2e6d44fb90a6eb655f5a9a47-15"></a><span class="p">}</span>
<a name="rest_code_25fc437b2e6d44fb90a6eb655f5a9a47-16"></a>
<a name="rest_code_25fc437b2e6d44fb90a6eb655f5a9a47-17"></a><span class="cp">#define REQUIRE_DIRECT(value) \</span>
<a name="rest_code_25fc437b2e6d44fb90a6eb655f5a9a47-18"></a><span class="cp">    evaluate_result_direct(Catch::ResultBuilder( "REQUIRE", CATCH_INTERNAL_LINEINFO, #value, Catch::ResultDisposition::Normal ), value);</span>
<a name="rest_code_25fc437b2e6d44fb90a6eb655f5a9a47-19"></a>
<a name="rest_code_25fc437b2e6d44fb90a6eb655f5a9a47-20"></a><span class="cp">#define REQUIRE_EQUALS(lhs, rhs) \</span>
<a name="rest_code_25fc437b2e6d44fb90a6eb655f5a9a47-21"></a><span class="cp">    evaluate_result(Catch::ResultBuilder( "REQUIRE", CATCH_INTERNAL_LINEINFO, #lhs " == " #rhs, Catch::ResultDisposition::Normal ), lhs, rhs);</span>
</pre>
<p>There is really nothing too special about it, I simply followed the macros and
functions in Catch source code until I found out what to bypass.</p>
<p>And now, we use them directly:</p>
<pre class="code cpp"><a name="rest_code_345529241741451abbedab636b886598-1"></a><span class="n">REQUIRE_DIRECT</span><span class="p">(</span><span class="n">am_i_true</span><span class="p">());</span>
<a name="rest_code_345529241741451abbedab636b886598-2"></a><span class="n">REQUIRE_EQUALS</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">);</span>
</pre>
<p>This is a bit less nice and it requires to know a few more macros, I admit, but
it turns out to be much faster (and who really cares about the beauty of test
code anyway...). Indeed, the total compilation time of the tests went from 764
seconds to 664 seconds!  This is <strong>a 13% reduction of the compilation time</strong>!
I really am impressed of the overhead of this technique. I cannot justify this
slowdown just for a bit nicer test code. Finally, the output in case of error
remains exactly the same as before.</p>
<p>This proves that sometimes the bottlenecks are not where we expect them :)</p>
<p>If you are interested, you can find the adapted code on <a class="reference external" href="https://github.com/wichtounet/etl/blob/master/test/include/fast_catch.hpp">Github</a>.</p>
</div>
        </div>
            
        
    <a href="posts/2016/05/speedup-compilation-by-13-by-simplifying-unit-test-with-catch.html#disqus_thread" data-disqus-identifier="cache/posts/2016/05/speedup-compilation-by-13-by-simplifying-unit-test-with-catch.html">Comments</a>


        </article><article class="postbox h-entry post-text"><h1 class="p-name">
<a href="posts/2016/04/simplify-deep-learning-library-usage-on-linux-and-windows.html" class="u-url">Simplify Deep Learning Library usage on Linux and Windows!</a>
        <br><small>  
             Posted: <time class="published dt-published" datetime="2016-04-29T12:48:18+02:00">2016-04-29 12:48</time></small>
</h1>
        <hr>
<div class="p-summary">
        <div>
<p>No, I'm not dead ;) I've been very busy with my Ph.D (and playing Path of Exile,
let's be honest...) and haven't had time to write something here in a long time.</p>
<p>Until now, there was too way to use my
<a class="reference external" href="https://github.com/wichtounet/dll/">Deep Learning Library (DLL)</a> project:</p>
<ol class="arabic simple">
<li>Write a C++ program that uses the library</li>
<li>Install DLL and write a configuration file to define your network and the problem to solve</li>
</ol>
<p>The first version gives you all the features of the tool and allows you to build
exactly what you need. The second version is a bit more limited, but does not
require any C++ knowledge. However, it still does require a recent C++ compiler
and build system.</p>
<p>Due to the high C++ requirements that are not met by Visual Studio and the fact
that I don't work on Windows, this platform is not supported by the tool. Until
now!</p>
<p>I've added a third option to use DLL in the form of a Docker image to make the
second option even easier and allow the use of DLL on Windows. All you need is
Docker, which is available on Linux, Mac and Windows. This is still limited to
the second option in that you need to write a configuration describing the
network, but you need to build DLL and don't need to install all its
dependencies.</p>
<div class="section" id="usage">
<h2>Usage</h2>
<p>To install the image, you can simply use <cite>docker pull</cite>:</p>
<pre class="code bash"><a name="rest_code_8279b1ab07f1418dbb3cb773c1551e08-1"></a>docker pull wichtounet/docker-dll
</pre>
<p>Then, to run it, you have to create a folder containing a <cite>dll.conf</cite> file and
mount in the container at <cite>/dll/data/</cite>. There are some examples in the
<a class="reference external" href="https://github.com/wichtounet/docker-dll/">image repository</a>.  For instance,
on Linux from the cloned repository:</p>
<pre class="code bash"><a name="rest_code_7b2d653159704ab5a440084dc3368f9e-1"></a>docker run -v <span class="si">${</span><span class="nv">pwd</span><span class="si">}</span>/rbm_mnist/:/dll/data/ wichtounet/docker-dll
</pre>
<p>or on Windows:</p>
<pre class="code bash"><a name="rest_code_9174d1c35485469ea6e4bfa7a71f2bf0-1"></a>docker run -v /c/Users/Baptiste/rbm_mnist/:/dll/data wichtounet/docker-dll
</pre>
<p>This will automatically run the actions specified in the configuration file and
train your network.</p>
</div>
<div class="section" id="conclusion">
<h2>Conclusion</h2>
<p>I would really have thought this would be harder, but it turned out that Docker
is a very good solution to deploy multiplatform demo tools :)</p>
<p>As of now, there is only support for mnist data format in the tool in this
form, but I plan to add basic CSV support as well in the near future.</p>
<p>I hope that this will help people willing to try the library with a simpler
usage.</p>
</div>
</div>
        </div>
            
        
    <a href="posts/2016/04/simplify-deep-learning-library-usage-on-linux-and-windows.html#disqus_thread" data-disqus-identifier="cache/posts/2016/04/simplify-deep-learning-library-usage-on-linux-and-windows.html">Comments</a>


        </article><article class="postbox h-entry post-text"><h1 class="p-name">
<a href="posts/2016/02/use-templight-and-templar-to-debug-cpp-templates.html" class="u-url">Use templight and Templar to debug C++ templates</a>
        <br><small>  
             Posted: <time class="published dt-published" datetime="2016-02-08T08:11:18+01:00">2016-02-08 08:11</time></small>
</h1>
        <hr>
<div class="p-summary">
        <div>
<p>C++ has some very good tools to debug, profile and analyze source files and executables. This all works well for standard runtime program. But, when you are using templates, you sometimes want these tools to act at compile-time. And at this point the support is much more scarce.</p>
<p><a class="reference external" href="https://github.com/mikael-s-persson/templight">templight</a> and <a class="reference external" href="https://github.com/schulmar/Templar">Templar</a> and two tools that are trying to fix this issue.</p>
<p>From the templight site:</p>
<blockquote>
Templight is a Clang-based tool to profile the time and memory consumption of template instantiations and to perform interactive debugging sessions to gain introspection into the template instantiation process.</blockquote>
<p>and Templar is a visualization tool for the traces generated by templight.</p>
<div class="section" id="installation">
<h2>Installation</h2>
<p>Unfortunately, the templight installation is not user-friendly at all. You need to clone the complete LLVM/Clang tree and add templight inside it before compiling the complete clang toolchain. But that is the case for all clang-based tools... You also need to patch clang but that may not be necessary in the future. The complete instructions are available <a class="reference external" href="https://github.com/mikael-s-persson/templight#getting-and-compiling-templight">here</a>.</p>
<p>The installation of Templar is much more convenient:</p>
<pre class="code bash"><a name="rest_code_ec4c8a2ffb7b4b2eaf74e768de292d09-1"></a>git clone https://github.com/schulmar/Templar.git
<a name="rest_code_ec4c8a2ffb7b4b2eaf74e768de292d09-2"></a>git checkout feature/templight2
<a name="rest_code_ec4c8a2ffb7b4b2eaf74e768de292d09-3"></a><span class="nb">cd</span> Templar
<a name="rest_code_ec4c8a2ffb7b4b2eaf74e768de292d09-4"></a>qmake .
<a name="rest_code_ec4c8a2ffb7b4b2eaf74e768de292d09-5"></a>make
<a name="rest_code_ec4c8a2ffb7b4b2eaf74e768de292d09-6"></a>sudo make install
</pre>
<p>The branch feature/templight2 has much more features than the master and should support both Qt4 and Qt5, but I have only tested it on Qt4.</p>
</div>
<div class="section" id="example">
<h2>Example</h2>
<p>Let's use the class Fibonacci function as an example:</p>
<pre class="code cpp"><a name="rest_code_cd8b921d4f6941b990cc5c3b2e485204-1"></a><span class="cp">#include</span> <span class="cpf">&lt;iostream&gt;</span><span class="cp"></span>
<a name="rest_code_cd8b921d4f6941b990cc5c3b2e485204-2"></a>
<a name="rest_code_cd8b921d4f6941b990cc5c3b2e485204-3"></a><span class="k">template</span> <span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="kt">size_t</span> <span class="n">N</span><span class="o">&gt;</span>
<a name="rest_code_cd8b921d4f6941b990cc5c3b2e485204-4"></a><span class="k">struct</span> <span class="n">Fibonacci</span> <span class="p">{</span>
<a name="rest_code_cd8b921d4f6941b990cc5c3b2e485204-5"></a>    <span class="k">static</span> <span class="k">constexpr</span> <span class="k">const</span> <span class="n">std</span><span class="o">::</span><span class="kt">size_t</span> <span class="n">value</span> <span class="o">=</span> <span class="n">Fibonacci</span><span class="o">&lt;</span><span class="n">N</span><span class="o">-</span><span class="mi">1</span><span class="o">&gt;::</span><span class="n">value</span> <span class="o">+</span> <span class="n">Fibonacci</span><span class="o">&lt;</span><span class="n">N</span><span class="o">-</span><span class="mi">2</span><span class="o">&gt;::</span><span class="n">value</span><span class="p">;</span>
<a name="rest_code_cd8b921d4f6941b990cc5c3b2e485204-6"></a><span class="p">};</span>
<a name="rest_code_cd8b921d4f6941b990cc5c3b2e485204-7"></a>
<a name="rest_code_cd8b921d4f6941b990cc5c3b2e485204-8"></a><span class="k">template</span> <span class="o">&lt;&gt;</span>
<a name="rest_code_cd8b921d4f6941b990cc5c3b2e485204-9"></a><span class="k">struct</span> <span class="n">Fibonacci</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span> <span class="p">{</span>
<a name="rest_code_cd8b921d4f6941b990cc5c3b2e485204-10"></a>    <span class="k">static</span> <span class="k">constexpr</span> <span class="k">const</span> <span class="n">std</span><span class="o">::</span><span class="kt">size_t</span> <span class="n">value</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
<a name="rest_code_cd8b921d4f6941b990cc5c3b2e485204-11"></a><span class="p">};</span>
<a name="rest_code_cd8b921d4f6941b990cc5c3b2e485204-12"></a>
<a name="rest_code_cd8b921d4f6941b990cc5c3b2e485204-13"></a><span class="k">template</span> <span class="o">&lt;&gt;</span>
<a name="rest_code_cd8b921d4f6941b990cc5c3b2e485204-14"></a><span class="k">struct</span> <span class="n">Fibonacci</span><span class="o">&lt;</span><span class="mi">0</span><span class="o">&gt;</span> <span class="p">{</span>
<a name="rest_code_cd8b921d4f6941b990cc5c3b2e485204-15"></a>    <span class="k">static</span> <span class="k">constexpr</span> <span class="k">const</span> <span class="n">std</span><span class="o">::</span><span class="kt">size_t</span> <span class="n">value</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
<a name="rest_code_cd8b921d4f6941b990cc5c3b2e485204-16"></a><span class="p">};</span>
<a name="rest_code_cd8b921d4f6941b990cc5c3b2e485204-17"></a>
<a name="rest_code_cd8b921d4f6941b990cc5c3b2e485204-18"></a><span class="kt">int</span> <span class="nf">main</span><span class="p">(){</span>
<a name="rest_code_cd8b921d4f6941b990cc5c3b2e485204-19"></a>    <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"Fibonacci&lt;5&gt;:"</span> <span class="o">&lt;&lt;</span> <span class="n">Fibonacci</span><span class="o">&lt;</span><span class="mi">5</span><span class="o">&gt;::</span><span class="n">value</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<a name="rest_code_cd8b921d4f6941b990cc5c3b2e485204-20"></a><span class="p">}</span>
</pre>
<p>Nothing fancy here, we're simply printing the fifth Fibonacci number on the console.</p>
<p>You can compile it with templight++:</p>
<pre class="code bash"><a name="rest_code_ddd22fb61b2c49b7bc6e57477bfa1b29-1"></a>templight++ -Xtemplight -profiler -Xtemplight -memory -Xtemplight -ignore-system -std<span class="o">=</span>c++14 main.cpp
</pre>
<p>All the templight options starts with -Xtemplight and then you can use any clang++ options. This will generate a <em>a.memory.trace.pbf</em> file in the current directory. You can then run Templar. use File &gt; Open Trace to open the trace file. This should open a window of this sort:</p>
<img alt="/images/templar.png" class="align-center" src="images/templar.png"><p>The top-left panel contains the source code of the application, automatically
refreshed whenever you move in the template tree. In the top right, there is
the template instantiation graph. In the bottom left, you'll see a list of list
of files to be able to filter them and in the bottom right, you'll see the list
of templates events. You can sort the list of template events by duration which
is really convenient. You can then select Fibonacci&lt;5&gt; by double clicking it in
the list (once sorted, it should be near the top). This should give you a tree
looking something like that:</p>
<img alt="/images/templar_tree.png" class="align-center" src="images/templar_tree.png"><p>The edgy nodes are template instantiations and the round nodes are template
memoization. We can directly see that each instantiation was only done once. I
think this graph view is really helpful if you need to debug computation done
at compile time. You can see that that not all nodes are displayed, this is
because there is a limit on the displayed depth. Simply click on Fibonacci&lt;3&gt;
and the remaining nodes will be shown.</p>
<p>I have already used this tool to find the most time-consuming templates in ETL
an DLL. This is a great tool to indicate where you should focus on improving
the template compile-time. I have also been able to find some unnecessary
instantiations that could be avoided (either with SFINAE or with refactorings).</p>
<p>templight also contains a fully-fledged debugger for template programs, but I haven't tested it.</p>
</div>
<div class="section" id="conclusion">
<h2>Conclusion</h2>
<p>In conclusion, I would say that templight and Templar are really helping with
template debugging and profiling. There is a real lack of tools in this domain
and I hope to see more tools of this kind in the future. I hope this will help
you develop template-heavy programs or template metaprograms.</p>
</div>
</div>
        </div>
            
        
    <a href="posts/2016/02/use-templight-and-templar-to-debug-cpp-templates.html#disqus_thread" data-disqus-identifier="cache/posts/2016/02/use-templight-and-templar-to-debug-cpp-templates.html">Comments</a>


        </article><article class="postbox h-entry post-text"><h1 class="p-name">
<a href="posts/2016/01/improve-dll-and-etl-compile-time-further.html" class="u-url">Improve DLL and ETL Compile Time further</a>
        <br><small>  
             Posted: <time class="published dt-published" datetime="2016-01-29T17:02:34+01:00">2016-01-29 17:02</time></small>
</h1>
        <hr>
<div class="p-summary">
        <div>
<p>For a while, the compilation time of my matrix/vector computation library (ETL), based on Expression Templates has become more and more problematic. I've already worked on this problem <a class="reference external" href="http://baptiste-wicht.com/posts/2015/06/how-i-improved-a-bit-compile-time-of-etl.html">here</a> and <a class="reference external" href="http://baptiste-wicht.com/posts/2015/06/improve-etl-compile-time-with-precompiled-headers.html">there</a>, using some general techniques (pragmas, precompiled headers, header removals and so on). On this post, I'll talk about two major improvements I have been able to do directly in the code.</p>
<div class="section" id="use-of-static-if">
<h2>Use of static_if</h2>
<p>Remember <a class="reference external" href="http://baptiste-wicht.com/posts/2015/07/simulate-static_if-with-c11c14.html">static_if</a> ? I was able to use it to really reduce the compile time of DLL.</p>
<p>I wrote a script to time each test case of the DLL project to find the test cases that took the longest to compile. Once I found the best candidate, I isolated the functions that took the longest to compile. It was quite tedious and I did it by hand, primarily by commenting parts of the code and going deeper and deeper in the code. I was quite suprised to find that a single function call (template function of course ;) ) was responsible for 60% of the compilation time of my candidate test case. The function was instantiating a whole bunch of expression templates (to compute the free energy of several models). The function itself was not really optimizable, but what was really interesting is that this function was only used in some very rare cases and that these cases were known at compile-time :) This was a perfect case to use a static_if. And once the call was inside the static_if, the test case was indeed about 60% faster. <strong>This reduced the overall compilation time of DLL by about 30%</strong>!</p>
<p>This could also of course also have been achieved by using two functions, one with the call, one empty and selected by SFINAE (Substitution Failure Is Not An Error). I prefer the statif_if version since this really shows the intent and hides SFINAE behind nicer syntax.</p>
<p>I was also able to use static_if at other places in the DLL code to avoid instantiating some templates, but the improvements were much less dramatic (about 1% of the total compilation time). I was very lucky to find a single function that accounted for so much compile time. After some more tests, I concluded that much of the compilation time of DLL was spent compiling the Expression Templates from my ETL library so I decided to delve into ETL code directly.</p>
</div>
<div class="section" id="removal-of-std-async">
<h2>Removal of std::async</h2>
<p>The second improvement was very surprising. I was working on improving the compilation of ETL and found out that the sum and average reductions of matrices were dramatically slow, about an order of magnitude slower than standard operations on matrices. In parallel (but the two facts are linked), I also found out another weird fact when splitting a file into 10 parts (the file was comprised of 10 test cases). Compiling the 10 parts separarely (and sequentially, not multiple threads) was about 40% faster than compiling the complete file. There was no swapping so it was not a memory issue. This is not expected. Generally, it is faster to compile a big file than to compile its parts separately. The advantage of smaller files is that you can compile them in parallel and that incremental builds are faster (only compile a small part).</p>
<p>By elimination, I found out that most of the time was spent inside the function that was dispatching in parallel the work for accumulating the sum of a matrix. Here is the function:</p>
<pre class="code cpp"><a name="rest_code_5509e52b69414fbfb93721528146cdd9-1"></a><span class="k">template</span> <span class="o">&lt;</span><span class="k">typename</span> <span class="n">T</span><span class="p">,</span> <span class="k">typename</span> <span class="n">Functor</span><span class="p">,</span> <span class="k">typename</span> <span class="n">AccFunctor</span><span class="o">&gt;</span>
<a name="rest_code_5509e52b69414fbfb93721528146cdd9-2"></a><span class="kr">inline</span> <span class="kt">void</span> <span class="n">dispatch_1d_acc</span><span class="p">(</span><span class="kt">bool</span> <span class="n">p</span><span class="p">,</span> <span class="n">Functor</span><span class="o">&amp;&amp;</span> <span class="n">functor</span><span class="p">,</span> <span class="n">AccFunctor</span><span class="o">&amp;&amp;</span> <span class="n">acc_functor</span><span class="p">,</span> <span class="n">std</span><span class="o">::</span><span class="kt">size_t</span> <span class="n">first</span><span class="p">,</span> <span class="n">std</span><span class="o">::</span><span class="kt">size_t</span> <span class="n">last</span><span class="p">){</span>
<a name="rest_code_5509e52b69414fbfb93721528146cdd9-3"></a>    <span class="k">if</span><span class="p">(</span><span class="n">p</span><span class="p">){</span>
<a name="rest_code_5509e52b69414fbfb93721528146cdd9-4"></a>        <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">future</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;&gt;</span> <span class="n">futures</span><span class="p">(</span><span class="n">threads</span> <span class="o">-</span> <span class="mi">1</span><span class="p">);</span>
<a name="rest_code_5509e52b69414fbfb93721528146cdd9-5"></a>
<a name="rest_code_5509e52b69414fbfb93721528146cdd9-6"></a>        <span class="k">auto</span> <span class="n">n</span> <span class="o">=</span> <span class="n">last</span> <span class="o">-</span> <span class="n">first</span><span class="p">;</span>
<a name="rest_code_5509e52b69414fbfb93721528146cdd9-7"></a>        <span class="k">auto</span> <span class="n">batch</span> <span class="o">=</span> <span class="n">n</span> <span class="o">/</span> <span class="n">threads</span><span class="p">;</span>
<a name="rest_code_5509e52b69414fbfb93721528146cdd9-8"></a>
<a name="rest_code_5509e52b69414fbfb93721528146cdd9-9"></a>        <span class="k">for</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="kt">size_t</span> <span class="n">t</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">t</span> <span class="o">&lt;</span> <span class="n">threads</span> <span class="o">-</span> <span class="mi">1</span><span class="p">;</span> <span class="o">++</span><span class="n">t</span><span class="p">){</span>
<a name="rest_code_5509e52b69414fbfb93721528146cdd9-10"></a>            <span class="n">futures</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">async</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">launch</span><span class="o">::</span><span class="n">async</span><span class="p">,</span> <span class="n">functor</span><span class="p">,</span> <span class="n">first</span> <span class="o">+</span> <span class="n">t</span> <span class="o">*</span> <span class="n">batch</span><span class="p">,</span> <span class="n">first</span> <span class="o">+</span> <span class="p">(</span><span class="n">t</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">batch</span><span class="p">);</span>
<a name="rest_code_5509e52b69414fbfb93721528146cdd9-11"></a>        <span class="p">}</span>
<a name="rest_code_5509e52b69414fbfb93721528146cdd9-12"></a>
<a name="rest_code_5509e52b69414fbfb93721528146cdd9-13"></a>        <span class="n">acc_functor</span><span class="p">(</span><span class="n">functor</span><span class="p">(</span><span class="n">first</span> <span class="o">+</span> <span class="p">(</span><span class="n">threads</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">batch</span><span class="p">,</span> <span class="n">last</span><span class="p">));</span>
<a name="rest_code_5509e52b69414fbfb93721528146cdd9-14"></a>
<a name="rest_code_5509e52b69414fbfb93721528146cdd9-15"></a>        <span class="k">for</span><span class="p">(</span><span class="k">auto</span><span class="o">&amp;</span> <span class="nl">fut</span> <span class="p">:</span> <span class="n">futures</span><span class="p">){</span>
<a name="rest_code_5509e52b69414fbfb93721528146cdd9-16"></a>            <span class="n">acc_functor</span><span class="p">(</span><span class="n">fut</span><span class="p">.</span><span class="n">get</span><span class="p">());</span>
<a name="rest_code_5509e52b69414fbfb93721528146cdd9-17"></a>        <span class="p">}</span>
<a name="rest_code_5509e52b69414fbfb93721528146cdd9-18"></a>    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
<a name="rest_code_5509e52b69414fbfb93721528146cdd9-19"></a>        <span class="n">acc_functor</span><span class="p">(</span><span class="n">functor</span><span class="p">(</span><span class="n">first</span><span class="p">,</span> <span class="n">last</span><span class="p">));</span>
<a name="rest_code_5509e52b69414fbfb93721528146cdd9-20"></a>    <span class="p">}</span>
<a name="rest_code_5509e52b69414fbfb93721528146cdd9-21"></a><span class="p">}</span>
</pre>
<p>There isn't anything really fancy about this function. This takes one functor that will be done in parallel and one function for accumulation.  It dispatches all the work in batch and then accumulates the results. I tried several things to optimize the compilation time of this function, but nothing worked. The line that was consuming all the time was the std::async line. This function was using std::async because the thread pool that I'm generally using does not support returning values from parallel functors. I decided to use a workaround and use my thread pool and I came out with this version:</p>
<pre class="code cpp"><a name="rest_code_52256ab912734b359b9460104c21b1b3-1"></a><span class="k">template</span> <span class="o">&lt;</span><span class="k">typename</span> <span class="n">T</span><span class="p">,</span> <span class="k">typename</span> <span class="n">Functor</span><span class="p">,</span> <span class="k">typename</span> <span class="n">AccFunctor</span><span class="o">&gt;</span>
<a name="rest_code_52256ab912734b359b9460104c21b1b3-2"></a><span class="kr">inline</span> <span class="kt">void</span> <span class="n">dispatch_1d_acc</span><span class="p">(</span><span class="kt">bool</span> <span class="n">p</span><span class="p">,</span> <span class="n">Functor</span><span class="o">&amp;&amp;</span> <span class="n">functor</span><span class="p">,</span> <span class="n">AccFunctor</span><span class="o">&amp;&amp;</span> <span class="n">acc_functor</span><span class="p">,</span> <span class="n">std</span><span class="o">::</span><span class="kt">size_t</span> <span class="n">first</span><span class="p">,</span> <span class="n">std</span><span class="o">::</span><span class="kt">size_t</span> <span class="n">last</span><span class="p">){</span>
<a name="rest_code_52256ab912734b359b9460104c21b1b3-3"></a>    <span class="k">if</span><span class="p">(</span><span class="n">p</span><span class="p">){</span>
<a name="rest_code_52256ab912734b359b9460104c21b1b3-4"></a>        <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span> <span class="n">futures</span><span class="p">(</span><span class="n">threads</span> <span class="o">-</span> <span class="mi">1</span><span class="p">);</span>
<a name="rest_code_52256ab912734b359b9460104c21b1b3-5"></a>        <span class="n">cpp</span><span class="o">::</span><span class="n">default_thread_pool</span><span class="o">&lt;&gt;</span> <span class="n">pool</span><span class="p">(</span><span class="n">threads</span> <span class="o">-</span> <span class="mi">1</span><span class="p">);</span>
<a name="rest_code_52256ab912734b359b9460104c21b1b3-6"></a>
<a name="rest_code_52256ab912734b359b9460104c21b1b3-7"></a>        <span class="k">auto</span> <span class="n">n</span> <span class="o">=</span> <span class="n">last</span> <span class="o">-</span> <span class="n">first</span><span class="p">;</span>
<a name="rest_code_52256ab912734b359b9460104c21b1b3-8"></a>        <span class="k">auto</span> <span class="n">batch</span> <span class="o">=</span> <span class="n">n</span> <span class="o">/</span> <span class="n">threads</span><span class="p">;</span>
<a name="rest_code_52256ab912734b359b9460104c21b1b3-9"></a>
<a name="rest_code_52256ab912734b359b9460104c21b1b3-10"></a>        <span class="k">auto</span> <span class="n">sub_functor</span> <span class="o">=</span> <span class="p">[</span><span class="o">&amp;</span><span class="n">futures</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">functor</span><span class="p">](</span><span class="n">std</span><span class="o">::</span><span class="kt">size_t</span> <span class="n">t</span><span class="p">,</span> <span class="n">std</span><span class="o">::</span><span class="kt">size_t</span> <span class="n">first</span><span class="p">,</span> <span class="n">std</span><span class="o">::</span><span class="kt">size_t</span> <span class="n">last</span><span class="p">){</span>
<a name="rest_code_52256ab912734b359b9460104c21b1b3-11"></a>            <span class="n">futures</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">functor</span><span class="p">(</span><span class="n">first</span><span class="p">,</span> <span class="n">last</span><span class="p">);</span>
<a name="rest_code_52256ab912734b359b9460104c21b1b3-12"></a>        <span class="p">};</span>
<a name="rest_code_52256ab912734b359b9460104c21b1b3-13"></a>
<a name="rest_code_52256ab912734b359b9460104c21b1b3-14"></a>        <span class="k">for</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="kt">size_t</span> <span class="n">t</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">t</span> <span class="o">&lt;</span> <span class="n">threads</span> <span class="o">-</span> <span class="mi">1</span><span class="p">;</span> <span class="o">++</span><span class="n">t</span><span class="p">){</span>
<a name="rest_code_52256ab912734b359b9460104c21b1b3-15"></a>            <span class="n">pool</span><span class="p">.</span><span class="n">do_task</span><span class="p">(</span><span class="n">sub_functor</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">first</span> <span class="o">+</span> <span class="n">t</span> <span class="o">*</span> <span class="n">batch</span><span class="p">,</span> <span class="n">first</span> <span class="o">+</span> <span class="p">(</span><span class="n">t</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">batch</span><span class="p">);</span>
<a name="rest_code_52256ab912734b359b9460104c21b1b3-16"></a>        <span class="p">}</span>
<a name="rest_code_52256ab912734b359b9460104c21b1b3-17"></a>
<a name="rest_code_52256ab912734b359b9460104c21b1b3-18"></a>        <span class="n">acc_functor</span><span class="p">(</span><span class="n">functor</span><span class="p">(</span><span class="n">first</span> <span class="o">+</span> <span class="p">(</span><span class="n">threads</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">batch</span><span class="p">,</span> <span class="n">last</span><span class="p">));</span>
<a name="rest_code_52256ab912734b359b9460104c21b1b3-19"></a>
<a name="rest_code_52256ab912734b359b9460104c21b1b3-20"></a>        <span class="n">pool</span><span class="p">.</span><span class="n">wait</span><span class="p">();</span>
<a name="rest_code_52256ab912734b359b9460104c21b1b3-21"></a>
<a name="rest_code_52256ab912734b359b9460104c21b1b3-22"></a>        <span class="k">for</span><span class="p">(</span><span class="k">auto</span> <span class="nl">fut</span> <span class="p">:</span> <span class="n">futures</span><span class="p">){</span>
<a name="rest_code_52256ab912734b359b9460104c21b1b3-23"></a>            <span class="n">acc_functor</span><span class="p">(</span><span class="n">fut</span><span class="p">);</span>
<a name="rest_code_52256ab912734b359b9460104c21b1b3-24"></a>        <span class="p">}</span>
<a name="rest_code_52256ab912734b359b9460104c21b1b3-25"></a>    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
<a name="rest_code_52256ab912734b359b9460104c21b1b3-26"></a>        <span class="n">acc_functor</span><span class="p">(</span><span class="n">functor</span><span class="p">(</span><span class="n">first</span><span class="p">,</span> <span class="n">last</span><span class="p">));</span>
<a name="rest_code_52256ab912734b359b9460104c21b1b3-27"></a>    <span class="p">}</span>
<a name="rest_code_52256ab912734b359b9460104c21b1b3-28"></a><span class="p">}</span>
</pre>
<p>I simply preallocate space for all the threads and create a new functor calling the input functor and saving its result inside the vector. It is less nice, but it works well. And it compiles MUCH faster. This <strong>reduced the compilation time</strong> of my biggest test case <strong>by a factor of 8</strong> (from 344 seconds to 44 seconds). This is really crazy. It also fixed the problem where splitting the test case was faster than big file (it is now twice faster to compile the big files than compiling all the small files separately). <strong>This reduced the total compilation time of dll by about 400%</strong>.</p>
<p>As of now, I still have no idea why this makes such a big difference. I have looked at the std::async code, but I haven't found a valid reason for this slowdown. If someone has any idea, I'd be very glad to discuss in the comments below.</p>
</div>
<div class="section" id="improving-the-template-instantiation-tree">
<h2>Improving the template instantiation tree</h2>
<p>I recently discovered the templight tool that is a profiler for templates (pretty cool). After some time, I was able to build it and use it on ETL. For now, I haven't been able to reduce compile time a lot, but I have been able to reduce the template instantiation tree a lot seeing that some instantiations were completely useless and I optimized the code to remove them.</p>
<p>I won't be go into much details here because I plan to write a post on this subject in the coming days.</p>
</div>
<div class="section" id="conclusion">
<h2>Conclusion</h2>
<p>In conclusion, I would say that it is pretty hard to improve the compile time of complex C++ programs once you have gone through all the standard methods. However, I was very happy to found that <strong>two optimizations in the source code reduced the overall compilation of DLL by almost 500%</strong>. I will continue working on this, but for now, the compilation time is much more reasonable.</p>
<p>I hope the two main facts in this article were interesting. If you have similar experience, comments or ideas for further improvements, I'd be glad to discuss them with you in the comments :)</p>
</div>
</div>
        </div>
            
        
    <a href="posts/2016/01/improve-dll-and-etl-compile-time-further.html#disqus_thread" data-disqus-identifier="cache/posts/2016/01/improve-dll-and-etl-compile-time-further.html">Comments</a>


        </article><nav class="postindexpager"><ul class="pager">
<li class="next">
                <a href="index-28.html" rel="next">Older posts</a>
            </li>
        </ul></nav><script>var disqus_shortname="blogwichtounet";(function(){var a=document.createElement("script");a.async=true;a.src="https://"+disqus_shortname+".disqus.com/count.js";(document.getElementsByTagName("head")[0]||document.getElementsByTagName("body")[0]).appendChild(a)}());</script>
</div>
        </div>
    </div>
</div>

<!-- Footer -->

<footer>
    Contents © 2016         <a href="mailto:baptistewicht@gmail.com">Baptiste Wicht</a> - Powered by         <a href="http://getnikola.com" rel="nofollow">Nikola</a>         
<a rel="license" href="http://creativecommons.org/licenses/by/4.0/"><img alt="Creative Commons License" style="padding-left:5px;border-width:0" src="assets/img/cc.png"></a>
        <ul class="footer_inline_ul"></ul></footer><!-- Late loading stuff  --><script src="assets/js/all-nocdn.js"></script><script type="text/javascript">
      $(document).ready(function() {
        jQuery.getJSON('/assets/js/tag_cloud_data.json', function(data) {
            var items = [];

            $.each(data, function(key, val) {
                items.push('<li><a href="' + val[1] +'" '+'data-weight="'+val[0]+'"'+'>' + key + '</a></li>');
            });

            $('<div/>', {
                'id': 'tags',
                html: '<ul>' + items.join('') + '</ul>'
            }).appendTo('body');

            if(!$('#tags_canvas').tagcanvas({
                textColour: '#FFFFFF',
                outlineColour: '#ff00ff',
                reverse: true,
                depth: 0.8,
                maxSpeed: 0.05,
                weight: true,
                weightFrom: "data-weight",
                weightSizeMin: 8,
                weightSizeMax: 24
            },'tags')) {
                //something went wrong, hide the canvas container
                $('#tags_container').hide();
            }});
        });
    </script><!-- Google platform JS --><script type="text/javascript" src="https://apis.google.com/js/platform.js"></script>
</body>
</html>
