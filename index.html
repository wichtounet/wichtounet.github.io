<!DOCTYPE html>
<html prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article# " lang="en">
<head>
<meta charset="utf-8">
<meta name="description" content="Tutorials and short posts about programming, C++, Java, Assembly, Operating Systems Development, Compilers, ...">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Blog blog("Baptiste Wicht");</title>
<link href="assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="alternate" type="application/rss+xml" title="RSS" href="rss.xml">
<link rel="canonical" href="http://baptiste-wicht.com/index.html">
<link rel="next" href="index-32.html" type="text/html">
<!--[if lt IE 9]><script src="assets/js/html5.js"></script><![endif]--><link href="favicon.ico" rel="icon" type="image/x-icon">
<link rel="publisher" href="https://plus.google.com/+BaptisteWicht">
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-2175227-7', 'auto');
  var metas = document.getElementsByTagName('meta'), tagsList = [];
  for (var i=0; i<metas.length; i++) {
    if (metas[i].getAttribute('property') == 'article:tag') {
      tagsList.push( metas[i].getAttribute('content'));
    }
  }
  ga('set', 'dimension1', tagsList.join('|'));
  ga('send', 'pageview');
</script>
</head>
<body>

<!-- Menubar -->

<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<div class="container-fluid">
<!-- This keeps the margins nice -->
    <div class="row">
        <div class="col-sm-3 col-lg-2">
            <nav class="navbar navbar-inverse navbar-fixed-side"><div class="navbar-header">
                    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-ex1-collapse">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    </button>
                    <a class="navbar-brand" href="http://baptiste-wicht.com/">
                        <span id="blog-title">Blog blog("Baptiste Wicht");</span>
                    </a>
                </div>
<!-- /.navbar-header -->

                <div class="collapse navbar-collapse navbar-ex1-collapse">
                    <ul class="nav navbar-nav">
<li>
<a href="stories/about.html">About</a>
                </li>
<li>
<a href="stories/publications.html">Publications</a>
                </li>
<li>
<a href="stories/projects.html">Projects</a>
                </li>
<li>
<a href="categories/index.html">Tags</a>
                </li>
<li>
<a href="archive.html">Archives</a>
                </li>
<li>
<a href="http://feeds.feedburner.com/BaptisteWicht">RSS</a>


                            </li>
<li class="navbar-content">
                                <h3>Tags</h3>
                            </li>
                            <li class="navbar-empty">
                                <div id="tag_cloud_left_container" style="line-height: 18px !important;"></div>
                            </li>
                            <li class="navbar-block">


                        <li class="wicht-navbar-right">
                            <a target="_blank" title="Follow @wichtounet on Twitter" href="https://twitter.com/wichtounet">
                                <img src="assets/img/twitter.png" alt="Follow @wichtounet on Twitter"></a>
                        </li>

                        <li class="wicht-navbar-right">
                            <a target="_blank" title="Follow +BaptisteWicht on Google+" href="https://plus.google.com/+BaptisteWicht">
                                <img src="assets/img/google_plus.png" alt="Follow +BaptisteWicht on Google+"></a>
                        </li>


                    </ul>
</div>
<!-- /.navbar-collapse -->
            </nav>
</div> <!-- col -->
        <div class="col-sm-9 col-lg-10">
            <div id="content"></div>
            
        <article class="postbox h-entry post-text"><h1 class="p-name">
<a href="posts/2017/11/initial-support-for-long-short-term-memory-lstm-in-dll.html" class="u-url">Initial support for Long Short Term Memory (LSTM) in DLL</a>
        <br><small>  
             Posted: <time class="published dt-published" datetime="2017-11-24T15:16:37+01:00">2017-11-24 15:16</time></small>
</h1>
        <hr>
<div class="p-summary">
        <div>
<p>I'm really happy to announce that I just merged support for</p>
<p>Long Short Term Memory
(LSTM) cells into my Deep Learning Library (DLL) machine learning framework. Two
weeks ago, <a href="posts/2017/11/initial-support-for-long-short-term-memory-lstm-in-dll.html#id1"><span class="problematic" id="id2">`I already merged suport for Recurrent Neural network (RNN) https://baptiste-wicht.com/posts/2017/11/initial-support-for-recurrent-neural-network-rnn-in-dll.html&gt;`_</span></a>.</p>
<p>It's nothing fancy yet, but forward propagation of LSTM and basic
Backpropagation Through Time (BPTT) are now supported. It was not really
complicated to implemenet the forward pass but the backward pass is much
complicated for an LSTM than for a RNN. It took me quite a long time to figure
out all the gradients formulas and the documentation on that is quite scarce.</p>
<p>For now, still only existing classification loss is supported for RNN and LSTM.
As I said last time, I still plan to add support for sequence-to-sequence loss
in order to be able to train models able to generate characters. However, I don't
know when I'll be able to work on that. Now that I've got the code for LSTM,
I should be able to implement a GRU cell and NAS cell quite easily I believe.</p>
<p>For example, here is a simple LSTM used on MNIST for classification:</p>
<pre class="code cpp"><a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-1"></a><span class="cp">#include</span> <span class="cpf">"dll/neural/dense_layer.hpp"</span><span class="cp"></span>
<a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-2"></a><span class="cp">#include</span> <span class="cpf">"dll/neural/lstm_layer.hpp"</span><span class="cp"></span>
<a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-3"></a><span class="cp">#include</span> <span class="cpf">"dll/neural/recurrent_last_layer.hpp"</span><span class="cp"></span>
<a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-4"></a><span class="cp">#include</span> <span class="cpf">"dll/network.hpp"</span><span class="cp"></span>
<a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-5"></a><span class="cp">#include</span> <span class="cpf">"dll/datasets.hpp"</span><span class="cp"></span>
<a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-6"></a>
<a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-7"></a><span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="cm">/*argc*/</span><span class="p">,</span> <span class="kt">char</span><span class="o">*</span> <span class="cm">/*argv*/</span> <span class="p">[])</span> <span class="p">{</span>
<a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-8"></a>    <span class="c1">// Load the dataset</span>
<a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-9"></a>    <span class="k">auto</span> <span class="n">dataset</span> <span class="o">=</span> <span class="n">dll</span><span class="o">::</span><span class="n">make_mnist_dataset_nc</span><span class="p">(</span><span class="n">dll</span><span class="o">::</span><span class="n">batch_size</span><span class="o">&lt;</span><span class="mi">100</span><span class="o">&gt;</span><span class="p">{},</span> <span class="n">dll</span><span class="o">::</span><span class="n">scale_pre</span><span class="o">&lt;</span><span class="mi">255</span><span class="o">&gt;</span><span class="p">{});</span>
<a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-10"></a>
<a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-11"></a>    <span class="k">constexpr</span> <span class="kt">size_t</span> <span class="n">time_steps</span>      <span class="o">=</span> <span class="mi">28</span><span class="p">;</span>
<a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-12"></a>    <span class="k">constexpr</span> <span class="kt">size_t</span> <span class="n">sequence_length</span> <span class="o">=</span> <span class="mi">28</span><span class="p">;</span>
<a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-13"></a>    <span class="k">constexpr</span> <span class="kt">size_t</span> <span class="n">hidden_units</span>    <span class="o">=</span> <span class="mi">100</span><span class="p">;</span>
<a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-14"></a>
<a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-15"></a>    <span class="c1">// Build the network</span>
<a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-16"></a>
<a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-17"></a>    <span class="k">using</span> <span class="n">network_t</span> <span class="o">=</span> <span class="n">dll</span><span class="o">::</span><span class="n">dyn_network_desc</span><span class="o">&lt;</span>
<a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-18"></a>        <span class="n">dll</span><span class="o">::</span><span class="n">network_layers</span><span class="o">&lt;</span>
<a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-19"></a>            <span class="n">dll</span><span class="o">::</span><span class="n">lstm_layer</span><span class="o">&lt;</span><span class="n">time_steps</span><span class="p">,</span> <span class="n">sequence_length</span><span class="p">,</span> <span class="n">hidden_units</span><span class="p">,</span> <span class="n">dll</span><span class="o">::</span><span class="n">last_only</span><span class="o">&gt;</span><span class="p">,</span>
<a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-20"></a>            <span class="n">dll</span><span class="o">::</span><span class="n">recurrent_last_layer</span><span class="o">&lt;</span><span class="n">time_steps</span><span class="p">,</span> <span class="n">hidden_units</span><span class="o">&gt;</span><span class="p">,</span>
<a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-21"></a>            <span class="n">dll</span><span class="o">::</span><span class="n">dense_layer</span><span class="o">&lt;</span><span class="n">hidden_units</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">dll</span><span class="o">::</span><span class="n">softmax</span><span class="o">&gt;</span>
<a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-22"></a>        <span class="o">&gt;</span>
<a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-23"></a>        <span class="p">,</span> <span class="n">dll</span><span class="o">::</span><span class="n">updater</span><span class="o">&lt;</span><span class="n">dll</span><span class="o">::</span><span class="n">updater_type</span><span class="o">::</span><span class="n">ADAM</span><span class="o">&gt;</span>      <span class="c1">// Adam</span>
<a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-24"></a>        <span class="p">,</span> <span class="n">dll</span><span class="o">::</span><span class="n">batch_size</span><span class="o">&lt;</span><span class="mi">100</span><span class="o">&gt;</span>                       <span class="c1">// The mini-batch size</span>
<a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-25"></a>    <span class="o">&gt;::</span><span class="n">network_t</span><span class="p">;</span>
<a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-26"></a>
<a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-27"></a>    <span class="k">auto</span> <span class="n">net</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">make_unique</span><span class="o">&lt;</span><span class="n">network_t</span><span class="o">&gt;</span><span class="p">();</span>
<a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-28"></a>
<a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-29"></a>    <span class="c1">// Display the network and dataset</span>
<a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-30"></a>    <span class="n">net</span><span class="o">-&gt;</span><span class="n">display</span><span class="p">();</span>
<a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-31"></a>    <span class="n">dataset</span><span class="p">.</span><span class="n">display</span><span class="p">();</span>
<a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-32"></a>
<a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-33"></a>    <span class="c1">// Train the network for performance sake</span>
<a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-34"></a>    <span class="n">net</span><span class="o">-&gt;</span><span class="n">fine_tune</span><span class="p">(</span><span class="n">dataset</span><span class="p">.</span><span class="n">train</span><span class="p">(),</span> <span class="mi">50</span><span class="p">);</span>
<a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-35"></a>
<a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-36"></a>    <span class="c1">// Test the network on test set</span>
<a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-37"></a>    <span class="n">net</span><span class="o">-&gt;</span><span class="n">evaluate</span><span class="p">(</span><span class="n">dataset</span><span class="p">.</span><span class="n">test</span><span class="p">());</span>
<a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-38"></a>
<a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-39"></a>    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<a name="rest_code_99454dd495d64524ae6a5adc383bc5dc-40"></a><span class="p">}</span>
</pre>
<p>The network is quite similar to the one used previously with an RNN, just
replace rnn with lstm and that's it. It starts with LSTM layer, followed by
a layer extracting the last time step and finally a dense layer with a softmax
function. The network is trained with Adam for 50 epochs. You can change the
activation function , the initializer for the weights and the biases and number
of steps for BPTT truncation.</p>
<p>Here is the result I got on my last run:</p>
<pre class="code text"><a name="rest_code_cac13a9e51474881adc905e6630b17ab-1"></a>------------------------------------------------------------
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-2"></a>| Index | Layer                | Parameters | Output Shape |
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-3"></a>------------------------------------------------------------
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-4"></a>| 0     | LSTM (TANH) (dyn)    |      51200 | [Bx28x100]   |
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-5"></a>| 1     | RNN(last)            |          0 | [Bx100]      |
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-6"></a>| 2     | Dense(SOFTMAX) (dyn) |       1000 | [Bx10]       |
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-7"></a>------------------------------------------------------------
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-8"></a>              Total Parameters:      52200
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-9"></a>
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-10"></a>--------------------------------------------
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-11"></a>| mnist | Size  | Batches | Augmented Size |
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-12"></a>--------------------------------------------
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-13"></a>| train | 60000 | 600     | 60000          |
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-14"></a>| test  | 10000 | 100     | 10000          |
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-15"></a>--------------------------------------------
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-16"></a>
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-17"></a>Network with 3 layers
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-18"></a>    LSTM(dyn): 28x28 -&gt; TANH -&gt; 28x100
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-19"></a>    RNN(last): 28x100 -&gt; 100
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-20"></a>    Dense(dyn): 100 -&gt; SOFTMAX -&gt; 10
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-21"></a>Total parameters: 52200
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-22"></a>Dataset
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-23"></a>Training: In-Memory Data Generator
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-24"></a>              Size: 60000
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-25"></a>           Batches: 600
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-26"></a>Testing: In-Memory Data Generator
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-27"></a>              Size: 10000
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-28"></a>           Batches: 100
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-29"></a>
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-30"></a>Train the network with "Stochastic Gradient Descent"
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-31"></a>    Updater: ADAM
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-32"></a>       Loss: CATEGORICAL_CROSS_ENTROPY
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-33"></a> Early Stop: Goal(error)
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-34"></a>
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-35"></a>With parameters:
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-36"></a>          epochs=50
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-37"></a>      batch_size=100
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-38"></a>   learning_rate=0.001
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-39"></a>           beta1=0.9
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-40"></a>           beta2=0.999
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-41"></a>
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-42"></a>epoch   0/50 batch  600/ 600 - error: 0.07943 loss: 0.28504 time 20910ms
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-43"></a>epoch   1/50 batch  600/ 600 - error: 0.06683 loss: 0.24021 time 20889ms
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-44"></a>epoch   2/50 batch  600/ 600 - error: 0.04828 loss: 0.18233 time 21061ms
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-45"></a>epoch   3/50 batch  600/ 600 - error: 0.04407 loss: 0.16665 time 20839ms
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-46"></a>epoch   4/50 batch  600/ 600 - error: 0.03515 loss: 0.13290 time 22108ms
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-47"></a>epoch   5/50 batch  600/ 600 - error: 0.03207 loss: 0.12019 time 21393ms
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-48"></a>epoch   6/50 batch  600/ 600 - error: 0.02973 loss: 0.11239 time 28199ms
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-49"></a>epoch   7/50 batch  600/ 600 - error: 0.02653 loss: 0.10455 time 37039ms
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-50"></a>epoch   8/50 batch  600/ 600 - error: 0.02482 loss: 0.09657 time 23127ms
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-51"></a>epoch   9/50 batch  600/ 600 - error: 0.02177 loss: 0.08422 time 41766ms
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-52"></a>epoch  10/50 batch  600/ 600 - error: 0.02453 loss: 0.09382 time 29765ms
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-53"></a>epoch  11/50 batch  600/ 600 - error: 0.02575 loss: 0.09796 time 21449ms
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-54"></a>epoch  12/50 batch  600/ 600 - error: 0.02107 loss: 0.07833 time 42056ms
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-55"></a>epoch  13/50 batch  600/ 600 - error: 0.01877 loss: 0.07171 time 24673ms
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-56"></a>epoch  14/50 batch  600/ 600 - error: 0.02095 loss: 0.08481 time 20878ms
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-57"></a>epoch  15/50 batch  600/ 600 - error: 0.02040 loss: 0.07578 time 41515ms
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-58"></a>epoch  16/50 batch  600/ 600 - error: 0.01580 loss: 0.06083 time 25705ms
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-59"></a>epoch  17/50 batch  600/ 600 - error: 0.01945 loss: 0.07046 time 20903ms
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-60"></a>epoch  18/50 batch  600/ 600 - error: 0.01728 loss: 0.06683 time 41828ms
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-61"></a>epoch  19/50 batch  600/ 600 - error: 0.01577 loss: 0.05947 time 27810ms
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-62"></a>epoch  20/50 batch  600/ 600 - error: 0.01528 loss: 0.05883 time 21477ms
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-63"></a>epoch  21/50 batch  600/ 600 - error: 0.01345 loss: 0.05127 time 44718ms
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-64"></a>epoch  22/50 batch  600/ 600 - error: 0.01410 loss: 0.05357 time 25174ms
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-65"></a>epoch  23/50 batch  600/ 600 - error: 0.01268 loss: 0.04765 time 23827ms
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-66"></a>epoch  24/50 batch  600/ 600 - error: 0.01342 loss: 0.05004 time 47232ms
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-67"></a>epoch  25/50 batch  600/ 600 - error: 0.01730 loss: 0.06872 time 22532ms
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-68"></a>epoch  26/50 batch  600/ 600 - error: 0.01337 loss: 0.05016 time 30114ms
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-69"></a>epoch  27/50 batch  600/ 600 - error: 0.01842 loss: 0.07049 time 40136ms
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-70"></a>epoch  28/50 batch  600/ 600 - error: 0.01262 loss: 0.04639 time 21793ms
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-71"></a>epoch  29/50 batch  600/ 600 - error: 0.01403 loss: 0.05292 time 34096ms
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-72"></a>epoch  30/50 batch  600/ 600 - error: 0.01185 loss: 0.04456 time 35420ms
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-73"></a>epoch  31/50 batch  600/ 600 - error: 0.01098 loss: 0.04180 time 20909ms
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-74"></a>epoch  32/50 batch  600/ 600 - error: 0.01337 loss: 0.04687 time 30113ms
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-75"></a>epoch  33/50 batch  600/ 600 - error: 0.01415 loss: 0.05292 time 37393ms
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-76"></a>epoch  34/50 batch  600/ 600 - error: 0.00982 loss: 0.03615 time 20962ms
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-77"></a>epoch  35/50 batch  600/ 600 - error: 0.01178 loss: 0.04830 time 29305ms
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-78"></a>epoch  36/50 batch  600/ 600 - error: 0.00882 loss: 0.03408 time 38293ms
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-79"></a>epoch  37/50 batch  600/ 600 - error: 0.01148 loss: 0.04341 time 20841ms
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-80"></a>epoch  38/50 batch  600/ 600 - error: 0.00960 loss: 0.03701 time 29204ms
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-81"></a>epoch  39/50 batch  600/ 600 - error: 0.00850 loss: 0.03094 time 39802ms
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-82"></a>epoch  40/50 batch  600/ 600 - error: 0.01473 loss: 0.05136 time 20831ms
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-83"></a>epoch  41/50 batch  600/ 600 - error: 0.01007 loss: 0.03579 time 29856ms
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-84"></a>epoch  42/50 batch  600/ 600 - error: 0.00943 loss: 0.03370 time 38200ms
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-85"></a>epoch  43/50 batch  600/ 600 - error: 0.01205 loss: 0.04409 time 21162ms
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-86"></a>epoch  44/50 batch  600/ 600 - error: 0.00980 loss: 0.03674 time 32279ms
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-87"></a>epoch  45/50 batch  600/ 600 - error: 0.01068 loss: 0.04133 time 38448ms
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-88"></a>epoch  46/50 batch  600/ 600 - error: 0.00913 loss: 0.03478 time 20797ms
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-89"></a>epoch  47/50 batch  600/ 600 - error: 0.00985 loss: 0.03759 time 28885ms
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-90"></a>epoch  48/50 batch  600/ 600 - error: 0.00912 loss: 0.03295 time 41120ms
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-91"></a>epoch  49/50 batch  600/ 600 - error: 0.00930 loss: 0.03438 time 21282ms
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-92"></a>Restore the best (error) weights from epoch 39
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-93"></a>Training took 1460s
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-94"></a>
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-95"></a>Evaluation Results
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-96"></a>   error: 0.02440
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-97"></a>    loss: 0.11315
<a name="rest_code_cac13a9e51474881adc905e6630b17ab-98"></a>evaluation took 1000ms
</pre>
<p>Again, nothing fancy yet, but this example has not been optimized for
performance nor for accuracy.</p>
<p>I also made a few changes to the RNN layer. I added support for biases and
improved the code as well for performance and readability.</p>
<p>All this support is now in the <strong>master</strong> branch of the DLL project if you want
to check it out. You can also check out the example online:
<a class="reference external" href="https://github.com/wichtounet/dll/blob/master/examples/src/mnist_lstm.cpp">mnist_lstm.cpp</a></p>
<p>You can access the project <a class="reference external" href="https://github.com/wichtounet/dll">on Github</a>.</p>
<p>Currently I'm working on the GPU performance again. The performance of some is
still not as good as I want it to be, especially complex operation like used in
Adam and Nadam. Currently, there are many calls to GPU BLAS libraries and
I want to try to extract some more optimized patterns. Once it's done, I'll post
more on that later on the blog.</p>
<div class="system-messages section">
<h2>Docutils System Messages</h2>
<div class="system-message" id="id1">
<p class="system-message-title">System Message: ERROR/3 (<tt class="docutils">&lt;string&gt;</tt>, line 3); <em><a href="posts/2017/11/initial-support-for-long-short-term-memory-lstm-in-dll.html#id2">backlink</a></em></p>
Unknown target name: "i already merged suport for recurrent neural network (rnn) https://baptiste-wicht.com/posts/2017/11/initial-support-for-recurrent-neural-network-rnn-in-dll.html&gt;".</div>
</div>
</div>
        </div>
            
        
    <a href="posts/2017/11/initial-support-for-long-short-term-memory-lstm-in-dll.html#disqus_thread" data-disqus-identifier="cache/posts/2017/11/initial-support-for-long-short-term-memory-lstm-in-dll.html">Comments</a>


        </article><article class="postbox h-entry post-text"><h1 class="p-name">
<a href="posts/2017/11/dll-pretty-printing-and-live-output.html" class="u-url">DLL: Pretty printing and live output</a>
        <br><small>  
             Posted: <time class="published dt-published" datetime="2017-11-19T15:15:57+01:00">2017-11-19 15:15</time></small>
</h1>
        <hr>
<div class="p-summary">
        <div>
<p>I've improved a lot the display of my Deep Learning Library (DLL). I know this
is generally not the most important point in a machine learning framework, but
the first impression being important. Therefore, I decided it was time to get
a nicer output in the console for training networks.</p>
<p>A network or a dataset can be displayed using the <code>display()</code> function.
I've added a <code>display_pretty()</code> function to them to display it more
nicely. I've also added the <code>dll::dump_timers_nice()</code> function to do the
same for <code>dll::dump_timers()</code>.</p>
<p>I've also improved the display for the results of the batches during training.
Now, the display is updated every 100ms and it also displays the current
estimated time until the end of the epoch. With that, the user should have
a much better idea on what's going on during training, especially when training
networks when the epochs are taking a long time to complete.</p>
<p>Here is a full output of the training of fully-connected network on MNIST
(<cite>mnist_mlp.cpp &lt;https://github.com/wichtounet/dll/blob/master/examples/src/mnist_mlp.cpp&gt;</cite>):</p>
<pre class="code bash"><a name="rest_code_da1bfede7721421f865a0df880090001-1"></a> ------------------------------------------------------------
<a name="rest_code_da1bfede7721421f865a0df880090001-2"></a> <span class="p">|</span> Index <span class="p">|</span> Layer                <span class="p">|</span> Parameters <span class="p">|</span> Output Shape <span class="p">|</span>
<a name="rest_code_da1bfede7721421f865a0df880090001-3"></a> ------------------------------------------------------------
<a name="rest_code_da1bfede7721421f865a0df880090001-4"></a> <span class="p">|</span> <span class="m">0</span>     <span class="p">|</span> Dense<span class="o">(</span>SIGMOID<span class="o">)</span> <span class="o">(</span>dyn<span class="o">)</span> <span class="p">|</span>     <span class="m">392000</span> <span class="p">|</span> <span class="o">[</span>Bx500<span class="o">]</span>      <span class="p">|</span>
<a name="rest_code_da1bfede7721421f865a0df880090001-5"></a> <span class="p">|</span> <span class="m">1</span>     <span class="p">|</span> Dropout<span class="o">(</span><span class="m">0</span>.50<span class="o">)(</span>dyn<span class="o">)</span>   <span class="p">|</span>          <span class="m">0</span> <span class="p">|</span> <span class="o">[</span>Bx500<span class="o">]</span>      <span class="p">|</span>
<a name="rest_code_da1bfede7721421f865a0df880090001-6"></a> <span class="p">|</span> <span class="m">2</span>     <span class="p">|</span> Dense<span class="o">(</span>SIGMOID<span class="o">)</span> <span class="o">(</span>dyn<span class="o">)</span> <span class="p">|</span>     <span class="m">125000</span> <span class="p">|</span> <span class="o">[</span>Bx250<span class="o">]</span>      <span class="p">|</span>
<a name="rest_code_da1bfede7721421f865a0df880090001-7"></a> <span class="p">|</span> <span class="m">3</span>     <span class="p">|</span> Dropout<span class="o">(</span><span class="m">0</span>.50<span class="o">)(</span>dyn<span class="o">)</span>   <span class="p">|</span>          <span class="m">0</span> <span class="p">|</span> <span class="o">[</span>Bx250<span class="o">]</span>      <span class="p">|</span>
<a name="rest_code_da1bfede7721421f865a0df880090001-8"></a> <span class="p">|</span> <span class="m">4</span>     <span class="p">|</span> Dense<span class="o">(</span>SOFTMAX<span class="o">)</span> <span class="o">(</span>dyn<span class="o">)</span> <span class="p">|</span>       <span class="m">2500</span> <span class="p">|</span> <span class="o">[</span>Bx10<span class="o">]</span>       <span class="p">|</span>
<a name="rest_code_da1bfede7721421f865a0df880090001-9"></a> ------------------------------------------------------------
<a name="rest_code_da1bfede7721421f865a0df880090001-10"></a>                Total Parameters:     <span class="m">519500</span>
<a name="rest_code_da1bfede7721421f865a0df880090001-11"></a>
<a name="rest_code_da1bfede7721421f865a0df880090001-12"></a> --------------------------------------------
<a name="rest_code_da1bfede7721421f865a0df880090001-13"></a> <span class="p">|</span> mnist <span class="p">|</span> Size  <span class="p">|</span> Batches <span class="p">|</span> Augmented Size <span class="p">|</span>
<a name="rest_code_da1bfede7721421f865a0df880090001-14"></a> --------------------------------------------
<a name="rest_code_da1bfede7721421f865a0df880090001-15"></a> <span class="p">|</span> train <span class="p">|</span> <span class="m">60000</span> <span class="p">|</span> <span class="m">600</span>     <span class="p">|</span> <span class="m">60000</span>          <span class="p">|</span>
<a name="rest_code_da1bfede7721421f865a0df880090001-16"></a> <span class="p">|</span> <span class="nb">test</span>  <span class="p">|</span> <span class="m">10000</span> <span class="p">|</span> <span class="m">100</span>     <span class="p">|</span> <span class="m">10000</span>          <span class="p">|</span>
<a name="rest_code_da1bfede7721421f865a0df880090001-17"></a> --------------------------------------------
<a name="rest_code_da1bfede7721421f865a0df880090001-18"></a>
<a name="rest_code_da1bfede7721421f865a0df880090001-19"></a>Train the network with <span class="s2">"Stochastic Gradient Descent"</span>
<a name="rest_code_da1bfede7721421f865a0df880090001-20"></a>    Updater: NADAM
<a name="rest_code_da1bfede7721421f865a0df880090001-21"></a>       Loss: CATEGORICAL_CROSS_ENTROPY
<a name="rest_code_da1bfede7721421f865a0df880090001-22"></a> Early Stop: Goal<span class="o">(</span>error<span class="o">)</span>
<a name="rest_code_da1bfede7721421f865a0df880090001-23"></a>
<a name="rest_code_da1bfede7721421f865a0df880090001-24"></a>With parameters:
<a name="rest_code_da1bfede7721421f865a0df880090001-25"></a>          <span class="nv">epochs</span><span class="o">=</span><span class="m">50</span>
<a name="rest_code_da1bfede7721421f865a0df880090001-26"></a>      <span class="nv">batch_size</span><span class="o">=</span><span class="m">100</span>
<a name="rest_code_da1bfede7721421f865a0df880090001-27"></a>   <span class="nv">learning_rate</span><span class="o">=</span><span class="m">0</span>.002
<a name="rest_code_da1bfede7721421f865a0df880090001-28"></a>           <span class="nv">beta1</span><span class="o">=</span><span class="m">0</span>.9
<a name="rest_code_da1bfede7721421f865a0df880090001-29"></a>           <span class="nv">beta2</span><span class="o">=</span><span class="m">0</span>.999
<a name="rest_code_da1bfede7721421f865a0df880090001-30"></a>
<a name="rest_code_da1bfede7721421f865a0df880090001-31"></a>epoch   <span class="m">0</span>/50 batch  <span class="m">600</span>/ <span class="m">600</span> - error: <span class="m">0</span>.04623 loss: <span class="m">0</span>.15097 <span class="nb">time</span> 3230ms
<a name="rest_code_da1bfede7721421f865a0df880090001-32"></a>epoch   <span class="m">1</span>/50 batch  <span class="m">600</span>/ <span class="m">600</span> - error: <span class="m">0</span>.03013 loss: <span class="m">0</span>.09947 <span class="nb">time</span> 3188ms
<a name="rest_code_da1bfede7721421f865a0df880090001-33"></a>epoch   <span class="m">2</span>/50 batch  <span class="m">600</span>/ <span class="m">600</span> - error: <span class="m">0</span>.02048 loss: <span class="m">0</span>.06565 <span class="nb">time</span> 3102ms
<a name="rest_code_da1bfede7721421f865a0df880090001-34"></a>epoch   <span class="m">3</span>/50 batch  <span class="m">600</span>/ <span class="m">600</span> - error: <span class="m">0</span>.01593 loss: <span class="m">0</span>.05258 <span class="nb">time</span> 3189ms
<a name="rest_code_da1bfede7721421f865a0df880090001-35"></a>epoch   <span class="m">4</span>/50 batch  <span class="m">600</span>/ <span class="m">600</span> - error: <span class="m">0</span>.01422 loss: <span class="m">0</span>.04623 <span class="nb">time</span> 3160ms
<a name="rest_code_da1bfede7721421f865a0df880090001-36"></a>epoch   <span class="m">5</span>/50 batch  <span class="m">600</span>/ <span class="m">600</span> - error: <span class="m">0</span>.01112 loss: <span class="m">0</span>.03660 <span class="nb">time</span> 3131ms
<a name="rest_code_da1bfede7721421f865a0df880090001-37"></a>epoch   <span class="m">6</span>/50 batch  <span class="m">600</span>/ <span class="m">600</span> - error: <span class="m">0</span>.01078 loss: <span class="m">0</span>.03546 <span class="nb">time</span> 3200ms
<a name="rest_code_da1bfede7721421f865a0df880090001-38"></a>epoch   <span class="m">7</span>/50 batch  <span class="m">600</span>/ <span class="m">600</span> - error: <span class="m">0</span>.01003 loss: <span class="m">0</span>.03184 <span class="nb">time</span> 3246ms
<a name="rest_code_da1bfede7721421f865a0df880090001-39"></a>epoch   <span class="m">8</span>/50 batch  <span class="m">600</span>/ <span class="m">600</span> - error: <span class="m">0</span>.00778 loss: <span class="m">0</span>.02550 <span class="nb">time</span> 3222ms
<a name="rest_code_da1bfede7721421f865a0df880090001-40"></a>epoch   <span class="m">9</span>/50 batch  <span class="m">600</span>/ <span class="m">600</span> - error: <span class="m">0</span>.00782 loss: <span class="m">0</span>.02505 <span class="nb">time</span> 3119ms
<a name="rest_code_da1bfede7721421f865a0df880090001-41"></a>epoch  <span class="m">10</span>/50 batch  <span class="m">600</span>/ <span class="m">600</span> - error: <span class="m">0</span>.00578 loss: <span class="m">0</span>.02056 <span class="nb">time</span> 3284ms
<a name="rest_code_da1bfede7721421f865a0df880090001-42"></a>epoch  <span class="m">11</span>/50 batch  <span class="m">600</span>/ <span class="m">600</span> - error: <span class="m">0</span>.00618 loss: <span class="m">0</span>.02045 <span class="nb">time</span> 3220ms
<a name="rest_code_da1bfede7721421f865a0df880090001-43"></a>epoch  <span class="m">12</span>/50 batch  <span class="m">600</span>/ <span class="m">600</span> - error: <span class="m">0</span>.00538 loss: <span class="m">0</span>.01775 <span class="nb">time</span> 3444ms
<a name="rest_code_da1bfede7721421f865a0df880090001-44"></a>epoch  <span class="m">13</span>/50 batch  <span class="m">600</span>/ <span class="m">600</span> - error: <span class="m">0</span>.00563 loss: <span class="m">0</span>.01803 <span class="nb">time</span> 3304ms
<a name="rest_code_da1bfede7721421f865a0df880090001-45"></a>epoch  <span class="m">14</span>/50 batch  <span class="m">600</span>/ <span class="m">600</span> - error: <span class="m">0</span>.00458 loss: <span class="m">0</span>.01598 <span class="nb">time</span> 3577ms
<a name="rest_code_da1bfede7721421f865a0df880090001-46"></a>epoch  <span class="m">15</span>/50 batch  <span class="m">600</span>/ <span class="m">600</span> - error: <span class="m">0</span>.00437 loss: <span class="m">0</span>.01436 <span class="nb">time</span> 3228ms
<a name="rest_code_da1bfede7721421f865a0df880090001-47"></a>epoch  <span class="m">16</span>/50 batch  <span class="m">600</span>/ <span class="m">600</span> - error: <span class="m">0</span>.00360 loss: <span class="m">0</span>.01214 <span class="nb">time</span> 3180ms
<a name="rest_code_da1bfede7721421f865a0df880090001-48"></a>epoch  <span class="m">17</span>/50 batch  <span class="m">600</span>/ <span class="m">600</span> - error: <span class="m">0</span>.00405 loss: <span class="m">0</span>.01309 <span class="nb">time</span> 3090ms
<a name="rest_code_da1bfede7721421f865a0df880090001-49"></a>epoch  <span class="m">18</span>/50 batch  <span class="m">600</span>/ <span class="m">600</span> - error: <span class="m">0</span>.00408 loss: <span class="m">0</span>.01346 <span class="nb">time</span> 3045ms
<a name="rest_code_da1bfede7721421f865a0df880090001-50"></a>epoch  <span class="m">19</span>/50 batch  <span class="m">600</span>/ <span class="m">600</span> - error: <span class="m">0</span>.00337 loss: <span class="m">0</span>.01153 <span class="nb">time</span> 3071ms
<a name="rest_code_da1bfede7721421f865a0df880090001-51"></a>epoch  <span class="m">20</span>/50 batch  <span class="m">600</span>/ <span class="m">600</span> - error: <span class="m">0</span>.00297 loss: <span class="m">0</span>.01021 <span class="nb">time</span> 3131ms
<a name="rest_code_da1bfede7721421f865a0df880090001-52"></a>epoch  <span class="m">21</span>/50 batch  <span class="m">600</span>/ <span class="m">600</span> - error: <span class="m">0</span>.00318 loss: <span class="m">0</span>.01103 <span class="nb">time</span> 3076ms
<a name="rest_code_da1bfede7721421f865a0df880090001-53"></a>epoch  <span class="m">22</span>/50 batch  <span class="m">600</span>/ <span class="m">600</span> - error: <span class="m">0</span>.00277 loss: <span class="m">0</span>.00909 <span class="nb">time</span> 3090ms
<a name="rest_code_da1bfede7721421f865a0df880090001-54"></a>epoch  <span class="m">23</span>/50 batch  <span class="m">600</span>/ <span class="m">600</span> - error: <span class="m">0</span>.00242 loss: <span class="m">0</span>.00818 <span class="nb">time</span> 3163ms
<a name="rest_code_da1bfede7721421f865a0df880090001-55"></a>epoch  <span class="m">24</span>/50 batch  <span class="m">600</span>/ <span class="m">600</span> - error: <span class="m">0</span>.00267 loss: <span class="m">0</span>.00913 <span class="nb">time</span> 3229ms
<a name="rest_code_da1bfede7721421f865a0df880090001-56"></a>epoch  <span class="m">25</span>/50 batch  <span class="m">600</span>/ <span class="m">600</span> - error: <span class="m">0</span>.00295 loss: <span class="m">0</span>.00947 <span class="nb">time</span> 3156ms
<a name="rest_code_da1bfede7721421f865a0df880090001-57"></a>epoch  <span class="m">26</span>/50 batch  <span class="m">600</span>/ <span class="m">600</span> - error: <span class="m">0</span>.00252 loss: <span class="m">0</span>.00809 <span class="nb">time</span> 3066ms
<a name="rest_code_da1bfede7721421f865a0df880090001-58"></a>epoch  <span class="m">27</span>/50 batch  <span class="m">600</span>/ <span class="m">600</span> - error: <span class="m">0</span>.00227 loss: <span class="m">0</span>.00773 <span class="nb">time</span> 3156ms
<a name="rest_code_da1bfede7721421f865a0df880090001-59"></a>epoch  <span class="m">28</span>/50 batch  <span class="m">600</span>/ <span class="m">600</span> - error: <span class="m">0</span>.00203 loss: <span class="m">0</span>.00728 <span class="nb">time</span> 3158ms
<a name="rest_code_da1bfede7721421f865a0df880090001-60"></a>epoch  <span class="m">29</span>/50 batch  <span class="m">600</span>/ <span class="m">600</span> - error: <span class="m">0</span>.00240 loss: <span class="m">0</span>.00753 <span class="nb">time</span> 3114ms
<a name="rest_code_da1bfede7721421f865a0df880090001-61"></a>epoch  <span class="m">30</span>/50 batch  <span class="m">600</span>/ <span class="m">600</span> - error: <span class="m">0</span>.00263 loss: <span class="m">0</span>.00864 <span class="nb">time</span> 3099ms
<a name="rest_code_da1bfede7721421f865a0df880090001-62"></a>epoch  <span class="m">31</span>/50 batch  <span class="m">600</span>/ <span class="m">600</span> - error: <span class="m">0</span>.00210 loss: <span class="m">0</span>.00675 <span class="nb">time</span> 3096ms
<a name="rest_code_da1bfede7721421f865a0df880090001-63"></a>epoch  <span class="m">32</span>/50 batch  <span class="m">600</span>/ <span class="m">600</span> - error: <span class="m">0</span>.00163 loss: <span class="m">0</span>.00628 <span class="nb">time</span> 3120ms
<a name="rest_code_da1bfede7721421f865a0df880090001-64"></a>epoch  <span class="m">33</span>/50 batch  <span class="m">600</span>/ <span class="m">600</span> - error: <span class="m">0</span>.00182 loss: <span class="m">0</span>.00611 <span class="nb">time</span> 3045ms
<a name="rest_code_da1bfede7721421f865a0df880090001-65"></a>epoch  <span class="m">34</span>/50 batch  <span class="m">600</span>/ <span class="m">600</span> - error: <span class="m">0</span>.00125 loss: <span class="m">0</span>.00468 <span class="nb">time</span> 3140ms
<a name="rest_code_da1bfede7721421f865a0df880090001-66"></a>epoch  <span class="m">35</span>/50 batch  <span class="m">600</span>/ <span class="m">600</span> - error: <span class="m">0</span>.00183 loss: <span class="m">0</span>.00598 <span class="nb">time</span> 3093ms
<a name="rest_code_da1bfede7721421f865a0df880090001-67"></a>epoch  <span class="m">36</span>/50 batch  <span class="m">600</span>/ <span class="m">600</span> - error: <span class="m">0</span>.00232 loss: <span class="m">0</span>.00711 <span class="nb">time</span> 3068ms
<a name="rest_code_da1bfede7721421f865a0df880090001-68"></a>epoch  <span class="m">37</span>/50 batch  <span class="m">600</span>/ <span class="m">600</span> - error: <span class="m">0</span>.00170 loss: <span class="m">0</span>.00571 <span class="nb">time</span> 3057ms
<a name="rest_code_da1bfede7721421f865a0df880090001-69"></a>epoch  <span class="m">38</span>/50 batch  <span class="m">600</span>/ <span class="m">600</span> - error: <span class="m">0</span>.00162 loss: <span class="m">0</span>.00530 <span class="nb">time</span> 3115ms
<a name="rest_code_da1bfede7721421f865a0df880090001-70"></a>epoch  <span class="m">39</span>/50 batch  <span class="m">600</span>/ <span class="m">600</span> - error: <span class="m">0</span>.00155 loss: <span class="m">0</span>.00513 <span class="nb">time</span> 3226ms
<a name="rest_code_da1bfede7721421f865a0df880090001-71"></a>epoch  <span class="m">40</span>/50 batch  <span class="m">600</span>/ <span class="m">600</span> - error: <span class="m">0</span>.00150 loss: <span class="m">0</span>.00501 <span class="nb">time</span> 2987ms
<a name="rest_code_da1bfede7721421f865a0df880090001-72"></a>epoch  <span class="m">41</span>/50 batch  <span class="m">600</span>/ <span class="m">600</span> - error: <span class="m">0</span>.00122 loss: <span class="m">0</span>.00425 <span class="nb">time</span> 3117ms
<a name="rest_code_da1bfede7721421f865a0df880090001-73"></a>epoch  <span class="m">42</span>/50 batch  <span class="m">600</span>/ <span class="m">600</span> - error: <span class="m">0</span>.00108 loss: <span class="m">0</span>.00383 <span class="nb">time</span> 3102ms
<a name="rest_code_da1bfede7721421f865a0df880090001-74"></a>epoch  <span class="m">43</span>/50 batch  <span class="m">600</span>/ <span class="m">600</span> - error: <span class="m">0</span>.00165 loss: <span class="m">0</span>.00533 <span class="nb">time</span> 2977ms
<a name="rest_code_da1bfede7721421f865a0df880090001-75"></a>epoch  <span class="m">44</span>/50 batch  <span class="m">600</span>/ <span class="m">600</span> - error: <span class="m">0</span>.00142 loss: <span class="m">0</span>.00469 <span class="nb">time</span> 3009ms
<a name="rest_code_da1bfede7721421f865a0df880090001-76"></a>epoch  <span class="m">45</span>/50 batch  <span class="m">600</span>/ <span class="m">600</span> - error: <span class="m">0</span>.00098 loss: <span class="m">0</span>.00356 <span class="nb">time</span> 3055ms
<a name="rest_code_da1bfede7721421f865a0df880090001-77"></a>epoch  <span class="m">46</span>/50 batch  <span class="m">600</span>/ <span class="m">600</span> - error: <span class="m">0</span>.00127 loss: <span class="m">0</span>.00409 <span class="nb">time</span> 3076ms
<a name="rest_code_da1bfede7721421f865a0df880090001-78"></a>epoch  <span class="m">47</span>/50 batch  <span class="m">600</span>/ <span class="m">600</span> - error: <span class="m">0</span>.00132 loss: <span class="m">0</span>.00438 <span class="nb">time</span> 3068ms
<a name="rest_code_da1bfede7721421f865a0df880090001-79"></a>epoch  <span class="m">48</span>/50 batch  <span class="m">600</span>/ <span class="m">600</span> - error: <span class="m">0</span>.00130 loss: <span class="m">0</span>.00459 <span class="nb">time</span> 3045ms
<a name="rest_code_da1bfede7721421f865a0df880090001-80"></a>epoch  <span class="m">49</span>/50 batch  <span class="m">600</span>/ <span class="m">600</span> - error: <span class="m">0</span>.00107 loss: <span class="m">0</span>.00365 <span class="nb">time</span> 3103ms
<a name="rest_code_da1bfede7721421f865a0df880090001-81"></a>Restore the best <span class="o">(</span>error<span class="o">)</span> weights from epoch <span class="m">45</span>
<a name="rest_code_da1bfede7721421f865a0df880090001-82"></a>Training took 160s
<a name="rest_code_da1bfede7721421f865a0df880090001-83"></a>
<a name="rest_code_da1bfede7721421f865a0df880090001-84"></a>Evaluation Results
<a name="rest_code_da1bfede7721421f865a0df880090001-85"></a>   error: <span class="m">0</span>.01740
<a name="rest_code_da1bfede7721421f865a0df880090001-86"></a>    loss: <span class="m">0</span>.07861
<a name="rest_code_da1bfede7721421f865a0df880090001-87"></a>evaluation took 67ms
<a name="rest_code_da1bfede7721421f865a0df880090001-88"></a>
<a name="rest_code_da1bfede7721421f865a0df880090001-89"></a> -----------------------------------------------------------------------------
<a name="rest_code_da1bfede7721421f865a0df880090001-90"></a> <span class="p">|</span> %        <span class="p">|</span> Timer                         <span class="p">|</span> Count  <span class="p">|</span> Total     <span class="p">|</span> Average   <span class="p">|</span>
<a name="rest_code_da1bfede7721421f865a0df880090001-91"></a> -----------------------------------------------------------------------------
<a name="rest_code_da1bfede7721421f865a0df880090001-92"></a> <span class="p">|</span> <span class="m">100</span>.000% <span class="p">|</span> net:train:ft                  <span class="p">|</span> <span class="m">1</span>      <span class="p">|</span> <span class="m">160</span>.183s  <span class="p">|</span> <span class="m">160</span>.183s  <span class="p">|</span>
<a name="rest_code_da1bfede7721421f865a0df880090001-93"></a> <span class="p">|</span> <span class="m">100</span>.000% <span class="p">|</span> net:trainer:train             <span class="p">|</span> <span class="m">1</span>      <span class="p">|</span> <span class="m">160</span>.183s  <span class="p">|</span> <span class="m">160</span>.183s  <span class="p">|</span>
<a name="rest_code_da1bfede7721421f865a0df880090001-94"></a> <span class="p">|</span>  <span class="m">99</span>.997% <span class="p">|</span> net:trainer:train:epoch       <span class="p">|</span> <span class="m">50</span>     <span class="p">|</span> <span class="m">160</span>.178s  <span class="p">|</span> <span class="m">3</span>.20356s  <span class="p">|</span>
<a name="rest_code_da1bfede7721421f865a0df880090001-95"></a> <span class="p">|</span>  <span class="m">84</span>.422% <span class="p">|</span> net:trainer:train:epoch:batch <span class="p">|</span> <span class="m">30000</span>  <span class="p">|</span> <span class="m">135</span>.229s  <span class="p">|</span> <span class="m">4</span>.50764ms <span class="p">|</span>
<a name="rest_code_da1bfede7721421f865a0df880090001-96"></a> <span class="p">|</span>  <span class="m">84</span>.261% <span class="p">|</span> sgd::train_batch              <span class="p">|</span> <span class="m">30000</span>  <span class="p">|</span> <span class="m">134</span>.971s  <span class="p">|</span> <span class="m">4</span>.49904ms <span class="p">|</span>
<a name="rest_code_da1bfede7721421f865a0df880090001-97"></a> <span class="p">|</span>  <span class="m">44</span>.404% <span class="p">|</span> sgd::grad                     <span class="p">|</span> <span class="m">30000</span>  <span class="p">|</span> <span class="m">71</span>.1271s  <span class="p">|</span> <span class="m">2</span>.3709ms  <span class="p">|</span>
<a name="rest_code_da1bfede7721421f865a0df880090001-98"></a> <span class="p">|</span>  <span class="m">35</span>.453% <span class="p">|</span> sgd::forward                  <span class="p">|</span> <span class="m">30000</span>  <span class="p">|</span> <span class="m">56</span>.7893s  <span class="p">|</span> <span class="m">1</span>.89298ms <span class="p">|</span>
<a name="rest_code_da1bfede7721421f865a0df880090001-99"></a> <span class="p">|</span>  <span class="m">32</span>.245% <span class="p">|</span> sgd::update_weights           <span class="p">|</span> <span class="m">90000</span>  <span class="p">|</span> <span class="m">51</span>.6505s  <span class="p">|</span> <span class="m">573</span>.894us <span class="p">|</span>
<a name="rest_code_da1bfede7721421f865a0df880090001-100"></a> <span class="p">|</span>  <span class="m">32</span>.226% <span class="p">|</span> sgd::apply_grad:nadam         <span class="p">|</span> <span class="m">180000</span> <span class="p">|</span> <span class="m">51</span>.6211s  <span class="p">|</span> <span class="m">286</span>.783us <span class="p">|</span>
<a name="rest_code_da1bfede7721421f865a0df880090001-101"></a> <span class="p">|</span>  <span class="m">28</span>.399% <span class="p">|</span> dense:dyn:forward             <span class="p">|</span> <span class="m">180300</span> <span class="p">|</span> <span class="m">45</span>.4903s  <span class="p">|</span> <span class="m">252</span>.303us <span class="p">|</span>
<a name="rest_code_da1bfede7721421f865a0df880090001-102"></a> <span class="p">|</span>  <span class="m">17</span>.642% <span class="p">|</span> dropout:train:forward         <span class="p">|</span> <span class="m">60000</span>  <span class="p">|</span> <span class="m">28</span>.2595s  <span class="p">|</span> <span class="m">470</span>.99us  <span class="p">|</span>
<a name="rest_code_da1bfede7721421f865a0df880090001-103"></a> <span class="p">|</span>  <span class="m">13</span>.707% <span class="p">|</span> net:trainer:train:epoch:error <span class="p">|</span> <span class="m">50</span>     <span class="p">|</span> <span class="m">21</span>.957s   <span class="p">|</span> <span class="m">439</span>.14ms  <span class="p">|</span>
<a name="rest_code_da1bfede7721421f865a0df880090001-104"></a> <span class="p">|</span>  <span class="m">12</span>.148% <span class="p">|</span> dense:dyn:gradients           <span class="p">|</span> <span class="m">90000</span>  <span class="p">|</span> <span class="m">19</span>.4587s  <span class="p">|</span> <span class="m">216</span>.207us <span class="p">|</span>
<a name="rest_code_da1bfede7721421f865a0df880090001-105"></a> <span class="p">|</span>   <span class="m">4</span>.299% <span class="p">|</span> sgd::backward                 <span class="p">|</span> <span class="m">30000</span>  <span class="p">|</span> <span class="m">6</span>.88546s  <span class="p">|</span> <span class="m">229</span>.515us <span class="p">|</span>
<a name="rest_code_da1bfede7721421f865a0df880090001-106"></a> <span class="p">|</span>   <span class="m">3</span>.301% <span class="p">|</span> dense:dyn:backward            <span class="p">|</span> <span class="m">60000</span>  <span class="p">|</span> <span class="m">5</span>.28729s  <span class="p">|</span> <span class="m">88</span>.121us  <span class="p">|</span>
<a name="rest_code_da1bfede7721421f865a0df880090001-107"></a> <span class="p">|</span>   <span class="m">0</span>.560% <span class="p">|</span> dense:dyn:errors              <span class="p">|</span> <span class="m">60000</span>  <span class="p">|</span> <span class="m">896</span>.471ms <span class="p">|</span> <span class="m">14</span>.941us  <span class="p">|</span>
<a name="rest_code_da1bfede7721421f865a0df880090001-108"></a> <span class="p">|</span>   <span class="m">0</span>.407% <span class="p">|</span> dropout:backward              <span class="p">|</span> <span class="m">60000</span>  <span class="p">|</span> <span class="m">651</span>.523ms <span class="p">|</span> <span class="m">10</span>.858us  <span class="p">|</span>
<a name="rest_code_da1bfede7721421f865a0df880090001-109"></a> <span class="p">|</span>   <span class="m">0</span>.339% <span class="p">|</span> dropout:test:forward          <span class="p">|</span> <span class="m">60000</span>  <span class="p">|</span> <span class="m">542</span>.799ms <span class="p">|</span> <span class="m">9</span>.046us   <span class="p">|</span>
<a name="rest_code_da1bfede7721421f865a0df880090001-110"></a> <span class="p">|</span>   <span class="m">0</span>.161% <span class="p">|</span> net:compute_loss:CCE          <span class="p">|</span> <span class="m">60100</span>  <span class="p">|</span> <span class="m">257</span>.915ms <span class="p">|</span> <span class="m">4</span>.291us   <span class="p">|</span>
<a name="rest_code_da1bfede7721421f865a0df880090001-111"></a> <span class="p">|</span>   <span class="m">0</span>.099% <span class="p">|</span> sgd::error                    <span class="p">|</span> <span class="m">30000</span>  <span class="p">|</span> <span class="m">158</span>.33ms  <span class="p">|</span> <span class="m">5</span>.277us   <span class="p">|</span>
<a name="rest_code_da1bfede7721421f865a0df880090001-112"></a> -----------------------------------------------------------------------------
</pre>
<p>I hope this will make the output of the machine learning framework more useful.</p>
<p>All this support is now in the <strong>master</strong> branch of the DLL project if you want
to check it out. You can also check out the example online:
<a class="reference external" href="https://github.com/wichtounet/dll/blob/master/examples/src/mnist_mlp.cpp">mnist_mlp.cpp</a></p>
<p>You can access the project <a class="reference external" href="https://github.com/wichtounet/dll">on Github</a>.</p>
</div>
        </div>
            
        
    <a href="posts/2017/11/dll-pretty-printing-and-live-output.html#disqus_thread" data-disqus-identifier="cache/posts/2017/11/dll-pretty-printing-and-live-output.html">Comments</a>


        </article><article class="postbox h-entry post-text"><h1 class="p-name">
<a href="posts/2017/11/inventor-on-four-new-research-patents.html" class="u-url">Inventor on four new research patents</a>
        <br><small>  
             Posted: <time class="published dt-published" datetime="2017-11-17T14:50:33+01:00">2017-11-17 14:50</time></small>
</h1>
        <hr>
<div class="p-summary">
        <div>
<p>During the first years of my thesis I worked on CTI research project with the
American company Verisign, which has also an office near my school. A CTI
research project is a project that is partially funded by the Commission on
Innovation and Technology (CTI) where a school and a company work together.
I was quite lucky to work on this project with the awesome people at Verisign
Fribourg. After the success of the project, Verisign filled several patents
regarding various points of the projects.</p>
<p>I'm quite happy now that these four patents are now approved and published. They
They have been approved by both the United States Patent and Trademark Office
(USPTO) and European Patent Office (EPO). The parents have been cl=¬ aimed by
Verisign, I'm only one of the inventor, I got no claim on the patent. But it's
still a great thing.</p>
<p>Here are the names of the four patents:</p>
<ul class="simple">
<li>Systems and methods for automatic phonetization of domain names¬</li>
<li>Construction of phonetic representation of a string of characters¬</li>
<li>Method for writing a foreign language in a pseudo language phonetically resembling native language of the speaker¬</li>
<li>Construction of a phonetic representation of a generated string of characters¬</li>
</ul>
<p>You can take a look at them on USPTO or EPO or on Google Patents, but the way
a patent is written make it relatively hard to follow, it's more on a lawyer
level or maybe I'm simply not used to patents anymore.</p>
<p>All these patents come from the research done during the CTI project with
Verisign. In this project, name suggestions were generated from the phonetic
sound of the name. The idea being to generate names that sounds the same as
another input (airmix could become rmix or rmics). We are using various
technologies to make this work: IG-Tree, Viterbi and HMM. And since we used
a model with an encoder and a decoder, we can also mix languages. For instance,
write something in French the way a English work would work (for instance school
could become scoule).</p>
<p>These patents concludes a very interesting and successful project. I'm now
working on yet another CTI research project with Verisign and it will surely be
as successful as the first one.</p>
</div>
        </div>
            
        
    <a href="posts/2017/11/inventor-on-four-new-research-patents.html#disqus_thread" data-disqus-identifier="cache/posts/2017/11/inventor-on-four-new-research-patents.html">Comments</a>


        </article><article class="postbox h-entry post-text"><h1 class="p-name">
<a href="posts/2017/11/initial-support-for-recurrent-neural-network-rnn-in-dll.html" class="u-url">Initial support for Recurrent Neural Network (RNN) in DLL</a>
        <br><small>  
             Posted: <time class="published dt-published" datetime="2017-11-12T15:22:44+01:00">2017-11-12 15:22</time></small>
</h1>
        <hr>
<div class="p-summary">
        <div>
<p>I'm happy to announce that I just merged support for Recurrent Neural Networks
(RNNs) into my Deep Learning Library (DLL) machine learning framework.</p>
<p>It's nothing fancy yet, but forward propagation of RNN and basic Backpropagation
Through Time (BPTT) are now supported. For now, only existing classification
loss is supported for RNN. I plan to add support for sequence-to-sequence loss
in order to be able to train models able to generate characters, but I don't
know when I'll be able to work on that. I also plan to add support for other
types of cells such as LSTM and GRU (maybe NAS) in the future.</p>
<p>For example, here is a simple RNN used on MNIST:</p>
<pre class="code cpp"><a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-1"></a><span class="cp">#include</span> <span class="cpf">"dll/neural/dense_layer.hpp"</span><span class="cp"></span>
<a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-2"></a><span class="cp">#include</span> <span class="cpf">"dll/neural/recurrent_layer.hpp"</span><span class="cp"></span>
<a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-3"></a><span class="cp">#include</span> <span class="cpf">"dll/neural/recurrent_last_layer.hpp"</span><span class="cp"></span>
<a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-4"></a><span class="cp">#include</span> <span class="cpf">"dll/network.hpp"</span><span class="cp"></span>
<a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-5"></a><span class="cp">#include</span> <span class="cpf">"dll/datasets.hpp"</span><span class="cp"></span>
<a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-6"></a>
<a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-7"></a><span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="cm">/*argc*/</span><span class="p">,</span> <span class="kt">char</span><span class="o">*</span> <span class="cm">/*argv*/</span> <span class="p">[])</span> <span class="p">{</span>
<a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-8"></a>    <span class="c1">// Load the dataset</span>
<a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-9"></a>    <span class="k">auto</span> <span class="n">dataset</span> <span class="o">=</span> <span class="n">dll</span><span class="o">::</span><span class="n">make_mnist_dataset_nc</span><span class="p">(</span><span class="n">dll</span><span class="o">::</span><span class="n">batch_size</span><span class="o">&lt;</span><span class="mi">100</span><span class="o">&gt;</span><span class="p">{},</span> <span class="n">dll</span><span class="o">::</span><span class="n">scale_pre</span><span class="o">&lt;</span><span class="mi">255</span><span class="o">&gt;</span><span class="p">{});</span>
<a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-10"></a>
<a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-11"></a>    <span class="k">constexpr</span> <span class="kt">size_t</span> <span class="n">time_steps</span>      <span class="o">=</span> <span class="mi">28</span><span class="p">;</span>
<a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-12"></a>    <span class="k">constexpr</span> <span class="kt">size_t</span> <span class="n">sequence_length</span> <span class="o">=</span> <span class="mi">28</span><span class="p">;</span>
<a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-13"></a>    <span class="k">constexpr</span> <span class="kt">size_t</span> <span class="n">hidden_units</span>    <span class="o">=</span> <span class="mi">100</span><span class="p">;</span>
<a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-14"></a>
<a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-15"></a>    <span class="c1">// Build the network</span>
<a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-16"></a>
<a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-17"></a>    <span class="k">using</span> <span class="n">network_t</span> <span class="o">=</span> <span class="n">dll</span><span class="o">::</span><span class="n">dyn_network_desc</span><span class="o">&lt;</span>
<a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-18"></a>        <span class="n">dll</span><span class="o">::</span><span class="n">network_layers</span><span class="o">&lt;</span>
<a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-19"></a>            <span class="n">dll</span><span class="o">::</span><span class="n">recurrent_layer</span><span class="o">&lt;</span><span class="n">time_steps</span><span class="p">,</span> <span class="n">sequence_length</span><span class="p">,</span> <span class="n">hidden_units</span><span class="p">,</span> <span class="n">dll</span><span class="o">::</span><span class="n">last_only</span><span class="o">&gt;</span><span class="p">,</span>
<a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-20"></a>            <span class="n">dll</span><span class="o">::</span><span class="n">recurrent_last_layer</span><span class="o">&lt;</span><span class="n">time_steps</span><span class="p">,</span> <span class="n">hidden_units</span><span class="o">&gt;</span><span class="p">,</span>
<a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-21"></a>            <span class="n">dll</span><span class="o">::</span><span class="n">dense_layer</span><span class="o">&lt;</span><span class="n">hidden_units</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">dll</span><span class="o">::</span><span class="n">softmax</span><span class="o">&gt;</span>
<a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-22"></a>        <span class="o">&gt;</span>
<a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-23"></a>        <span class="p">,</span> <span class="n">dll</span><span class="o">::</span><span class="n">updater</span><span class="o">&lt;</span><span class="n">dll</span><span class="o">::</span><span class="n">updater_type</span><span class="o">::</span><span class="n">ADAM</span><span class="o">&gt;</span>      <span class="c1">// Adam</span>
<a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-24"></a>        <span class="p">,</span> <span class="n">dll</span><span class="o">::</span><span class="n">batch_size</span><span class="o">&lt;</span><span class="mi">100</span><span class="o">&gt;</span>                       <span class="c1">// The mini-batch size</span>
<a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-25"></a>    <span class="o">&gt;::</span><span class="n">network_t</span><span class="p">;</span>
<a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-26"></a>
<a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-27"></a>    <span class="k">auto</span> <span class="n">net</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">make_unique</span><span class="o">&lt;</span><span class="n">network_t</span><span class="o">&gt;</span><span class="p">();</span>
<a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-28"></a>
<a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-29"></a>    <span class="c1">// Display the network and dataset</span>
<a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-30"></a>    <span class="n">net</span><span class="o">-&gt;</span><span class="n">display</span><span class="p">();</span>
<a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-31"></a>
<a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-32"></a>    <span class="c1">// Train the network for performance sake</span>
<a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-33"></a>    <span class="n">net</span><span class="o">-&gt;</span><span class="n">fine_tune</span><span class="p">(</span><span class="n">dataset</span><span class="p">.</span><span class="n">train</span><span class="p">(),</span> <span class="mi">50</span><span class="p">);</span>
<a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-34"></a>
<a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-35"></a>    <span class="c1">// Test the network on test set</span>
<a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-36"></a>    <span class="n">net</span><span class="o">-&gt;</span><span class="n">evaluate</span><span class="p">(</span><span class="n">dataset</span><span class="p">.</span><span class="n">test</span><span class="p">());</span>
<a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-37"></a>
<a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-38"></a>    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<a name="rest_code_67cb26f00eaf4d6b970a19dece1ffeb6-39"></a><span class="p">}</span>
</pre>
<p>The network starts with recurrent layer, followed by a layer that extracts only
the last layer and finally a dense layer with a softmax function. The recurrent
layer has support to change the activation function, change the initializer for
the two weights matrices of the RNN and the number of steps for BPTT truncation.</p>
<p>Here is a possible result:</p>
<pre class="code text"><a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-1"></a>Network with 3 layers
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-2"></a>    RNN(dyn): 28x28 -&gt; TANH -&gt; 28x100
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-3"></a>    RNN(last): 28x100 -&gt; 100
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-4"></a>    Dense(dyn): 100 -&gt; SOFTMAX -&gt; 10
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-5"></a>Total parameters: 13800
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-6"></a>Train the network with "Stochastic Gradient Descent"
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-7"></a>    Updater: ADAM
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-8"></a>       Loss: CATEGORICAL_CROSS_ENTROPY
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-9"></a> Early Stop: Goal(error)
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-10"></a>
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-11"></a>With parameters:
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-12"></a>          epochs=50
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-13"></a>      batch_size=100
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-14"></a>   learning_rate=0.001
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-15"></a>           beta1=0.9
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-16"></a>           beta2=0.999
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-17"></a>
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-18"></a>Epoch   0/50 - Classification error: 0.11635 Loss: 0.39999 Time 4717ms
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-19"></a>Epoch   1/50 - Classification error: 0.11303 Loss: 0.36994 Time 4702ms
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-20"></a>Epoch   2/50 - Classification error: 0.06732 Loss: 0.23469 Time 4702ms
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-21"></a>Epoch   3/50 - Classification error: 0.04865 Loss: 0.17091 Time 4696ms
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-22"></a>Epoch   4/50 - Classification error: 0.05957 Loss: 0.20437 Time 4706ms
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-23"></a>Epoch   5/50 - Classification error: 0.05022 Loss: 0.16888 Time 4696ms
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-24"></a>Epoch   6/50 - Classification error: 0.03912 Loss: 0.13743 Time 4698ms
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-25"></a>Epoch   7/50 - Classification error: 0.04097 Loss: 0.14509 Time 4706ms
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-26"></a>Epoch   8/50 - Classification error: 0.03938 Loss: 0.13397 Time 4694ms
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-27"></a>Epoch   9/50 - Classification error: 0.03525 Loss: 0.12284 Time 4706ms
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-28"></a>Epoch  10/50 - Classification error: 0.03927 Loss: 0.13770 Time 4694ms
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-29"></a>Epoch  11/50 - Classification error: 0.03315 Loss: 0.11315 Time 4711ms
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-30"></a>Epoch  12/50 - Classification error: 0.05037 Loss: 0.17123 Time 4711ms
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-31"></a>Epoch  13/50 - Classification error: 0.02927 Loss: 0.10042 Time 4780ms
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-32"></a>Epoch  14/50 - Classification error: 0.03322 Loss: 0.11027 Time 4746ms
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-33"></a>Epoch  15/50 - Classification error: 0.03397 Loss: 0.11585 Time 4684ms
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-34"></a>Epoch  16/50 - Classification error: 0.02938 Loss: 0.09984 Time 4708ms
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-35"></a>Epoch  17/50 - Classification error: 0.03262 Loss: 0.11152 Time 4690ms
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-36"></a>Epoch  18/50 - Classification error: 0.02872 Loss: 0.09753 Time 4672ms
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-37"></a>Epoch  19/50 - Classification error: 0.02548 Loss: 0.08605 Time 4691ms
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-38"></a>Epoch  20/50 - Classification error: 0.02245 Loss: 0.07797 Time 4693ms
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-39"></a>Epoch  21/50 - Classification error: 0.02705 Loss: 0.08984 Time 4684ms
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-40"></a>Epoch  22/50 - Classification error: 0.02422 Loss: 0.08164 Time 4688ms
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-41"></a>Epoch  23/50 - Classification error: 0.02645 Loss: 0.08804 Time 4690ms
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-42"></a>Epoch  24/50 - Classification error: 0.02927 Loss: 0.09739 Time 4715ms
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-43"></a>Epoch  25/50 - Classification error: 0.02578 Loss: 0.08669 Time 4702ms
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-44"></a>Epoch  26/50 - Classification error: 0.02785 Loss: 0.09368 Time 4700ms
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-45"></a>Epoch  27/50 - Classification error: 0.02472 Loss: 0.08237 Time 4695ms
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-46"></a>Epoch  28/50 - Classification error: 0.02125 Loss: 0.07324 Time 4690ms
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-47"></a>Epoch  29/50 - Classification error: 0.01977 Loss: 0.06635 Time 4688ms
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-48"></a>Epoch  30/50 - Classification error: 0.03635 Loss: 0.12140 Time 4689ms
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-49"></a>Epoch  31/50 - Classification error: 0.02862 Loss: 0.09704 Time 4698ms
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-50"></a>Epoch  32/50 - Classification error: 0.02463 Loss: 0.08158 Time 4686ms
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-51"></a>Epoch  33/50 - Classification error: 0.02565 Loss: 0.08771 Time 4697ms
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-52"></a>Epoch  34/50 - Classification error: 0.02278 Loss: 0.07634 Time 4718ms
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-53"></a>Epoch  35/50 - Classification error: 0.02105 Loss: 0.07075 Time 4697ms
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-54"></a>Epoch  36/50 - Classification error: 0.02770 Loss: 0.09358 Time 4711ms
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-55"></a>Epoch  37/50 - Classification error: 0.02627 Loss: 0.08805 Time 4742ms
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-56"></a>Epoch  38/50 - Classification error: 0.02282 Loss: 0.07712 Time 4708ms
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-57"></a>Epoch  39/50 - Classification error: 0.02305 Loss: 0.07661 Time 4697ms
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-58"></a>Epoch  40/50 - Classification error: 0.02243 Loss: 0.07773 Time 4700ms
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-59"></a>Epoch  41/50 - Classification error: 0.02467 Loss: 0.08234 Time 4712ms
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-60"></a>Epoch  42/50 - Classification error: 0.01808 Loss: 0.06186 Time 4691ms
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-61"></a>Epoch  43/50 - Classification error: 0.02388 Loss: 0.07917 Time 4681ms
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-62"></a>Epoch  44/50 - Classification error: 0.02162 Loss: 0.07508 Time 4699ms
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-63"></a>Epoch  45/50 - Classification error: 0.01877 Loss: 0.06289 Time 4735ms
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-64"></a>Epoch  46/50 - Classification error: 0.02263 Loss: 0.07969 Time 4764ms
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-65"></a>Epoch  47/50 - Classification error: 0.02100 Loss: 0.07207 Time 4684ms
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-66"></a>Epoch  48/50 - Classification error: 0.02425 Loss: 0.08076 Time 4752ms
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-67"></a>Epoch  49/50 - Classification error: 0.02328 Loss: 0.07803 Time 4718ms
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-68"></a>Restore the best (error) weights from epoch 42
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-69"></a>Training took 235s
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-70"></a>Evaluation Results
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-71"></a>   error: 0.03000
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-72"></a>    loss: 0.12260
<a name="rest_code_c19dab79c3af497ab7b7e3d7ef9fb5c5-73"></a>evaluation took 245ms
</pre>
<p>Nothing fancy, but this example is not necessarily optimized.</p>
<p>All this support is now in the <strong>master</strong> branch of the DLL project if you want
to check it out. You can also check out the example online:
<a class="reference external" href="https://github.com/wichtounet/dll/blob/master/examples/src/mnist_rnn.cpp">mnist_rnn.cpp</a></p>
<p>You can access the project <a class="reference external" href="https://github.com/wichtounet/dll">on Github</a>.</p>
</div>
        </div>
            
        
    <a href="posts/2017/11/initial-support-for-recurrent-neural-network-rnn-in-dll.html#disqus_thread" data-disqus-identifier="cache/posts/2017/11/initial-support-for-recurrent-neural-network-rnn-in-dll.html">Comments</a>


        </article><article class="postbox h-entry post-text"><h1 class="p-name">
<a href="posts/2017/10/dll-new-features-embeddings-and-merge-layers.html" class="u-url">DLL New Features: Embeddings and Merge layers</a>
        <br><small>  
             Posted: <time class="published dt-published" datetime="2017-10-17T19:50:40+02:00">2017-10-17 19:50</time></small>
</h1>
        <hr>
<div class="p-summary">
        <div>
<p>I've just finished integrating new features into DLL, my deep learning library.
I've added support for an embeddings layer, a group layer and a merge layer.
This is not yet released, but available in the master branch.</p>
<p>Embeddings are used more and more these days to learn dense representation of
characters or word. An embedding layer in a neural network transform labels into
a vector. It's generally used as the first layer of the network. The embedding
are learned as part of the network.</p>
<p>The merge layer allows to create branches in the network. The input is passed to
each sub layer and then the output of each layer is concatenated to form the
output of the merged layers. This can be very useful to use different
convolutional filter sizes.</p>
<p>The group layer is a simple utility to group layers together. This is mostly to
use with merge layers to form several branches.</p>
<p>I've put together a new example to use these features on text classification.
The dataset is totally synthetic for now, but this can easily be reproduced with
a normal text classification dataset. This kind of model is called a Character
Convolutional Neural Network.</p>
<p>Here is the code for example:</p>
<pre class="code cpp"><a name="rest_code_16c87aa06c274967be5d3c250da7f9af-1"></a><span class="k">constexpr</span> <span class="kt">size_t</span> <span class="n">embedding</span> <span class="o">=</span> <span class="mi">16</span><span class="p">;</span> <span class="c1">// The length of the embedding vector</span>
<a name="rest_code_16c87aa06c274967be5d3c250da7f9af-2"></a><span class="k">constexpr</span> <span class="kt">size_t</span> <span class="n">length</span> <span class="o">=</span> <span class="mi">15</span><span class="p">;</span>    <span class="c1">// The word (or sequence) length</span>
<a name="rest_code_16c87aa06c274967be5d3c250da7f9af-3"></a>
<a name="rest_code_16c87aa06c274967be5d3c250da7f9af-4"></a><span class="k">using</span> <span class="n">embedding_network_t</span> <span class="o">=</span> <span class="n">dll</span><span class="o">::</span><span class="n">dyn_network_desc</span><span class="o">&lt;</span>
<a name="rest_code_16c87aa06c274967be5d3c250da7f9af-5"></a>    <span class="n">dll</span><span class="o">::</span><span class="n">network_layers</span><span class="o">&lt;</span>
<a name="rest_code_16c87aa06c274967be5d3c250da7f9af-6"></a>        <span class="c1">// The embedding layer</span>
<a name="rest_code_16c87aa06c274967be5d3c250da7f9af-7"></a>        <span class="n">dll</span><span class="o">::</span><span class="n">embedding_layer</span><span class="o">&lt;</span><span class="mi">26</span><span class="p">,</span> <span class="n">length</span><span class="p">,</span> <span class="n">embedding</span><span class="o">&gt;</span>
<a name="rest_code_16c87aa06c274967be5d3c250da7f9af-8"></a>
<a name="rest_code_16c87aa06c274967be5d3c250da7f9af-9"></a>        <span class="c1">// The convolutional layers</span>
<a name="rest_code_16c87aa06c274967be5d3c250da7f9af-10"></a>        <span class="p">,</span> <span class="n">dll</span><span class="o">::</span><span class="n">merge_layer</span><span class="o">&lt;</span>
<a name="rest_code_16c87aa06c274967be5d3c250da7f9af-11"></a>            <span class="mi">0</span>
<a name="rest_code_16c87aa06c274967be5d3c250da7f9af-12"></a>            <span class="p">,</span> <span class="n">dll</span><span class="o">::</span><span class="n">group_layer</span><span class="o">&lt;</span>
<a name="rest_code_16c87aa06c274967be5d3c250da7f9af-13"></a>                  <span class="n">dll</span><span class="o">::</span><span class="n">conv_layer</span><span class="o">&lt;</span><span class="mi">1</span><span class="p">,</span> <span class="n">length</span><span class="p">,</span> <span class="n">embedding</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">embedding</span><span class="o">&gt;</span>
<a name="rest_code_16c87aa06c274967be5d3c250da7f9af-14"></a>                <span class="p">,</span> <span class="n">dll</span><span class="o">::</span><span class="n">mp_2d_layer</span><span class="o">&lt;</span><span class="mi">16</span><span class="p">,</span> <span class="n">length</span> <span class="o">-</span> <span class="mi">3</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">length</span> <span class="o">-</span> <span class="mi">3</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="o">&gt;</span>
<a name="rest_code_16c87aa06c274967be5d3c250da7f9af-15"></a>            <span class="o">&gt;</span>
<a name="rest_code_16c87aa06c274967be5d3c250da7f9af-16"></a>            <span class="p">,</span> <span class="n">dll</span><span class="o">::</span><span class="n">group_layer</span><span class="o">&lt;</span>
<a name="rest_code_16c87aa06c274967be5d3c250da7f9af-17"></a>                  <span class="n">dll</span><span class="o">::</span><span class="n">conv_layer</span><span class="o">&lt;</span><span class="mi">1</span><span class="p">,</span> <span class="n">length</span><span class="p">,</span> <span class="n">embedding</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">embedding</span><span class="o">&gt;</span>
<a name="rest_code_16c87aa06c274967be5d3c250da7f9af-18"></a>                <span class="p">,</span> <span class="n">dll</span><span class="o">::</span><span class="n">mp_2d_layer</span><span class="o">&lt;</span><span class="mi">16</span><span class="p">,</span> <span class="n">length</span> <span class="o">-</span> <span class="mi">4</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">length</span> <span class="o">-</span> <span class="mi">4</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="o">&gt;</span>
<a name="rest_code_16c87aa06c274967be5d3c250da7f9af-19"></a>            <span class="o">&gt;</span>
<a name="rest_code_16c87aa06c274967be5d3c250da7f9af-20"></a>            <span class="p">,</span> <span class="n">dll</span><span class="o">::</span><span class="n">group_layer</span><span class="o">&lt;</span>
<a name="rest_code_16c87aa06c274967be5d3c250da7f9af-21"></a>                  <span class="n">dll</span><span class="o">::</span><span class="n">conv_layer</span><span class="o">&lt;</span><span class="mi">1</span><span class="p">,</span> <span class="n">length</span><span class="p">,</span> <span class="n">embedding</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">embedding</span><span class="o">&gt;</span>
<a name="rest_code_16c87aa06c274967be5d3c250da7f9af-22"></a>                <span class="p">,</span> <span class="n">dll</span><span class="o">::</span><span class="n">mp_2d_layer</span><span class="o">&lt;</span><span class="mi">16</span><span class="p">,</span> <span class="n">length</span> <span class="o">-</span> <span class="mi">5</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">length</span> <span class="o">-</span> <span class="mi">5</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="o">&gt;</span>
<a name="rest_code_16c87aa06c274967be5d3c250da7f9af-23"></a>            <span class="o">&gt;</span>
<a name="rest_code_16c87aa06c274967be5d3c250da7f9af-24"></a>        <span class="o">&gt;</span>
<a name="rest_code_16c87aa06c274967be5d3c250da7f9af-25"></a>
<a name="rest_code_16c87aa06c274967be5d3c250da7f9af-26"></a>        <span class="c1">// The final softmax layer</span>
<a name="rest_code_16c87aa06c274967be5d3c250da7f9af-27"></a>        <span class="p">,</span> <span class="n">dll</span><span class="o">::</span><span class="n">dense_layer</span><span class="o">&lt;</span><span class="mi">48</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">dll</span><span class="o">::</span><span class="n">softmax</span><span class="o">&gt;</span>
<a name="rest_code_16c87aa06c274967be5d3c250da7f9af-28"></a>    <span class="o">&gt;</span>
<a name="rest_code_16c87aa06c274967be5d3c250da7f9af-29"></a>    <span class="p">,</span> <span class="n">dll</span><span class="o">::</span><span class="n">updater</span><span class="o">&lt;</span><span class="n">dll</span><span class="o">::</span><span class="n">updater_type</span><span class="o">::</span><span class="n">NADAM</span><span class="o">&gt;</span>     <span class="c1">// Nesterov Adam (NADAM)</span>
<a name="rest_code_16c87aa06c274967be5d3c250da7f9af-30"></a>    <span class="p">,</span> <span class="n">dll</span><span class="o">::</span><span class="n">batch_size</span><span class="o">&lt;</span><span class="mi">50</span><span class="o">&gt;</span>                        <span class="c1">// The mini-batch size</span>
<a name="rest_code_16c87aa06c274967be5d3c250da7f9af-31"></a>    <span class="p">,</span> <span class="n">dll</span><span class="o">::</span><span class="n">shuffle</span>                               <span class="c1">// Shuffle before each epoch</span>
<a name="rest_code_16c87aa06c274967be5d3c250da7f9af-32"></a><span class="o">&gt;::</span><span class="n">network_t</span><span class="p">;</span>
<a name="rest_code_16c87aa06c274967be5d3c250da7f9af-33"></a>
<a name="rest_code_16c87aa06c274967be5d3c250da7f9af-34"></a><span class="k">auto</span> <span class="n">net</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">make_unique</span><span class="o">&lt;</span><span class="n">embedding_network_t</span><span class="o">&gt;</span><span class="p">();</span>
<a name="rest_code_16c87aa06c274967be5d3c250da7f9af-35"></a>
<a name="rest_code_16c87aa06c274967be5d3c250da7f9af-36"></a><span class="c1">// Display the network and dataset</span>
<a name="rest_code_16c87aa06c274967be5d3c250da7f9af-37"></a><span class="n">net</span><span class="o">-&gt;</span><span class="n">display</span><span class="p">();</span>
<a name="rest_code_16c87aa06c274967be5d3c250da7f9af-38"></a>
<a name="rest_code_16c87aa06c274967be5d3c250da7f9af-39"></a><span class="c1">// Train the network for performance sake</span>
<a name="rest_code_16c87aa06c274967be5d3c250da7f9af-40"></a><span class="n">net</span><span class="o">-&gt;</span><span class="n">fine_tune</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="mi">50</span><span class="p">);</span>
<a name="rest_code_16c87aa06c274967be5d3c250da7f9af-41"></a>
<a name="rest_code_16c87aa06c274967be5d3c250da7f9af-42"></a><span class="c1">// Test the network on train set</span>
<a name="rest_code_16c87aa06c274967be5d3c250da7f9af-43"></a><span class="n">net</span><span class="o">-&gt;</span><span class="n">evaluate</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">labels</span><span class="p">);</span>
</pre>
<p>The network starts with an embedding layer. The embedding is then passed to
three convolutional layers with different filter sizes, each followed by
a pooling layer. The outputs of the three layers are merged at the end of the
merge layer. Finally, a softmax layer is used for classification.</p>
<p>This kind of model can be very powerful and is used regularly. These new
features make for a much larger variety of models that can be build with the DLL
library.</p>
<p>The full code with the dataset generation can be found online:
<a class="reference external" href="https://github.com/wichtounet/dll/blob/master/examples/src/char_cnn.cpp">char_cnn.cpp</a></p>
<p>The next feature I want to focus on is recurrent neural networks. I'll probably
try a single RNN layer first and then upgrade to multi-layers and LSTM and maybe
GRU.</p>
</div>
        </div>
            
        
    <a href="posts/2017/10/dll-new-features-embeddings-and-merge-layers.html#disqus_thread" data-disqus-identifier="cache/posts/2017/10/dll-new-features-embeddings-and-merge-layers.html">Comments</a>


        </article><article class="postbox h-entry post-text"><h1 class="p-name">
<a href="posts/2017/10/i-successfully-defended-my-phd.html" class="u-url">I successfully defended my Ph.D.</a>
        <br><small>  
             Posted: <time class="published dt-published" datetime="2017-10-15T17:16:29+02:00">2017-10-15 17:16</time></small>
</h1>
        <hr>
<div class="p-summary">
        <div>
<p>I'm happy to announce that I've successfully defended my thesis "Deep Learning
Features for Image Processing". After four years, I've defended it officially in
front of the thesis committed last Friday and then again two days ago I've
successfully publicly defended in front of my friends, family and colleagues.</p>
<p>I'm now a "Doctor of Philosophy in Computer Science :)</p>
<p>I will update my thesis with the last comments in November and send the final
version to the university. At which point, I'll publish it on this website as
well.</p>
</div>
        </div>
            
        
    <a href="posts/2017/10/i-successfully-defended-my-phd.html#disqus_thread" data-disqus-identifier="cache/posts/2017/10/i-successfully-defended-my-phd.html">Comments</a>


        </article><article class="postbox h-entry post-text"><h1 class="p-name">
<a href="posts/2017/10/budgetwarrior-track-assets-portfolio-savings-rates-auto-completion.html" class="u-url">Budgetwarrior: Track assets and portfolio, savings rates and auto-completion</a>
        <br><small>  
             Posted: <time class="published dt-published" datetime="2017-10-12T19:40:14+02:00">2017-10-12 19:40</time></small>
</h1>
        <hr>
<div class="p-summary">
        <div>
<p>This last month, I've been reading quite a few blogs about personal finance and
I've decided to integrate more features into budgetwarrior. This post is about
three new features that I've integrated. It's not yet a new release, so if you
want to test this version, you'll have to compile it from the <em>master</em> branch on
Git.</p>
<p>As it was last time, the values on my screenshots have all been randomized.</p>
<p>If you have several assets with different distributions, I believe it is a great
value to have them all shown at the same time. Especially if you want to change
the distribution of your portfolio or if you plan big changes in it.</p>
<div class="section" id="track-assets">
<h2>Track assets</h2>
<p>The first feature I've added is a feature to precisely track each of your assets
independently. And you can also track the allocation of your portfolio in terms
of stocks, bonds and cash. The tool also lets you set the desired distribution
of your assets and will compute the difference that you should make in order to
comply to your desired distribution.</p>
<p>First, you need to define all your asset classes (your accounts, funds, and
stocks, ...) and their distribution with <code>budget asset add</code>. It also
supports to set a currency. The default currency is now CHF, but you can set it
in the configuration file, for instance <code>default_currency=USD</code>. You can
see your assets using <code>budget asset</code>:</p>
<img alt="View of your assets" src="images/budgetwarrior_assets.png"><p>You can then set the value of your assets using <code>budget asset value add</code>.
The system will save all the values of your assets. For now, only the last value
is used in the application to display. In the future, I plan to add new reports
for evolution of the portfolio over time. You can see your current net worth
with the <code>budget asset value</code>:</p>
<img alt="View of your portfolio" src="images/budgetwarrior_asset_values.png"><p>The different currencies will all be converted to the default currency.</p>
</div>
<div class="section" id="savings-rate">
<h2>Savings rate</h2>
<p>The second change I did is to compute the savings rate of each month and year.
The savings rate is simply the portion of your income that you are able to save
each month. The savings rate for a year is simple the average of the savings
rate of each month.</p>
<p>The savings rate of the month can be seen with <code>budget overview month</code>:</p>
<img alt="Savings rate of the month" src="images/budgetwarrior_savings_rate.png"><p>The saving rates of each month can also be seen in the overview of the year with
<code>budget overview year</code>:</p>
<img alt="Savings rate of the year" src="images/budgetwarrior_savings_rate_year.png"><p>This shows the savings rate of each month, the average of the year and the
average of the current year up to the current month.</p>
<p>The savings rate is a very important metric of your budget. In my case, it's
currently way too low and made me realize I really need to save more. Any
savings rate below 10% is too low. There are no rule as too much it should be,
but I'd like to augment mine to at least 20% next year.</p>
</div>
<div class="section" id="auto-completion">
<h2>Auto-completion</h2>
<p>The last feature is mostly some quality-of-life improvement. Some of the inputs
in the console can now be completed. It's not really auto-completion per se, but
you can cycle through the list of possible values using the UP and DOWN.</p>
<p>This makes it much easier to set some values such as asset names (in
<code>budget asset value add</code> for instance), account names and objective types
and sources. I'm trying to make the input of values easier.</p>
</div>
<div class="section" id="conclusion">
<h2>Conclusion</h2>
<p>I don't know exactly what else will be integrated in this feature, but I may
already improve some visualization for asset values. If I learn something new
about personal finance that I may integrate in the tool, I'll do it as well.</p>
<p>If you are interested by the sources or want to install this version,
you can download them on Github:
<a class="reference external" href="https://github.com/wichtounet/budgetwarrior">budgetwarrior</a>.</p>
<p>The new features are in the <em>master</em> branch.</p>
<p>If you have a suggestion for a new features or you found a bug, please post an
issue on Github, I'd be glad to help you.</p>
<p>If you have any comment, don't hesitate to contact me, either by letting a
comment on this post or by email.</p>
</div>
</div>
        </div>
            
        
    <a href="posts/2017/10/budgetwarrior-track-assets-portfolio-savings-rates-auto-completion.html#disqus_thread" data-disqus-identifier="cache/posts/2017/10/budgetwarrior-track-assets-portfolio-savings-rates-auto-completion.html">Comments</a>


        </article><article class="postbox h-entry post-text"><h1 class="p-name">
<a href="posts/2017/10/deep-learning-library-10-fast-neural-network-library.html" class="u-url">Deep Learning Library 1.0 - Fast Neural Network Library</a>
        <br><small>  
             Posted: <time class="published dt-published" datetime="2017-10-07T15:42:16+02:00">2017-10-07 15:42</time></small>
</h1>
        <hr>
<div class="p-summary">
        <div>
<img alt="DLL Logo" class="align-center" src="images/dll_logo.png"><p>I'm very happy to announce the release of the first version of Deep Learning
Library (DLL) 1.0. DLL is a neural network library with a focus on speed and
ease of use.</p>
<p>I started working on this library about 4 years ago for my Ph.D. thesis.
I needed a good library to train and use Restricted Boltzmann Machines (RBMs)
and at this time there was no good support for it. Therefore, I decided to write
my own. It now has very complete support for the RBM and the Convolutional RBM
(CRBM) models. Stacks of RBMs (or Deep Belief Networks (DBNs)) can be pretrained
using Contrastive Divergence and then either fine-tuned with mini-batch gradient
descent or Conjugate Gradient or used as a feature extractor. Over the years,
the library has been extended to handle Artificial Neural Networks (ANNs) and
Convolutional Neural Networks (CNNs). The network is also able to train regular
auto-encoders. Several advanced layers such as Dropout or Batch Normalization
are also available as well as adaptive learning rates techniques such as
Adadelta and Adam. The library also has integrated support for a few datasets:
MNIST, CIFAR-10 and ImageNet.</p>
<p>This library can be used using a C++ interface. The library is fully
header-only. It requires a C++14 compiler, which means a minimum of clang 3.9 or
GCC 6.3.</p>
<p>In this post, I'm going to present a few examples on using the library and give
some information about the performance of the library and the roadmap for the
project.</p>
<p class="more"><a href="posts/2017/10/deep-learning-library-10-fast-neural-network-library.html">Read more…</a></p>
</div>
        </div>
            
        
    <a href="posts/2017/10/deep-learning-library-10-fast-neural-network-library.html#disqus_thread" data-disqus-identifier="cache/posts/2017/10/deep-learning-library-10-fast-neural-network-library.html">Comments</a>


        </article><article class="postbox h-entry post-text"><h1 class="p-name">
<a href="posts/2017/10/expression-templates-library-etl-1-2-complete-gpu-support.html" class="u-url">Expression Templates Library (ETL) 1.2 - Complete GPU support</a>
        <br><small>  
             Posted: <time class="published dt-published" datetime="2017-10-02T10:49:02+02:00">2017-10-02 10:49</time></small>
</h1>
        <hr>
<div class="p-summary">
        <div>
<img alt="ETL Logo" class="align-center" src="images/logo.png"><p>I'm happy to announce the version 1.2 of my Expression Templates Library (ETL):
ETL 1.2, two months after <a class="reference external" href="https://baptiste-wicht.com/posts/2017/08/expression-templates-library-etl-11.html">I released the version 1.1</a>.
This version features much better GPU Support, a few new features and a lot of
changes in the internal code.</p>
<div class="section" id="gpu-support">
<h2>GPU Support</h2>
<p>Before, only algorithms such as 4D convolution or matrix-matrix multiplication
were computed in the GPU and lots of operations were causing copies between CPU
and GPU version. Now, the support for basic operations has also been completed
and therefore, expressions like this:</p>
<pre class="code cpp"><a name="rest_code_900e9dfd9c8341c0a19b8b99df952e1d-1"></a><span class="n">C</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="mf">2.0</span> <span class="o">*</span> <span class="p">(</span><span class="n">A</span> <span class="o">+</span> <span class="n">B</span><span class="p">))</span> <span class="o">/</span> <span class="n">sum</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
</pre>
<p>Can be computed entirely on GPU.</p>
<p>Each matrix and vector containers have a secondary GPU memory space.  During the
execution, the status of both memory spaces is being managed and when necessary,
copies are made between two spaces. In the best case, there should only be
initial copies to the GPU and then everything should be done on the GPU. I've
also considered using Unified Memory in place of this system, but this is
a problem for fast matrix and I'd rather not have two different systems.</p>
<p>If you have an expression such as <code>c = a + b * 2</code>, it can be entirely computed
on GPU, however, it will be computed in two GPU operations such as:</p>
<pre class="code cpp"><a name="rest_code_abcf1b9ac1d240188a459fc4e9277dd4-1"></a><span class="n">t1</span> <span class="o">=</span> <span class="n">b</span> <span class="o">*</span> <span class="mi">2</span>
<a name="rest_code_abcf1b9ac1d240188a459fc4e9277dd4-2"></a><span class="n">c</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">t1</span>
</pre>
<p>This is not perfect in terms of performance but this will be done without any
copies between CPU and GPU memory. I plan to improve this system with a bit more
complex operations to avoid too many GPU operations, but there will always be
more operations than in CPU where this can easily be done in one go.</p>
<p>There are a few expressions that are not computable on the GPU, such as random
generations. A few transformations are also not fully compatible with GPU.
Moreover, if you access an element with operators <code>[]</code> or <code>()</code>, this
will invalidate the GPU memory and force an update to the CPU memory.</p>
<p>GPU operations are not implemented directly in ETL, there are coming from
various libraries. ETL is using NVIDIA CUDNN, CUFFT and CUDNN for most
algorithms. Moreover, for other operations, I've implemented a libraries with
simple GPU operations: ETL-GPU-BLAS (EGBLAS). You can have a look at
<a class="reference external" href="https://github.com/wichtounet/etl-gpu-blas">egblas</a> if you are interested.</p>
<p>My Deep Learning Library (DLL) project is based on ETL and its performances are
mostly dependent on ETL's performances. Now that ETL fully supports GPU, the
GPU performance of DLL is much improved. You may remember a few weeks ago
I posted <a class="reference external" href="https://baptiste-wicht.com/posts/2017/08/dll-blazing-fast-neural-network-library.html">very high CPU performance of DLL</a>.
Now, I've run again the tests to see the GPU performance with DLL. Here is the
performance for training a small CNN on the MNIST data set:</p>
<img alt="Performances for training a Convolutional Neural Network on MNIST" class="align-center" src="images/etl_12_dll_gpu_mnist.png"><p>As you can see, the performances on GPU are now excellent. DLL's performances
are on par with Tensorflow and Keras!</p>
<p>The next results are for training a much larger CNN on ImageNet, with the time
necessary to train a single batch:</p>
<img alt="Performances for training a Convolutional Neural Network on Imagenet" class="align-center" src="images/etl_12_dll_gpu_imagenet.png"><p>Again, using the new version of ETL inside DLL has led to excellent performance.
The framework is again on par with TensorFlow and Keras and faster than all the
other frameworks. The large difference between DLL and Tensorflow and Keras is
due to the inefficiency of reading the dataset in the two frameworks, so the
performance of the three framework themselves are about the same.</p>
</div>
<div class="section" id="other-changes">
<h2>Other Changes</h2>
<p>The library also has a few other new features. Logarithms of base 2 and base 10
are now supported in complement to the base e that was already available before.
Categorical Cross Entropy (CCE) computation is also available now, the CCE loss
and error can be computed for one or many samples. Convolutions have also been
improved in that you can use mixed types in both the image and the kernel and
different storage order as well. Nevertheless, the most optimized version
remains the version with the same storage order and the same data type.</p>
<p>I've also made a major change in the way implementations are selected for each
operation. The tests and the benchmark are using a system to force the selection
of an algorithm. This system is now disabled by default. This makes the
compilation much faster by default. Since it's not necessary in most cases, this
will help regular use cases of the library by compiling much faster.</p>
<p>Overall, the support for complex numbers has been improved in ETL. There are
more routines that are supported and <code>etl::complex</code> is better supported
throughout the code. I'll still work on this in the future to make it totally
complete.</p>
<p>The internal code also has a few new changes. First, all traits have been
rewritten to use variable templates instead of struct traits. This makes the
code much nicer in my opinion. Moreover, I've started experimenting with C++17
<code>if constexpr</code>. Most of the if conditions that can be transformed to if
constexpr have been annotated with comments that I can quickly enable or disable
so that I can test the impact of C++17, especially on compilation time.</p>
<p>Finally, a few bugs have been fixed. ETL is now working better with parallel
BLAS library. There should not be issues with double parallelization in ETL and
BLAS. There was a slight bug in the Column-Major matrix-matrix multiplication
kernel. Binary operations with different types in the left and right hand sides
was also problematic with vectorization. The last bug was about GPU status in
case ETL containers were moved.</p>
</div>
<div class="section" id="what-s-next">
<h2>What's next ?</h2>
<p>I don't yet know exactly on which features I'm going to focus for the next
version of ETL. I plan to focus a bit more in the near future on Deep Learning
Library (DLL) for which I should release the version 1.0 soon. I also plan to
start support for Recurrent Neural Networks on it, so that will take me quite
some time.</p>
<p>Nevertheless, I'm still planning to consider the switch to C++17, since it is
<a class="reference external" href="https://baptiste-wicht.com/posts/2017/09/how-i-made-deep-learning-library-38-faster-to-compile-optimization-and-cpp17-if-constexpr.html">a bit faster to compile ETL with if constexpr</a>. The next version of ETL will also probably have GPU-support for
integers, at least in the cases that depend on the etl-gpu-blas library, which
is the standard operators. I also plan to improve the support for complex
numbers, especially in terms of performance and tests. Hopefully, I will have also time (and motivation)
to start working on  the sparse capabilities of ETL. It really needs much more
unit tests and the performance should be improved as well.</p>
</div>
<div class="section" id="download-etl">
<h2>Download ETL</h2>
<p>You can download ETL <a class="reference external" href="https://github.com/wichtounet/etl">on Github</a>. If you
only interested in the 1.2 version, you can look at the
<a class="reference external" href="https://github.com/wichtounet/etl/releases">Releases pages</a> or clone the tag
1.2. There are several branches:</p>
<ul class="simple">
<li>
<em>master</em> Is the eternal development branch, may not always be stable</li>
<li>
<em>stable</em> Is a branch always pointing to the last tag, no development here</li>
</ul>
<p>For the future release, there always will tags pointing to the corresponding
commits. You can also have access to previous releases on Github or via the
release tags.</p>
<p>The documentation is still a bit sparse. There are a few examples and the Wiki,
but there still is work to be done. If you have questions on how to use or
configure the library, please don't hesitate.</p>
<p>Don't hesitate to comment this post if you have any comment on this library or
any question. You can also open an Issue on Github if you have a problem using
this library or propose a Pull Request if you have any contribution you'd like
to make to the library.</p>
<p>Hope this may be useful to some of you :)</p>
</div>
</div>
        </div>
            
        
    <a href="posts/2017/10/expression-templates-library-etl-1-2-complete-gpu-support.html#disqus_thread" data-disqus-identifier="cache/posts/2017/10/expression-templates-library-etl-1-2-complete-gpu-support.html">Comments</a>


        </article><article class="postbox h-entry post-text"><h1 class="p-name">
<a href="posts/2017/09/cpp11-performance-tip-update-when-to-use-std-pow.html" class="u-url">C++11 Performance tip: Update on when to use std::pow ?</a>
        <br><small>  
             Posted: <time class="published dt-published" datetime="2017-09-22T11:21:07+02:00">2017-09-22 11:21</time></small>
</h1>
        <hr>
<div class="p-summary">
        <div>
<p>A few days ago, I published a post comparing the
<a class="reference external" href="https://baptiste-wicht.com/posts/2017/09/cpp11-performance-tip-when-to-use-std-pow.html">performance of std::pow against direct multiplications</a>. When not compiling with -ffast-math, direct multiplication was significantly faster than <code>std::pow</code>, around two orders of magnitude faster when comparing <code>x * x * x</code> and <code>code:std::pow(x, 3)</code>.
One comment that I've got was to test for which <code>n</code> is
<code>code:std::pow(x, n)</code> becoming faster than multiplying in a loop. Since
std::pow is using a special algorithm to perform the computation rather than be
simply loop-based multiplications, there may be a point after which it's more interesting to use the
algorithm rather than a loop. So I decided to do the tests. You can also find
the result in the original article, which I've updated.</p>
<p>First, our pow function:</p>
<pre class="code c++"><a name="rest_code_37b07bb7e42843bcacd05fc3087f3ab1-1"></a><span class="kt">double</span> <span class="nf">my_pow</span><span class="p">(</span><span class="kt">double</span> <span class="n">x</span><span class="p">,</span> <span class="kt">size_t</span> <span class="n">n</span><span class="p">){</span>
<a name="rest_code_37b07bb7e42843bcacd05fc3087f3ab1-2"></a>    <span class="kt">double</span> <span class="n">r</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">;</span>
<a name="rest_code_37b07bb7e42843bcacd05fc3087f3ab1-3"></a>
<a name="rest_code_37b07bb7e42843bcacd05fc3087f3ab1-4"></a>    <span class="k">while</span><span class="p">(</span><span class="n">n</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">){</span>
<a name="rest_code_37b07bb7e42843bcacd05fc3087f3ab1-5"></a>        <span class="n">r</span> <span class="o">*=</span> <span class="n">x</span><span class="p">;</span>
<a name="rest_code_37b07bb7e42843bcacd05fc3087f3ab1-6"></a>        <span class="o">--</span><span class="n">n</span><span class="p">;</span>
<a name="rest_code_37b07bb7e42843bcacd05fc3087f3ab1-7"></a>    <span class="p">}</span>
<a name="rest_code_37b07bb7e42843bcacd05fc3087f3ab1-8"></a>
<a name="rest_code_37b07bb7e42843bcacd05fc3087f3ab1-9"></a>    <span class="k">return</span> <span class="n">r</span><span class="p">;</span>
<a name="rest_code_37b07bb7e42843bcacd05fc3087f3ab1-10"></a><span class="p">}</span>
</pre>
<p>And now, let's see the performance. I've compiled my benchmark with GCC 4.9.3
and running on my old Sandy Bridge processor. Here are the results for 1000
calls to each functions:</p>
<div id="graph_std_pow_my_pow_1" style="width: 700px; height: 400px;"></div>
<p>We can see that between <code>n=100</code> and <code>n=110</code>, <code>std::pow(x, n)</code>
starts to be faster than <code>my_pow(x, n)</code>. At this point, you should only
use <code>std::pow(x, n)</code>.  Interestingly too, the time for <code>std::pow(x,
n)</code> is decreasing. Let's see how is the performance with higher range of
<code>n</code>:</p>
<div id="graph_std_pow_my_pow_2" style="width: 700px; height: 400px;"></div>
<p>We can see that the pow function time still remains stable while our loop-based
pow function still increases linearly. At <code>n=1000</code>, <code>std::pow</code> is
one order of magnitude faster than <code>my_pow</code>.</p>
<p>Overall, if you do not care much about extreme accuracy, you may consider using
you own pow function for small-ish (integer) <code>n</code> values. After
<code>n=100</code>, it becomes more interesting to use <code>std::pow</code>.</p>
<p>If you want more results on the subject, you take a look at the
<a class="reference external" href="https://baptiste-wicht.com/posts/2017/09/cpp11-performance-tip-when-to-use-std-pow.html">original article</a>.</p>
<p>If you are interested in the code of this benchmark, it's available online:
<a class="reference external" href="https://github.com/wichtounet/articles/blob/master/src/bench_pow_my_pow.cpp">bench_pow_my_pow.cpp</a></p>
<script type="text/javascript" src="https://www.google.com/jsapi"></script><script type="text/javascript">google.load('visualization', '1.0', {'packages':['corechart']});</script><script type="text/javascript">
function draw_graph_pow_my_pow_1(){
var data = google.visualization.arrayToDataTable([
['n', 'my_pow(x, n)', 'std::pow(x, n)'],
['10',   2,     127],
['20',   17,     123],
['30',   26,     127],
['40',   36,     123],
['50',   43,     123],
['60',   55,     123],
['70',   72,     123],
['80',   85,     123],
['90',   102,    126],
['100',  114,    125],
['110',  131,    115],
['120',  144,    111],
['130',  165,    111],
['140',  173,    108],
['150',  189,    107],
['160',  202,    112],
['170',  219,    106],
['180',  232,    105],
['190',  249,    108],
['200',  261,    105],
]);
var graph = new google.visualization.LineChart(document.getElementById('graph_std_pow_my_pow_1'));
var options = {curveType: "function",title: "std::pow(x, 2) (float)",animation: {duration:1200, easing:"in"},width: 700, height: 400,hAxis: {title:"Number of elements", slantedText:true},vAxis: {viewWindow: {min:0}, title:"us"}};
graph.draw(data, options);
}
function draw_graph_pow_my_pow_2(){
var data = google.visualization.arrayToDataTable([
['n', 'my_pow(x, n)', 'std::pow(x, n)'],
['100',  114,    125],
['200',  261,    105],
['300',  410,    104],
['400',  558,    104],
['500',  708,    104],
['600',  855,    104],
['700',  1002,   104],
['800',  1148,   104],
['900',  1300,   104],
['1000', 1442,   104],
]);
var graph = new google.visualization.LineChart(document.getElementById('graph_std_pow_my_pow_2'));
var options = {curveType: "function",title: "std::pow(x, 2) (float)",animation: {duration:1200, easing:"in"},width: 700, height: 400,hAxis: {title:"Number of elements", slantedText:true},vAxis: {viewWindow: {min:0}, title:"us"}};
graph.draw(data, options);
}
function draw_all(){
draw_graph_pow_my_pow_1();
draw_graph_pow_my_pow_2();
}
google.setOnLoadCallback(draw_all);
</script>
</div>
        </div>
            
        
    <a href="posts/2017/09/cpp11-performance-tip-update-when-to-use-std-pow.html#disqus_thread" data-disqus-identifier="cache/posts/2017/09/cpp11-performance-tip-update-when-to-use-std-pow.html">Comments</a>


        </article><nav class="postindexpager"><ul class="pager">
<li class="next">
                <a href="index-32.html" rel="next">Older posts</a>
            </li>
        </ul></nav><script>var disqus_shortname="blogwichtounet";(function(){var a=document.createElement("script");a.async=true;a.src="https://"+disqus_shortname+".disqus.com/count.js";(document.getElementsByTagName("head")[0]||document.getElementsByTagName("body")[0]).appendChild(a)}());</script>
</div> <!-- col -->
    </div>
<!-- row  -->
</div>
<!-- container-fluid -->

<!-- End of Menubar -->

<!-- Footer -->

<footer>
    Contents © 2017         <a href="mailto:baptistewicht@gmail.com">Baptiste Wicht</a> - Powered by         <a href="http://getnikola.com" rel="nofollow">Nikola</a>         - License: 
<a rel="license" href="http://creativecommons.org/licenses/by/4.0/"><img alt="Creative Commons License" style="padding-left:5px;border-width:0" src="assets/img/cc.png"></a>
        <ul class="footer_inline_ul"></ul></footer><!-- Late loading stuff  --><script src="assets/js/all-nocdn.js"></script><script type="text/javascript">
      $(document).ready(function() {
        $.getJSON("/assets/js/tx3_tag_cloud.json", function(data){
            var items = [];
            $.each(data, function(key, val){
                var count = val[0];
                var url = val[1];
                var posts = val[2];

                if(count > 9){
                    items.push("<li data-weight='" + count + "'><a href='" + url + "'>" + key + "</a></li>");
                }
            });

            $("<ul/>", {
                "id": "tag_cloud_left",
                html: items.join("")
            }).appendTo("#tag_cloud_left_container");

            $("#tag_cloud_left").tx3TagCloud({
                multiplier: 0.8 // default multiplier is "1"
            });
        });
      });
    </script><!-- Google platform JS -->
</body>
</html>
